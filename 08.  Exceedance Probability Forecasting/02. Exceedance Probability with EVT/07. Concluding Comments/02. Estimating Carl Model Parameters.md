## Estimativa de Parâmetros do Modelo CARL com Máxima Verossimilhança Restrita Baseada na Verossimilhança AL

### Introdução
Este capítulo explora aprimoramentos na estimativa de parâmetros para modelos **Conditional Autoregressive Logit (CARL)**, especificamente focando no uso de uma abordagem de **máxima verossimilhança restrita** baseada na **verossimilhança Asymmetric Laplace (AL)** [^3]. Como discutido anteriormente, a modelagem direta da probabilidade de excedência $p_t$ é um aspecto interessante em comparação com as abordagens tradicionais que requerem suposições distribucionais [^3].  Este capítulo detalha como a verossimilhança AL pode ser usada para melhorar a precisão na estimativa dos parâmetros do modelo CARL e avalia a competitividade do modelo **CARL-AsymVol** em relação aos *benchmarks* **GARCH** e **simulação histórica** em termos do *Brier score* [^1].

### Conceitos Fundamentais

#### Verossimilhança Bernoulli vs. Verossimilhança Asymmetric Laplace (AL)
A abordagem padrão para estimar os parâmetros em modelos para uma variável de resposta binária é **maximizar a verossimilhança de Bernoulli** [^3]. No contexto da modelagem de probabilidades de excedência, isso envolve modelar a probabilidade $p_t$ de $y_t$ cair abaixo de um limiar escolhido $Q$, com a densidade de Bernoulli especificada como:
$$\nf(y_t) = p_t^{I(y_t \le Q)}(1-p_t)^{(1-I(y_t \le Q))}\n$$
No entanto, essa abordagem pode ser considerada ineficiente porque não captura a extensão em que a variável $y_t$ está acima ou abaixo do limiar $Q$ [^3]. Para superar essa limitação, a **verossimilhança Asymmetric Laplace (AL)** é introduzida para capturar o grau em que uma observação excede o limiar [^3]. A maximização da verossimilhança AL tem sido demonstrada como equivalente à **regressão quantílica**, envolvendo um quantil variável no tempo e um nível de probabilidade constante [^3].

#### Máxima Verossimilhança Restrita Baseada na Distribuição Asymmetric Laplace (AL)
A regressão quantílica é apresentada na expressão (9) como:
$$\n\min_{Q_t} \sum_{t=1}^n \tau |y_t - Q_t|(\rho - I(y_t \le Q_t))\n$$
onde $Q_t$ é o quantil de uma variável $y_t$ correspondente a um nível de probabilidade escolhido $\rho$, com base em $n$ observações [^7].  Em vez de um quantil variável no tempo, o objetivo é a probabilidade variável no tempo $p_t$ de excedência sobre um limiar constante $Q$ [^7].  A minimização adaptada é dada por:
$$\n\min_{Q} \sum_{t=1}^n \tau |y_t - Q|(p_t - I(y_t \le Q))\n$$
A densidade AL é dada por:
$$\nf(y_t) = \frac{\rho(1-\rho)}{\sigma} \exp\left(-\frac{(y_t - Q_t)(\rho - I(y_t \le Q_t))}{\sigma}\right)\n$$
onde $\rho$ é o nível de probabilidade de interesse, $\sigma$ é um parâmetro de escala e $Q_t$ é a localização variável no tempo da densidade AL [^8].
Para modelar a probabilidade de excedência, a densidade AL é reescrita para ter uma probabilidade variável no tempo $p_t$ e um parâmetro de localização fixo $Q$, com $p_t$ representando a probabilidade de $y_t$ cair abaixo de $Q$ [^8]:
$$\nf(y_t) = \frac{p_t(1-p_t)}{\sigma_t} \exp\left(-\frac{(y_t - Q)(p_t - I(y_t \le Q))}{\sigma_t}\right)\n$$
Com retornos de ativos $y_t$ exibindo heteroscedasticidade, $p_t$ varia ao longo do tempo [^9].  A escala $\sigma$ também é permitida variar no tempo, adaptando o estimador de máxima verossimilhança da escala de uma densidade AL estática [^9]:
$$\n\sigma_t = \frac{p_t(1-p_t)|\mu - Q|}{(1-2p_t)}\n$$
onde $\mu$ é a média das observações na amostra [^9]. Para garantir estimativas consistentes para a probabilidade $p_t$, a maximização da verossimilhança é realizada com a expressão (12) como uma restrição [^9]. Essa restrição é imposta subtraindo, da soma das verossimilhanças logarítmicas, um termo de penalidade igual a $10^5$ multiplicado pelo quadrado da diferença entre os lados esquerdo e direito da expressão (12) [^9]. A verossimilhança logarítmica penalizada resultante é dada na expressão (16) [^9]:
$$\n\sum_{t=1}^n \left[\ln(p_t)I(y_t \le Q) + \ln(1-p_t)(1-I(y_t \le Q))\right] - 10^5 \left[\frac{1}{n}\sum_{t=1}^n I(y_t \le Q) - \frac{1}{n}\sum_{t=1}^n p_t\right]^2\n$$
onde a primeira parte é a soma das verossimilhanças logarítmicas, e a segunda parte é o termo de penalidade [^9]. Sob certas condições de regularidade, os estimadores de parâmetros de verossimilhança penalizada são assintoticamente consistentes e gaussianos [^9].

#### Modelos CARL
Os modelos **CARL** são formulados para restringir a probabilidade $p_t$ a variar entre 0 e 0.5 para um limiar negativo e entre 0.5 e 1 para um limiar positivo, conforme mostrado na expressão (1) [^4, 5]:

$$\np_t = \frac{0.5}{1 + \exp(-x_t)} + 0.5I(Q > 0)\n$$

Onde $x_t$ é o logito de $(2p_t - I(Q>0))$. Vários modelos CARL diferem na especificação de $x_t$, que é o logito de (2pt-I(Q>0)) [^5]. O modelo **CARL-Ind** envolve o indicador defasado $I(y_{t-1}<Q)$, conforme demonstrado na expressão (2) [^5]:

$$\nx_t = a_0 + a_1I(y_{t-1}<Q) + \beta_1x_{t-1}\n$$

O modelo **CARL-AsymInd** inclui $I(y_{t-1}>-Q)$ para permitir uma resposta mais rápida à mudança na volatilidade [^5]:

$$\nx_t = a_0 + a_1I(y_{t-1}<Q) + a_2I(y_{t-1}>-Q) + \beta_1x_{t-1}\n$$
O modelo **CARL-Abs** contém o valor absoluto defasado do retorno como um proxy para a volatilidade, conforme demonstrado na expressão (3) [^5]:

$$\nx_t = a_0 + a_1|y_{t-1}| + \beta_1x_{t-1}\n$$
O modelo **CARL-AsymAbs** permite uma resposta assimétrica de $x_t$ às mudanças no retorno absoluto defasado, conforme demonstrado na expressão (4) [^5]:

$$\nx_t = a_0 + a_1|y_{t-1}|I(y_{t-1} \ge 0) + a_2|y_{t-1}|I(y_{t-1} < 0) + \beta_1x_{t-1}\n$$
O modelo **CARL-Vol** utiliza uma função logística com o termo logito linearmente relacionado à variância $h_t$ [^6]:
$$\nx_t = \phi_0 + \phi_1h_t\n$$
$$\nh_t = a_0 + \alpha(y_{t-1} - \mu)^2 + \beta_1h_{t-1}\n$$
O modelo **CARL-AsymVol** utiliza a estrutura do modelo GJRGARCH(1,1) para dar o efeito de alavancagem, conforme demonstrado nas expressões (7) e (8) [^6]:

$$\nx_t = \phi_0 + \phi_1h_t\n$$
$$\nh_t = a_0 + \alpha_1I(y_{t-1} \ge 0)(y_{t-1} - \mu)^2 + \alpha_2I(y_{t-1} < 0)(y_{t-1} - \mu)^2 + \beta_1h_{t-1}\n$$

### Avaliação Empírica
A avaliação empírica envolveu o uso de retornos logarítmicos diários para os índices de ações FTSE 100, NIKKEI 225 e S&P 500 [^10]. Cada série consistiu em 3500 retornos logarítmicos diários [^10]. Os modelos foram avaliados para uma variedade de limiares baixos e altos, de diferentes sinais, incluindo -3%, -2%, -1%, 1%, 2% e 3% [^10]. Os primeiros 2500 pontos de dados foram usados para estimar os parâmetros do modelo, e as previsões fora da amostra foram produzidas para os próximos 250 períodos [^10]. Este processo foi repetido quatro vezes, resultando em um total de 1000 previsões de probabilidade fora da amostra [^10].

#### Brier Score
O desempenho preditivo dos modelos é avaliado usando o **Brier score**, que é definido como [^15]:
$$\n\text{Brier score} = \frac{1}{N} \sum_{t=n+1}^{n+N} (I(y_t \le Q) - p_t)^2\n$$
onde $p_t$ é a previsão de probabilidade para o evento de $y_t$ cair abaixo do limiar $Q$, $n$ é o tamanho da amostra de estimativa e $N$ é o número de períodos fora da amostra [^15]. Um Brier score mais baixo indica melhor precisão [^15].

#### Brier Skill Score
O **Brier skill score** é usado para comparar o Brier score de um modelo ao de um método de referência, que neste caso é a abordagem de simulação histórica baseada em 2500 observações [^16]. O Brier skill score é definido como [^16]:
$$\n\text{Brier skill score} = \left(1 - \frac{\sum_{t=n+1}^{n+N} (I(y_t \le Q) - p_t)^2}{\sum_{t=n+1}^{n+N} (I(y_t \le Q) - p_{reference})^2}\right) \times 100\n$$
Valores mais altos indicam precisão superior, e valores positivos indicam desempenho superior ao do método de referência [^16].

### Resultados

Os resultados empíricos indicaram que a estimativa dos parâmetros do modelo CARL usando a **verossimilhança AL restrita** forneceu uma precisão ligeiramente melhor em comparação com a verossimilhança de Bernoulli padrão [^1]. Além disso, o modelo **CARL-AsymVol** se mostrou muito competitivo em termos do Brier score em comparação com os *benchmarks* GARCH e simulação histórica [^1].

### Conclusão

Este capítulo demonstrou a eficácia do uso de uma abordagem de máxima verossimilhança restrita baseada na verossimilhança AL para estimar os parâmetros do modelo CARL [^1]. Os resultados empíricos destacaram a competitividade do modelo CARL-AsymVol em relação aos *benchmarks* GARCH e simulação histórica em termos do Brier score [^1]. Esses resultados fornecem *insights* valiosos para a modelagem de probabilidades de excedência e podem ter aplicações práticas no gerenciamento de risco financeiro [^2].
### Referências
[^1]: James W. Taylor and Keming Yu, "Using Autoregressive Logit Models to Forecast the Exceedance Probability for Financial Risk Management"
[^2]: Introduction, James W. Taylor and Keming Yu
[^3]: Parameter estimation for the CARL models, James W. Taylor and Keming Yu
[^4]: A new set of autoregressive models, James W. Taylor and Keming Yu
[^5]: Our various CARL models differ in the specification of x₁, James W. Taylor and Keming Yu
[^6]: logistic function with the logit term a linear function of hī, James W. Taylor and Keming Yu
[^7]: Constrained maximum likelihood based on the asymmetric Laplace distribution, James W. Taylor and Keming Yu
[^8]: In this paper, we propose a quasi-maximum likelihood based on an AL distribution to estimate models for the exceedance probability, James W. Taylor and Keming Yu
[^9]: Our proposal is to estimate a model for the probability p₁ of y₁ falling below a chosen threshold Q by maximizing the likelihood based on the AL density of expression (14), James W. Taylor and Keming Yu
[^10]: Empirical evaluation of exceedance probability forecasts, James W. Taylor and Keming Yu
[^15]: Out-of-sample evaluation, James W. Taylor and Keming Yu
[^16]: For each method, we calculated the Brier skill score, which is presented in expression (19), James W. Taylor and Keming Yu
<!-- END -->