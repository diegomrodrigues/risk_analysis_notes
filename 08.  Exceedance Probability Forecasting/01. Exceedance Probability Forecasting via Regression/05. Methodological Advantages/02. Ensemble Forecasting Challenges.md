## Capítulo 4: Limitações Computacionais e de Transparência em Estratégias de Previsão Baseadas em Ensembles

### Introdução

Como explorado na discussão sobre as vantagens metodológicas da abordagem proposta para a previsão de probabilidade de excedência [^14], certas características desejáveis, como a flexibilidade de limiar (*threshold flexibility*), podem ser teoricamente alcançadas através de diferentes estratégias. Uma dessas estratégias envolve o uso de **ensembles de modelos de previsão** [^15]. No entanto, a aplicação prática de métodos baseados em ensemble frequentemente encontra barreiras significativas. Este capítulo foca-se em duas das principais limitações que, conforme apontado no contexto da nossa discussão metodológica, muitas vezes inviabilizam a adoção generalizada destas estratégias: os **elevados custos computacionais** e a **falta de transparência** inerente a muitos modelos de ensemble [^2]. Analisaremos como estas limitações se manifestam, particularmente no contexto da previsão de probabilidade de excedência, utilizando exclusivamente as informações e os exemplos fornecidos no trabalho de referência.

### Conceitos Fundamentais

#### Custo Computacional Elevado

Uma estratégia de previsão baseada em ensemble, por definição, utiliza um conjunto $F$ composto por $M$ modelos individuais: $F = \{f_1, f_2, ..., f_M\}$ [^4]. A premissa fundamental é que a combinação das previsões de múltiplos modelos pode levar a um desempenho superior ou mais robusto do que um único modelo isolado. No entanto, esta abordagem multiplica intrinsecamente o esforço computacional.

Consideremos os exemplos de ensembles mencionados no estudo. Temos ensembles **homogêneos**, como o *Random Forest Regressor* (RFR), que é ele próprio um ensemble de árvores de decisão [^13], e ensembles **heterogêneos** (HRE), que são compostos por modelos base treinados com diferentes algoritmos de aprendizagem [^8]. O HRE exemplificado no estudo utilizou uma vasta gama de algoritmos, incluindo *Cubist*, *Bagging*, *Ridge*, *ElasticNet*, *LASSO*, *MARS*, *LGBM*, *ExtraTree*, *AdaBoost*, *RFR*, *PLS*, *PCR*, *KNN* e uma rede neural profunda (*NN*) [^9]. Além disso, múltiplas configurações de parâmetros foram aplicadas, resultando num número inicial de 50 modelos base [^10].

> O processo de construção de um ensemble HRE envolve não apenas treinar cada um destes modelos $f_k$, mas também potencialmente otimizar os seus hiperparâmetros e realizar uma seleção ou *trimming* dos modelos. No estudo, por exemplo, metade dos modelos com pior desempenho num conjunto de validação foi removida [^10], um processo que, embora possa melhorar o desempenho [^11], adiciona uma camada adicional de complexidade e custo computacional à fase de desenvolvimento do modelo.

A fase de inferência (previsão) também é computacionalmente intensiva. Para estimar a probabilidade de excedência $p_i$ num instante $i$ usando o método direto baseado em ensemble [^6], é necessário calcular a previsão de *cada um* dos $M$ membros do ensemble, $f_k(X_i, Z_i)$, e então computar a proporção daqueles que excedem o limiar $\tau$ [^5]:
$$
p_i = \frac{1}{M} \sum_{k=1}^{M} I(f_k(X_i, Z_i) \ge \tau)
$$
onde $I(\cdot)$ é a função indicadora. Executar $M$ modelos para cada ponto de previsão pode ser proibitivo em cenários que exigem previsões rápidas ou que lidam com grandes volumes de dados, como pode ser o caso da previsão de *Significant Wave Height* (SWH) em tempo real [^22]. Este requisito substancial de recursos computacionais constitui os "elevados custos computacionais" que frequentemente limitam a aplicação prática de ensembles [^2].

#### Falta de Transparência

A segunda limitação significativa dos ensembles é a sua **falta de transparência** ou interpretabilidade [^2]. Enquanto modelos individuais, como uma regressão linear ou uma única árvore de decisão, podem oferecer algum grau de interpretabilidade, compreender como uma combinação de dezenas ou centenas de modelos, possivelmente heterogêneos [^8], [^9], chega a uma previsão específica torna-se consideravelmente mais complexo.

A previsão final de um ensemble é tipicamente uma agregação (e.g., média, voto ponderado, ou, no caso da probabilidade de excedência, uma contagem de limiar [^5]) das saídas dos modelos individuais. Explicar *porquê* o ensemble produziu um determinado valor $p_i$ exigiria desconstruir as contribuições e interações entre todos os modelos $f_k$. Por exemplo, como é que a combinação de um modelo baseado em regras (Cubist), uma rede neural (NN), um método de vizinhos mais próximos (KNN) e vários modelos de regressão linear regularizada (Ridge, LASSO, ElasticNet) [^9] interage para determinar se a SWH excederá $\tau$? Esta complexidade inerente torna os ensembles frequentemente "caixas-pretas" (*black boxes*).

Esta opacidade dificulta a validação do modelo por especialistas do domínio, a depuração de erros e a construção de confiança no sistema de previsão, especialmente em aplicações críticas. Se o ensemble prevê uma baixa probabilidade de excedência quando um evento extremo de facto ocorre, ou vice-versa, diagnosticar a causa raiz dentro da complexa interação dos $M$ modelos é um desafio formidável. A referência a fontes externas [27, 9] no contexto original [^2] sugere que esta é uma preocupação reconhecida na literatura sobre interpretabilidade de modelos.

#### Implicações na Previsão de Probabilidade de Excedência

No contexto específico da previsão de probabilidade de excedência, estas duas limitações são particularmente relevantes. A tarefa visa estimar a probabilidade de um evento potencialmente raro, mas de alto impacto (como a SWH exceder um limiar crítico [^1]). A fiabilidade e a compreensibilidade da previsão são cruciais para a tomada de decisão (e.g., em operações marítimas [^1]).

O método direto baseado em ensemble (referido como RFR+D ou HRE+D nos experimentos [^12]) calcula a probabilidade como a fração de modelos do ensemble que preveem uma excedência [^3], [^5]. Como discutido, isto exige a execução de todos os modelos, implicando um custo computacional [^2]. Adicionalmente, a falta de transparência significa que o utilizador final recebe um valor de probabilidade $p_i$ sem uma compreensão clara de como os diferentes componentes do ensemble contribuíram para esse valor [^2]. Curiosamente, os resultados experimentais indicaram que o ensemble heterogêneo complexo (HRE+D) apresentou um desempenho fraco na estimativa da probabilidade de excedência, enquanto um ensemble homogêneo mais simples (RFR+D) foi competitivo com métodos de classificação [^13]. Isto sugere que o aumento da complexidade e do custo computacional de um ensemble heterogêneo pode não se traduzir necessariamente em melhor desempenho para esta tarefa específica, reforçando as preocupações sobre a sua aplicabilidade prática quando comparado com alternativas potencialmente mais eficientes e transparentes.

### Conclusão

Em suma, embora as estratégias de previsão baseadas em ensemble sejam uma ferramenta poderosa e amplamente utilizada em diversas áreas, incluindo ciências ambientais como meteorologia e hidrologia [^7], a sua aplicação prática enfrenta obstáculos significativos. Conforme destacado na análise das vantagens metodológicas [^14], os **elevados custos computacionais**, decorrentes da necessidade de treinar, validar e executar múltiplos modelos [^4], [^10], e a inerente **falta de transparência**, que dificulta a interpretação e a validação das previsões [^2], são fatores limitantes cruciais. Estas limitações, suportadas por referências externas [27, 9] citadas no contexto, muitas vezes *inviabilizam* a utilização de ensembles [^2], especialmente em domínios onde a eficiência computacional e a interpretabilidade são críticas, como na previsão de probabilidade de excedência para gestão de risco. Esta constatação motiva a busca e o desenvolvimento de abordagens alternativas, como o método baseado na *Cumulative Distribution Function* (CDF) proposto no estudo [página 7, Seção 4.1], que visam oferecer um equilíbrio mais favorável entre desempenho, custo computacional e interpretabilidade.

### Referências

[^1]: Página 8: "Aside from performance considerations, which we will delve into in Section 6, the proposed method may be preferable relative to a classifier for two main reasons. The first reason is integration because the same forecasting model can be used to predict both the upcoming values of SWH and to estimate exceedance probability."
[^2]: Página 8: "However, the high computational costs and lack of transparency often preclude the application of these strategies [27,9]."
[^3]: Página 2: "Ensemble-based forecasting (regression) approaches can also be applied, in which the exceedance probability is estimated according to the ratio of individual predictions that exceed the threshold."
[^4]: Página 6: "The alternative to using a classification model is to use a forecasting ensemble F composed of a set of M models: F = {f1, f2,..., fM}."
[^5]: Página 6: "We can also use the ensemble F to estimate the exceedance probability according to the ratio of ensemble members that forecast a value that exceeds the threshold τ: pi = (1/M) * Σ I(fk(Xi, Zi) ≥ τ)"
[^6]: Página 6: "Hereafter, we will refer to this approach as an ensemble-based direct method for exceedance probability."
[^7]: Página 6: "Ensemble-based approaches are commonly used in some fields related to environmental science, for example, meteorology or hydrology [43]."
[^8]: Página 13: "The fourth approach is a heterogeneous regression ensemble (HRE). An ensemble is referred to as heterogeneous, as opposed to homogeneous, if it is comprised of base models trained with different learning algorithms."
[^9]: Página 13: "The following learning algorithms were used to train the base models of HRE: a rule-based model based on the Cubist algorithm, a bagging ensemble of decision trees (Bagging), ridge regression (Ridge), elastic-net (ElasticNet), LASSO, multivariate adaptive regression splines (MARS), light gradient boosting optimized using random search (LGBM); extra trees (ExtraTree), Adaboost (AdaBoost), Random Forests (RFR), partial least squares regression (PLS), principal components regression (PCR), nearest neighbors (KNN), and a deep feedforward neural network (NN)."
[^10]: Página 13: "We applied different parameter settings and the total number of initial models is 50. The complete list of parameters is shown in Table 1. Using a validation set we trimmed the ensemble by removing half of the models with worse performance."
[^11]: Página 13: "The trimming process has been shown to improve the forecasting performance of ensembles [23,8]."
[^12]: Página 13: "We apply the regression approaches in two different ways to obtain the estimates for exceedance probability. The first is a Direct (abbreviated as D) approach: the exceedance probability p is computed according to the ratio of ensemble members which predicts a value above the threshold τ. The Direct approach is only valid for ensembles, in this case, HRE (a heterogeneous ensemble) and RFR (a homogeneous ensemble)."
[^13]: Página 14: "Another interesting result to note is that HRE+D provides poor estimates regarding exceedance probability, while RFR+D is competitive with classification methods. This outcome suggests that building an ensemble with weak models (RFR is an ensemble of decision trees) is better than an ensemble of strong models, such as HRE."
[^14]: Página 8: "4.2 Methodological Advantages" - O início da seção onde o tema é introduzido.
[^15]: Página 8: "These advantages apply to an ensemble-based forecasting approach."
[^22]: Página 19, Ref 22: "Jain, P., Deo, M.: Real-time wave forecasts off the western indian coast. Applied ocean research 29(1-2), 72-79 (2007)" (Implica a necessidade de previsões rápidas/em tempo real)

<!-- END -->