## Heterogeneous Regression Ensembles for Exceedance Probability Forecasting

### Introdução
Este capítulo explora o uso de **Heterogeneous Regression Ensembles (HRE)** [^13] para a tarefa de **exceedance probability forecasting**, com foco em modelos de regressão diversos combinados para prever se uma série temporal excederá um determinado limiar. HREs combinam modelos base diversos (Cubist, Bagging, Ridge, ElasticNet, LASSO, MARS, LGBM, ExtraTree, AdaBoost, RFR, PLS, PCR, KNN, NN) com ajuste de parâmetros e ensemble trimming baseado no desempenho do conjunto de validação, alavancando uma média simples para combinação. A combinação da diversidade de modelos e do ajuste fino dos parâmetros visa melhorar a precisão e a robustez das previsões, especialmente em cenários onde a previsão de valores extremos é crucial [^2, ^5, ^34]. Exploraremos como os HREs podem ser aplicados para estimar a probabilidade de excedência em séries temporais, como as de altura significativa de ondas (SWH) [^13], e compararemos seu desempenho com métodos de classificação binária e outros ensembles de regressão [^38, ^42].

### Conceitos Fundamentais

Um **Heterogeneous Regression Ensemble (HRE)** [^13] é uma técnica de modelagem que combina as previsões de múltiplos modelos de regressão, cada um construído usando um algoritmo diferente. A ideia central é que diferentes algoritmos podem capturar diferentes padrões nos dados [^2, ^5], e combinar suas previsões pode levar a um modelo mais preciso e robusto. No contexto de exceedance probability forecasting, o HRE pode ser usado para prever diretamente o valor da série temporal, e essa previsão pode então ser usada para estimar a probabilidade de excedência [^13].

A construção de um HRE envolve diversas etapas:

1.  **Seleção de Modelos Base:** Escolha de uma variedade de algoritmos de regressão a serem incluídos no ensemble [^13]. A diversidade é fundamental, então é comum incluir modelos lineares (Ridge, LASSO, ElasticNet) [^13], modelos baseados em árvores (Cubist, Bagging, Random Forest, Extra Trees, AdaBoost, LGBM) [^13], modelos não lineares (MARS, KNN, NN) [^13], e modelos de redução de dimensionalidade (PLS, PCR) [^13].
2.  **Ajuste de Parâmetros:** Cada modelo base requer ajuste de seus hiperparâmetros [^13]. Isso pode ser feito usando técnicas como busca em grade (grid search), busca aleatória (random search) [^13], ou otimização Bayesiana [^13], usando um conjunto de validação para avaliar o desempenho [^13].
3.  **Ensemble Trimming:** Nem todos os modelos base contribuem igualmente para a precisão do ensemble [^23, ^8]. Ensemble trimming é o processo de remover modelos com desempenho ruim do ensemble, tipicamente com base no desempenho em um conjunto de validação [^13]. Isso pode melhorar a precisão e a interpretabilidade do ensemble [^27, ^9].
4.  **Combinação de Previsões:** As previsões dos modelos base restantes são combinadas para gerar a previsão final do ensemble [^13]. Uma abordagem comum é usar uma média simples [^13], onde cada modelo tem o mesmo peso. Métodos mais sofisticados incluem weighted averaging [^13], onde os pesos são determinados com base no desempenho dos modelos, ou modelos de stacking [^13], onde um meta-modelo é treinado para combinar as previsões dos modelos base [^13].

No contexto do trabalho de Cerqueira e Torgo [^13], o HRE utiliza uma média simples para a combinação das previsões dos modelos base após o processo de trimming. A avaliação do desempenho do HRE é realizada em um conjunto de validação, e os modelos com pior desempenho são removidos, mantendo-se apenas a metade com melhor performance [^13].

#### Vantagens dos HREs

Os HREs oferecem diversas vantagens sobre os modelos de regressão individuais:

*   **Maior Precisão:** Ao combinar as previsões de múltiplos modelos, os HREs podem alcançar maior precisão do que qualquer modelo individual [^2, ^5].
*   **Maior Robustez:** Os HREs são menos suscetíveis a overfitting e outliers do que os modelos individuais [^2, ^5].
*   **Melhor Generalização:** Os HREs tendem a generalizar melhor para novos dados do que os modelos individuais [^2, ^5].
*   **Flexibilidade:** Os HREs podem ser adaptados a uma ampla gama de problemas de regressão [^2, ^5].

#### Desafios dos HREs

Apesar de suas vantagens, os HREs também apresentam alguns desafios:

*   **Complexidade:** A construção e o ajuste de um HRE podem ser mais complexos do que a construção de um modelo individual [^2, ^5].
*   **Custo Computacional:** O treinamento e a previsão com um HRE podem ser mais custosos computacionalmente do que com um modelo individual [^2, ^5].
*   **Interpretabilidade:** A interpretabilidade de um HRE pode ser mais difícil do que a de um modelo individual [^27, ^9].

#### Estimando a Exceedance Probability com HREs

Existem duas abordagens principais para usar HREs para estimar a exceedance probability [^13]:

1.  **Abordagem Direta (D):** Calcular a exceedance probability diretamente a partir das previsões do ensemble [^13]. Isso é feito contando a proporção de modelos no ensemble que preveem um valor acima do limiar [^13]. Se *M* é o número total de modelos no ensemble e *I* é a função indicadora, então a exceedance probability *p* é dada por:

    $$\
    p = \frac{1}{M} \sum_{k=1}^{M} I(f_k(X_i, Z_i) > \tau)\
    $$

    onde $f_k(X_i, Z_i)$ é a previsão do *k*-ésimo modelo, $X_i$ são os lags da série temporal, $Z_i$ são covariáveis adicionais, e $\tau$ é o limiar [^13].
2.  **Abordagem CDF (CDF):** Usar a previsão do ensemble como um parâmetro de localização para uma distribuição contínua e, em seguida, usar a função de distribuição cumulativa (CDF) dessa distribuição para estimar a exceedance probability [^13]. Essa abordagem assume que as previsões do ensemble seguem uma distribuição específica, como a distribuição de Weibull [^13], e usa a CDF dessa distribuição para calcular a probabilidade de exceder o limiar. A exceedance probability *p* é dada por:

    $$\
    p = 1 - F(\tau; \hat{y_i}, \beta, \alpha)\
    $$

    onde $F$ é a CDF da distribuição de Weibull, $\hat{y_i}$ é a previsão do ensemble, e $\beta$ e $\alpha$ são os parâmetros de escala e forma da distribuição de Weibull, respectivamente [^13].

### Conclusão

Os Heterogeneous Regression Ensembles representam uma abordagem promissora para a exceedance probability forecasting, combinando a diversidade de múltiplos modelos de regressão com técnicas de ajuste de parâmetros e ensemble trimming [^13]. Ao usar HREs, é possível obter previsões mais precisas e robustas, bem como estimar a probabilidade de excedência de uma forma flexível e adaptável [^13]. As abordagens direta e CDF oferecem diferentes maneiras de usar as previsões do ensemble para estimar a exceedance probability, cada uma com suas próprias vantagens e desvantagens [^13]. A escolha da abordagem mais adequada depende das características específicas dos dados e do problema em questão [^13].

### Referências
[^1]: Abdullah, F., Ningsih, N., Al-Khan, T.: Significant wave height forecasting using long short-term memory neural network in indonesian waters. Journal of Ocean Engineering and Marine Energy 8(2), 183-192 (2022)
[^2]: Ali, M., Prasad, R., Xiang, Y., Deo, R.C.: Near real-time significant wave height forecasting with hybridized multiple linear regression algorithms. Renewable and Sustainable Energy Reviews 132, 110003 (2020)
[^5]: Branco, P., Torgo, L., Ribeiro, R.P.: A survey of predictive modeling on imbalanced domains. ACM Computing Surveys (CSUR) 49(2), 1-50 (2016)
[^8]: Cerqueira, V., Torgo, L., Pinto, F., Soares, C.: Arbitrage of forecasting experts. Machine Learning 108(6), 913-944 (2019)
[^9]: Cerqueira, V., Torgo, L., Soares, C., Bifet, A.: Model compression for dynamic forecast combination. arXiv preprint arXiv:2104.01830 (2021)
[^13]: Cerqueira, V., Torgo, L.: Exceedance Probability Forecasting via Regression: A Case Study of Significant Wave Height Prediction
[^23]: Jose, V.R.R., Winkler, R.L.: Simple robust averages of forecasts: Some empirical results. International journal of forecasting 24(1), 163-169 (2008)
[^27]: Lakkaraju, H., Bach, S.H., Leskovec, J.: Interpretable decision sets: A joint framework for description and prediction. In: Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, pp. 1675-1684 (2016)
[^34]: Polson, M., Sokolov, V.: Deep learning for energy markets. Applied Stochastic Models in Business and Industry 36(1), 195-209 (2020)
[^38]: Slud, E., Kedem, B.: Partial likelihood analysis of logistic regression and autoregression. Statistica Sinica pp. 89-106 (1994)
[^42]: Taylor, J.W., Yu, K.: Using auto-regressive logit models to forecast the exceedance probability for financial risk management. Journal of the Royal Statistical Society: Series A (Statistics in Society) 179 (4), 1069-1092 (2016)
<!-- END -->