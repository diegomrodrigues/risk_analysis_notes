## Estimativa de Probabilidade de Excedência via Função de Distribuição Cumulativa Baseada em Previsões Pontuais

### Introdução

A previsão da probabilidade de excedência, definida como a tarefa de estimar a probabilidade de uma série temporal exceder um limiar predefinido num período futuro específico [^33], representa um problema crucial em diversas áreas, incluindo a análise de dados oceânicos, onde a previsão da Significant Wave Height (SWH) é um exemplo proeminente [^30]. Tradicionalmente, este problema é abordado através de modelos de classificação binária probabilística ou pelo uso de ensembles de previsões [^1], [^31], [^32]. No entanto, uma abordagem alternativa e inovadora, que constitui o foco deste capítulo, baseia-se na utilização de **previsões pontuais** (point forecasts) geradas por modelos de regressão [^1], [^4]. Esta metodologia propõe assumir que a previsão pontual segue uma determinada distribuição de probabilidade contínua, permitindo então o cálculo da probabilidade de excedência através da sua **função de distribuição cumulativa (CDF)** [^3], [^7]. Este capítulo detalhará os fundamentos teóricos e a implementação desta abordagem, explorando as suas características e vantagens em relação aos métodos convencionais.

### Conceitos Fundamentais

A metodologia proposta para a estimação da probabilidade de excedência $p_i$ – a probabilidade de a variável de interesse $y_i$ exceder um limiar $\tau$ no instante $i$ [^33] – articula-se em dois passos principais: a geração de uma previsão pontual e a sua conversão numa estimativa de probabilidade via CDF [^9].

**Geração da Previsão Pontual ($\hat{y}_i$)**

O ponto de partida é a obtenção de uma previsão numérica pontual, $\hat{y}_i$, para o valor futuro da série temporal [^13]. Tipicamente, esta previsão é gerada por um modelo de forecasting $f$, como por exemplo, um modelo **auto-regressivo** [^4], [^10]. Formalmente, considerando uma estratégia auto-regressiva, o valor futuro $y_i$ é modelado com base nos seus lags passados $X_i = \\{y_{i-1}, y_{i-2},..., y_{i-q}\\}$ e, potencialmente, em covariáveis exógenas $Z_i$, resultando num modelo $y_i = f(X_i, Z_i)$ [^10], [^11]. É importante notar que a metodologia aqui descrita é, em princípio, **agnóstica em relação ao modelo de forecasting subjacente** utilizado para produzir $\hat{y}_i$ [^12]. O essencial é que o modelo $f$ forneça uma previsão pontual $\hat{y}_i = f(X_i, Z_i)$ [^13].

**Modelação Distribucional da Previsão Pontual**

A inovação central reside na forma como a previsão pontual $\hat{y}_i$ é utilizada. Em vez de a tratar como um valor determinístico final, assume-se que $\hat{y}_i$ representa um parâmetro de uma **distribuição de probabilidade contínua** que modela a incerteza associada à previsão [^2], [^5]. Especificamente, assume-se que a previsão pontual $\hat{y}_i$ corresponde ao **parâmetro de localização** (location parameter) dessa distribuição [^2], [^8], [^14].

> A hipótese fundamental é que a previsão pontual $\hat{y}_i$ segue (ou é um parâmetro central de) uma distribuição de probabilidade contínua, $D$. A escolha da distribuição $D$ deve ser adequada à natureza dos dados em análise [^17], [^29].

No contexto específico da previsão de SWH, trabalhos anteriores sugerem que a **distribuição de Weibull** oferece um ajuste adequado aos dados [^6], [^16], dada a sua assimetria positiva (right-skewed) [^14]. Assim, assume-se que $\hat{y}_i$ segue uma distribuição de Weibull [^14]. Os restantes parâmetros da distribuição, como os parâmetros de **escala ($\beta$)** e **forma ($\alpha$)** para a Weibull, não dependem da previsão pontual específica $\hat{y}_i$, mas são estimados utilizando os dados de treino (*training data*) [^8], [^15]. Este procedimento pode ser visualizado no passo `β, α ← weibull.fit(ytrain)` do Algorithm 1 apresentado no contexto [^22]. Desta forma, os parâmetros $\beta$ e $\alpha$ capturam características gerais da variabilidade e forma da distribuição dos dados observados no período de treino.

**Cálculo da Probabilidade de Excedência via CDF**

Uma vez definida a distribuição de probabilidade associada à previsão $\hat{y}_i$ (e.g., Weibull com localização $\hat{y}_i$ e parâmetros $\beta, \alpha$ fixos), a probabilidade de excedência $p_i$ para um dado limiar $\tau$ pode ser calculada utilizando a **função de distribuição cumulativa (CDF)** correspondente, denotada por $F$ [^3], [^7], [^18]. A CDF, $F(x; \theta)$, representa a probabilidade de a variável aleatória ser menor ou igual a um valor $x$, dados os parâmetros $\theta$. No nosso caso, $F(\tau; \hat{y}_i, \beta, \alpha)$ representa a probabilidade de o valor futuro ser menor ou igual ao limiar $\tau$, condicionada pela previsão $\hat{y}_i$ e pelos parâmetros globais $\beta, \alpha$ [^20].

A probabilidade de excedência, $p_i = P(Y > \tau | \hat{y}_i, \beta, \alpha)$, é então obtida como o complementar da CDF avaliada em $\tau$:\n\n$$\np_i = 1 - F(\tau; \hat{y}_i, \beta, \alpha)\n$$\n\nEsta fórmula [^19], [^22] expressa que a probabilidade de exceder $\tau$ é igual a 1 menos a probabilidade de ser menor ou igual a $\tau$ [^21]. Este cálculo é realizado para cada nova previsão pontual $\hat{y}_i$ gerada pelo modelo $f$.\n\n**Vantagens Metodológicas**\n\nEsta abordagem baseada na CDF apresenta vantagens significativas em relação às alternativas [^23], [^25]:\n\n1.  **Integração da Informação:** O mesmo modelo de forecasting $f$ pode ser utilizado tanto para gerar previsões pontuais $\hat{y}_i$, que oferecem informação detalhada sobre a dinâmica futura esperada da variável, quanto para estimar a probabilidade de excedência $p_i$, que simplifica a informação para tomada de decisão [^23], [^24]. Esta capacidade de fornecer ambos os tipos de previsão é desejável para operadores com diferentes níveis de experiência [^24].\n2.  **Flexibilidade do Limiar (Threshold Flexibility):** Ao contrário das abordagens de classificação, onde o limiar $\tau$ é tipicamente fixado durante o treino do modelo classificador [^25], esta metodologia adota uma abordagem *lazy* em relação ao limiar [^26]. O limiar $\tau$ é apenas um parâmetro na função de cálculo da probabilidade $p_i = 1 - F(\tau; ...)$ e não influencia o treino do modelo $f$ nem a estimação dos parâmetros $\beta$ e $\alpha$. Consequentemente, o mesmo modelo treinado pode ser usado para calcular a probabilidade de excedência para **diferentes limiares $\tau$** em tempo de inferência, permitindo, por exemplo, a construção de curvas de probabilidade de excedência [^26].\n3.  **Eficiência Computacional:** Embora as vantagens de flexibilidade do limiar também se apliquem a algumas abordagens baseadas em ensembles [^27], o método CDF pode evitar os elevados custos computacionais e a potencial falta de transparência associados a ensembles muito grandes ou complexos [^27].\n\nA escolha da distribuição de probabilidade (e.g., Weibull, Rayleigh, etc.) é um aspeto importante [^28] e deve ser guiada pelas características dos dados em questão [^29], sendo a Weibull uma escolha justificada para dados de SWH com base em trabalhos anteriores [^6], [^16].\n\n### Conclusão\n\nEste capítulo detalhou uma abordagem inovadora para a previsão da probabilidade de excedência, que se baseia na conversão de previsões pontuais em estimativas probabilísticas através da função de distribuição cumulativa (CDF) de uma distribuição contínua assumida [^1], [^3], [^9], [^37]. A metodologia envolve a utilização de um modelo de forecasting para gerar a previsão pontual $\hat{y}_i$, que é então usada como parâmetro de localização de uma distribuição (e.g., Weibull), cujos restantes parâmetros são estimados a partir dos dados de treino [^2], [^8], [^14], [^15]. A probabilidade de exceder um limiar $\tau$ é calculada como $p_i = 1 - F(\tau; \hat{y}_i, \beta, \alpha)$ [^19], [^21]. As principais vantagens desta abordagem incluem a **integração** da previsão pontual e probabilística a partir do mesmo modelo [^23] e a **flexibilidade na definição do limiar** de excedência em tempo de inferência [^26]. Evidências sugerem que esta abordagem pode oferecer melhor desempenho em comparação com métodos tradicionais de classificação ou baseados em ensembles para certas aplicações, como a previsão de SWH [^36]. A seleção criteriosa da distribuição de probabilidade mais adequada aos dados é um passo crucial para a aplicação bem-sucedida deste método [^28], [^29].\n\n### Referências\n\n[^1]: Page 1, Abstract: "Instead, we propose a novel approach based on point forecasting."\n[^2]: Page 1, Abstract: "The proposed solution works by assuming that the point forecasts follow a distribution with the location parameter equal to that forecast."\n[^3]: Page 1, Abstract: "Then, we convert these point forecasts into exceedance probability estimates using the cumulative distribution function."\n[^4]: Page 3, Para 1: "In this paper, we propose a novel approach to exceedance probabilistic forecasting. The method is based on the numeric point forecasts, for example, produced by an auto-regressive model."\n[^5]: Page 3, Para 1: "Essentially, we assume that a given forecast is modeled using a continuous distribution."\n[^6]: Page 3, Para 1: "In this case, we resort to a Weibull distribution following previous works on modeling SWH data [31]."\n[^7]: Page 3, Para 1: "Then, we use the cumulative distribution function (CDF) of this distribution to estimate the exceedance probability."\n[^8]: Page 3, Para 1: "The point forecast represents the location parameter of the distribution, while the remaining parameters (e.g. scale) are estimated using the training data."\n[^9]: Page 7, Section 4.1: "This work introduces a novel approach for exceedance probability forecasting based on a time series forecasting model. The proposed solution works in two main steps: – Building a forecasting model and use it to obtain point forecasts – Converting point forecasts into exceedance probability estimates using the CDF"\n[^10]: Page 7, Section 4.1.1: "We build a forecasting model f using auto-regression as formalized in Section 3.1."\n[^11]: Page 7, Section 4.1.1: "The value of future observations are modeled based on their past lags."\n[^12]: Page 7, Section 4.1.1: "However, it is important to remark that the proposed methodology is agnostic to the underlying forecasting model."\n[^13]: Page 7, Section 4.1.1: "The proposed method leverages the numeric predictions produced by the forecasting model regarding the value of future observations. Here, we denote the point forecast for the i-th observation as ŷᵢ."\n[^14]: Page 7, Section 4.1.2: "We assume that ŷᵢ can be modeled according to a right-skewed Weibull distribution with a location parameter equal to the forecast ŷᵢ."\n[^15]: Page 7, Section 4.1.2: "The scale β and shape α parameters are estimated using the training data."\n[^16]: Page 7, Section 4.1.2: "We use the Weibull distribution as it provides an adequate fit to SWH data [31]."\n[^17]: Page 7, Section 4.1.2: "For other case studies, a different distribution may be more appropriate."\n[^18]: Page 7, Section 4.1.2: "In these conditions, we can estimate pi, the exceedance probability at the i-th time step, using the corresponding CDF."\n[^19]: Page 7, Eq. 2: "$p_i = 1 - F(\tau; \hat{y}_i, \beta, \alpha)$"\n[^20]: Page 7, Para after Eq. 2: "Where F denotes the CDF of the Weibull distribution. When evaluated at the threshold τ, the CDF represents the probability that the respective random variable will take a value less than or equal to τ."\n[^21]: Page 8, Para 1: "In effect, we subtract F(τ; ŷᵢ, β, α) from 1 to obtain the probability that the random variable will exceed τ."\n[^22]: Page 8, Algo 1: Shows the steps: fit Weibull params (β, α) from `ytrain`, compute forecast ŷᵢ, compute $p_i = 1 - F(\tau; \hat{y}_i, \beta, \alpha)$.\n[^23]: Page 8, Section 4.2, Para 1: "The first reason is integration because the same forecasting model can be used to predict both the upcoming values of SWH and to estimate exceedance probability."\n[^24]: Page 8, Section 4.2, Para 1: "The exceedance probability estimate simplifies the information being given to the end user... Yet, complementary numeric forecast offers more information..."\n[^25]: Page 8, Section 4.2, Para 2: "The second reason is threshold flexibility: a classification approach fixes the threshold during training, and it cannot be changed during inference."\n[^26]: Page 8, Section 4.2, Para 2: "Conversely, a regression model follows a lazy approach regarding the threshold. Therefore, in a given instant we can use the same model to estimate the exceedance probability for different thresholds - this enables the plotting of exceedance probability curves."\n[^27]: Page 8, Section 4.2, Para 2: Mentions advantages apply to ensemble-based approaches too, but they have issues with computational costs/transparency [27, 9].\n[^28]: Page 18, Para 1: "An important part of the proposed method is the choice of distribution."\n[^29]: Page 18, Para 1: "...the most appropriate distribution depends on the input data."\n[^30]: Page 1, Abstract: "Significant wave height forecasting is a key problem in ocean data analytics."\n[^31]: Page 2, last para: "Exceedance forecasting is typically formalized as a binary classification problem..."\n[^32]: Page 2, last para: "Ensemble-based forecasting (regression) approaches can also be applied..."\n[^33]: Page 6, Section 3.2: Defines $p_i$ and the binary target $b_i$.\n[^34]: Page 6, Section 3.2: Mentions Logistic Regression for classification.\n[^35]: Page 6, Section 3.2: Describes ensemble approach probability calculation $p_i = (1/M) \sum I(f_k(X_i, Z_i) \ge \tau)$.\n[^36]: Page 17, Para 1: "The main conclusion from the experiments is that the proposed method provides better exceedance probability estimates relative to state-of-the-art alternatives..."\n[^37]: Page 18, Section 8: Summarizes the proposed method.

<!-- END -->