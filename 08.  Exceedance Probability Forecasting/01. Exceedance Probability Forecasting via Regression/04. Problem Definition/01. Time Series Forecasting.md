## Formalização da Previsão de Séries Temporais: Abordagem Auto-Regressiva e Incorporação por Atraso Temporal

### Introdução

A previsão de séries temporais constitui um problema fundamental em diversas áreas, incluindo a análise de dados oceânicos, onde a previsão da altura significativa das ondas (Significant Wave Height - SWH) é crucial para operações marítimas e prevenção de desastres costeiros [^1]. De forma geral, a previsão de séries temporais envolve a predição de valores futuros com base em observações passadas [^2]. Este capítulo dedica-se a formalizar rigorosamente esta tarefa, estabelecendo a base matemática e conceitual para os métodos de previsão. Focaremos na estratégia **auto-regressiva**, uma abordagem prevalente que modela o valor atual ou futuro de uma série com base em seus valores passados recentes [^3, ^4]. Além disso, detalharemos como a técnica de **incorporação por atraso temporal (time delay embedding)**, fundamentada pelo **teorema de Takens** [^5], permite estruturar os dados temporais para aplicação de modelos de aprendizagem de máquina, especificamente modelos de regressão. Esta formalização é essencial para compreender e desenvolver métodos avançados de previsão, como os explorados em estudos de caso específicos, por exemplo, na previsão de probabilidade de excedência [^6].

### Conceitos Fundamentais

**Definição Formal e Objetivo da Previsão**

Uma série temporal univariada é definida como uma sequência temporal de valores $Y = \\{Y_1, Y_2, ..., Y_n\\}$, onde $Y_i \in \mathcal{Y} \subset \mathbb{R}$ representa o valor da variável de interesse no instante de tempo $i$, e $n$ é o comprimento total da série observada [^7]. O objetivo primordial da previsão de séries temporais é estimar os valores das observações futuras, denotadas por $Y_{n+1}, Y_{n+2}, ..., Y_{n+h}$, com base no histórico de observações passadas $\\{Y_1, Y_2, ..., Y_n\\}$ [^8]. O parâmetro $h$ define o **horizonte de previsão**, ou seja, quantos passos no futuro desejamos prever [^8].

**Estratégia Auto-Regressiva e Incorporação por Atraso Temporal**

A formalização da previsão de séries temporais frequentemente adota uma **estratégia auto-regressiva** [^3]. Nesta abordagem, assume-se que o valor de uma observação em um determinado instante pode ser modelado como uma função dos seus valores em instantes anteriores, ou seja, seus **lags recentes** [^4]. Para operacionalizar esta estratégia no contexto de modelos de aprendizagem supervisionada, utilizamos a técnica de **incorporação por atraso temporal (time delay embedding)** [^5]. Este procedimento, cuja validade teórica para reconstrução da dinâmica subjacente do sistema a partir de observações escalares é suportada pelo **teorema de Takens [40]** [^5], transforma a série temporal original num conjunto de dados estruturado em pares de entrada-saída $(\mathbf{X}_i, y_i)$.

Especificamente, para prever o valor $y_i = Y_i$, construímos um vetor de características $\mathbf{X}_i$ composto pelos $q$ valores mais recentes que antecedem $Y_i$:
$$\
\mathbf{X}_i = \\{Y_{i-1}, Y_{i-2}, \dots, Y_{i-q}\\}\
$$
onde $y_i \in \mathcal{Y} \subset \mathbb{R}$ é a observação que desejamos prever (o alvo), e $\mathbf{X}_i \in \mathcal{X} \subset \mathbb{R}^q$ é o vetor de incorporação (embedding vector) correspondente [^9]. O parâmetro $q$ é conhecido como a dimensão de incorporação ou o número de lags a serem considerados. A tarefa de previsão, então, resume-se a construir um **modelo de regressão** $f$ tal que $y_i \approx f(\mathbf{X}_i)$ [^9].

**Inclusão de Covariáveis e Modelagem ARDL**

A formulação pode ser estendida para incluir informações adicionais relevantes para a previsão, conhecidas como **covariáveis** ou variáveis explanatórias. Se denotarmos por $\mathbf{Z}_i$ um vetor de covariáveis conhecidas no instante $i$, o modelo de regressão torna-se $y_i = f(\mathbf{X}_i, \mathbf{Z}_i)$ [^9]. No contexto de séries temporais multivariadas, como no estudo de caso da previsão de SWH que utiliza dados de velocidade do vento ou temperatura da superfície do mar [^10], estas covariáveis são frequentemente outras séries temporais. Nesses casos, as próprias covariáveis também podem ser representadas através de vetores de incorporação baseados nos seus valores passados recentes [^10]. A inclusão de lags da variável dependente ($\mathbf{X}_i$) e lags das variáveis explanatórias (contidos em $\mathbf{Z}_i$) caracteriza a **técnica de modelagem de lags distribuídos auto-regressivos (Auto-Regressive Distributed Lags - ARDL) [32]** [^11]. Em aplicações práticas, como a mencionada previsão de SWH, pode-se utilizar uma dimensão de incorporação $q=6$ para todas as variáveis e incluir variáveis adicionais como o dia do ano para capturar efeitos sazonais, resultando num número significativo de variáveis explanatórias [^12, ^13].

**Previsão Multi-Step Ahead: Método Direto**

Quando o objetivo é prever múltiplos passos à frente (i.e., $h > 1$), abordamos o problema de **previsão multi-step ahead**. Uma estratégia comum para isso é o **método direto (direct method) [39]** [^14]. Em contraste com métodos iterativos (que usam previsões anteriores para gerar as subsequentes), o método direto consiste em construir $h$ modelos de previsão distintos, um para cada passo futuro dentro do horizonte de previsão $\\{1, 2, ..., h\\}$ [^15]. Ou seja, teremos um modelo $f_k$ para prever $Y_{n+k}$ com base nas informações disponíveis até o tempo $n$, para cada $k \in \\{1, ..., h\\}$. A formalização via incorporação por atraso temporal e a modelagem de regressão (potencialmente ARDL) aplicam-se individualmente a cada um desses $h$ modelos.

> **Formalização:** A tarefa de previsão de séries temporais via abordagem auto-regressiva com incorporação por atraso temporal visa aprender uma função $f: \mathbb{R}^q \times \mathcal{Z} \rightarrow \mathbb{R}$ (onde $\mathcal{Z}$ é o espaço das covariáveis) a partir de um conjunto de treino $\\{( \mathbf{X}_i, \mathbf{Z}_i, y_i )\\}$, tal que $f(\mathbf{X}_i, \mathbf{Z}_i)$ seja uma boa aproximação de $y_i = Y_i$, utilizando $\mathbf{X}_i = \\{Y_{i-1}, \dots, Y_{i-q}\\}$ e covariáveis $\mathbf{Z}_i$. Para previsão multi-step ahead direta, $h$ funções $f_1, \dots, f_h$ são aprendidas independentemente.

Esta estruturação do problema é fundamental, pois permite a aplicação direta de uma vasta gama de algoritmos de regressão de aprendizagem de máquina, como redes neuronais, máquinas de vetores de suporte, random forests, entre outros [^16], para a tarefa de previsão de séries temporais [^17].

### Conclusão

Este capítulo apresentou uma formalização detalhada do problema de previsão de séries temporais, com ênfase na estratégia auto-regressiva e na utilização da incorporação por atraso temporal, justificada pelo teorema de Takens. Definimos a estrutura de dados $(\mathbf{X}_i, y_i)$ gerada por este processo e como ela permite enquadrar a previsão como um problema de regressão supervisionada. Discutimos a extensão para incluir covariáveis, levando à modelagem ARDL, e abordamos a estratégia direta para previsão multi-step ahead. Esta formalização rigorosa não só clarifica os pressupostos e mecanismos subjacentes a muitas técnicas de previsão, mas também fornece a base necessária para a construção e avaliação de modelos preditivos complexos, como os utilizados em aplicações críticas como a previsão de SWH e a estimação de probabilidades de excedência [^1, ^6, ^18]. A compreensão destes conceitos fundamentais é, portanto, indispensável para qualquer académico ou profissional que trabalhe com análise e modelagem de dados temporais.

### Referências

[^1]: Abstract, Page 1: *Significant wave height forecasting is a key problem in ocean data analytics. This task affects several maritime operations...*
[^2]: Input Topic: *Time series forecasting involves predicting future values based on past observations...*
[^3]: Page 5, Section 3.1: *We formalize the problem of time series forecasting based on an **auto-regressive strategy**.*
[^4]: Page 5, Section 3.1: *Accordingly, observations of a time series are modeled based on their **recent lags**.*
[^5]: Page 5, Section 3.1: *We construct a set of observations of the form (Xi, yi) using **time delay embedding** according to the **Takens theorem [40]**.*
[^6]: Page 5, Section 3: *This section formalizes the predictive task addressed in this work. We start by defining SWH forecasting problems (Section 3.1), followed by the formalization of exceedance probability forecasting (Section 3.2).*
[^7]: Page 5, Section 3.1: *A univariate time series represents a temporal sequence of values Y = {Y1, Y2,..., Yn}, where Yi ∈ Y ⊂ R is the value of Y at time i and n is the length of Y.*
[^8]: Page 5, Section 3.1: *The general goal behind forecasting is to predict the value of the upcoming observations of the time series, Yn+1, ..., Yn+h, given the past observations, where h denotes the forecasting horizon.*
[^9]: Page 5, Section 3.1: *In each observation, the value of yi is modelled based on the most recent q known values: Xi = {Yi−1, Yi-2,···, Yi-q}, where yi ∈ Y ⊂ R, which represents the observation we want to predict, Xi ∈ X ⊂ Rq represents the i-th embedding vector. For each horizon, the goal is to build a **regression model** f that can be written as yi = f(Xi, Zi), where Zi represents additional covariates known at the i-th instance.*
[^10]: Page 6, Continuation of Section 3.1: *In this case, the covariates Z are explanatory time series related to SWH, including wind speed or sea surface temperature. Each of the explanatory time series is also represented at each time step i with an embedding vector based on the past recent values.*
[^11]: Page 6, Continuation of Section 3.1: *This leads to an **auto-regressive distributed lags modeling technique [32]**.*
[^12]: Page 11, Section 5.2: *Regarding the predictor variables, we follow the procedure described in Section 3. We apply time delay embedding to all variables in the time series with an embedding size (number of lags) of 6.*
[^13]: Page 11, Section 5.2: *We also added the day of the year in the explanatory variables to account for yearly seasonal effects. This leads to a total of 49 explanatory variables.*
[^14]: Page 6, Continuation of Section 3.1: *In effect, we address the **multi-step ahead forecasting** problem with a **direct method [39]**.*
[^15]: Page 6, Continuation of Section 3.1: *We build h models, one for predicting each future step {1,...,h}.*
[^16]: Page 4, Section 2.1: *Shamshirband et al. [37] compared different regression algorithms for significant wave height forecasting, including artificial neural networks, support vector regression, and extreme learning machines [20].* (Implies regression models are used). Page 13, Section 6.2.2 lists RFR, LASSO, NN, HRE as regression approaches tested.
[^17]: Page 17, Section 7: *We transformed the time series into a trainable format using time delay embedding on each variable, as we formalized in Section 3.*
[^18]: Page 18, Section 8: *We proposed a new method to estimate exceedance probability using the point forecasts produced by an auto-regressive forecasting model.*

<!-- END -->