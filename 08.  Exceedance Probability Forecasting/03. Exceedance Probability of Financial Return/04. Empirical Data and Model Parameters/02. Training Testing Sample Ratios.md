## Divisão da Amostra para Treinamento e Teste e Seleção do Limiar Ótimo

### Introdução
Este capítulo detalha a metodologia utilizada para dividir a amostra de dados em conjuntos de treinamento (*in-sample*) e teste (*out-sample*), bem como a estratégia para selecionar o limiar de treinamento que otimiza a estimativa do Value at Risk (VaR). A correta divisão da amostra e a escolha do limiar de treinamento são cruciais para o desenvolvimento de modelos robustos e com boa capacidade de generalização [^6].

### Conceitos Fundamentais

A divisão da amostra em conjuntos de treinamento e teste é uma prática comum na modelagem estatística e aprendizado de máquina. O conjunto de treinamento é usado para calibrar os parâmetros do modelo, enquanto o conjunto de teste é utilizado para avaliar o desempenho do modelo em dados não vistos, fornecendo uma estimativa da sua capacidade de generalização [^6].

No contexto do estudo, a amostra foi dividida em duas partes: treinamento (*in-sample*) e teste (*out-sample*) [^6]. As razões de divisão foram de 4:1 para SBER (Sberbank shares) e de 10:1 para USD-RUB (dólar-rublo) [^6]. Isso significa que, para SBER, 80% dos dados foram usados para treinamento e 20% para teste, enquanto para USD-RUB, aproximadamente 91% dos dados foram usados para treinamento e 9% para teste.

A escolha de diferentes razões de divisão para diferentes ativos pode ser justificada pelas características específicas de cada série temporal. Por exemplo, a série USD-RUB, que é baseada em *minute-by-minute tick-transactions* [^6], pode exigir uma maior proporção de dados de treinamento para capturar padrões complexos e nuances presentes nos dados de alta frequência.

Além da divisão da amostra, o modelo foi calculado para diferentes limiares (*thresholds*) do conjunto de treinamento [^6]. O limiar que forneceu o melhor resultado para a estimativa do VaR foi então selecionado [^6]. Essa abordagem permite otimizar o modelo para a tarefa específica de estimativa do VaR, garantindo que o modelo seja calibrado de forma a minimizar o erro de previsão do risco.

A metodologia de seleção do limiar ideal envolve o cálculo do modelo para diferentes limiares de treinamento e a avaliação do desempenho de cada modelo na estimativa do VaR [^6]. O limiar que resulta na menor diferença entre o VaR estimado e o VaR verdadeiro (ou uma proxy razoável) é então selecionado como o limiar ideal. Essa abordagem pode ser implementada usando técnicas de validação cruzada ou outras métricas de desempenho apropriadas.

O Value at Risk (VaR) é uma medida de risco amplamente utilizada no setor financeiro. Ele quantifica a perda máxima esperada em um determinado horizonte de tempo, dado um nível de confiança específico. A estimativa precisa do VaR é crucial para a gestão de risco e tomada de decisões de investimento [^1, 2, 3].

O estudo utiliza o *autoregressive binary choice model* para estimar a probabilidade de excedência do retorno, que é então aplicada no cálculo do VaR [^1]. O modelo proposto introduz uma nova parametrização da equação de volatilidade, que implica a presença de um termo aleatório adicional [^1]. A estimativa desse modelo requer o uso de algoritmos Bayesianos, como o *Bayesian NUTS algorithm* [^1].

### Conclusão

A divisão da amostra em conjuntos de treinamento e teste e a seleção do limiar de treinamento que otimiza a estimativa do VaR são etapas críticas na construção de modelos robustos e com boa capacidade de generalização [^6]. A escolha das razões de divisão e a metodologia de seleção do limiar devem ser cuidadosamente consideradas, levando em conta as características específicas dos dados e os objetivos da modelagem. A utilização de técnicas de validação cruzada e outras métricas de desempenho apropriadas pode auxiliar na seleção do limiar ideal e na avaliação do desempenho do modelo.

### Referências
[^6]: Empirical Data and Model Parameters, p. 6.
[^1]: Abstract, p. 1.
[^2]: Introduction, p. 1-2.
[^3]: VaR calculation, p. 3.
<!-- END -->