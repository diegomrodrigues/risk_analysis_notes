### Model Backtesting and Horizon Selection in VAR

### Introdu√ß√£o
Em continuidade ao estudo do Value at Risk (VAR) e suas aplica√ß√µes, este cap√≠tulo aborda um aspecto crucial para a valida√ß√£o e confiabilidade dos modelos: o *backtesting*. Como vimos anteriormente, o VAR √© uma medida de risco que resume a potencial perda em um determinado horizonte de tempo e n√≠vel de confian√ßa [^1]. No entanto, a precis√£o do VAR depende da qualidade dos dados e da adequa√ß√£o do modelo utilizado. O *backtesting* √© uma ferramenta essencial para avaliar a performance de um modelo VAR e identificar poss√≠veis vieses nas previs√µes [^1]. Esta se√ß√£o se aprofundar√° nos crit√©rios para realizar o *backtesting*, com foco especial na import√¢ncia do horizonte de tempo na efic√°cia dos testes.

### Conceitos Fundamentais
O *backtesting* consiste em comparar sistematicamente as previs√µes de perdas obtidas por meio do VAR com as perdas e lucros (P&L) efetivamente realizados posteriormente [^1]. O objetivo principal do *backtesting* √© detectar vieses ou inconsist√™ncias nos resultados do VAR, garantindo que o modelo esteja gerando previs√µes confi√°veis. A ideia central √© que um modelo VAR bem calibrado deve ser capaz de prever a frequ√™ncia com que as perdas efetivas excedem o VAR previsto, alinhando-se com o n√≠vel de confian√ßa estabelecido [^2].

Para realizar um *backtesting* eficaz, √© fundamental levar em considera√ß√£o o horizonte de tempo utilizado no c√°lculo do VAR. A escolha do horizonte de tempo influencia diretamente o n√∫mero de observa√ß√µes independentes dispon√≠veis para o teste, afetando o poder estat√≠stico do mesmo [^1]. O poder de um teste refere-se √† sua capacidade de detectar desvios significativos entre as previs√µes do VAR e os resultados reais.

Como mencionado anteriormente, o horizonte de tempo √© um dos fatores quantitativos que influenciam o c√°lculo do VAR. Em geral, um horizonte mais longo leva a um VAR maior. Ao usar o VAR como uma medida de risco potencial, o horizonte de tempo deve ser definido pela liquidez dos ativos, ou seja, o tempo necess√°rio para liquidar o portf√≥lio sem grandes impactos no mercado [^1].

#### O Impacto do Horizonte de Tempo no Backtesting
A escolha do horizonte de tempo tem um impacto significativo no n√∫mero de observa√ß√µes independentes dispon√≠veis para o *backtesting*. Um horizonte mais longo reduz o n√∫mero de observa√ß√µes independentes em um determinado per√≠odo. Por exemplo, se utilizarmos um horizonte de VAR de duas semanas, teremos apenas 26 observa√ß√µes independentes por ano [^1]. Por outro lado, um horizonte de um dia fornecer√° aproximadamente 252 observa√ß√µes independentes ao longo de um ano [^1].

O poder do teste, ou seja, a capacidade de detectar vieses no modelo, est√° diretamente relacionado ao n√∫mero de observa√ß√µes independentes. Com um n√∫mero maior de observa√ß√µes, o teste se torna mais sens√≠vel a desvios entre as previs√µes do VAR e as perdas efetivas [^1]. Por isso, para fins de *backtesting*, √© prefer√≠vel utilizar horizontes de tempo mais curtos, como um dia, para maximizar o poder dos testes [^1].

**Proposi√ß√£o 1**
   *A escolha de um horizonte de tempo $h$ para o c√°lculo do VAR implica que, em um per√≠odo de $T$ dias, temos aproximadamente $T/h$ observa√ß√µes independentes. Para um dado per√≠odo de tempo $T$, o n√∫mero de observa√ß√µes independentes √© inversamente proporcional ao tamanho do horizonte $h$.*
   
   *Proof:*

   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Each observation period for the VAR spans $h$ days.

   II. **Main Logical Steps**:
      - The total number of days, $T$, is divided by the length of each observation period, $h$, to determine the number of non-overlapping observation periods.
      - This gives the number of independent observations.

   III. **Key Transformations**:
      -  Number of independent observations $\approx \frac{T}{h}$

   IV. **Conclusion**:
      - As $h$ increases, $T/h$ decreases, implying an inverse relationship between $h$ and the number of independent observations for a fixed $T$.
      - This proves the statement: "the number of independent observations is inversely proportional to the size of the horizon $h$". ‚ñ†
> üí° **Exemplo Num√©rico:**
> Suponha que temos um per√≠odo de $T = 252$ dias (um ano de negocia√ß√£o). Se usarmos um horizonte de tempo $h = 1$ dia, teremos aproximadamente $252/1 = 252$ observa√ß√µes independentes. Se aumentarmos o horizonte para $h = 5$ dias (uma semana), teremos $252/5 \approx 50$ observa√ß√µes independentes. E se o horizonte for $h=21$ (aproximadamente um m√™s), teremos $252/21=12$ observa√ß√µes independentes. Este exemplo ilustra claramente a rela√ß√£o inversa entre o horizonte de tempo e o n√∫mero de observa√ß√µes independentes.

#### Rela√ß√£o com o N√≠vel de Confian√ßa
√â importante notar que o n√≠vel de confian√ßa tamb√©m influencia o n√∫mero de observa√ß√µes na cauda da distribui√ß√£o. N√≠veis de confian√ßa mais altos, como 99%, resultam em menos observa√ß√µes na cauda, dificultando a identifica√ß√£o de vieses no modelo. Em outras palavras, para confirmar a validade do modelo com um n√≠vel de confian√ßa de 99%, seria necess√°rio um longo per√≠odo de observa√ß√µes para coletar dados suficientes na cauda da distribui√ß√£o [^1]. Por isso, para o *backtesting*, n√≠veis de confian√ßa mais baixos, como 95%, podem ser prefer√≠veis, permitindo uma an√°lise mais frequente dos resultados do modelo [^1].

**Lema 1**
   *Para um n√≠vel de confian√ßa $\alpha$, o n√∫mero de observa√ß√µes esperadas na cauda da distribui√ß√£o em um per√≠odo $T$ com horizonte de tempo $h$ √© aproximadamente $(1-\alpha)T/h$.*

   *Proof:*
   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Let $\alpha$ be the confidence level.
      - The number of independent observations is approximately $T/h$.

   II. **Main Logical Steps**:
       - With a confidence level $\alpha$, the probability of an observation falling in the tail (exceeding the VAR) is $1 - \alpha$.
       - The expected number of observations in the tail is the product of the number of independent observations and the probability of falling in the tail.

   III. **Key Transformations**:
        - Expected number of observations in the tail $\approx \frac{T}{h} \times (1-\alpha) = (1-\alpha) \frac{T}{h}$

   IV. **Conclusion**:
      - This shows that the expected number of observations in the tail is approximately $(1-\alpha)T/h$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Usando o exemplo anterior com $T=252$ dias e um horizonte de $h=1$ dia, se o n√≠vel de confian√ßa for $\alpha = 0.95$ (95%), o n√∫mero esperado de observa√ß√µes na cauda √© $(1-0.95) \times 252/1 = 0.05 \times 252 = 12.6$. Isso significa que, em m√©dia, esperamos que o VAR seja violado aproximadamente 12 ou 13 vezes em um ano. Se o n√≠vel de confian√ßa for $\alpha=0.99$, o n√∫mero esperado de viola√ß√µes cai para $(1-0.99) \times 252 = 0.01 \times 252 = 2.52$, indicando que seria necess√°rio um per√≠odo muito maior de observa√ß√µes para testar o modelo de forma eficaz. Se, por outro lado, mantemos o n√≠vel de confian√ßa em 95% mas aumentamos o horizonte para $h=5$, o n√∫mero de observa√ß√µes na cauda ser√° $(1-0.95)\times 252/5 \approx 2.5$.
  
**Corol√°rio 1.1**
   *O n√∫mero de observa√ß√µes na cauda √© diretamente proporcional ao per√≠odo $T$ e inversamente proporcional ao horizonte $h$, e diminui com o aumento do n√≠vel de confian√ßa $\alpha$.*

   *Proof:*
   I. **Initial Setup**:
       - From Lema 1, the number of observations in the tail is approximately $(1-\alpha)T/h$.

   II. **Main Logical Steps**:
       - We analyze the effect of $T$, $h$, and $\alpha$ on this expression.

   III. **Key Transformations**:
        - As $T$ increases, the number of observations in the tail increases proportionally.
        - As $h$ increases, the number of observations in the tail decreases proportionally.
        - As $\alpha$ increases, $(1-\alpha)$ decreases, thus decreasing the number of observations in the tail.

   IV. **Conclusion**:
        -  This confirms the statement that the number of tail observations is directly proportional to $T$, inversely proportional to $h$, and decreases with an increase in $\alpha$. ‚ñ†

Al√©m disso, vale ressaltar que a escolha do n√≠vel de confian√ßa afeta o tipo de erros que o *backtesting* ser√° capaz de detectar. Um n√≠vel de confian√ßa mais alto prioriza a detec√ß√£o de erros na cauda da distribui√ß√£o, enquanto um n√≠vel de confian√ßa mais baixo permite uma detec√ß√£o mais frequente de erros, ainda que menos extremos.

**Proposi√ß√£o 2**
    *Um n√≠vel de confian√ßa mais baixo aumenta a frequ√™ncia com que os resultados do VAR s√£o comparados com os retornos realizados, e, consequentemente, aumenta a sensibilidade a potenciais vieses no modelo.*
  
  *Proof:*

  I. **Initial Setup**:
    - Let $\alpha$ be the confidence level.
    - A lower confidence level implies a smaller $\alpha$.
    - VAR is calculated for a given confidence level.

  II. **Main Logical Steps**:
    - A lower confidence level (smaller $\alpha$) corresponds to a lower VAR value (since the VAR is a quantile).
    - A lower VAR value means a greater chance of actual losses exceeding the VAR.
    - If the actual loss exceeds the VAR value, this is considered a violation in the backtesting process.
    - More violations mean more comparisons between VAR and actual returns.

  III. **Key Transformations**:
    - Lower $\alpha$  $\implies$ Lower VAR
    - Lower VAR $\implies$ More violations
    - More violations $\implies$ More frequent comparisons between VAR and actual returns

  IV. **Conclusion**:
    - This demonstrates that a lower confidence level results in more frequent comparisons between VAR predictions and actual returns. Therefore, the sensitivity of the backtesting to potential biases in the model increases.‚ñ†

> üí° **Exemplo Num√©rico:**
> Considere um modelo VAR com um horizonte de um dia ($h=1$). Se o n√≠vel de confian√ßa for $\alpha = 0.99$, espera-se que as viola√ß√µes sejam raras, e a cada 100 dias de negocia√ß√£o, apenas 1 dia, em m√©dia, apresentar√° uma perda que ultrapassa o VAR. Se o n√≠vel de confian√ßa for reduzido para $\alpha=0.95$, as viola√ß√µes tornam-se mais frequentes, com uma m√©dia de 5 dias a cada 100, e isso permite uma an√°lise mais detalhada e frequente do modelo.

**Teorema 1**
*Existe um trade-off entre o horizonte de tempo $h$ e o n√≠vel de confian√ßa $\alpha$ no *backtesting*. Diminuir $h$ aumenta o n√∫mero de observa√ß√µes independentes e, portanto, o poder do teste, enquanto diminuir $\alpha$ aumenta a frequ√™ncia de viola√ß√µes do VAR e, tamb√©m, aumenta o poder do teste.*
 *Proof:*
    I. **Initial Setup**:
        - The power of a backtesting test is directly related to the number of independent observations and the frequency of violations.
    
    II. **Main Logical Steps**:
         - From Proposi√ß√£o 1, reducing the time horizon $h$ increases the number of independent observations. An increase in independent observations leads to an increase in the power of the test.
         - From Proposi√ß√£o 2, reducing the confidence level $\alpha$ increases the frequency of violations. More frequent violations increase the data available to backtest, increasing the power of the test.
        
    III. **Key Transformations**:
        - $h \downarrow \implies \text{Number of Independent Observations} \uparrow \implies \text{Test Power} \uparrow$
        - $\alpha \downarrow \implies \text{Frequency of Violations} \uparrow \implies \text{Test Power} \uparrow$

    IV. **Conclusion**:
        - The theorem states that there is a trade-off. Both lowering $h$ and $\alpha$ increase the power of the backtest, supporting the claim. Therefore, this proves the existence of the trade-off.‚ñ†

**Lema 2**
*Seja $N$ o n√∫mero de observa√ß√µes independentes, e seja $X_i$ uma vari√°vel indicadora que vale 1 se a perda observada no per√≠odo $i$ excede o VAR previsto e 0 caso contr√°rio. Se o modelo VAR estiver bem calibrado, ent√£o $X_i$ s√£o vari√°veis aleat√≥rias independentes de Bernoulli com probabilidade de sucesso $1 - \alpha$.*

*Proof:*
   I. **Initial Setup**:
       - $N$ is the number of independent observations.
       - $X_i$ is an indicator variable, where $X_i = 1$ if the loss exceeds the predicted VAR at time $i$, and $X_i = 0$ otherwise.
       - $\alpha$ is the confidence level of the VAR.
       - A well-calibrated VAR model has a probability of $1-\alpha$ of the loss exceeding the VAR.
       - We assume independence between observations.

   II. **Main Logical Steps**:
       - For each observation $i$, there are only two outcomes: the loss exceeds the VAR ($X_i = 1$) or the loss does not exceed the VAR ($X_i = 0$).
       - Under a well-calibrated model, the probability of $X_i = 1$ (a loss exceeding the VAR) is $1 - \alpha$.
       - This is precisely the definition of a Bernoulli trial with a success probability of $1-\alpha$.
       - The independence of the $X_i$ variables comes from the assumption of independence of observations.

   III. **Key Transformations**:
       - $P(X_i=1) = 1-\alpha$.

   IV. **Conclusion**:
       - The variables $X_i$ are independent and follow a Bernoulli distribution with success probability $1-\alpha$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Vamos supor que estamos analisando 252 dias de negocia√ß√£o com um n√≠vel de confian√ßa de 95% ($\alpha=0.95$). Para cada dia $i$, definimos $X_i = 1$ se a perda naquele dia excedeu o VAR previsto e $X_i = 0$ caso contr√°rio. Se o modelo estiver bem calibrado, cada $X_i$ √© uma vari√°vel de Bernoulli com $p = 1 - 0.95 = 0.05$. Isso significa que a probabilidade de uma viola√ß√£o em qualquer dia √© de 5%.

**Teorema 1.1**
*Sob as condi√ß√µes do Lema 2, o n√∫mero de viola√ß√µes do VAR, $V = \sum_{i=1}^N X_i$, segue uma distribui√ß√£o binomial com par√¢metros $N$ e $1-\alpha$, ou seja, $V \sim Bin(N, 1 - \alpha)$.*

*Proof:*
   I. **Initial Setup**:
      - From Lema 2, $X_i$ are independent Bernoulli random variables with success probability $1-\alpha$.
      - $V$ is defined as the sum of these Bernoulli variables: $V = \sum_{i=1}^N X_i$.

   II. **Main Logical Steps**:
      - The sum of $N$ independent Bernoulli random variables with the same success probability follows a binomial distribution.
      - The parameters of the binomial distribution are $N$ (the number of trials) and $1-\alpha$ (the success probability).

   III. **Key Transformations**:
      - $V = \sum_{i=1}^N X_i \implies V \sim Bin(N, 1 - \alpha)$

   IV. **Conclusion**:
      - Therefore, the number of violations $V$ follows a binomial distribution with parameters $N$ and $1-\alpha$. ‚ñ†
> üí° **Exemplo Num√©rico:**
> Continuando o exemplo anterior, onde temos 252 observa√ß√µes independentes ($N=252$) e $\alpha = 0.95$, o n√∫mero total de viola√ß√µes $V$ segue uma distribui√ß√£o binomial com par√¢metros $N=252$ e $p=0.05$, ou seja, $V \sim Bin(252, 0.05)$. Isso nos permite calcular a probabilidade de observar um n√∫mero espec√≠fico de viola√ß√µes, assumindo que o modelo VAR est√° bem calibrado.

**Corol√°rio 1.2**
*A m√©dia e a vari√¢ncia do n√∫mero de viola√ß√µes $V$ s√£o dadas por $E[V] = N(1-\alpha)$ e $Var[V] = N(1-\alpha)\alpha$.*

*Proof:*
   I. **Initial Setup**:
      - From Theorem 1.1, $V \sim Bin(N, 1-\alpha)$.
      - We recall the mean and variance of a binomial distribution.
   II. **Main Logical Steps**:
        - The expected value (mean) of a binomial distribution $Bin(n,p)$ is given by $E[V]=np$.
        - The variance of a binomial distribution $Bin(n,p)$ is given by $Var[V]=np(1-p)$.
   III. **Key Transformations**:
      - Substituting $n = N$ and $p = 1 - \alpha$, we have
      -  $E[V] = N(1-\alpha)$.
      - $Var[V] = N(1-\alpha)(1-(1-\alpha)) = N(1-\alpha)\alpha$.

   IV. **Conclusion**:
     -  This shows that the mean and the variance of $V$ are given by $E[V] = N(1-\alpha)$ and $Var[V] = N(1-\alpha)\alpha$, respectively. ‚ñ†

> üí° **Exemplo Num√©rico:**
> No mesmo exemplo, com $N=252$ e $\alpha=0.95$, a m√©dia do n√∫mero de viola√ß√µes √© $E[V] = 252 \times (1 - 0.95) = 252 \times 0.05 = 12.6$, e a vari√¢ncia √© $Var[V] = 252 \times 0.05 \times 0.95 = 11.97$. Isso significa que, em m√©dia, esperamos 12.6 viola√ß√µes, com uma variabilidade em torno desse valor, quantificada pela vari√¢ncia.

Al√©m disso, √© crucial considerar a autocorrela√ß√£o das perdas. Se as perdas em per√≠odos sucessivos forem correlacionadas, a suposi√ß√£o de independ√™ncia das observa√ß√µes pode ser violada, comprometendo a validade do *backtesting*.

**Proposi√ß√£o 3**
    *A autocorrela√ß√£o positiva das perdas pode levar a um excesso de viola√ß√µes do VAR em clusters, o que pode reduzir o poder de um *backtesting* que assume independ√™ncia das observa√ß√µes.*
    *Proof:*
       I. **Initial Setup**:
        -  Assume positive autocorrelation in losses.
        -  Assume that we are using a backtesting method that assumes independence.
        
       II. **Main Logical Steps**:
           - Positive autocorrelation implies that if a loss exceeds the VAR in a given period, the probability of a loss exceeding the VAR in the next period is higher than expected under independence.
           - This causes violations to occur in clusters, i.e. if one violation occurs, the probability of seeing more violations in close succession is higher.
           - When violations cluster, the assumption of independent Bernoulli trials underlying most backtesting procedures is violated.
           - The methods assume that the number of violations is a realization of a binomial distribution, which does not hold under autocorrelation.
           - Since the number of observations is reduced, a clustered violation process has less power than an independent violation process.

       III. **Key Transformations**:
           - Autocorrelation $\implies$ violation clusters
           - Clusters $\implies$ violation of independence
           - Violation of independence $\implies$ Reduction in the power of the test

       IV. **Conclusion**:
        - Therefore, positive autocorrelation can lead to clustered violations, and reduce the effectiveness of backtesting.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
> Suponha que as perdas do dia atual sejam positivamente correlacionadas com as perdas do dia anterior. Se o VAR for violado hoje, √© mais prov√°vel que ele seja violado amanh√£ tamb√©m. Isso cria *clusters* de viola√ß√µes, onde v√°rios dias consecutivos apresentam perdas acima do VAR, em vez de viola√ß√µes aleat√≥rias e independentes. Um modelo que ignora essa autocorrela√ß√£o pode n√£o capturar a din√¢mica real do risco.
    
**Lema 3**
*Para detectar a presen√ßa de autocorrela√ß√£o nas viola√ß√µes do VAR, pode-se realizar um teste de raz√£o de verossimilhan√ßa (LR) de independ√™ncia de viola√ß√µes, ou similar, como o teste de Kupiec ou Christoffersen.*

    *Proof:*
     I. **Initial Setup**:
          - We want to detect if there is autocorrelation in the violations of the VAR model.
          - We know that violations of a well-calibrated VAR should be independent events.

     II. **Main Logical Steps**:
          - The test of the likelihood ratio (LR) is designed to test the hypothesis that the distribution of the violations is independent.
          - The Kupiec test checks if the overall violation rate is consistent with the confidence level, implicitly assuming independence over time.
          - The Christoffersen test is specifically designed to test for both correct violation rate and independence over time.

     III. **Key Transformations**:
          - These tests check the null hypothesis of independence against the alternative of an autocorrelation in the violations.

     IV. **Conclusion**:
          -  The LR test and specific tests such as Kupiec and Christoffersen can all detect the presence of autocorrelation, supporting the claim. ‚ñ†
> üí° **Exemplo Num√©rico:**
>  Se os resultados do *backtesting* mostram uma sequ√™ncia de viola√ß√µes em dias pr√≥ximos (por exemplo, viola√ß√µes nos dias 1, 2, 3, e depois nenhuma viola√ß√£o por v√°rias semanas, e em seguida viola√ß√µes nos dias 45 e 46) isso levanta suspeitas de autocorrela√ß√£o. Testes como o de Christoffersen ajudam a quantificar essa suspeita, e a verificar se os *clusters* de viola√ß√£o s√£o estatisticamente significativos ou apenas devidos ao acaso.

**Proposi√ß√£o 4**
    *A presen√ßa de *clusters* de viola√ß√µes, causada por autocorrela√ß√£o, implica que a vari√¢ncia do n√∫mero de viola√ß√µes pode ser maior do que o previsto pela distribui√ß√£o binomial sob a hip√≥tese de independ√™ncia.*
    
  *Proof:*
  
    I. **Initial Setup**:
        - Assume that the violations are positively autocorrelated, so that violations tend to cluster together.
        - Let $X_i$ be indicator variables such that $X_i = 1$ if there is a violation at time $i$ and 0 otherwise.
        - Let the number of violations be given by $V=\sum_{i=1}^N X_i$.
        
    II. **Main Logical Steps**:
        - If the violations were independent, then we could calculate the variance of the total number of violations using the fact that it follows a binomial distribution (as shown in Corol√°rio 1.2). In that case, $Var[V] = N(1-\alpha)\alpha$.
        - However, because of autocorrelation, the $X_i$ are not independent. The variance of the sum of correlated random variables is not the sum of the variances.
        - If $\text{Cov}(X_i,X_j) > 0$ for at least some $i \neq j$, then $Var[\sum X_i] > \sum Var[X_i]$.
        - The autocorrelation causes $\text{Cov}(X_i,X_j) > 0$, implying that the variance of the sum will be greater than if the $X_i$ were independent.

   III. **Key Transformations**:
       - Autocorrelation $\implies \text{Cov}(X_i,X_j) > 0$.
       -  $\text{Cov}(X_i,X_j) > 0$  $\implies$  $Var[\sum X_i] > \sum Var[X_i]$
       - $Var[\sum X_i] > \sum Var[X_i]$ $\implies$ $Var[V] > N(1-\alpha)\alpha$

   IV. **Conclusion**:
      -  The presence of autocorrelation increases the variance of the sum of violations over the case with independent variables.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
>  Usando o exemplo de 252 observa√ß√µes com $\alpha = 0.95$, sob a hip√≥tese de independ√™ncia, a vari√¢ncia do n√∫mero de viola√ß√µes √© de 11.97. No entanto, se houver autocorrela√ß√£o positiva, a vari√¢ncia real das viola√ß√µes pode ser muito maior. Por exemplo, se as viola√ß√µes ocorrem em *clusters*, a vari√¢ncia poderia ser 20 ou at√© mais. Isso significa que as viola√ß√µes ser√£o mais vari√°veis do que o esperado sob o modelo binomial, e o modelo de VAR pode estar subestimando o risco.
   
**Teorema 2**
 *O teste de Kupiec √© um teste de hip√≥tese para verificar se a frequ√™ncia de viola√ß√µes do VAR √© estatisticamente diferente do esperado dado o n√≠vel de confian√ßa $\alpha$. Ele testa a hip√≥tese nula de que a frequ√™ncia de viola√ß√µes observada √© consistente com a frequ√™ncia esperada sob um modelo bem calibrado.*

 *Proof:*
    I. **Initial Setup**:
      - The null hypothesis ($H_0$) is that the model is well-calibrated, i.e., the observed violation rate matches the expected violation rate.
      - The alternative hypothesis ($H_1$) is that the model is not well-calibrated, i.e., the observed violation rate is different from the expected rate.
      - Let $V$ be the observed number of violations, $N$ the number of independent observations, and $\alpha$ the confidence level.
      - We know that if the model is well-calibrated, the number of violations follows a binomial distribution $V \sim Bin(N, 1-\alpha)$.
      
    II. **Main Logical Steps**:
      -  The Kupiec test uses a likelihood ratio test to compare the likelihood under the null hypothesis (where $p = 1-\alpha$) with the likelihood of a model that admits a free violation probability $\hat{p}$ estimated from data (observed frequency of violations, i.e., $\hat{p} = V/N$).
      - The likelihood ratio statistic is constructed based on the binomial distribution.
      - The statistic is asymptotically chi-squared distributed, which allows for the construction of the test.
      
    III. **Key Transformations**:
      - Let $p$ be the expected probability of violation under the null hypothesis $p = 1-\alpha$.
      - The likelihood function is given by $L(p) = \binom{N}{V} p^V (1-p)^{N-V}$.
      - The test statistic is given by $-2ln\frac{L(1-\alpha)}{L(\hat{p})}$.
      - Under the null hypothesis, this statistic converges in distribution to a $\chi^2(1)$.

    IV. **Conclusion**:
      -  The Kupiec test checks if the frequency of violations is statistically different from that expected under the well-calibrated model hypothesis, using the distribution of the violations implied by a model with binomial violations. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que em 252 dias com um n√≠vel de confian√ßa de 95%, um modelo VAR tenha apresentado 20 viola√ß√µes. Sob a hip√≥tese nula de que o modelo est√° bem calibrado, o n√∫mero esperado de viola√ß√µes √© de 12.6. O teste de Kupiec calcula uma estat√≠stica de teste que compara a probabilidade de observar 20 viola√ß√µes se o modelo estiver bem calibrado com a probabilidade de observar 20 viola√ß√µes com a probabilidade de viola√ß√£o observada nos dados (20/252). Essa estat√≠stica de teste segue uma distribui√ß√£o $\chi^2$ com 1 grau de liberdade. Se o valor da estat√≠stica de teste for muito alto (e o p-valor correspondente for baixo), rejeita-se a hip√≥tese de que o modelo est√° bem calibrado e conclui-se que o modelo est√° subestimando o risco.
 
 **Lema 4**
 *O teste de Christoffersen testa se as viola√ß√µes do VAR s√£o independentes ao longo do tempo, e, portanto, se h√° *clusters* de viola√ß√µes. Ele testa a hip√≥tese nula de independ√™ncia das viola√ß√µes contra a hip√≥tese alternativa de que as viola√ß√µes seguem um processo de Markov de primeira ordem.*

    *Proof:*
    I. **Initial Setup**:
         - Null Hypothesis $H_0$: The violations are independent over time.
         - Alternative Hypothesis $H_1$: The violations follow a first-order Markov process (i.e., the probability of a violation depends on whether the previous observation was a violation or not).
         - $X_t$ is an indicator variable that is 1 if a violation occurs at time t, and 0 otherwise.

    II. **Main Logical Steps**:
         -  The Christoffersen test examines the transitions between violation and no-violation states using a likelihood ratio test.
         - Under $H_0$, the probability of a violation at time $t$ is independent of the occurrence of a violation at time $t-1$.
         - Under $H_1$, the probability of a violation depends on whether there was a violation in the previous period.
         - This dependence is expressed using a transition matrix:
        $$
        \begin{bmatrix}
          \pi_{00} & \pi_{01} \\
          \pi_{10} & \pi_{11}
        \end{bmatrix}
        $$
         where $\pi_{ij}$ is the probability of observing $X_t=j$ given $X_{t-1} = i$.
        
    III. **Key Transformations**:
         - The likelihood function under the null hypothesis (independence) is compared to the likelihood under the alternative hypothesis (Markov model).
         - The likelihood ratio is used to evaluate if the alternative hypothesis fits the data significantly better than the null hypothesis.
         - The test statistic is asymptotically chi-squared distributed.
        
    IV. **Conclusion**:
         -  The Christoffersen test determines if the observed transitions between violations and no-violations are consistent with the assumption of independence (i.e., if violations are clustered). ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que temos 252 dias de dados, e as viola√ß√µes do VAR ocorrem em sequ√™ncia. Por exemplo, se tivermos uma viola√ß√£o no dia $t-1$, a probabilidade de ter uma viola√ß√£o no dia $t$ √© muito maior do que se n√£o tivermos uma viola√ß√£o no dia $t-1$. O teste de Christoffersen verifica se essas transi√ß√µes entre estados (viola√ß√£o/n√£o-viola√ß√£o) s√£o estatisticamente significativas e inconsistentes com a hip√≥tese de independ√™ncia. Ele estima a matriz de transi√ß√£o e compara a probabilidade de os dados terem sido gerados por uma cadeia de Markov ou por um processo independente, calculando uma estat√≠stica de teste, que segue uma distribui√ß√£o $\chi^2$.

    
**Teorema 2.1**
    *O teste de Christoffersen tamb√©m avalia se a frequ√™ncia de viola√ß√µes √© consistente com o n√≠vel de confian√ßa $\alpha$, simultaneamente com a avalia√ß√£o da independ√™ncia das viola√ß√µes.*

    *Proof:*
        I. **Initial Setup**:
            - The null hypothesis for the Christoffersen test is that the model is well-calibrated and that the violations are independent of each other.
            - The alternative hypothesis is that either the violation frequency is not correct or the violations are not independent.
            -  The null hypothesis is given by $H_0: \pi_{01}=\pi_{11} = 1-\alpha$.

        II. **Main Logical Steps**:
            - The Christoffersen test is actually a joint test. It is composed of two likelihood ratio (LR) tests.
            -  The first LR test looks at whether the frequency of violations is compatible with the confidence level $\alpha$. This part of the test does not test independence.
            - The second LR test checks if there is statistical evidence of dependence on the previous state. This second test checks independence.
            - If we reject the null hypothesis in the Christoffersen test, it means that the data is incompatible with the assumption that the violations are both independent and have the correct frequency.
            
        III. **Key Transformations**:
            - The first test checks if $\pi_{01}=\pi_{11}=1-\alpha$ jointly. If not, then either the frequency or the independence is rejected.
            - The second test checks the independence of the violations, by testing if $\pi_{01}=\pi_{11}$.
            - The combination of both tests gives the Christoffersen test statistic.
            
        IV. **Conclusion**:
            -  Because of the structure of the test, the Christoffersen test assesses both the frequency of violations and the independence of the violations simultaneously. Therefore, it assesses if both the frequency of violations is consistent with $\alpha$ and if the violations are independent of each other, simultaneously.  ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Continuando o exemplo anterior, o teste de Christoffersen n√£o apenas verifica se a frequ√™ncia de viola√ß√µes √© aproximadamente 5% (se $\alpha=0.95$), mas tamb√©m se a ocorr√™ncia de uma viola√ß√£o em um dia aumenta a probabilidade de uma viola√ß√£o no dia seguinte. Ele faz isso de forma simult√¢nea. Isso √© especialmente importante porque um modelo pode ter a frequ√™ncia de viola√ß√µes correta, mas as viola√ß√µes ocorrem em *clusters*, o que o teste de Christoffersen √© capaz de detectar.
    
**Proposi√ß√£o 5**
   *Al√©m do teste de Kupiec e do teste de Christoffersen, existem outros testes de *backtesting* como o teste de Lopez, o teste de correla√ß√£o serial, e testes baseados em fun√ß√µes de perda, que podem complementar a an√°lise do desempenho do modelo VAR.*
   *Proof:*
        I. **Initial Setup**:
            - The Kupiec and Christoffersen tests are not exhaustive.
            - There are other ways to evaluate a VAR model through backtesting.
        II. **Main Logical Steps**:
            - The Lopez test assesses the magnitude of losses that violate the VAR, not just the frequency. It uses a loss function that considers both the number and the size of the violations.
            - Tests of serial correlation can detect if violations cluster or are predictable, which is undesirable. For example, the Ljung-Box test.
            - Test based on loss functions (such as the tick loss) can be tailored to capture specific properties that are relevant for the user.
        III. **Key Transformations**:
             - The Lopez test, tests of serial correlation, and loss function-based tests provide additional tests that measure aspects of the VAR model not assessed by the Kupiec and Christoffersen test.
       IV. **Conclusion**:
            -  These other tests are useful to evaluate if the VAR model is adequate to a certain situation, and offer a more complete picture of the VAR model‚Äôs quality. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que o teste de Kupiec tenha aprovado um modelo VAR com um n√≠vel de confian√ßa de 95% mas o teste de Christoffersen tenha rejeitado o modelo por apresentar autocorrela√ß√£o. Nesse caso, podemos aplicar outros testes de *backtesting*. Por exemplo, o teste de Lopez poder√° apontar
### Model Backtesting and Horizon Selection in VAR

### Introdu√ß√£o
Em continuidade ao estudo do Value at Risk (VAR) e suas aplica√ß√µes, este cap√≠tulo aborda um aspecto crucial para a valida√ß√£o e confiabilidade dos modelos: o *backtesting*. Como vimos anteriormente, o VAR √© uma medida de risco que resume a potencial perda em um determinado horizonte de tempo e n√≠vel de confian√ßa [^1]. No entanto, a precis√£o do VAR depende da qualidade dos dados e da adequa√ß√£o do modelo utilizado. O *backtesting* √© uma ferramenta essencial para avaliar a performance de um modelo VAR e identificar poss√≠veis vieses nas previs√µes [^1]. Esta se√ß√£o se aprofundar√° nos crit√©rios para realizar o *backtesting*, com foco especial na import√¢ncia do horizonte de tempo na efic√°cia dos testes.

### Conceitos Fundamentais
O *backtesting* consiste em comparar sistematicamente as previs√µes de perdas obtidas por meio do VAR com as perdas e lucros (P&L) efetivamente realizados posteriormente [^1]. O objetivo principal do *backtesting* √© detectar vieses ou inconsist√™ncias nos resultados do VAR, garantindo que o modelo esteja gerando previs√µes confi√°veis. A ideia central √© que um modelo VAR bem calibrado deve ser capaz de prever a frequ√™ncia com que as perdas efetivas excedem o VAR previsto, alinhando-se com o n√≠vel de confian√ßa estabelecido [^2].

Para realizar um *backtesting* eficaz, √© fundamental levar em considera√ß√£o o horizonte de tempo utilizado no c√°lculo do VAR. A escolha do horizonte de tempo influencia diretamente o n√∫mero de observa√ß√µes independentes dispon√≠veis para o teste, afetando o poder estat√≠stico do mesmo [^1]. O poder de um teste refere-se √† sua capacidade de detectar desvios significativos entre as previs√µes do VAR e os resultados reais.

Como mencionado anteriormente, o horizonte de tempo √© um dos fatores quantitativos que influenciam o c√°lculo do VAR. Em geral, um horizonte mais longo leva a um VAR maior. Ao usar o VAR como uma medida de risco potencial, o horizonte de tempo deve ser definido pela liquidez dos ativos, ou seja, o tempo necess√°rio para liquidar o portf√≥lio sem grandes impactos no mercado [^1].

#### O Impacto do Horizonte de Tempo no Backtesting
A escolha do horizonte de tempo tem um impacto significativo no n√∫mero de observa√ß√µes independentes dispon√≠veis para o *backtesting*. Um horizonte mais longo reduz o n√∫mero de observa√ß√µes independentes em um determinado per√≠odo. Por exemplo, se utilizarmos um horizonte de VAR de duas semanas, teremos apenas 26 observa√ß√µes independentes por ano [^1]. Por outro lado, um horizonte de um dia fornecer√° aproximadamente 252 observa√ß√µes independentes ao longo de um ano [^1].

O poder do teste, ou seja, a capacidade de detectar vieses no modelo, est√° diretamente relacionado ao n√∫mero de observa√ß√µes independentes. Com um n√∫mero maior de observa√ß√µes, o teste se torna mais sens√≠vel a desvios entre as previs√µes do VAR e as perdas efetivas [^1]. Por isso, para fins de *backtesting*, √© prefer√≠vel utilizar horizontes de tempo mais curtos, como um dia, para maximizar o poder dos testes [^1].

**Proposi√ß√£o 1**
   *A escolha de um horizonte de tempo $h$ para o c√°lculo do VAR implica que, em um per√≠odo de $T$ dias, temos aproximadamente $T/h$ observa√ß√µes independentes. Para um dado per√≠odo de tempo $T$, o n√∫mero de observa√ß√µes independentes √© inversamente proporcional ao tamanho do horizonte $h$.*
   
   *Proof:*

   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Each observation period for the VAR spans $h$ days.

   II. **Main Logical Steps**:
      - The total number of days, $T$, is divided by the length of each observation period, $h$, to determine the number of non-overlapping observation periods.
      - This gives the number of independent observations.

   III. **Key Transformations**:
      -  Number of independent observations $\approx \frac{T}{h}$

   IV. **Conclusion**:
      - As $h$ increases, $T/h$ decreases, implying an inverse relationship between $h$ and the number of independent observations for a fixed $T$.
      - This proves the statement: "the number of independent observations is inversely proportional to the size of the horizon $h$". ‚ñ†
> üí° **Exemplo Num√©rico:**
> Suponha que temos um per√≠odo de $T = 252$ dias (um ano de negocia√ß√£o). Se usarmos um horizonte de tempo $h = 1$ dia, teremos aproximadamente $252/1 = 252$ observa√ß√µes independentes. Se aumentarmos o horizonte para $h = 5$ dias (uma semana), teremos $252/5 \approx 50$ observa√ß√µes independentes. E se o horizonte for $h=21$ (aproximadamente um m√™s), teremos $252/21=12$ observa√ß√µes independentes. Este exemplo ilustra claramente a rela√ß√£o inversa entre o horizonte de tempo e o n√∫mero de observa√ß√µes independentes.

#### Rela√ß√£o com o N√≠vel de Confian√ßa
√â importante notar que o n√≠vel de confian√ßa tamb√©m influencia o n√∫mero de observa√ß√µes na cauda da distribui√ß√£o. N√≠veis de confian√ßa mais altos, como 99%, resultam em menos observa√ß√µes na cauda, dificultando a identifica√ß√£o de vieses no modelo. Em outras palavras, para confirmar a validade do modelo com um n√≠vel de confian√ßa de 99%, seria necess√°rio um longo per√≠odo de observa√ß√µes para coletar dados suficientes na cauda da distribui√ß√£o [^1]. Por isso, para o *backtesting*, n√≠veis de confian√ßa mais baixos, como 95%, podem ser prefer√≠veis, permitindo uma an√°lise mais frequente dos resultados do modelo [^1].

**Lema 1**
   *Para um n√≠vel de confian√ßa $\alpha$, o n√∫mero de observa√ß√µes esperadas na cauda da distribui√ß√£o em um per√≠odo $T$ com horizonte de tempo $h$ √© aproximadamente $(1-\alpha)T/h$.*

   *Proof:*
   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Let $\alpha$ be the confidence level.
      - The number of independent observations is approximately $T/h$.

   II. **Main Logical Steps**:
       - With a confidence level $\alpha$, the probability of an observation falling in the tail (exceeding the VAR) is $1 - \alpha$.
       - The expected number of observations in the tail is the product of the number of independent observations and the probability of falling in the tail.

   III. **Key Transformations**:
        - Expected number of observations in the tail $\approx \frac{T}{h} \times (1-\alpha) = (1-\alpha) \frac{T}{h}$

   IV. **Conclusion**:
      - This shows that the expected number of observations in the tail is approximately $(1-\alpha)T/h$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Usando o exemplo anterior com $T=252$ dias e um horizonte de $h=1$ dia, se o n√≠vel de confian√ßa for $\alpha = 0.95$ (95%), o n√∫mero esperado de observa√ß√µes na cauda √© $(1-0.95) \times 252/1 = 0.05 \times 252 = 12.6$. Isso significa que, em m√©dia, esperamos que o VAR seja violado aproximadamente 12 ou 13 vezes em um ano. Se o n√≠vel de confian√ßa for $\alpha=0.99$, o n√∫mero esperado de viola√ß√µes cai para $(1-0.99) \times 252 = 0.01 \times 252 = 2.52$, indicando que seria necess√°rio um per√≠odo muito maior de observa√ß√µes para testar o modelo de forma eficaz. Se, por outro lado, mantemos o n√≠vel de confian√ßa em 95% mas aumentamos o horizonte para $h=5$, o n√∫mero de observa√ß√µes na cauda ser√° $(1-0.95)\times 252/5 \approx 2.5$.
  
**Corol√°rio 1.1**
   *O n√∫mero de observa√ß√µes na cauda √© diretamente proporcional ao per√≠odo $T$ e inversamente proporcional ao horizonte $h$, e diminui com o aumento do n√≠vel de confian√ßa $\alpha$.*

   *Proof:*
   I. **Initial Setup**:
       - From Lema 1, the number of observations in the tail is approximately $(1-\alpha)T/h$.

   II. **Main Logical Steps**:
       - We analyze the effect of $T$, $h$, and $\alpha$ on this expression.

   III. **Key Transformations**:
        - As $T$ increases, the number of observations in the tail increases proportionally.
        - As $h$ increases, the number of observations in the tail decreases proportionally.
        - As $\alpha$ increases, $(1-\alpha)$ decreases, thus decreasing the number of observations in the tail.

   IV. **Conclusion**:
        -  This confirms the statement that the number of tail observations is directly proportional to $T$, inversely proportional to $h$, and decreases with an increase in $\alpha$. ‚ñ†

Al√©m disso, vale ressaltar que a escolha do n√≠vel de confian√ßa afeta o tipo de erros que o *backtesting* ser√° capaz de detectar. Um n√≠vel de confian√ßa mais alto prioriza a detec√ß√£o de erros na cauda da distribui√ß√£o, enquanto um n√≠vel de confian√ßa mais baixo permite uma detec√ß√£o mais frequente de erros, ainda que menos extremos.

**Proposi√ß√£o 2**
    *Um n√≠vel de confian√ßa mais baixo aumenta a frequ√™ncia com que os resultados do VAR s√£o comparados com os retornos realizados, e, consequentemente, aumenta a sensibilidade a potenciais vieses no modelo.*
  
  *Proof:*

  I. **Initial Setup**:
    - Let $\alpha$ be the confidence level.
    - A lower confidence level implies a smaller $\alpha$.
    - VAR is calculated for a given confidence level.

  II. **Main Logical Steps**:
    - A lower confidence level (smaller $\alpha$) corresponds to a lower VAR value (since the VAR is a quantile).
    - A lower VAR value means a greater chance of actual losses exceeding the VAR.
    - If the actual loss exceeds the VAR value, this is considered a violation in the backtesting process.
    - More violations mean more comparisons between VAR and actual returns.

  III. **Key Transformations**:
    - Lower $\alpha$  $\implies$ Lower VAR
    - Lower VAR $\implies$ More violations
    - More violations $\implies$ More frequent comparisons between VAR and actual returns

  IV. **Conclusion**:
    - This demonstrates that a lower confidence level results in more frequent comparisons between VAR predictions and actual returns. Therefore, the sensitivity of the backtesting to potential biases in the model increases.‚ñ†

> üí° **Exemplo Num√©rico:**
> Considere um modelo VAR com um horizonte de um dia ($h=1$). Se o n√≠vel de confian√ßa for $\alpha = 0.99$, espera-se que as viola√ß√µes sejam raras, e a cada 100 dias de negocia√ß√£o, apenas 1 dia, em m√©dia, apresentar√° uma perda que ultrapassa o VAR. Se o n√≠vel de confian√ßa for reduzido para $\alpha=0.95$, as viola√ß√µes tornam-se mais frequentes, com uma m√©dia de 5 dias a cada 100, e isso permite uma an√°lise mais detalhada e frequente do modelo.

**Teorema 1**
*Existe um trade-off entre o horizonte de tempo $h$ e o n√≠vel de confian√ßa $\alpha$ no *backtesting*. Diminuir $h$ aumenta o n√∫mero de observa√ß√µes independentes e, portanto, o poder do teste, enquanto diminuir $\alpha$ aumenta a frequ√™ncia de viola√ß√µes do VAR e, tamb√©m, aumenta o poder do teste.*
 *Proof:*
    I. **Initial Setup**:
        - The power of a backtesting test is directly related to the number of independent observations and the frequency of violations.
    
    II. **Main Logical Steps**:
         - From Proposi√ß√£o 1, reducing the time horizon $h$ increases the number of independent observations. An increase in independent observations leads to an increase in the power of the test.
         - From Proposi√ß√£o 2, reducing the confidence level $\alpha$ increases the frequency of violations. More frequent violations increase the data available to backtest, increasing the power of the test.
        
    III. **Key Transformations**:
        - $h \downarrow \implies \text{Number of Independent Observations} \uparrow \implies \text{Test Power} \uparrow$
        - $\alpha \downarrow \implies \text{Frequency of Violations} \uparrow \implies \text{Test Power} \uparrow$

    IV. **Conclusion**:
        - The theorem states that there is a trade-off. Both lowering $h$ and $\alpha$ increase the power of the backtest, supporting the claim. Therefore, this proves the existence of the trade-off.‚ñ†

**Lema 2**
*Seja $N$ o n√∫mero de observa√ß√µes independentes, e seja $X_i$ uma vari√°vel indicadora que vale 1 se a perda observada no per√≠odo $i$ excede o VAR previsto e 0 caso contr√°rio. Se o modelo VAR estiver bem calibrado, ent√£o $X_i$ s√£o vari√°veis aleat√≥rias independentes de Bernoulli com probabilidade de sucesso $1 - \alpha$.*

*Proof:*
   I. **Initial Setup**:
       - $N$ is the number of independent observations.
       - $X_i$ is an indicator variable, where $X_i = 1$ if the loss exceeds the predicted VAR at time $i$, and $X_i = 0$ otherwise.
       - $\alpha$ is the confidence level of the VAR.
       - A well-calibrated VAR model has a probability of $1-\alpha$ of the loss exceeding the VAR.
       - We assume independence between observations.

   II. **Main Logical Steps**:
       - For each observation $i$, there are only two outcomes: the loss exceeds the VAR ($X_i = 1$) or the loss does not exceed the VAR ($X_i = 0$).
       - Under a well-calibrated model, the probability of $X_i = 1$ (a loss exceeding the VAR) is $1 - \alpha$.
       - This is precisely the definition of a Bernoulli trial with a success probability of $1-\alpha$.
       - The independence of the $X_i$ variables comes from the assumption of independence of observations.

   III. **Key Transformations**:
       - $P(X_i=1) = 1-\alpha$.

   IV. **Conclusion**:
       - The variables $X_i$ are independent and follow a Bernoulli distribution with success probability $1-\alpha$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Vamos supor que estamos analisando 252 dias de negocia√ß√£o com um n√≠vel de confian√ßa de 95% ($\alpha=0.95$). Para cada dia $i$, definimos $X_i = 1$ se a perda naquele dia excedeu o VAR previsto e $X_i = 0$ caso contr√°rio. Se o modelo estiver bem calibrado, cada $X_i$ √© uma vari√°vel de Bernoulli com $p = 1 - 0.95 = 0.05$. Isso significa que a probabilidade de uma viola√ß√£o em qualquer dia √© de 5%.

**Teorema 1.1**
*Sob as condi√ß√µes do Lema 2, o n√∫mero de viola√ß√µes do VAR, $V = \sum_{i=1}^N X_i$, segue uma distribui√ß√£o binomial com par√¢metros $N$ e $1-\alpha$, ou seja, $V \sim Bin(N, 1 - \alpha)$.*

*Proof:*
   I. **Initial Setup**:
      - From Lema 2, $X_i$ are independent Bernoulli random variables with success probability $1-\alpha$.
      - $V$ is defined as the sum of these Bernoulli variables: $V = \sum_{i=1}^N X_i$.

   II. **Main Logical Steps**:
      - The sum of $N$ independent Bernoulli random variables with the same success probability follows a binomial distribution.
      - The parameters of the binomial distribution are $N$ (the number of trials) and $1-\alpha$ (the success probability).

   III. **Key Transformations**:
      - $V = \sum_{i=1}^N X_i \implies V \sim Bin(N, 1 - \alpha)$

   IV. **Conclusion**:
      - Therefore, the number of violations $V$ follows a binomial distribution with parameters $N$ and $1-\alpha$. ‚ñ†
> üí° **Exemplo Num√©rico:**
> Continuando o exemplo anterior, onde temos 252 observa√ß√µes independentes ($N=252$) e $\alpha = 0.95$, o n√∫mero total de viola√ß√µes $V$ segue uma distribui√ß√£o binomial com par√¢metros $N=252$ e $p=0.05$, ou seja, $V \sim Bin(252, 0.05)$. Isso nos permite calcular a probabilidade de observar um n√∫mero espec√≠fico de viola√ß√µes, assumindo que o modelo VAR est√° bem calibrado.

**Corol√°rio 1.2**
*A m√©dia e a vari√¢ncia do n√∫mero de viola√ß√µes $V$ s√£o dadas por $E[V] = N(1-\alpha)$ e $Var[V] = N(1-\alpha)\alpha$.*

*Proof:*
   I. **Initial Setup**:
      - From Theorem 1.1, $V \sim Bin(N, 1-\alpha)$.
      - We recall the mean and variance of a binomial distribution.
   II. **Main Logical Steps**:
        - The expected value (mean) of a binomial distribution $Bin(n,p)$ is given by $E[V]=np$.
        - The variance of a binomial distribution $Bin(n,p)$ is given by $Var[V]=np(1-p)$.
   III. **Key Transformations**:
      - Substituting $n = N$ and $p = 1 - \alpha$, we have
      -  $E[V] = N(1-\alpha)$.
      - $Var[V] = N(1-\alpha)(1-(1-\alpha)) = N(1-\alpha)\alpha$.

   IV. **Conclusion**:
     -  This shows that the mean and the variance of $V$ are given by $E[V] = N(1-\alpha)$ and $Var[V] = N(1-\alpha)\alpha$, respectively. ‚ñ†

> üí° **Exemplo Num√©rico:**
> No mesmo exemplo, com $N=252$ e $\alpha=0.95$, a m√©dia do n√∫mero de viola√ß√µes √© $E[V] = 252 \times (1 - 0.95) = 252 \times 0.05 = 12.6$, e a vari√¢ncia √© $Var[V] = 252 \times 0.05 \times 0.95 = 11.97$. Isso significa que, em m√©dia, esperamos 12.6 viola√ß√µes, com uma variabilidade em torno desse valor, quantificada pela vari√¢ncia.

Al√©m disso, √© crucial considerar a autocorrela√ß√£o das perdas. Se as perdas em per√≠odos sucessivos forem correlacionadas, a suposi√ß√£o de independ√™ncia das observa√ß√µes pode ser violada, comprometendo a validade do *backtesting*.

**Proposi√ß√£o 3**
    *A autocorrela√ß√£o positiva das perdas pode levar a um excesso de viola√ß√µes do VAR em clusters, o que pode reduzir o poder de um *backtesting* que assume independ√™ncia das observa√ß√µes.*
    *Proof:*
       I. **Initial Setup**:
        -  Assume positive autocorrelation in losses.
        -  Assume that we are using a backtesting method that assumes independence.
        
       II. **Main Logical Steps**:
           - Positive autocorrelation implies that if a loss exceeds the VAR in a given period, the probability of a loss exceeding the VAR in the next period is higher than expected under independence.
           - This causes violations to occur in clusters, i.e. if one violation occurs, the probability of seeing more violations in close succession is higher.
           - When violations cluster, the assumption of independent Bernoulli trials underlying most backtesting procedures is violated.
           - The methods assume that the number of violations is a realization of a binomial distribution, which does not hold under autocorrelation.
           - Since the number of observations is reduced, a clustered violation process has less power than an independent violation process.

       III. **Key Transformations**:
           - Autocorrelation $\implies$ violation clusters
           - Clusters $\implies$ violation of independence
           - Violation of independence $\implies$ Reduction in the power of the test

       IV. **Conclusion**:
        - Therefore, positive autocorrelation can lead to clustered violations, and reduce the effectiveness of backtesting.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
> Suponha que as perdas do dia atual sejam positivamente correlacionadas com as perdas do dia anterior. Se o VAR for violado hoje, √© mais prov√°vel que ele seja violado amanh√£ tamb√©m. Isso cria *clusters* de viola√ß√µes, onde v√°rios dias consecutivos apresentam perdas acima do VAR, em vez de viola√ß√µes aleat√≥rias e independentes. Um modelo que ignora essa autocorrela√ß√£o pode n√£o capturar a din√¢mica real do risco.
    
**Lema 3**
*Para detectar a presen√ßa de autocorrela√ß√£o nas viola√ß√µes do VAR, pode-se realizar um teste de raz√£o de verossimilhan√ßa (LR) de independ√™ncia de viola√ß√µes, ou similar, como o teste de Kupiec ou Christoffersen.*

    *Proof:*
     I. **Initial Setup**:
          - We want to detect if there is autocorrelation in the violations of the VAR model.
          - We know that violations of a well-calibrated VAR should be independent events.

     II. **Main Logical Steps**:
          - The test of the likelihood ratio (LR) is designed to test the hypothesis that the distribution of the violations is independent.
          - The Kupiec test checks if the overall violation rate is consistent with the confidence level, implicitly assuming independence over time.
          - The Christoffersen test is specifically designed to test for both correct violation rate and independence over time.

     III. **Key Transformations**:
          - These tests check the null hypothesis of independence against the alternative of an autocorrelation in the violations.

     IV. **Conclusion**:
          -  The LR test and specific tests such as Kupiec and Christoffersen can all detect the presence of autocorrelation, supporting the claim. ‚ñ†
> üí° **Exemplo Num√©rico:**
>  Se os resultados do *backtesting* mostram uma sequ√™ncia de viola√ß√µes em dias pr√≥ximos (por exemplo, viola√ß√µes nos dias 1, 2, 3, e depois nenhuma viola√ß√£o por v√°rias semanas, e em seguida viola√ß√µes nos dias 45 e 46) isso levanta suspeitas de autocorrela√ß√£o. Testes como o de Christoffersen ajudam a quantificar essa suspeita, e a verificar se os *clusters* de viola√ß√£o s√£o estatisticamente significativos ou apenas devidos ao acaso.

**Proposi√ß√£o 4**
    *A presen√ßa de *clusters* de viola√ß√µes, causada por autocorrela√ß√£o, implica que a vari√¢ncia do n√∫mero de viola√ß√µes pode ser maior do que o previsto pela distribui√ß√£o binomial sob a hip√≥tese de independ√™ncia.*
    
  *Proof:*
  
    I. **Initial Setup**:
        - Assume that the violations are positively autocorrelated, so that violations tend to cluster together.
        - Let $X_i$ be indicator variables such that $X_i = 1$ if there is a violation at time $i$ and 0 otherwise.
        - Let the number of violations be given by $V=\sum_{i=1}^N X_i$.
        
    II. **Main Logical Steps**:
        - If the violations were independent, then we could calculate the variance of the total number of violations using the fact that it follows a binomial distribution (as shown in Corol√°rio 1.2). In that case, $Var[V] = N(1-\alpha)\alpha$.
        - However, because of autocorrelation, the $X_i$ are not independent. The variance of the sum of correlated random variables is not the sum of the variances.
        - If $\text{Cov}(X_i,X_j) > 0$ for at least some $i \neq j$, then $Var[\sum X_i] > \sum Var[X_i]$.
        - The autocorrelation causes $\text{Cov}(X_i,X_j) > 0$, implying that the variance of the sum will be greater than if the $X_i$ were independent.

   III. **Key Transformations**:
       - Autocorrelation $\implies \text{Cov}(X_i,X_j) > 0$.
       -  $\text{Cov}(X_i,X_j) > 0$  $\implies$  $Var[\sum X_i] > \sum Var[X_i]$
       - $Var[\sum X_i] > \sum Var[X_i]$ $\implies$ $Var[V] > N(1-\alpha)\alpha$

   IV. **Conclusion**:
      -  The presence of autocorrelation increases the variance of the sum of violations over the case with independent variables.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
>  Usando o exemplo de 252 observa√ß√µes com $\alpha = 0.95$, sob a hip√≥tese de independ√™ncia, a vari√¢ncia do n√∫mero de viola√ß√µes √© de 11.97. No entanto, se houver autocorrela√ß√£o positiva, a vari√¢ncia real das viola√ß√µes pode ser muito maior. Por exemplo, se as viola√ß√µes ocorrem em *clusters*, a vari√¢ncia poderia ser 20 ou at√© mais. Isso significa que as viola√ß√µes ser√£o mais vari√°veis do que o esperado sob o modelo binomial, e o modelo de VAR pode estar subestimando o risco.
   
**Teorema 2**
 *O teste de Kupiec √© um teste de hip√≥tese para verificar se a frequ√™ncia de viola√ß√µes do VAR √© estatisticamente diferente do esperado dado o n√≠vel de confian√ßa $\alpha$. Ele testa a hip√≥tese nula de que a frequ√™ncia de viola√ß√µes observada √© consistente com a frequ√™ncia esperada sob um modelo bem calibrado.*

 *Proof:*
    I. **Initial Setup**:
      - The null hypothesis ($H_0$) is that the model is well-calibrated, i.e., the observed violation rate matches the expected violation rate.
      - The alternative hypothesis ($H_1$) is that the model is not well-calibrated, i.e., the observed violation rate is different from the expected rate.
      - Let $V$ be the observed number of violations, $N$ the number of independent observations, and $\alpha$ the confidence level.
      - We know that if the model is well-calibrated, the number of violations follows a binomial distribution $V \sim Bin(N, 1-\alpha)$.
      
    II. **Main Logical Steps**:
      -  The Kupiec test uses a likelihood ratio test to compare the likelihood under the null hypothesis (where $p = 1-\alpha$) with the likelihood of a model that admits a free violation probability $\hat{p}$ estimated from data (observed frequency of violations, i.e., $\hat{p} = V/N$).
      - The likelihood ratio statistic is constructed based on the binomial distribution.
      - The statistic is asymptotically chi-squared distributed, which allows for the construction of the test.
      
    III. **Key Transformations**:
      - Let $p$ be the expected probability of violation under the null hypothesis $p = 1-\alpha$.
      - The likelihood function is given by $L(p) = \binom{N}{V} p^V (1-p)^{N-V}$.
      - The test statistic is given by $-2ln\frac{L(1-\alpha)}{L(\hat{p})}$.
      - Under the null hypothesis, this statistic converges in distribution to a $\chi^2(1)$.

    IV. **Conclusion**:
      -  The Kupiec test checks if the frequency of violations is statistically different from that expected under the well-calibrated model hypothesis, using the distribution of the violations implied by a model with binomial violations. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que em 252 dias com um n√≠vel de confian√ßa de 95%, um modelo VAR tenha apresentado 20 viola√ß√µes. Sob a hip√≥tese nula de que o modelo est√° bem calibrado, o n√∫mero esperado de viola√ß√µes √© de 12.6. O teste de Kupiec calcula uma estat√≠stica de teste que compara a probabilidade de observar 20 viola√ß√µes se o modelo estiver bem calibrado com a probabilidade de observar 20 viola√ß√µes com a probabilidade de viola√ß√£o observada nos dados (20/252). Essa estat√≠stica de teste segue uma distribui√ß√£o $\chi^2$ com 1 grau de liberdade. Se o valor da estat√≠stica de teste for muito alto (e o p-valor correspondente for baixo), rejeita-se a hip√≥tese de que o modelo est√° bem calibrado e conclui-se que o modelo est√° subestimando o risco.
 
 **Lema 4**
 *O teste de Christoffersen testa se as viola√ß√µes do VAR s√£o independentes ao longo do tempo, e, portanto, se h√° *clusters* de viola√ß√µes. Ele testa a hip√≥tese nula de independ√™ncia das viola√ß√µes contra a hip√≥tese alternativa de que as viola√ß√µes seguem um processo de Markov de primeira ordem.*

    *Proof:*
    I. **Initial Setup**:
         - Null Hypothesis $H_0$: The violations are independent over time.
         - Alternative Hypothesis $H_1$: The violations follow a first-order Markov process (i.e., the probability of a violation depends on whether the previous observation was a violation or not).
         - $X_t$ is an indicator variable that is 1 if a violation occurs at time t, and 0 otherwise.

    II. **Main Logical Steps**:
         -  The Christoffersen test examines the transitions between violation and no-violation states using a likelihood ratio test.
         - Under $H_0$, the probability of a violation at time $t$ is independent of the occurrence of a violation at time $t-1$.
         - Under $H_1$, the probability of a violation depends on whether there was a violation in the previous period.
         - This dependence is expressed using a transition matrix:
        $$
        \begin{bmatrix}
          \pi_{00} & \pi_{01} \\
          \pi_{10} & \pi_{11}
        \end{bmatrix}
        $$
         where $\pi_{ij}$ is the probability of observing $X_t=j$ given $X_{t-1} = i$.
        
    III. **Key Transformations**:
         - The likelihood function under the null hypothesis (independence) is compared to the likelihood under the alternative hypothesis (Markov model).
         - The likelihood ratio is used to evaluate if the alternative hypothesis fits the data significantly better than the null hypothesis.
         - The test statistic is asymptotically chi-squared distributed.
        
    IV. **Conclusion**:
         -  The Christoffersen test determines if the observed transitions between violations and no-violations are consistent with the assumption of independence (i.e., if violations are clustered). ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que temos 252 dias de dados, e as viola√ß√µes do VAR ocorrem em sequ√™ncia. Por exemplo, se tivermos uma viola√ß√£o no dia $t-1$, a probabilidade de ter uma viola√ß√£o no dia $t$ √© muito maior do que se n√£o tivermos uma viola√ß√£o no dia $t-1$. O teste de Christoffersen verifica se essas transi√ß√µes entre estados (viola√ß√£o/n√£o-viola√ß√£o) s√£o estatisticamente significativas e inconsistentes com a hip√≥tese de independ√™ncia. Ele estima a matriz de transi√ß√£o e compara a probabilidade de os dados terem sido gerados por uma cadeia de Markov ou por um processo independente, calculando uma estat√≠stica de teste, que segue uma distribui√ß√£o $\chi^2$.

    
**Teorema 2.1**
    *O teste de Christoffersen tamb√©m avalia se a frequ√™ncia de viola√ß√µes √© consistente com o n√≠vel de confian√ßa $\alpha$, simultaneamente com a avalia√ß√£o da independ√™ncia das viola√ß√µes.*

    *Proof:*
        I. **Initial Setup**:
            - The null hypothesis for the Christoffersen test is that the model is well-calibrated and that the violations are independent of each other.
            - The alternative hypothesis is that either the violation frequency is not correct or the violations are not independent.
            -  The null hypothesis is given by $H_0: \pi_{01}=\pi_{11} = 1-\alpha$.

        II. **Main Logical Steps**:
            - The Christoffersen test is actually a joint test. It is composed of two likelihood ratio (LR) tests.
            -  The first LR test looks at whether the frequency of violations is compatible with the confidence level $\alpha$. This part of the test does not test independence.
            - The second LR test checks if there is statistical evidence of dependence on the previous state. This second test checks independence.
            - If we reject the null hypothesis in the Christoffersen test, it means that the data is incompatible with the assumption that the violations are both independent and have the correct frequency.
            
        III. **Key Transformations**:
            - The first test checks if $\pi_{01}=\pi_{11}=1-\alpha$ jointly. If not, then either the frequency or the independence is rejected.
            - The second test checks the independence of the violations, by testing if $\pi_{01}=\pi_{11}$.
            - The combination of both tests gives the Christoffersen test statistic.
            
        IV. **Conclusion**:
            -  Because of the structure of the test, the Christoffersen test assesses both the frequency of violations and the independence of the violations simultaneously. Therefore, it assesses if both the frequency of violations is consistent with $\alpha$ and if the violations are independent of each other, simultaneously.  ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Continuando o exemplo anterior, o teste de Christoffersen n√£o apenas verifica se a frequ√™ncia de viola√ß√µes √© aproximadamente 5% (se $\alpha=0.95$), mas tamb√©m se a ocorr√™ncia de uma viola√ß√£o em um dia aumenta a probabilidade de uma viola√ß√£o no dia seguinte. Ele faz isso de forma simult√¢nea. Isso √© especialmente importante porque um modelo pode ter a frequ√™ncia de viola√ß√µes correta, mas as viola√ß√µes ocorrem em *clusters*, o que o teste de Christoffersen √© capaz de detectar.
    
**Proposi√ß√£o 5**
   *Al√©m do teste de Kupiec e do teste de Christoffersen, existem outros testes de *backtesting* como o teste de Lopez, o teste de correla√ß√£o serial, e testes baseados em fun√ß√µes de perda, que podem complementar a an√°lise do desempenho do modelo VAR.*
   *Proof:*
        I. **Initial Setup**:
            - The Kupiec and Christoffersen tests are not exhaustive.
            - There are other ways to evaluate a VAR model through backtesting.
        II. **Main Logical Steps**:
            - The Lopez test assesses the magnitude of losses that violate the VAR, not just the frequency. It uses a loss function that considers both the number and the size of the violations.
            - Tests of serial correlation can detect if violations cluster or are predictable, which is undesirable. For example, the Ljung-Box test.
            - Test based on loss functions (such as the tick loss) can be tailored to capture specific properties that are relevant for the user.
        III. **Key Transformations**:
             - The Lopez test, tests of serial correlation, and loss function-based tests provide additional tests that measure aspects of the VAR model not assessed by the Kupiec and Christoffersen test.
       IV. **Conclusion**:
            -  These other tests are useful to evaluate if the VAR model is adequate to a certain situation, and offer a more complete picture of the VAR model‚Äôs quality. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que o teste de Kupiec tenha aprovado um modelo VAR com um n√≠vel de confian√ßa de 95% mas o teste de Christoffersen tenha rejeitado o modelo por apresentar autocorrela√ß√£o. Nesse caso, podemos aplicar outros testes de *backtesting*. Por exemplo, o teste de Lopez poder√° apontar
que as viola√ß√µes do VAR s√£o muito maiores do que o esperado. Um teste de correla√ß√£o serial poder√° confirmar que as viola√ß√µes est√£o clusterizadas. Um teste baseado em fun√ß√µes de perda poder√° indicar que as perdas acima do VAR causam um grande impacto no balan√ßo da institui√ß√£o.
que as viola√ß√µes do VAR s√£o muito maiores do que o esperado. Um teste de correla√ß√£o serial poder√° confirmar que as viola√ß√µes est√£o clusterizadas. Um teste baseado em fun√ß√µes de perda poder√° indicar que as perdas acima do VAR causam um grande impacto no balan√ßo da institui√ß√£o.
### Model Backtesting and Horizon Selection in VAR

### Introdu√ß√£o
Em continuidade ao estudo do Value at Risk (VAR) e suas aplica√ß√µes, este cap√≠tulo aborda um aspecto crucial para a valida√ß√£o e confiabilidade dos modelos: o *backtesting*. Como vimos anteriormente, o VAR √© uma medida de risco que resume a potencial perda em um determinado horizonte de tempo e n√≠vel de confian√ßa [^1]. No entanto, a precis√£o do VAR depende da qualidade dos dados e da adequa√ß√£o do modelo utilizado. O *backtesting* √© uma ferramenta essencial para avaliar a performance de um modelo VAR e identificar poss√≠veis vieses nas previs√µes [^1]. Esta se√ß√£o se aprofundar√° nos crit√©rios para realizar o *backtesting*, com foco especial na import√¢ncia do horizonte de tempo na efic√°cia dos testes.

### Conceitos Fundamentais
O *backtesting* consiste em comparar sistematicamente as previs√µes de perdas obtidas por meio do VAR com as perdas e lucros (P&L) efetivamente realizados posteriormente [^1]. O objetivo principal do *backtesting* √© detectar vieses ou inconsist√™ncias nos resultados do VAR, garantindo que o modelo esteja gerando previs√µes confi√°veis. A ideia central √© que um modelo VAR bem calibrado deve ser capaz de prever a frequ√™ncia com que as perdas efetivas excedem o VAR previsto, alinhando-se com o n√≠vel de confian√ßa estabelecido [^2].

Para realizar um *backtesting* eficaz, √© fundamental levar em considera√ß√£o o horizonte de tempo utilizado no c√°lculo do VAR. A escolha do horizonte de tempo influencia diretamente o n√∫mero de observa√ß√µes independentes dispon√≠veis para o teste, afetando o poder estat√≠stico do mesmo [^1]. O poder de um teste refere-se √† sua capacidade de detectar desvios significativos entre as previs√µes do VAR e os resultados reais.

Como mencionado anteriormente, o horizonte de tempo √© um dos fatores quantitativos que influenciam o c√°lculo do VAR. Em geral, um horizonte mais longo leva a um VAR maior. Ao usar o VAR como uma medida de risco potencial, o horizonte de tempo deve ser definido pela liquidez dos ativos, ou seja, o tempo necess√°rio para liquidar o portf√≥lio sem grandes impactos no mercado [^1].

#### O Impacto do Horizonte de Tempo no Backtesting
A escolha do horizonte de tempo tem um impacto significativo no n√∫mero de observa√ß√µes independentes dispon√≠veis para o *backtesting*. Um horizonte mais longo reduz o n√∫mero de observa√ß√µes independentes em um determinado per√≠odo. Por exemplo, se utilizarmos um horizonte de VAR de duas semanas, teremos apenas 26 observa√ß√µes independentes por ano [^1]. Por outro lado, um horizonte de um dia fornecer√° aproximadamente 252 observa√ß√µes independentes ao longo de um ano [^1].

O poder do teste, ou seja, a capacidade de detectar vieses no modelo, est√° diretamente relacionado ao n√∫mero de observa√ß√µes independentes. Com um n√∫mero maior de observa√ß√µes, o teste se torna mais sens√≠vel a desvios entre as previs√µes do VAR e as perdas efetivas [^1]. Por isso, para fins de *backtesting*, √© prefer√≠vel utilizar horizontes de tempo mais curtos, como um dia, para maximizar o poder dos testes [^1].

**Proposi√ß√£o 1**
   *A escolha de um horizonte de tempo $h$ para o c√°lculo do VAR implica que, em um per√≠odo de $T$ dias, temos aproximadamente $T/h$ observa√ß√µes independentes. Para um dado per√≠odo de tempo $T$, o n√∫mero de observa√ß√µes independentes √© inversamente proporcional ao tamanho do horizonte $h$.*
   
   *Proof:*

   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Each observation period for the VAR spans $h$ days.

   II. **Main Logical Steps**:
      - The total number of days, $T$, is divided by the length of each observation period, $h$, to determine the number of non-overlapping observation periods.
      - This gives the number of independent observations.

   III. **Key Transformations**:
      -  Number of independent observations $\approx \frac{T}{h}$

   IV. **Conclusion**:
      - As $h$ increases, $T/h$ decreases, implying an inverse relationship between $h$ and the number of independent observations for a fixed $T$.
      - This proves the statement: "the number of independent observations is inversely proportional to the size of the horizon $h$". ‚ñ†
> üí° **Exemplo Num√©rico:**
> Suponha que temos um per√≠odo de $T = 252$ dias (um ano de negocia√ß√£o). Se usarmos um horizonte de tempo $h = 1$ dia, teremos aproximadamente $252/1 = 252$ observa√ß√µes independentes. Se aumentarmos o horizonte para $h = 5$ dias (uma semana), teremos $252/5 \approx 50$ observa√ß√µes independentes. E se o horizonte for $h=21$ (aproximadamente um m√™s), teremos $252/21=12$ observa√ß√µes independentes. Este exemplo ilustra claramente a rela√ß√£o inversa entre o horizonte de tempo e o n√∫mero de observa√ß√µes independentes.

#### Rela√ß√£o com o N√≠vel de Confian√ßa
√â importante notar que o n√≠vel de confian√ßa tamb√©m influencia o n√∫mero de observa√ß√µes na cauda da distribui√ß√£o. N√≠veis de confian√ßa mais altos, como 99%, resultam em menos observa√ß√µes na cauda, dificultando a identifica√ß√£o de vieses no modelo. Em outras palavras, para confirmar a validade do modelo com um n√≠vel de confian√ßa de 99%, seria necess√°rio um longo per√≠odo de observa√ß√µes para coletar dados suficientes na cauda da distribui√ß√£o [^1]. Por isso, para o *backtesting*, n√≠veis de confian√ßa mais baixos, como 95%, podem ser prefer√≠veis, permitindo uma an√°lise mais frequente dos resultados do modelo [^1].

**Lema 1**
   *Para um n√≠vel de confian√ßa $\alpha$, o n√∫mero de observa√ß√µes esperadas na cauda da distribui√ß√£o em um per√≠odo $T$ com horizonte de tempo $h$ √© aproximadamente $(1-\alpha)T/h$.*

   *Proof:*
   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Let $\alpha$ be the confidence level.
      - The number of independent observations is approximately $T/h$.

   II. **Main Logical Steps**:
       - With a confidence level $\alpha$, the probability of an observation falling in the tail (exceeding the VAR) is $1 - \alpha$.
       - The expected number of observations in the tail is the product of the number of independent observations and the probability of falling in the tail.

   III. **Key Transformations**:
        - Expected number of observations in the tail $\approx \frac{T}{h} \times (1-\alpha) = (1-\alpha) \frac{T}{h}$

   IV. **Conclusion**:
      - This shows that the expected number of observations in the tail is approximately $(1-\alpha)T/h$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Usando o exemplo anterior com $T=252$ dias e um horizonte de $h=1$ dia, se o n√≠vel de confian√ßa for $\alpha = 0.95$ (95%), o n√∫mero esperado de observa√ß√µes na cauda √© $(1-0.95) \times 252/1 = 0.05 \times 252 = 12.6$. Isso significa que, em m√©dia, esperamos que o VAR seja violado aproximadamente 12 ou 13 vezes em um ano. Se o n√≠vel de confian√ßa for $\alpha=0.99$, o n√∫mero esperado de viola√ß√µes cai para $(1-0.99) \times 252 = 0.01 \times 252 = 2.52$, indicando que seria necess√°rio um per√≠odo muito maior de observa√ß√µes para testar o modelo de forma eficaz. Se, por outro lado, mantemos o n√≠vel de confian√ßa em 95% mas aumentamos o horizonte para $h=5$, o n√∫mero de observa√ß√µes na cauda ser√° $(1-0.95)\times 252/5 \approx 2.5$.
  
**Corol√°rio 1.1**
   *O n√∫mero de observa√ß√µes na cauda √© diretamente proporcional ao per√≠odo $T$ e inversamente proporcional ao horizonte $h$, e diminui com o aumento do n√≠vel de confian√ßa $\alpha$.*

   *Proof:*
   I. **Initial Setup**:
       - From Lema 1, the number of observations in the tail is approximately $(1-\alpha)T/h$.

   II. **Main Logical Steps**:
       - We analyze the effect of $T$, $h$, and $\alpha$ on this expression.

   III. **Key Transformations**:
        - As $T$ increases, the number of observations in the tail increases proportionally.
        - As $h$ increases, the number of observations in the tail decreases proportionally.
        - As $\alpha$ increases, $(1-\alpha)$ decreases, thus decreasing the number of observations in the tail.

   IV. **Conclusion**:
        -  This confirms the statement that the number of tail observations is directly proportional to $T$, inversely proportional to $h$, and decreases with an increase in $\alpha$. ‚ñ†

Al√©m disso, vale ressaltar que a escolha do n√≠vel de confian√ßa afeta o tipo de erros que o *backtesting* ser√° capaz de detectar. Um n√≠vel de confian√ßa mais alto prioriza a detec√ß√£o de erros na cauda da distribui√ß√£o, enquanto um n√≠vel de confian√ßa mais baixo permite uma detec√ß√£o mais frequente de erros, ainda que menos extremos.

**Proposi√ß√£o 2**
    *Um n√≠vel de confian√ßa mais baixo aumenta a frequ√™ncia com que os resultados do VAR s√£o comparados com os retornos realizados, e, consequentemente, aumenta a sensibilidade a potenciais vieses no modelo.*
  
  *Proof:*

  I. **Initial Setup**:
    - Let $\alpha$ be the confidence level.
    - A lower confidence level implies a smaller $\alpha$.
    - VAR is calculated for a given confidence level.

  II. **Main Logical Steps**:
    - A lower confidence level (smaller $\alpha$) corresponds to a lower VAR value (since the VAR is a quantile).
    - A lower VAR value means a greater chance of actual losses exceeding the VAR.
    - If the actual loss exceeds the VAR value, this is considered a violation in the backtesting process.
    - More violations mean more comparisons between VAR and actual returns.

  III. **Key Transformations**:
    - Lower $\alpha$  $\implies$ Lower VAR
    - Lower VAR $\implies$ More violations
    - More violations $\implies$ More frequent comparisons between VAR and actual returns

  IV. **Conclusion**:
    - This demonstrates that a lower confidence level results in more frequent comparisons between VAR predictions and actual returns. Therefore, the sensitivity of the backtesting to potential biases in the model increases.‚ñ†

> üí° **Exemplo Num√©rico:**
> Considere um modelo VAR com um horizonte de um dia ($h=1$). Se o n√≠vel de confian√ßa for $\alpha = 0.99$, espera-se que as viola√ß√µes sejam raras, e a cada 100 dias de negocia√ß√£o, apenas 1 dia, em m√©dia, apresentar√° uma perda que ultrapassa o VAR. Se o n√≠vel de confian√ßa for reduzido para $\alpha=0.95$, as viola√ß√µes tornam-se mais frequentes, com uma m√©dia de 5 dias a cada 100, e isso permite uma an√°lise mais detalhada e frequente do modelo.

**Teorema 1**
*Existe um trade-off entre o horizonte de tempo $h$ e o n√≠vel de confian√ßa $\alpha$ no *backtesting*. Diminuir $h$ aumenta o n√∫mero de observa√ß√µes independentes e, portanto, o poder do teste, enquanto diminuir $\alpha$ aumenta a frequ√™ncia de viola√ß√µes do VAR e, tamb√©m, aumenta o poder do teste.*
 *Proof:*
    I. **Initial Setup**:
        - The power of a backtesting test is directly related to the number of independent observations and the frequency of violations.
    
    II. **Main Logical Steps**:
         - From Proposi√ß√£o 1, reducing the time horizon $h$ increases the number of independent observations. An increase in independent observations leads to an increase in the power of the test.
         - From Proposi√ß√£o 2, reducing the confidence level $\alpha$ increases the frequency of violations. More frequent violations increase the data available to backtest, increasing the power of the test.
        
    III. **Key Transformations**:
        - $h \downarrow \implies \text{Number of Independent Observations} \uparrow \implies \text{Test Power} \uparrow$
        - $\alpha \downarrow \implies \text{Frequency of Violations} \uparrow \implies \text{Test Power} \uparrow$

    IV. **Conclusion**:
        - The theorem states that there is a trade-off. Both lowering $h$ and $\alpha$ increase the power of the backtest, supporting the claim. Therefore, this proves the existence of the trade-off.‚ñ†

**Lema 2**
*Seja $N$ o n√∫mero de observa√ß√µes independentes, e seja $X_i$ uma vari√°vel indicadora que vale 1 se a perda observada no per√≠odo $i$ excede o VAR previsto e 0 caso contr√°rio. Se o modelo VAR estiver bem calibrado, ent√£o $X_i$ s√£o vari√°veis aleat√≥rias independentes de Bernoulli com probabilidade de sucesso $1 - \alpha$.*

*Proof:*
   I. **Initial Setup**:
       - $N$ is the number of independent observations.
       - $X_i$ is an indicator variable, where $X_i = 1$ if the loss exceeds the predicted VAR at time $i$, and $X_i = 0$ otherwise.
       - $\alpha$ is the confidence level of the VAR.
       - A well-calibrated VAR model has a probability of $1-\alpha$ of the loss exceeding the VAR.
       - We assume independence between observations.

   II. **Main Logical Steps**:
       - For each observation $i$, there are only two outcomes: the loss exceeds the VAR ($X_i = 1$) or the loss does not exceed the VAR ($X_i = 0$).
       - Under a well-calibrated model, the probability of $X_i = 1$ (a loss exceeding the VAR) is $1 - \alpha$.
       - This is precisely the definition of a Bernoulli trial with a success probability of $1-\alpha$.
       - The independence of the $X_i$ variables comes from the assumption of independence of observations.

   III. **Key Transformations**:
       - $P(X_i=1) = 1-\alpha$.

   IV. **Conclusion**:
       - The variables $X_i$ are independent and follow a Bernoulli distribution with success probability $1-\alpha$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Vamos supor que estamos analisando 252 dias de negocia√ß√£o com um n√≠vel de confian√ßa de 95% ($\alpha=0.95$). Para cada dia $i$, definimos $X_i = 1$ se a perda naquele dia excedeu o VAR previsto e $X_i = 0$ caso contr√°rio. Se o modelo estiver bem calibrado, cada $X_i$ √© uma vari√°vel de Bernoulli com $p = 1 - 0.95 = 0.05$. Isso significa que a probabilidade de uma viola√ß√£o em qualquer dia √© de 5%.

**Teorema 1.1**
*Sob as condi√ß√µes do Lema 2, o n√∫mero de viola√ß√µes do VAR, $V = \sum_{i=1}^N X_i$, segue uma distribui√ß√£o binomial com par√¢metros $N$ e $1-\alpha$, ou seja, $V \sim Bin(N, 1 - \alpha)$.*

*Proof:*
   I. **Initial Setup**:
      - From Lema 2, $X_i$ are independent Bernoulli random variables with success probability $1-\alpha$.
      - $V$ is defined as the sum of these Bernoulli variables: $V = \sum_{i=1}^N X_i$.

   II. **Main Logical Steps**:
      - The sum of $N$ independent Bernoulli random variables with the same success probability follows a binomial distribution.
      - The parameters of the binomial distribution are $N$ (the number of trials) and $1-\alpha$ (the success probability).

   III. **Key Transformations**:
      - $V = \sum_{i=1}^N X_i \implies V \sim Bin(N, 1 - \alpha)$

   IV. **Conclusion**:
      - Therefore, the number of violations $V$ follows a binomial distribution with parameters $N$ and $1-\alpha$. ‚ñ†
> üí° **Exemplo Num√©rico:**
> Continuando o exemplo anterior, onde temos 252 observa√ß√µes independentes ($N=252$) e $\alpha = 0.95$, o n√∫mero total de viola√ß√µes $V$ segue uma distribui√ß√£o binomial com par√¢metros $N=252$ e $p=0.05$, ou seja, $V \sim Bin(252, 0.05)$. Isso nos permite calcular a probabilidade de observar um n√∫mero espec√≠fico de viola√ß√µes, assumindo que o modelo VAR est√° bem calibrado.

**Corol√°rio 1.2**
*A m√©dia e a vari√¢ncia do n√∫mero de viola√ß√µes $V$ s√£o dadas por $E[V] = N(1-\alpha)$ e $Var[V] = N(1-\alpha)\alpha$.*

*Proof:*
   I. **Initial Setup**:
      - From Theorem 1.1, $V \sim Bin(N, 1-\alpha)$.
      - We recall the mean and variance of a binomial distribution.
   II. **Main Logical Steps**:
        - The expected value (mean) of a binomial distribution $Bin(n,p)$ is given by $E[V]=np$.
        - The variance of a binomial distribution $Bin(n,p)$ is given by $Var[V]=np(1-p)$.
   III. **Key Transformations**:
      - Substituting $n = N$ and $p = 1 - \alpha$, we have
      -  $E[V] = N(1-\alpha)$.
      - $Var[V] = N(1-\alpha)(1-(1-\alpha)) = N(1-\alpha)\alpha$.

   IV. **Conclusion**:
     -  This shows that the mean and the variance of $V$ are given by $E[V] = N(1-\alpha)$ and $Var[V] = N(1-\alpha)\alpha$, respectively. ‚ñ†

> üí° **Exemplo Num√©rico:**
> No mesmo exemplo, com $N=252$ e $\alpha=0.95$, a m√©dia do n√∫mero de viola√ß√µes √© $E[V] = 252 \times (1 - 0.95) = 252 \times 0.05 = 12.6$, e a vari√¢ncia √© $Var[V] = 252 \times 0.05 \times 0.95 = 11.97$. Isso significa que, em m√©dia, esperamos 12.6 viola√ß√µes, com uma variabilidade em torno desse valor, quantificada pela vari√¢ncia.

Al√©m disso, √© crucial considerar a autocorrela√ß√£o das perdas. Se as perdas em per√≠odos sucessivos forem correlacionadas, a suposi√ß√£o de independ√™ncia das observa√ß√µes pode ser violada, comprometendo a validade do *backtesting*.

**Proposi√ß√£o 3**
    *A autocorrela√ß√£o positiva das perdas pode levar a um excesso de viola√ß√µes do VAR em clusters, o que pode reduzir o poder de um *backtesting* que assume independ√™ncia das observa√ß√µes.*
    *Proof:*
       I. **Initial Setup**:
        -  Assume positive autocorrelation in losses.
        -  Assume that we are using a backtesting method that assumes independence.
        
       II. **Main Logical Steps**:
           - Positive autocorrelation implies that if a loss exceeds the VAR in a given period, the probability of a loss exceeding the VAR in the next period is higher than expected under independence.
           - This causes violations to occur in clusters, i.e. if one violation occurs, the probability of seeing more violations in close succession is higher.
           - When violations cluster, the assumption of independent Bernoulli trials underlying most backtesting procedures is violated.
           - The methods assume that the number of violations is a realization of a binomial distribution, which does not hold under autocorrelation.
           - Since the number of observations is reduced, a clustered violation process has less power than an independent violation process.

       III. **Key Transformations**:
           - Autocorrelation $\implies$ violation clusters
           - Clusters $\implies$ violation of independence
           - Violation of independence $\implies$ Reduction in the power of the test

       IV. **Conclusion**:
        - Therefore, positive autocorrelation can lead to clustered violations, and reduce the effectiveness of backtesting.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
> Suponha que as perdas do dia atual sejam positivamente correlacionadas com as perdas do dia anterior. Se o VAR for violado hoje, √© mais prov√°vel que ele seja violado amanh√£ tamb√©m. Isso cria *clusters* de viola√ß√µes, onde v√°rios dias consecutivos apresentam perdas acima do VAR, em vez de viola√ß√µes aleat√≥rias e independentes. Um modelo que ignora essa autocorrela√ß√£o pode n√£o capturar a din√¢mica real do risco.
    
**Lema 3**
*Para detectar a presen√ßa de autocorrela√ß√£o nas viola√ß√µes do VAR, pode-se realizar um teste de raz√£o de verossimilhan√ßa (LR) de independ√™ncia de viola√ß√µes, ou similar, como o teste de Kupiec ou Christoffersen.*

    *Proof:*
     I. **Initial Setup**:
          - We want to detect if there is autocorrelation in the violations of the VAR model.
          - We know that violations of a well-calibrated VAR should be independent events.

     II. **Main Logical Steps**:
          - The test of the likelihood ratio (LR) is designed to test the hypothesis that the distribution of the violations is independent.
          - The Kupiec test checks if the overall violation rate is consistent with the confidence level, implicitly assuming independence over time.
          - The Christoffersen test is specifically designed to test for both correct violation rate and independence over time.

     III. **Key Transformations**:
          - These tests check the null hypothesis of independence against the alternative of an autocorrelation in the violations.

     IV. **Conclusion**:
          -  The LR test and specific tests such as Kupiec and Christoffersen can all detect the presence of autocorrelation, supporting the claim. ‚ñ†
> üí° **Exemplo Num√©rico:**
>  Se os resultados do *backtesting* mostram uma sequ√™ncia de viola√ß√µes em dias pr√≥ximos (por exemplo, viola√ß√µes nos dias 1, 2, 3, e depois nenhuma viola√ß√£o por v√°rias semanas, e em seguida viola√ß√µes nos dias 45 e 46) isso levanta suspeitas de autocorrela√ß√£o. Testes como o de Christoffersen ajudam a quantificar essa suspeita, e a verificar se os *clusters* de viola√ß√£o s√£o estatisticamente significativos ou apenas devidos ao acaso.

**Proposi√ß√£o 4**
    *A presen√ßa de *clusters* de viola√ß√µes, causada por autocorrela√ß√£o, implica que a vari√¢ncia do n√∫mero de viola√ß√µes pode ser maior do que o previsto pela distribui√ß√£o binomial sob a hip√≥tese de independ√™ncia.*
    
  *Proof:*
  
    I. **Initial Setup**:
        - Assume that the violations are positively autocorrelated, so that violations tend to cluster together.
        - Let $X_i$ be indicator variables such that $X_i = 1$ if there is a violation at time $i$ and 0 otherwise.
        - Let the number of violations be given by $V=\sum_{i=1}^N X_i$.
        
    II. **Main Logical Steps**:
        - If the violations were independent, then we could calculate the variance of the total number of violations using the fact that it follows a binomial distribution (as shown in Corol√°rio 1.2). In that case, $Var[V] = N(1-\alpha)\alpha$.
        - However, because of autocorrelation, the $X_i$ are not independent. The variance of the sum of correlated random variables is not the sum of the variances.
        - If $\text{Cov}(X_i,X_j) > 0$ for at least some $i \neq j$, then $Var[\sum X_i] > \sum Var[X_i]$.
        - The autocorrelation causes $\text{Cov}(X_i,X_j) > 0$, implying that the variance of the sum will be greater than if the $X_i$ were independent.

   III. **Key Transformations**:
       - Autocorrelation $\implies \text{Cov}(X_i,X_j) > 0$.
       -  $\text{Cov}(X_i,X_j) > 0$  $\implies$  $Var[\sum X_i] > \sum Var[X_i]$
       - $Var[\sum X_i] > \sum Var[X_i]$ $\implies$ $Var[V] > N(1-\alpha)\alpha$

   IV. **Conclusion**:
      -  The presence of autocorrelation increases the variance of the sum of violations over the case with independent variables.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
>  Usando o exemplo de 252 observa√ß√µes com $\alpha = 0.95$, sob a hip√≥tese de independ√™ncia, a vari√¢ncia do n√∫mero de viola√ß√µes √© de 11.97. No entanto, se houver autocorrela√ß√£o positiva, a vari√¢ncia real das viola√ß√µes pode ser muito maior. Por exemplo, se as viola√ß√µes ocorrem em *clusters*, a vari√¢ncia poderia ser 20 ou at√© mais. Isso significa que as viola√ß√µes ser√£o mais vari√°veis do que o esperado sob o modelo binomial, e o modelo de VAR pode estar subestimando o risco.
   
**Teorema 2**
 *O teste de Kupiec √© um teste de hip√≥tese para verificar se a frequ√™ncia de viola√ß√µes do VAR √© estatisticamente diferente do esperado dado o n√≠vel de confian√ßa $\alpha$. Ele testa a hip√≥tese nula de que a frequ√™ncia de viola√ß√µes observada √© consistente com a frequ√™ncia esperada sob um modelo bem calibrado.*

 *Proof:*
    I. **Initial Setup**:
      - The null hypothesis ($H_0$) is that the model is well-calibrated, i.e., the observed violation rate matches the expected violation rate.
      - The alternative hypothesis ($H_1$) is that the model is not well-calibrated, i.e., the observed violation rate is different from the expected rate.
      - Let $V$ be the observed number of violations, $N$ the number of independent observations, and $\alpha$ the confidence level.
      - We know that if the model is well-calibrated, the number of violations follows a binomial distribution $V \sim Bin(N, 1-\alpha)$.
      
    II. **Main Logical Steps**:
      -  The Kupiec test uses a likelihood ratio test to compare the likelihood under the null hypothesis (where $p = 1-\alpha$) with the likelihood of a model that admits a free violation probability $\hat{p}$ estimated from data (observed frequency of violations, i.e., $\hat{p} = V/N$).
      - The likelihood ratio statistic is constructed based on the binomial distribution.
      - The statistic is asymptotically chi-squared distributed, which allows for the construction of the test.
      
    III. **Key Transformations**:
      - Let $p$ be the expected probability of violation under the null hypothesis $p = 1-\alpha$.
      - The likelihood function is given by $L(p) = \binom{N}{V} p^V (1-p)^{N-V}$.
      - The test statistic is given by $-2ln\frac{L(1-\alpha)}{L(\hat{p})}$.
      - Under the null hypothesis, this statistic converges in distribution to a $\chi^2(1)$.

    IV. **Conclusion**:
      -  The Kupiec test checks if the frequency of violations is statistically different from that expected under the well-calibrated model hypothesis, using the distribution of the violations implied by a model with binomial violations. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que em 252 dias com um n√≠vel de confian√ßa de 95%, um modelo VAR tenha apresentado 20 viola√ß√µes. Sob a hip√≥tese nula de que o modelo est√° bem calibrado, o n√∫mero esperado de viola√ß√µes √© de 12.6. O teste de Kupiec calcula uma estat√≠stica de teste que compara a probabilidade de observar 20 viola√ß√µes se o modelo estiver bem calibrado com a probabilidade de observar 20 viola√ß√µes com a probabilidade de viola√ß√£o observada nos dados (20/252). Essa estat√≠stica de teste segue uma distribui√ß√£o $\chi^2$ com 1 grau de liberdade. Se o valor da estat√≠stica de teste for muito alto (e o p-valor correspondente for baixo), rejeita-se a hip√≥tese de que o modelo est√° bem calibrado e conclui-se que o modelo est√° subestimando o risco.
 
 **Lema 4**
 *O teste de Christoffersen testa se as viola√ß√µes do VAR s√£o independentes ao longo do tempo, e, portanto, se h√° *clusters* de viola√ß√µes. Ele testa a hip√≥tese nula de independ√™ncia das viola√ß√µes contra a hip√≥tese alternativa de que as viola√ß√µes seguem um processo de Markov de primeira ordem.*

    *Proof:*
    I. **Initial Setup**:
         - Null Hypothesis $H_0$: The violations are independent over time.
         - Alternative Hypothesis $H_1$: The violations follow a first-order Markov process (i.e., the probability of a violation depends on whether the previous observation was a violation or not).
         - $X_t$ is an indicator variable that is 1 if a violation occurs at time t, and 0 otherwise.

    II. **Main Logical Steps**:
         -  The Christoffersen test examines the transitions between violation and no-violation states using a likelihood ratio test.
         - Under $H_0$, the probability of a violation at time $t$ is independent of the occurrence of a violation at time $t-1$.
         - Under $H_1$, the probability of a violation depends on whether there was a violation in the previous period.
         - This dependence is expressed using a transition matrix:
        $$
        \begin{bmatrix}
          \pi_{00} & \pi_{01} \\
          \pi_{10} & \pi_{11}
        \end{bmatrix}
        $$
         where $\pi_{ij}$ is the probability of observing $X_t=j$ given $X_{t-1} = i$.
        
    III. **Key Transformations**:
         - The likelihood function under the null hypothesis (independence) is compared to the likelihood under the alternative hypothesis (Markov model).
         - The likelihood ratio is used to evaluate if the alternative hypothesis fits the data significantly better than the null hypothesis.
         - The test statistic is asymptotically chi-squared distributed.
        
    IV. **Conclusion**:
         -  The Christoffersen test determines if the observed transitions between violations and no-violations are consistent with the assumption of independence (i.e., if violations are clustered). ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que temos 252 dias de dados, e as viola√ß√µes do VAR ocorrem em sequ√™ncia. Por exemplo, se tivermos uma viola√ß√£o no dia $t-1$, a probabilidade de ter uma viola√ß√£o no dia $t$ √© muito maior do que se n√£o tivermos uma viola√ß√£o no dia $t-1$. O teste de Christoffersen verifica se essas transi√ß√µes entre estados (viola√ß√£o/n√£o-viola√ß√£o) s√£o estatisticamente significativas e inconsistentes com a hip√≥tese de independ√™ncia. Ele estima a matriz de transi√ß√£o e compara a probabilidade de os dados terem sido gerados por uma cadeia de Markov ou por um processo independente, calculando uma estat√≠stica de teste, que segue uma distribui√ß√£o $\chi^2$.

    
**Teorema 2.1**
    *O teste de Christoffersen tamb√©m avalia se a frequ√™ncia de viola√ß√µes √© consistente com o n√≠vel de confian√ßa $\alpha$, simultaneamente com a avalia√ß√£o da independ√™ncia das viola√ß√µes.*

    *Proof:*
        I. **Initial Setup**:
            - The null hypothesis for the Christoffersen test is that the model is well-calibrated and that the violations are independent of each other.
            - The alternative hypothesis is that either the violation frequency is not correct or the violations are not independent.
            -  The null hypothesis is given by $H_0: \pi_{01}=\pi_{11} = 1-\alpha$.

        II. **Main Logical Steps**:
            - The Christoffersen test is actually a joint test. It is composed of two likelihood ratio (LR) tests.
            -  The first LR test looks at whether the frequency of violations is compatible with the confidence level $\alpha$. This part of the test does not test independence.
            - The second LR test checks if there is statistical evidence of dependence on the previous state. This second test checks independence.
            - If we reject the null hypothesis in the Christoffersen test, it means that the data is incompatible with the assumption that the violations are both independent and have the correct frequency.
            
        III. **Key Transformations**:
            - The first test checks if $\pi_{01}=\pi_{11}=1-\alpha$ jointly. If not, then either the frequency or the independence is rejected.
            - The second test checks the independence of the violations, by testing if $\pi_{01}=\pi_{11}$.
            - The combination of both tests gives the Christoffersen test statistic.
            
        IV. **Conclusion**:
            -  Because of the structure of the test, the Christoffersen test assesses both the frequency of violations and the independence of the violations simultaneously. Therefore, it assesses if both the frequency of violations is consistent with $\alpha$ and if the violations are independent of each other, simultaneously.  ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Continuando o exemplo anterior, o teste de Christoffersen n√£o apenas verifica se a frequ√™ncia de viola√ß√µes √© aproximadamente 5% (se $\alpha=0.95$), mas tamb√©m se a ocorr√™ncia de uma viola√ß√£o em um dia aumenta a probabilidade de uma viola√ß√£o no dia seguinte. Ele faz isso de forma simult√¢nea. Isso √© especialmente importante porque um modelo pode ter a frequ√™ncia de viola√ß√µes correta, mas as viola√ß√µes ocorrem em *clusters*, o que o teste de Christoffersen √© capaz de detectar.
    
**Proposi√ß√£o 5**
   *Al√©m do teste de Kupiec e do teste de Christoffersen, existem outros testes de *backtesting* como o teste de Lopez, o teste de correla√ß√£o serial, e testes baseados em fun√ß√µes de perda, que podem complementar a an√°lise do desempenho do modelo VAR.*
   *Proof:*
        I. **Initial Setup**:
            - The Kupiec and Christoffersen tests are not exhaustive.
            - There are other ways to evaluate a VAR model through backtesting.
        II. **Main Logical Steps**:
            - The Lopez test assesses the magnitude of losses that violate the VAR, not just the frequency. It uses a loss function that considers both the number and the size of the violations.
            - Tests of serial correlation can detect if violations cluster or are predictable, which is undesirable. For example, the Ljung-Box test.
            - Test based on loss functions (such as the tick loss) can be tailored to capture specific properties that are relevant for the user.
        III. **Key Transformations**:
             - The Lopez test, tests of serial correlation, and loss function-based tests provide additional tests that measure aspects of the VAR model not assessed by the Kupiec and Christoffersen test.
       IV. **Conclusion**:
            -  These other tests are useful to evaluate if the VAR model is adequate to a certain situation, and offer a more complete picture of the VAR model‚Äôs quality. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que o teste de Kupiec tenha aprovado um modelo VAR com um n√≠vel de confian√ßa de 95% mas o teste de Christoffersen tenha rejeitado o modelo por apresentar autocorrela√ß√£o. Nesse caso, podemos aplicar outros testes de *backtesting*. Por exemplo, o teste de Lopez poder√° apontar
que as viola√ß√µes do VAR s√£o muito maiores do que o esperado. Um teste de correla√ß√£o serial poder√° confirmar que as viola√ß√µes est√£o clusterizadas. Um teste baseado em fun√ß√µes de perda poder√° indicar que as perdas acima do### Model Backtesting and Horizon Selection in VAR

### Introdu√ß√£o
Em continuidade ao estudo do Value at Risk (VAR) e suas aplica√ß√µes, este cap√≠tulo aborda um aspecto crucial para a valida√ß√£o e confiabilidade dos modelos: o *backtesting*. Como vimos anteriormente, o VAR √© uma medida de risco que resume a potencial perda em um determinado horizonte de tempo e n√≠vel de confian√ßa [^1]. No entanto, a precis√£o do VAR depende da qualidade dos dados e da adequa√ß√£o do modelo utilizado. O *backtesting* √© uma ferramenta essencial para avaliar a performance de um modelo VAR e identificar poss√≠veis vieses nas previs√µes [^1]. Esta se√ß√£o se aprofundar√° nos crit√©rios para realizar o *backtesting*, com foco especial na import√¢ncia do horizonte de tempo na efic√°cia dos testes.

### Conceitos Fundamentais
O *backtesting* consiste em comparar sistematicamente as previs√µes de perdas obtidas por meio do VAR com as perdas e lucros (P&L) efetivamente realizados posteriormente [^1]. O objetivo principal do *backtesting* √© detectar vieses ou inconsist√™ncias nos resultados do VAR, garantindo que o modelo esteja gerando previs√µes confi√°veis. A ideia central √© que um modelo VAR bem calibrado deve ser capaz de prever a frequ√™ncia com que as perdas efetivas excedem o VAR previsto, alinhando-se com o n√≠vel de confian√ßa estabelecido [^2].

Para realizar um *backtesting* eficaz, √© fundamental levar em considera√ß√£o o horizonte de tempo utilizado no c√°lculo do VAR. A escolha do horizonte de tempo influencia diretamente o n√∫mero de observa√ß√µes independentes dispon√≠veis para o teste, afetando o poder estat√≠stico do mesmo [^1]. O poder de um teste refere-se √† sua capacidade de detectar desvios significativos entre as previs√µes do VAR e os resultados reais.

Como mencionado anteriormente, o horizonte de tempo √© um dos fatores quantitativos que influenciam o c√°lculo do VAR. Em geral, um horizonte mais longo leva a um VAR maior. Ao usar o VAR como uma medida de risco potencial, o horizonte de tempo deve ser definido pela liquidez dos ativos, ou seja, o tempo necess√°rio para liquidar o portf√≥lio sem grandes impactos no mercado [^1].

#### O Impacto do Horizonte de Tempo no Backtesting
A escolha do horizonte de tempo tem um impacto significativo no n√∫mero de observa√ß√µes independentes dispon√≠veis para o *backtesting*. Um horizonte mais longo reduz o n√∫mero de observa√ß√µes independentes em um determinado per√≠odo. Por exemplo, se utilizarmos um horizonte de VAR de duas semanas, teremos apenas 26 observa√ß√µes independentes por ano [^1]. Por outro lado, um horizonte de um dia fornecer√° aproximadamente 252 observa√ß√µes independentes ao longo de um ano [^1].

O poder do teste, ou seja, a capacidade de detectar vieses no modelo, est√° diretamente relacionado ao n√∫mero de observa√ß√µes independentes. Com um n√∫mero maior de observa√ß√µes, o teste se torna mais sens√≠vel a desvios entre as previs√µes do VAR e as perdas efetivas [^1]. Por isso, para fins de *backtesting*, √© prefer√≠vel utilizar horizontes de tempo mais curtos, como um dia, para maximizar o poder dos testes [^1].

**Proposi√ß√£o 1**
   *A escolha de um horizonte de tempo $h$ para o c√°lculo do VAR implica que, em um per√≠odo de $T$ dias, temos aproximadamente $T/h$ observa√ß√µes independentes. Para um dado per√≠odo de tempo $T$, o n√∫mero de observa√ß√µes independentes √© inversamente proporcional ao tamanho do horizonte $h$.*
   
   *Proof:*

   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Each observation period for the VAR spans $h$ days.

   II. **Main Logical Steps**:
      - The total number of days, $T$, is divided by the length of each observation period, $h$, to determine the number of non-overlapping observation periods.
      - This gives the number of independent observations.

   III. **Key Transformations**:
      -  Number of independent observations $\approx \frac{T}{h}$

   IV. **Conclusion**:
      - As $h$ increases, $T/h$ decreases, implying an inverse relationship between $h$ and the number of independent observations for a fixed $T$.
      - This proves the statement: "the number of independent observations is inversely proportional to the size of the horizon $h$". ‚ñ†
> üí° **Exemplo Num√©rico:**
> Suponha que temos um per√≠odo de $T = 252$ dias (um ano de negocia√ß√£o). Se usarmos um horizonte de tempo $h = 1$ dia, teremos aproximadamente $252/1 = 252$ observa√ß√µes independentes. Se aumentarmos o horizonte para $h = 5$ dias (uma semana), teremos $252/5 \approx 50$ observa√ß√µes independentes. E se o horizonte for $h=21$ (aproximadamente um m√™s), teremos $252/21=12$ observa√ß√µes independentes. Este exemplo ilustra claramente a rela√ß√£o inversa entre o horizonte de tempo e o n√∫mero de observa√ß√µes independentes.

#### Rela√ß√£o com o N√≠vel de Confian√ßa
√â importante notar que o n√≠vel de confian√ßa tamb√©m influencia o n√∫mero de observa√ß√µes na cauda da distribui√ß√£o. N√≠veis de confian√ßa mais altos, como 99%, resultam em menos observa√ß√µes na cauda, dificultando a identifica√ß√£o de vieses no modelo. Em outras palavras, para confirmar a validade do modelo com um n√≠vel de confian√ßa de 99%, seria necess√°rio um longo per√≠odo de observa√ß√µes para coletar dados suficientes na cauda da distribui√ß√£o [^1]. Por isso, para o *backtesting*, n√≠veis de confian√ßa mais baixos, como 95%, podem ser prefer√≠veis, permitindo uma an√°lise mais frequente dos resultados do modelo [^1].

**Lema 1**
   *Para um n√≠vel de confian√ßa $\alpha$, o n√∫mero de observa√ß√µes esperadas na cauda da distribui√ß√£o em um per√≠odo $T$ com horizonte de tempo $h$ √© aproximadamente $(1-\alpha)T/h$.*

   *Proof:*
   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Let $\alpha$ be the confidence level.
      - The number of independent observations is approximately $T/h$.

   II. **Main Logical Steps**:
       - With a confidence level $\alpha$, the probability of an observation falling in the tail (exceeding the VAR) is $1 - \alpha$.
       - The expected number of observations in the tail is the product of the number of independent observations and the probability of falling in the tail.

   III. **Key Transformations**:
        - Expected number of observations in the tail $\approx \frac{T}{h} \times (1-\alpha) = (1-\alpha) \frac{T}{h}$

   IV. **Conclusion**:
      - This shows that the expected number of observations in the tail is approximately $(1-\alpha)T/h$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Usando o exemplo anterior com $T=252$ dias e um horizonte de $h=1$ dia, se o n√≠vel de confian√ßa for $\alpha = 0.95$ (95%), o n√∫mero esperado de observa√ß√µes na cauda √© $(1-0.95) \times 252/1 = 0.05 \times 252 = 12.6$. Isso significa que, em m√©dia, esperamos que o VAR seja violado aproximadamente 12 ou 13 vezes em um ano. Se o n√≠vel de confian√ßa for $\alpha=0.99$, o n√∫mero esperado de viola√ß√µes cai para $(1-0.99) \times 252 = 0.01 \times 252 = 2.52$, indicando que seria necess√°rio um per√≠odo muito maior de observa√ß√µes para testar o modelo de forma eficaz. Se, por outro lado, mantemos o n√≠vel de confian√ßa em 95% mas aumentamos o horizonte para $h=5$, o n√∫mero de observa√ß√µes na cauda ser√° $(1-0.95)\times 252/5 \approx 2.5$.
  
**Corol√°rio 1.1**
   *O n√∫mero de observa√ß√µes na cauda √© diretamente proporcional ao per√≠odo $T$ e inversamente proporcional ao horizonte $h$, e diminui com o aumento do n√≠vel de confian√ßa $\alpha$.*

   *Proof:*
   I. **Initial Setup**:
       - From Lema 1, the number of observations in the tail is approximately $(1-\alpha)T/h$.

   II. **Main Logical Steps**:
       - We analyze the effect of $T$, $h$, and $\alpha$ on this expression.

   III. **Key Transformations**:
        - As $T$ increases, the number of observations in the tail increases proportionally.
        - As $h$ increases, the number of observations in the tail decreases proportionally.
        - As $\alpha$ increases, $(1-\alpha)$ decreases, thus decreasing the number of observations in the tail.

   IV. **Conclusion**:
        -  This confirms the statement that the number of tail observations is directly proportional to $T$, inversely proportional to $h$, and decreases with an increase in $\alpha$. ‚ñ†

Al√©m disso, vale ressaltar que a escolha do n√≠vel de confian√ßa afeta o tipo de erros que o *backtesting* ser√° capaz de detectar. Um n√≠vel de confian√ßa mais alto prioriza a detec√ß√£o de erros na cauda da distribui√ß√£o, enquanto um n√≠vel de confian√ßa mais baixo permite uma detec√ß√£o mais frequente de erros, ainda que menos extremos.

**Proposi√ß√£o 2**
    *Um n√≠vel de confian√ßa mais baixo aumenta a frequ√™ncia com que os resultados do VAR s√£o comparados com os retornos realizados, e, consequentemente, aumenta a sensibilidade a potenciais vieses no modelo.*
  
  *Proof:*

  I. **Initial Setup**:
    - Let $\alpha$ be the confidence level.
    - A lower confidence level implies a smaller $\alpha$.
    - VAR is calculated for a given confidence level.

  II. **Main Logical Steps**:
    - A lower confidence level (smaller $\alpha$) corresponds to a lower VAR value (since the VAR is a quantile).
    - A lower VAR value means a greater chance of actual losses exceeding the VAR.
    - If the actual loss exceeds the VAR value, this is considered a violation in the backtesting process.
    - More violations mean more comparisons between VAR and actual returns.

  III. **Key Transformations**:
    - Lower $\alpha$  $\implies$ Lower VAR
    - Lower VAR $\implies$ More violations
    - More violations $\implies$ More frequent comparisons between VAR and actual returns

  IV. **Conclusion**:
    - This demonstrates that a lower confidence level results in more frequent comparisons between VAR predictions and actual returns. Therefore, the sensitivity of the backtesting to potential biases in the model increases.‚ñ†

> üí° **Exemplo Num√©rico:**
> Considere um modelo VAR com um horizonte de um dia ($h=1$). Se o n√≠vel de confian√ßa for $\alpha = 0.99$, espera-se que as viola√ß√µes sejam raras, e a cada 100 dias de negocia√ß√£o, apenas 1 dia, em m√©dia, apresentar√° uma perda que ultrapassa o VAR. Se o n√≠vel de confian√ßa for reduzido para $\alpha=0.95$, as viola√ß√µes tornam-se mais frequentes, com uma m√©dia de 5 dias a cada 100, e isso permite uma an√°lise mais detalhada e frequente do modelo.

**Teorema 1**
*Existe um trade-off entre o horizonte de tempo $h$ e o n√≠vel de confian√ßa $\alpha$ no *backtesting*. Diminuir $h$ aumenta o n√∫mero de observa√ß√µes independentes e, portanto, o poder do teste, enquanto diminuir $\alpha$ aumenta a frequ√™ncia de viola√ß√µes do VAR e, tamb√©m, aumenta o poder do teste.*
 *Proof:*
    I. **Initial Setup**:
        - The power of a backtesting test is directly related to the number of independent observations and the frequency of violations.
    
    II. **Main Logical Steps**:
         - From Proposi√ß√£o 1, reducing the time horizon $h$ increases the number of independent observations. An increase in independent observations leads to an increase in the power of the test.
         - From Proposi√ß√£o 2, reducing the confidence level $\alpha$ increases the frequency of violations. More frequent violations increase the data available to backtest, increasing the power of the test.
        
    III. **Key Transformations**:
        - $h \downarrow \implies \text{Number of Independent Observations} \uparrow \implies \text{Test Power} \uparrow$
        - $\alpha \downarrow \implies \text{Frequency of Violations} \uparrow \implies \text{Test Power} \uparrow$

    IV. **Conclusion**:
        - The theorem states that there is a trade-off. Both lowering $h$ and $\alpha$ increase the power of the backtest, supporting the claim. Therefore, this proves the existence of the trade-off.‚ñ†

**Lema 2**
*Seja $N$ o n√∫mero de observa√ß√µes independentes, e seja $X_i$ uma vari√°vel indicadora que vale 1 se a perda observada no per√≠odo $i$ excede o VAR previsto e 0 caso contr√°rio. Se o modelo VAR estiver bem calibrado, ent√£o $X_i$ s√£o vari√°veis aleat√≥rias independentes de Bernoulli com probabilidade de sucesso $1 - \alpha$.*

*Proof:*
   I. **Initial Setup**:
       - $N$ is the number of independent observations.
       - $X_i$ is an indicator variable, where $X_i = 1$ if the loss exceeds the predicted VAR at time $i$, and $X_i = 0$ otherwise.
       - $\alpha$ is the confidence level of the VAR.
       - A well-calibrated VAR model has a probability of $1-\alpha$ of the loss exceeding the VAR.
       - We assume independence between observations.

   II. **Main Logical Steps**:
       - For each observation $i$, there are only two outcomes: the loss exceeds the VAR ($X_i = 1$) or the loss does not exceed the VAR ($X_i = 0$).
       - Under a well-calibrated model, the probability of $X_i = 1$ (a loss exceeding the VAR) is $1 - \alpha$.
       - This is precisely the definition of a Bernoulli trial with a success probability of $1-\alpha$.
       - The independence of the $X_i$ variables comes from the assumption of independence of observations.

   III. **Key Transformations**:
       - $P(X_i=1) = 1-\alpha$.

   IV. **Conclusion**:
       - The variables $X_i$ are independent and follow a Bernoulli distribution with success probability $1-\alpha$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Vamos supor que estamos analisando 252 dias de negocia√ß√£o com um n√≠vel de confian√ßa de 95% ($\alpha=0.95$). Para cada dia $i$, definimos $X_i = 1$ se a perda naquele dia excedeu o VAR previsto e $X_i = 0$ caso contr√°rio. Se o modelo estiver bem calibrado, cada $X_i$ √© uma vari√°vel de Bernoulli com $p = 1 - 0.95 = 0.05$. Isso significa que a probabilidade de uma viola√ß√£o em qualquer dia √© de 5%.

**Teorema 1.1**
*Sob as condi√ß√µes do Lema 2, o n√∫mero de viola√ß√µes do VAR, $V = \sum_{i=1}^N X_i$, segue uma distribui√ß√£o binomial com par√¢metros $N$ e $1-\alpha$, ou seja, $V \sim Bin(N, 1 - \alpha)$.*

*Proof:*
   I. **Initial Setup**:
      - From Lema 2, $X_i$ are independent Bernoulli random variables with success probability $1-\alpha$.
      - $V$ is defined as the sum of these Bernoulli variables: $V = \sum_{i=1}^N X_i$.

   II. **Main Logical Steps**:
      - The sum of $N$ independent Bernoulli random variables with the same success probability follows a binomial distribution.
      - The parameters of the binomial distribution are $N$ (the number of trials) and $1-\alpha$ (the success probability).

   III. **Key Transformations**:
      - $V = \sum_{i=1}^N X_i \implies V \sim Bin(N, 1 - \alpha)$

   IV. **Conclusion**:
      - Therefore, the number of violations $V$ follows a binomial distribution with parameters $N$ and $1-\alpha$. ‚ñ†
> üí° **Exemplo Num√©rico:**
> Continuando o exemplo anterior, onde temos 252 observa√ß√µes independentes ($N=252$) e $\alpha = 0.95$, o n√∫mero total de viola√ß√µes $V$ segue uma distribui√ß√£o binomial com par√¢metros $N=252$ e $p=0.05$, ou seja, $V \sim Bin(252, 0.05)$. Isso nos permite calcular a probabilidade de observar um n√∫mero espec√≠fico de viola√ß√µes, assumindo que o modelo VAR est√° bem calibrado.

**Corol√°rio 1.2**
*A m√©dia e a vari√¢ncia do n√∫mero de viola√ß√µes $V$ s√£o dadas por $E[V] = N(1-\alpha)$ e $Var[V] = N(1-\alpha)\alpha$.*

*Proof:*
   I. **Initial Setup**:
      - From Theorem 1.1, $V \sim Bin(N, 1-\alpha)$.
      - We recall the mean and variance of a binomial distribution.
   II. **Main Logical Steps**:
        - The expected value (mean) of a binomial distribution $Bin(n,p)$ is given by $E[V]=np$.
        - The variance of a binomial distribution $Bin(n,p)$ is given by $Var[V]=np(1-p)$.
   III. **Key Transformations**:
      - Substituting $n = N$ and $p = 1 - \alpha$, we have
      -  $E[V] = N(1-\alpha)$.
      - $Var[V] = N(1-\alpha)(1-(1-\alpha)) = N(1-\alpha)\alpha$.

   IV. **Conclusion**:
     -  This shows that the mean and the variance of $V$ are given by $E[V] = N(1-\alpha)$ and $Var[V] = N(1-\alpha)\alpha$, respectively. ‚ñ†

> üí° **Exemplo Num√©rico:**
> No mesmo exemplo, com $N=252$ e $\alpha=0.95$, a m√©dia do n√∫mero de viola√ß√µes √© $E[V] = 252 \times (1 - 0.95) = 252 \times 0.05 = 12.6$, e a vari√¢ncia √© $Var[V] = 252 \times 0.05 \times 0.95 = 11.97$. Isso significa que, em m√©dia, esperamos 12.6 viola√ß√µes, com uma variabilidade em torno desse valor, quantificada pela vari√¢ncia.

Al√©m disso, √© crucial considerar a autocorrela√ß√£o das perdas. Se as perdas em per√≠odos sucessivos forem correlacionadas, a suposi√ß√£o de independ√™ncia das observa√ß√µes pode ser violada, comprometendo a validade do *backtesting*.

**Proposi√ß√£o 3**
    *A autocorrela√ß√£o positiva das perdas pode levar a um excesso de viola√ß√µes do VAR em clusters, o que pode reduzir o poder de um *backtesting* que assume independ√™ncia das observa√ß√µes.*
    *Proof:*
       I. **Initial Setup**:
        -  Assume positive autocorrelation in losses.
        -  Assume that we are using a backtesting method that assumes independence.
        
       II. **Main Logical Steps**:
           - Positive autocorrelation implies that if a loss exceeds the VAR in a given period, the probability of a loss exceeding the VAR in the next period is higher than expected under independence.
           - This causes violations to occur in clusters, i.e. if one violation occurs, the probability of seeing more violations in close succession is higher.
           - When violations cluster, the assumption of independent Bernoulli trials underlying most backtesting procedures is violated.
           - The methods assume that the number of violations is a realization of a binomial distribution, which does not hold under autocorrelation.
           - Since the number of observations is reduced, a clustered violation process has less power than an independent violation process.

       III. **Key Transformations**:
           - Autocorrelation $\implies$ violation clusters
           - Clusters $\implies$ violation of independence
           - Violation of independence $\implies$ Reduction in the power of the test

       IV. **Conclusion**:
        - Therefore, positive autocorrelation can lead to clustered violations, and reduce the effectiveness of backtesting.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
> Suponha que as perdas do dia atual sejam positivamente correlacionadas com as perdas do dia anterior. Se o VAR for violado hoje, √© mais prov√°vel que ele seja violado amanh√£ tamb√©m. Isso cria *clusters* de viola√ß√µes, onde v√°rios dias consecutivos apresentam perdas acima do VAR, em vez de viola√ß√µes aleat√≥rias e independentes. Um modelo que ignora essa autocorrela√ß√£o pode n√£o capturar a din√¢mica real do risco.
    
**Lema 3**
*Para detectar a presen√ßa de autocorrela√ß√£o nas viola√ß√µes do VAR, pode-se realizar um teste de raz√£o de verossimilhan√ßa (LR) de independ√™ncia de viola√ß√µes, ou similar, como o teste de Kupiec ou Christoffersen.*

    *Proof:*
     I. **Initial Setup**:
          - We want to detect if there is autocorrelation in the violations of the VAR model.
          - We know that violations of a well-calibrated VAR should be independent events.

     II. **Main Logical Steps**:
          - The test of the likelihood ratio (LR) is designed to test the hypothesis that the distribution of the violations is independent.
          - The Kupiec test checks if the overall violation rate is consistent with the confidence level, implicitly assuming independence over time.
          - The Christoffersen test is specifically designed to test for both correct violation rate and independence over time.

     III. **Key Transformations**:
          - These tests check the null hypothesis of independence against the alternative of an autocorrelation in the violations.

     IV. **Conclusion**:
          -  The LR test and specific tests such as Kupiec and Christoffersen can all detect the presence of autocorrelation, supporting the claim. ‚ñ†
> üí° **Exemplo Num√©rico:**
>  Se os resultados do *backtesting* mostram uma sequ√™ncia de viola√ß√µes em dias pr√≥ximos (por exemplo, viola√ß√µes nos dias 1, 2, 3, e depois nenhuma viola√ß√£o por v√°rias semanas, e em seguida viola√ß√µes nos dias 45 e 46) isso levanta suspeitas de autocorrela√ß√£o. Testes como o de Christoffersen ajudam a quantificar essa suspeita, e a verificar se os *clusters* de viola√ß√£o s√£o estatisticamente significativos ou apenas devidos ao acaso.

**Proposi√ß√£o 4**
    *A presen√ßa de *clusters* de viola√ß√µes, causada por autocorrela√ß√£o, implica que a vari√¢ncia do n√∫mero de viola√ß√µes pode ser maior do que o previsto pela distribui√ß√£o binomial sob a hip√≥tese de independ√™ncia.*
    
  *Proof:*
  
    I. **Initial Setup**:
        - Assume that the violations are positively autocorrelated, so that violations tend to cluster together.
        - Let $X_i$ be indicator variables such that $X_i = 1$ if there is a violation at time $i$ and 0 otherwise.
        - Let the number of violations be given by $V=\sum_{i=1}^N X_i$.
        
    II. **Main Logical Steps**:
        - If the violations were independent, then we could calculate the variance of the total number of violations using the fact that it follows a binomial distribution (as shown in Corol√°rio 1.2). In that case, $Var[V] = N(1-\alpha)\alpha$.
        - However, because of autocorrelation, the $X_i$ are not independent. The variance of the sum of correlated random variables is not the sum of the variances.
        - If $\text{Cov}(X_i,X_j) > 0$ for at least some $i \neq j$, then $Var[\sum X_i] > \sum Var[X_i]$.
        - The autocorrelation causes $\text{Cov}(X_i,X_j) > 0$, implying that the variance of the sum will be greater than if the $X_i$ were independent.

   III. **Key Transformations**:
       - Autocorrelation $\implies \text{Cov}(X_i,X_j) > 0$.
       -  $\text{Cov}(X_i,X_j) > 0$  $\implies$  $Var[\sum X_i] > \sum Var[X_i]$
       - $Var[\sum X_i] > \sum Var[X_i]$ $\implies$ $Var[V] > N(1-\alpha)\alpha$

   IV. **Conclusion**:
      -  The presence of autocorrelation increases the variance of the sum of violations over the case with independent variables.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
>  Usando o exemplo de 252 observa√ß√µes com $\alpha = 0.95$, sob a hip√≥tese de independ√™ncia, a vari√¢ncia do n√∫mero de viola√ß√µes √© de 11.97. No entanto, se houver autocorrela√ß√£o positiva, a vari√¢ncia real das viola√ß√µes pode ser muito maior. Por exemplo, se as viola√ß√µes ocorrem em *clusters*, a vari√¢ncia poderia ser 20 ou at√© mais. Isso significa que as viola√ß√µes ser√£o mais vari√°veis do que o esperado sob o modelo binomial, e o modelo de VAR pode estar subestimando o risco.
   
**Teorema 2**
 *O teste de Kupiec √© um teste de hip√≥tese para verificar se a frequ√™ncia de viola√ß√µes do VAR √© estatisticamente diferente do esperado dado o n√≠vel de confian√ßa $\alpha$. Ele testa a hip√≥tese nula de que a frequ√™ncia de viola√ß√µes observada √© consistente com a frequ√™ncia esperada sob um modelo bem calibrado.*

 *Proof:*
    I. **Initial Setup**:
      - The null hypothesis ($H_0$) is that the model is well-calibrated, i.e., the observed violation rate matches the expected violation rate.
      - The alternative hypothesis ($H_1$) is that the model is not well-calibrated, i.e., the observed violation rate is different from the expected rate.
      - Let $V$ be the observed number of violations, $N$ the number of independent observations, and $\alpha$ the confidence level.
      - We know that if the model is well-calibrated, the number of violations follows a binomial distribution $V \sim Bin(N, 1-\alpha)$.
      
    II. **Main Logical Steps**:
      -  The Kupiec test uses a likelihood ratio test to compare the likelihood under the null hypothesis (where $p = 1-\alpha$) with the likelihood of a model that admits a free violation probability $\hat{p}$ estimated from data (observed frequency of violations, i.e., $\hat{p} = V/N$).
      - The likelihood ratio statistic is constructed based on the binomial distribution.
      - The statistic is asymptotically chi-squared distributed, which allows for the construction of the test.
      
    III. **Key Transformations**:
      - Let $p$ be the expected probability of violation under the null hypothesis $p = 1-\alpha$.
      - The likelihood function is given by $L(p) = \binom{N}{V} p^V (1-p)^{N-V}$.
      - The test statistic is given by $-2ln\frac{L(1-\alpha)}{L(\hat{p})}$.
      - Under the null hypothesis, this statistic converges in distribution to a $\chi^2(1)$.

    IV. **Conclusion**:
      -  The Kupiec test checks if the frequency of violations is statistically different from that expected under the well-calibrated model hypothesis, using the distribution of the violations implied by a model with binomial violations. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que em 252 dias com um n√≠vel de confian√ßa de 95%, um modelo VAR tenha apresentado 20 viola√ß√µes. Sob a hip√≥tese nula de que o modelo est√° bem calibrado, o n√∫mero esperado de viola√ß√µes √© de 12.6. O teste de Kupiec calcula uma estat√≠stica de teste que compara a probabilidade de observar 20 viola√ß√µes se o modelo estiver bem calibrado com a probabilidade de observar 20 viola√ß√µes com a probabilidade de viola√ß√£o observada nos dados (20/252). Essa estat√≠stica de teste segue uma distribui√ß√£o $\chi^2$ com 1 grau de liberdade. Se o valor da estat√≠stica de teste for muito alto (e o p-valor correspondente for baixo), rejeita-se a hip√≥tese de que o modelo est√° bem calibrado e conclui-se que o modelo est√° subestimando o risco.
 
 **Lema 4**
 *O teste de Christoffersen testa se as viola√ß√µes do VAR s√£o independentes ao longo do tempo, e, portanto, se h√° *clusters* de viola√ß√µes. Ele testa a hip√≥tese nula de independ√™ncia das viola√ß√µes contra a hip√≥tese alternativa de que as viola√ß√µes seguem um processo de Markov de primeira ordem.*

    *Proof:*
    I. **Initial Setup**:
         - Null Hypothesis $H_0$: The violations are independent over time.
         - Alternative Hypothesis $H_1$: The violations follow a first-order Markov process (i.e., the probability of a violation depends on whether the previous observation was a violation or not).
         - $X_t$ is an indicator variable that is 1 if a violation occurs at time t, and 0 otherwise.

    II. **Main Logical Steps**:
         -  The Christoffersen test examines the transitions between violation and no-violation states using a likelihood ratio test.
         - Under $H_0$, the probability of a violation at time $t$ is independent of the occurrence of a violation at time $t-1$.
         - Under $H_1$, the probability of a violation depends on whether there was a violation in the previous period.
         - This dependence is expressed using a transition matrix:
        $$
        \begin{bmatrix}
          \pi_{00} & \pi_{01} \\
          \pi_{10} & \pi_{11}
        \end{bmatrix}
        $$
         where $\pi_{ij}$ is the probability of observing $X_t=j$ given $X_{t-1} = i$.
        
    III. **Key Transformations**:
         - The likelihood function under the null hypothesis (independence) is compared to the likelihood under the alternative hypothesis (Markov model).
         - The likelihood ratio is used to evaluate if the alternative hypothesis fits the data significantly better than the null hypothesis.
         - The test statistic is asymptotically chi-squared distributed.
        
    IV. **Conclusion**:
         -  The Christoffersen test determines if the observed transitions between violations and no-violations are consistent with the assumption of independence (i.e., if violations are clustered). ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que temos 252 dias de dados, e as viola√ß√µes do VAR ocorrem em sequ√™ncia. Por exemplo, se tivermos uma viola√ß√£o no dia $t-1$, a probabilidade de ter uma viola√ß√£o no dia $t$ √© muito maior do que se n√£o tivermos uma viola√ß√£o no dia $t-1$. O teste de Christoffersen verifica se essas transi√ß√µes entre estados (viola√ß√£o/n√£o-viola√ß√£o) s√£o estatisticamente significativas e inconsistentes com a hip√≥tese de independ√™ncia. Ele estima a matriz de transi√ß√£o e compara a probabilidade de os dados terem sido gerados por uma cadeia de Markov ou por um processo independente, calculando uma estat√≠stica de teste, que segue uma distribui√ß√£o $\chi^2$.

    
**Teorema 2.1**
    *O teste de Christoffersen tamb√©m avalia se a frequ√™ncia de viola√ß√µes √© consistente com o n√≠vel de confian√ßa $\alpha$, simultaneamente com a avalia√ß√£o da independ√™ncia das viola√ß√µes.*

    *Proof:*
        I. **Initial Setup**:
            - The null hypothesis for the Christoffersen test is that the model is well-calibrated and that the violations are independent of each other.
            - The alternative hypothesis is that either the violation frequency is not correct or the violations are not independent.
            -  The null hypothesis is given by $H_0: \pi_{01}=\pi_{11} = 1-\alpha$.

        II. **Main Logical Steps**:
            - The Christoffersen test is actually a joint test. It is composed of two likelihood ratio (LR) tests.
            -  The first LR test looks at whether the frequency of violations is compatible with the confidence level $\alpha$. This part of the test does not test independence.
            - The second LR test checks if there is statistical evidence of dependence on the previous state. This second test checks independence.
            - If we reject the null hypothesis in the Christoffersen test, it means that the data is incompatible with the assumption that the violations are both independent and have the correct frequency.
            
        III. **Key Transformations**:
            - The first test checks if $\pi_{01}=\pi_{11}=1-\alpha$ jointly. If not, then either the frequency or the independence is rejected.
            - The second test checks the independence of the violations, by testing if $\pi_{01}=\pi_{11}$.
            - The combination of both tests gives the Christoffersen test statistic.
            
        IV. **Conclusion**:
            -  Because of the structure of the test, the Christoffersen test assesses both the frequency of violations and the independence of the violations simultaneously. Therefore, it assesses if both the frequency of violations is consistent with $\alpha$ and if the violations are independent of each other, simultaneously.  ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Continuando o exemplo anterior, o teste de Christoffersen n√£o apenas verifica se a frequ√™ncia de viola√ß√µes √© aproximadamente 5% (se $\alpha=0.95$), mas tamb√©m se a ocorr√™ncia de uma viola√ß√£o em um dia aumenta a probabilidade de uma viola√ß√£o no dia seguinte. Ele faz isso de forma simult√¢nea. Isso √© especialmente importante porque um modelo pode ter a frequ√™ncia de viola√ß√µes correta, mas as viola√ß√µes ocorrem em *clusters*, o que o teste de Christoffersen √© capaz de detectar.
    
**Proposi√ß√£o 5**
   *Al√©m do teste de Kupiec e do teste de Christoffersen, existem outros testes de *backtesting* como o teste de Lopez, o teste de correla√ß√£o serial, e testes baseados em fun√ß√µes de perda, que podem complementar a an√°lise do desempenho do modelo VAR.*
   *Proof:*
        I. **Initial Setup**:
            - The Kupiec and Christoffersen tests are not exhaustive.
            - There are other ways to evaluate a VAR model through backtesting.
        II. **Main Logical Steps**:
            - The Lopez test assesses the magnitude of losses that violate the VAR, not just the frequency. It uses a loss function that considers both the number and the size of the violations.
            - Tests of serial correlation can detect if violations cluster or are predictable, which is undesirable. For example, the Ljung-Box test.
            - Test based on loss functions (such as the tick loss) can be tailored to capture specific properties that are relevant for the user.
        III. **Key Transformations**:
             - The Lopez test, tests of serial correlation, and loss function-based tests provide additional tests that measure aspects of the VAR model not assessed by the Kupiec and Christoffersen test.
       IV. **Conclusion**:
            -  These other tests are useful to evaluate if the VAR model is adequate to a certain situation, and offer a more complete picture of the VAR model‚Äôs quality. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que o teste de Kupiec tenha aprovado um modelo VAR com um n√≠vel de confian√ßa de 95% mas o teste de Christoffersen tenha rejeitado o modelo por apresentar autocorrela√ß√£o. Nesse caso, podemos aplicar outros testes de *backtesting*. Por exemplo, o teste de Lopez poder√° apontar
que as viola√ß√µes do VAR s√£o muito maiores do que o esperado. Um teste de correla√ß√£o serial poder√° confirmar que as viola√ß√µes est√£o clusterizadas. Um teste baseado em fun√ß√µes de perda poder√° indicar que as perdas acima doVAR causam um grande impacto no balan√ßo da institui√ß√£o.
### Model Backtesting and Horizon Selection in VAR

### Introdu√ß√£o
Em continuidade ao estudo do Value at Risk (VAR) e suas aplica√ß√µes, este cap√≠tulo aborda um aspecto crucial para a valida√ß√£o e confiabilidade dos modelos: o *backtesting*. Como vimos anteriormente, o VAR √© uma medida de risco que resume a potencial perda em um determinado horizonte de tempo e n√≠vel de confian√ßa [^1]. No entanto, a precis√£o do VAR depende da qualidade dos dados e da adequa√ß√£o do modelo utilizado. O *backtesting* √© uma ferramenta essencial para avaliar a performance de um modelo VAR e identificar poss√≠veis vieses nas previs√µes [^1]. Esta se√ß√£o se aprofundar√° nos crit√©rios para realizar o *backtesting*, com foco especial na import√¢ncia do horizonte de tempo na efic√°cia dos testes.

### Conceitos Fundamentais
O *backtesting* consiste em comparar sistematicamente as previs√µes de perdas obtidas por meio do VAR com as perdas e lucros (P&L) efetivamente realizados posteriormente [^1]. O objetivo principal do *backtesting* √© detectar vieses ou inconsist√™ncias nos resultados do VAR, garantindo que o modelo esteja gerando previs√µes confi√°veis. A ideia central √© que um modelo VAR bem calibrado deve ser capaz de prever a frequ√™ncia com que as perdas efetivas excedem o VAR previsto, alinhando-se com o n√≠vel de confian√ßa estabelecido [^2].

Para realizar um *backtesting* eficaz, √© fundamental levar em considera√ß√£o o horizonte de tempo utilizado no c√°lculo do VAR. A escolha do horizonte de tempo influencia diretamente o n√∫mero de observa√ß√µes independentes dispon√≠veis para o teste, afetando o poder estat√≠stico do mesmo [^1]. O poder de um teste refere-se √† sua capacidade de detectar desvios significativos entre as previs√µes do VAR e os resultados reais.

Como mencionado anteriormente, o horizonte de tempo √© um dos fatores quantitativos que influenciam o c√°lculo do VAR. Em geral, um horizonte mais longo leva a um VAR maior. Ao usar o VAR como uma medida de risco potencial, o horizonte de tempo deve ser definido pela liquidez dos ativos, ou seja, o tempo necess√°rio para liquidar o portf√≥lio sem grandes impactos no mercado [^1].

#### O Impacto do Horizonte de Tempo no Backtesting
A escolha do horizonte de tempo tem um impacto significativo no n√∫mero de observa√ß√µes independentes dispon√≠veis para o *backtesting*. Um horizonte mais longo reduz o n√∫mero de observa√ß√µes independentes em um determinado per√≠odo. Por exemplo, se utilizarmos um horizonte de VAR de duas semanas, teremos apenas 26 observa√ß√µes independentes por ano [^1]. Por outro lado, um horizonte de um dia fornecer√° aproximadamente 252 observa√ß√µes independentes ao longo de um ano [^1].

O poder do teste, ou seja, a capacidade de detectar vieses no modelo, est√° diretamente relacionado ao n√∫mero de observa√ß√µes independentes. Com um n√∫mero maior de observa√ß√µes, o teste se torna mais sens√≠vel a desvios entre as previs√µes do VAR e as perdas efetivas [^1]. Por isso, para fins de *backtesting*, √© prefer√≠vel utilizar horizontes de tempo mais curtos, como um dia, para maximizar o poder dos testes [^1].

**Proposi√ß√£o 1**
   *A escolha de um horizonte de tempo $h$ para o c√°lculo do VAR implica que, em um per√≠odo de $T$ dias, temos aproximadamente $T/h$ observa√ß√µes independentes. Para um dado per√≠odo de tempo $T$, o n√∫mero de observa√ß√µes independentes √© inversamente proporcional ao tamanho do horizonte $h$.*
   
   *Proof:*

   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Each observation period for the VAR spans $h$ days.

   II. **Main Logical Steps**:
      - The total number of days, $T$, is divided by the length of each observation period, $h$, to determine the number of non-overlapping observation periods.
      - This gives the number of independent observations.

   III. **Key Transformations**:
      -  Number of independent observations $\approx \frac{T}{h}$

   IV. **Conclusion**:
      - As $h$ increases, $T/h$ decreases, implying an inverse relationship between $h$ and the number of independent observations for a fixed $T$.
      - This proves the statement: "the number of independent observations is inversely proportional to the size of the horizon $h$". ‚ñ†
> üí° **Exemplo Num√©rico:**
> Suponha que temos um per√≠odo de $T = 252$ dias (um ano de negocia√ß√£o). Se usarmos um horizonte de tempo $h = 1$ dia, teremos aproximadamente $252/1 = 252$ observa√ß√µes independentes. Se aumentarmos o horizonte para $h = 5$ dias (uma semana), teremos $252/5 \approx 50$ observa√ß√µes independentes. E se o horizonte for $h=21$ (aproximadamente um m√™s), teremos $252/21=12$ observa√ß√µes independentes. Este exemplo ilustra claramente a rela√ß√£o inversa entre o horizonte de tempo e o n√∫mero de observa√ß√µes independentes.

#### Rela√ß√£o com o N√≠vel de Confian√ßa
√â importante notar que o n√≠vel de confian√ßa tamb√©m influencia o n√∫mero de observa√ß√µes na cauda da distribui√ß√£o. N√≠veis de confian√ßa mais altos, como 99%, resultam em menos observa√ß√µes na cauda, dificultando a identifica√ß√£o de vieses no modelo. Em outras palavras, para confirmar a validade do modelo com um n√≠vel de confian√ßa de 99%, seria necess√°rio um longo per√≠odo de observa√ß√µes para coletar dados suficientes na cauda da distribui√ß√£o [^1]. Por isso, para o *backtesting*, n√≠veis de confian√ßa mais baixos, como 95%, podem ser prefer√≠veis, permitindo uma an√°lise mais frequente dos resultados do modelo [^1].

**Lema 1**
   *Para um n√≠vel de confian√ßa $\alpha$, o n√∫mero de observa√ß√µes esperadas na cauda da distribui√ß√£o em um per√≠odo $T$ com horizonte de tempo $h$ √© aproximadamente $(1-\alpha)T/h$.*

   *Proof:*
   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Let $\alpha$ be the confidence level.
      - The number of independent observations is approximately $T/h$.

   II. **Main Logical Steps**:
       - With a confidence level $\alpha$, the probability of an observation falling in the tail (exceeding the VAR) is $1 - \alpha$.
       - The expected number of observations in the tail is the product of the number of independent observations and the probability of falling in the tail.

   III. **Key Transformations**:
        - Expected number of observations in the tail $\approx \frac{T}{h} \times (1-\alpha) = (1-\alpha) \frac{T}{h}$

   IV. **Conclusion**:
      - This shows that the expected number of observations in the tail is approximately $(1-\alpha)T/h$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Usando o exemplo anterior com $T=252$ dias e um horizonte de $h=1$ dia, se o n√≠vel de confian√ßa for $\alpha = 0.95$ (95%), o n√∫mero esperado de observa√ß√µes na cauda √© $(1-0.95) \times 252/1 = 0.05 \times 252 = 12.6$. Isso significa que, em m√©dia, esperamos que o VAR seja violado aproximadamente 12 ou 13 vezes em um ano. Se o n√≠vel de confian√ßa for $\alpha=0.99$, o n√∫mero esperado de viola√ß√µes cai para $(1-0.99) \times 252 = 0.01 \times 252 = 2.52$, indicando que seria necess√°rio um per√≠odo muito maior de observa√ß√µes para testar o modelo de forma eficaz. Se, por outro lado, mantemos o n√≠vel de confian√ßa em 95% mas aumentamos o horizonte para $h=5$, o n√∫mero de observa√ß√µes na cauda ser√° $(1-0.95)\times 252/5 \approx 2.5$.
  
**Corol√°rio 1.1**
   *O n√∫mero de observa√ß√µes na cauda √© diretamente proporcional ao per√≠odo $T$ e inversamente proporcional ao horizonte $h$, e diminui com o aumento do n√≠vel de confian√ßa $\alpha$.*

   *Proof:*
   I. **Initial Setup**:
       - From Lema 1, the number of observations in the tail is approximately $(1-\alpha)T/h$.

   II. **Main Logical Steps**:
       - We analyze the effect of $T$, $h$, and $\alpha$ on this expression.

   III. **Key Transformations**:
        - As $T$ increases, the number of observations in the tail increases proportionally.
        - As $h$ increases, the number of observations in the tail decreases proportionally.
        - As $\alpha$ increases, $(1-\alpha)$ decreases, thus decreasing the number of observations in the tail.

   IV. **Conclusion**:
        -  This confirms the statement that the number of tail observations is directly proportional to $T$, inversely proportional to $h$, and decreases with an increase in $\alpha$. ‚ñ†

Al√©m disso, vale ressaltar que a escolha do n√≠vel de confian√ßa afeta o tipo de erros que o *backtesting* ser√° capaz de detectar. Um n√≠vel de confian√ßa mais alto prioriza a detec√ß√£o de erros na cauda da distribui√ß√£o, enquanto um n√≠vel de confian√ßa mais baixo permite uma detec√ß√£o mais frequente de erros, ainda que menos extremos.

**Proposi√ß√£o 2**
    *Um n√≠vel de confian√ßa mais baixo aumenta a frequ√™ncia com que os resultados do VAR s√£o comparados com os retornos realizados, e, consequentemente, aumenta a sensibilidade a potenciais vieses no modelo.*
  
  *Proof:*

  I. **Initial Setup**:
    - Let $\alpha$ be the confidence level.
    - A lower confidence level implies a smaller $\alpha$.
    - VAR is calculated for a given confidence level.

  II. **Main Logical Steps**:
    - A lower confidence level (smaller $\alpha$) corresponds to a lower VAR value (since the VAR is a quantile).
    - A lower VAR value means a greater chance of actual losses exceeding the VAR.
    - If the actual loss exceeds the VAR value, this is considered a violation in the backtesting process.
    - More violations mean more comparisons between VAR and actual returns.

  III. **Key Transformations**:
    - Lower $\alpha$  $\implies$ Lower VAR
    - Lower VAR $\implies$ More violations
    - More violations $\implies$ More frequent comparisons between VAR and actual returns

  IV. **Conclusion**:
    - This demonstrates that a lower confidence level results in more frequent comparisons between VAR predictions and actual returns. Therefore, the sensitivity of the backtesting to potential biases in the model increases.‚ñ†

> üí° **Exemplo Num√©rico:**
> Considere um modelo VAR com um horizonte de um dia ($h=1$). Se o n√≠vel de confian√ßa for $\alpha = 0.99$, espera-se que as viola√ß√µes sejam raras, e a cada 100 dias de negocia√ß√£o, apenas 1 dia, em m√©dia, apresentar√° uma perda que ultrapassa o VAR. Se o n√≠vel de confian√ßa for reduzido para $\alpha=0.95$, as viola√ß√µes tornam-se mais frequentes, com uma m√©dia de 5 dias a cada 100, e isso permite uma an√°lise mais detalhada e frequente do modelo.

**Teorema 1**
*Existe um trade-off entre o horizonte de tempo $h$ e o n√≠vel de confian√ßa $\alpha$ no *backtesting*. Diminuir $h$ aumenta o n√∫mero de observa√ß√µes independentes e, portanto, o poder do teste, enquanto diminuir $\alpha$ aumenta a frequ√™ncia de viola√ß√µes do VAR e, tamb√©m, aumenta o poder do teste.*
 *Proof:*
    I. **Initial Setup**:
        - The power of a backtesting test is directly related to the number of independent observations and the frequency of violations.
    
    II. **Main Logical Steps**:
         - From Proposi√ß√£o 1, reducing the time horizon $h$ increases the number of independent observations. An increase in independent observations leads to an increase in the power of the test.
         - From Proposi√ß√£o 2, reducing the confidence level $\alpha$ increases the frequency of violations. More frequent violations increase the data available to backtest, increasing the power of the test.
        
    III. **Key Transformations**:
        - $h \downarrow \implies \text{Number of Independent Observations} \uparrow \implies \text{Test Power} \uparrow$
        - $\alpha \downarrow \implies \text{Frequency of Violations} \uparrow \implies \text{Test Power} \uparrow$

    IV. **Conclusion**:
        - The theorem states that there is a trade-off. Both lowering $h$ and $\alpha$ increase the power of the backtest, supporting the claim. Therefore, this proves the existence of the trade-off.‚ñ†

**Lema 2**
*Seja $N$ o n√∫mero de observa√ß√µes independentes, e seja $X_i$ uma vari√°vel indicadora que vale 1 se a perda observada no per√≠odo $i$ excede o VAR previsto e 0 caso contr√°rio. Se o modelo VAR estiver bem calibrado, ent√£o $X_i$ s√£o vari√°veis aleat√≥rias independentes de Bernoulli com probabilidade de sucesso $1 - \alpha$.*

*Proof:*
   I. **Initial Setup**:
       - $N$ is the number of independent observations.
       - $X_i$ is an indicator variable, where $X_i = 1$ if the loss exceeds the predicted VAR at time $i$, and $X_i = 0$ otherwise.
       - $\alpha$ is the confidence level of the VAR.
       - A well-calibrated VAR model has a probability of $1-\alpha$ of the loss exceeding the VAR.
       - We assume independence between observations.

   II. **Main Logical Steps**:
       - For each observation $i$, there are only two outcomes: the loss exceeds the VAR ($X_i = 1$) or the loss does not exceed the VAR ($X_i = 0$).
       - Under a well-calibrated model, the probability of $X_i = 1$ (a loss exceeding the VAR) is $1 - \alpha$.
       - This is precisely the definition of a Bernoulli trial with a success probability of $1-\alpha$.
       - The independence of the $X_i$ variables comes from the assumption of independence of observations.

   III. **Key Transformations**:
       - $P(X_i=1) = 1-\alpha$.

   IV. **Conclusion**:
       - The variables $X_i$ are independent and follow a Bernoulli distribution with success probability $1-\alpha$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Vamos supor que estamos analisando 252 dias de negocia√ß√£o com um n√≠vel de confian√ßa de 95% ($\alpha=0.95$). Para cada dia $i$, definimos $X_i = 1$ se a perda naquele dia excedeu o VAR previsto e $X_i = 0$ caso contr√°rio. Se o modelo estiver bem calibrado, cada $X_i$ √© uma vari√°vel de Bernoulli com $p = 1 - 0.95 = 0.05$. Isso significa que a probabilidade de uma viola√ß√£o em qualquer dia √© de 5%.

**Teorema 1.1**
*Sob as condi√ß√µes do Lema 2, o n√∫mero de viola√ß√µes do VAR, $V = \sum_{i=1}^N X_i$, segue uma distribui√ß√£o binomial com par√¢metros $N$ e $1-\alpha$, ou seja, $V \sim Bin(N, 1 - \alpha)$.*

*Proof:*
   I. **Initial Setup**:
      - From Lema 2, $X_i$ are independent Bernoulli random variables with success probability $1-\alpha$.
      - $V$ is defined as the sum of these Bernoulli variables: $V = \sum_{i=1}^N X_i$.

   II. **Main Logical Steps**:
      - The sum of $N$ independent Bernoulli random variables with the same success probability follows a binomial distribution.
      - The parameters of the binomial distribution are $N$ (the number of trials) and $1-\alpha$ (the success probability).

   III. **Key Transformations**:
      - $V = \sum_{i=1}^N X_i \implies V \sim Bin(N, 1 - \alpha)$

   IV. **Conclusion**:
      - Therefore, the number of violations $V$ follows a binomial distribution with parameters $N$ and $1-\alpha$. ‚ñ†
> üí° **Exemplo Num√©rico:**
> Continuando o exemplo anterior, onde temos 252 observa√ß√µes independentes ($N=252$) e $\alpha = 0.95$, o n√∫mero total de viola√ß√µes $V$ segue uma distribui√ß√£o binomial com par√¢metros $N=252$ e $p=0.05$, ou seja, $V \sim Bin(252, 0.05)$. Isso nos permite calcular a probabilidade de observar um n√∫mero espec√≠fico de viola√ß√µes, assumindo que o modelo VAR est√° bem calibrado.

**Corol√°rio 1.2**
*A m√©dia e a vari√¢ncia do n√∫mero de viola√ß√µes $V$ s√£o dadas por $E[V] = N(1-\alpha)$ e $Var[V] = N(1-\alpha)\alpha$.*

*Proof:*
   I. **Initial Setup**:
      - From Theorem 1.1, $V \sim Bin(N, 1-\alpha)$.
      - We recall the mean and variance of a binomial distribution.
   II. **Main Logical Steps**:
        - The expected value (mean) of a binomial distribution $Bin(n,p)$ is given by $E[V]=np$.
        - The variance of a binomial distribution $Bin(n,p)$ is given by $Var[V]=np(1-p)$.
   III. **Key Transformations**:
      - Substituting $n = N$ and $p = 1 - \alpha$, we have
      -  $E[V] = N(1-\alpha)$.
      - $Var[V] = N(1-\alpha)(1-(1-\alpha)) = N(1-\alpha)\alpha$.

   IV. **Conclusion**:
     -  This shows that the mean and the variance of $V$ are given by $E[V] = N(1-\alpha)$ and $Var[V] = N(1-\alpha)\alpha$, respectively. ‚ñ†

> üí° **Exemplo Num√©rico:**
> No mesmo exemplo, com $N=252$ e $\alpha=0.95$, a m√©dia do n√∫mero de viola√ß√µes √© $E[V] = 252 \times (1 - 0.95) = 252 \times 0.05 = 12.6$, e a vari√¢ncia √© $Var[V] = 252 \times 0.05 \times 0.95 = 11.97$. Isso significa que, em m√©dia, esperamos 12.6 viola√ß√µes, com uma variabilidade em torno desse valor, quantificada pela vari√¢ncia.

Al√©m disso, √© crucial considerar a autocorrela√ß√£o das perdas. Se as perdas em per√≠odos sucessivos forem correlacionadas, a suposi√ß√£o de independ√™ncia das observa√ß√µes pode ser violada, comprometendo a validade do *backtesting*.

**Proposi√ß√£o 3**
    *A autocorrela√ß√£o positiva das perdas pode levar a um excesso de viola√ß√µes do VAR em clusters, o que pode reduzir o poder de um *backtesting* que assume independ√™ncia das observa√ß√µes.*
    *Proof:*
       I. **Initial Setup**:
        -  Assume positive autocorrelation in losses.
        -  Assume that we are using a backtesting method that assumes independence.
        
       II. **Main Logical Steps**:
           - Positive autocorrelation implies that if a loss exceeds the VAR in a given period, the probability of a loss exceeding the VAR in the next period is higher than expected under independence.
           - This causes violations to occur in clusters, i.e. if one violation occurs, the probability of seeing more violations in close succession is higher.
           - When violations cluster, the assumption of independent Bernoulli trials underlying most backtesting procedures is violated.
           - The methods assume that the number of violations is a realization of a binomial distribution, which does not hold under autocorrelation.
           - Since the number of observations is reduced, a clustered violation process has less power than an independent violation process.

       III. **Key Transformations**:
           - Autocorrelation $\implies$ violation clusters
           - Clusters $\implies$ violation of independence
           - Violation of independence $\implies$ Reduction in the power of the test

       IV. **Conclusion**:
        - Therefore, positive autocorrelation can lead to clustered violations, and reduce the effectiveness of backtesting.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
> Suponha que as perdas do dia atual sejam positivamente correlacionadas com as perdas do dia anterior. Se o VAR for violado hoje, √© mais prov√°vel que ele seja violado amanh√£ tamb√©m. Isso cria *clusters* de viola√ß√µes, onde v√°rios dias consecutivos apresentam perdas acima do VAR, em vez de viola√ß√µes aleat√≥rias e independentes. Um modelo que ignora essa autocorrela√ß√£o pode n√£o capturar a din√¢mica real do risco.
    
**Lema 3**
*Para detectar a presen√ßa de autocorrela√ß√£o nas viola√ß√µes do VAR, pode-se realizar um teste de raz√£o de verossimilhan√ßa (LR) de independ√™ncia de viola√ß√µes, ou similar, como o teste de Kupiec ou Christoffersen.*

    *Proof:*
     I. **Initial Setup**:
          - We want to detect if there is autocorrelation in the violations of the VAR model.
          - We know that violations of a well-calibrated VAR should be independent events.

     II. **Main Logical Steps**:
          - The test of the likelihood ratio (LR) is designed to test the hypothesis that the distribution of the violations is independent.
          - The Kupiec test checks if the overall violation rate is consistent with the confidence level, implicitly assuming independence over time.
          - The Christoffersen test is specifically designed to test for both correct violation rate and independence over time.

     III. **Key Transformations**:
          - These tests check the null hypothesis of independence against the alternative of an autocorrelation in the violations.

     IV. **Conclusion**:
          -  The LR test and specific tests such as Kupiec and Christoffersen can all detect the presence of autocorrelation, supporting the claim. ‚ñ†
> üí° **Exemplo Num√©rico:**
>  Se os resultados do *backtesting* mostram uma sequ√™ncia de viola√ß√µes em dias pr√≥ximos (por exemplo, viola√ß√µes nos dias 1, 2, 3, e depois nenhuma viola√ß√£o por v√°rias semanas, e em seguida viola√ß√µes nos dias 45 e 46) isso levanta suspeitas de autocorrela√ß√£o. Testes como o de Christoffersen ajudam a quantificar essa suspeita, e a verificar se os *clusters* de viola√ß√£o s√£o estatisticamente significativos ou apenas devidos ao acaso.

**Proposi√ß√£o 4**
    *A presen√ßa de *clusters* de viola√ß√µes, causada por autocorrela√ß√£o, implica que a vari√¢ncia do n√∫mero de viola√ß√µes pode ser maior do que o previsto pela distribui√ß√£o binomial sob a hip√≥tese de independ√™ncia.*
    
  *Proof:*
  
    I. **Initial Setup**:
        - Assume that the violations are positively autocorrelated, so that violations tend to cluster together.
        - Let $X_i$ be indicator variables such that $X_i = 1$ if there is a violation at time $i$ and 0 otherwise.
        - Let the number of violations be given by $V=\sum_{i=1}^N X_i$.
        
    II. **Main Logical Steps**:
        - If the violations were independent, then we could calculate the variance of the total number of violations using the fact that it follows a binomial distribution (as shown in Corol√°rio 1.2). In that case, $Var[V] = N(1-\alpha)\alpha$.
        - However, because of autocorrelation, the $X_i$ are not independent. The variance of the sum of correlated random variables is not the sum of the variances.
        - If $\text{Cov}(X_i,X_j) > 0$ for at least some $i \neq j$, then $Var[\sum X_i] > \sum Var[X_i]$.
        - The autocorrelation causes $\text{Cov}(X_i,X_j) > 0$, implying that the variance of the sum will be greater than if the $X_i$ were independent.

   III. **Key Transformations**:
       - Autocorrelation $\implies \text{Cov}(X_i,X_j) > 0$.
       -  $\text{Cov}(X_i,X_j) > 0$  $\implies$  $Var[\sum X_i] > \sum Var[X_i]$
       - $Var[\sum X_i] > \sum Var[X_i]$ $\implies$ $Var[V] > N(1-\alpha)\alpha$

   IV. **Conclusion**:
      -  The presence of autocorrelation increases the variance of the sum of violations over the case with independent variables.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
>  Usando o exemplo de 252 observa√ß√µes com $\alpha = 0.95$, sob a hip√≥tese de independ√™ncia, a vari√¢ncia do n√∫mero de viola√ß√µes √© de 11.97. No entanto, se houver autocorrela√ß√£o positiva, a vari√¢ncia real das viola√ß√µes pode ser muito maior. Por exemplo, se as viola√ß√µes ocorrem em *clusters*, a vari√¢ncia poderia ser 20 ou at√© mais. Isso significa que as viola√ß√µes ser√£o mais vari√°veis do que o esperado sob o modelo binomial, e o modelo de VAR pode estar subestimando o risco.
   
**Teorema 2**
 *O teste de Kupiec √© um teste de hip√≥tese para verificar se a frequ√™ncia de viola√ß√µes do VAR √© estatisticamente diferente do esperado dado o n√≠vel de confian√ßa $\alpha$. Ele testa a hip√≥tese nula de que a frequ√™ncia de viola√ß√µes observada √© consistente com a frequ√™ncia esperada sob um modelo bem calibrado.*

 *Proof:*
    I. **Initial Setup**:
      - The null hypothesis ($H_0$) is that the model is well-calibrated, i.e., the observed violation rate matches the expected violation rate.
      - The alternative hypothesis ($H_1$) is that the model is not well-calibrated, i.e., the observed violation rate is different from the expected rate.
      - Let $V$ be the observed number of violations, $N$ the number of independent observations, and $\alpha$ the confidence level.
      - We know that if the model is well-calibrated, the number of violations follows a binomial distribution $V \sim Bin(N, 1-\alpha)$.
      
    II. **Main Logical Steps**:
      -  The Kupiec test uses a likelihood ratio test to compare the likelihood under the null hypothesis (where $p = 1-\alpha$) with the likelihood of a model that admits a free violation probability $\hat{p}$ estimated from data (observed frequency of violations, i.e., $\hat{p} = V/N$).
      - The likelihood ratio statistic is constructed based on the binomial distribution.
      - The statistic is asymptotically chi-squared distributed, which allows for the construction of the test.
      
    III. **Key Transformations**:
      - Let $p$ be the expected probability of violation under the null hypothesis $p = 1-\alpha$.
      - The likelihood function is given by $L(p) = \binom{N}{V} p^V (1-p)^{N-V}$.
      - The test statistic is given by $-2ln\frac{L(1-\alpha)}{L(\hat{p})}$.
      - Under the null hypothesis, this statistic converges in distribution to a $\chi^2(1)$.

    IV. **Conclusion**:
      -  The Kupiec test checks if the frequency of violations is statistically different from that expected under the well-calibrated model hypothesis, using the distribution of the violations implied by a model with binomial violations. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que em 252 dias com um n√≠vel de confian√ßa de 95%, um modelo VAR tenha apresentado 20 viola√ß√µes. Sob a hip√≥tese nula de que o modelo est√° bem calibrado, o n√∫mero esperado de viola√ß√µes √© de 12.6. O teste de Kupiec calcula uma estat√≠stica de teste que compara a probabilidade de observar 20 viola√ß√µes se o modelo estiver bem calibrado com a probabilidade de observar 20 viola√ß√µes com a probabilidade de viola√ß√£o observada nos dados (20/252). Essa estat√≠stica de teste segue uma distribui√ß√£o $\chi^2$ com 1 grau de liberdade. Se o valor da estat√≠stica de teste for muito alto (e o p-valor correspondente for baixo), rejeita-se a hip√≥tese de que o modelo est√° bem calibrado e conclui-se que o modelo est√° subestimando o risco.
 
 **Lema 4**
 *O teste de Christoffersen testa se as viola√ß√µes do VAR s√£o independentes ao longo do tempo, e, portanto, se h√° *clusters* de viola√ß√µes. Ele testa a hip√≥tese nula de independ√™ncia das viola√ß√µes contra a hip√≥tese alternativa de que as viola√ß√µes seguem um processo de Markov de primeira ordem.*

    *Proof:*
    I. **Initial Setup**:
         - Null Hypothesis $H_0$: The violations are independent over time.
         - Alternative Hypothesis $H_1$: The violations follow a first-order Markov process (i.e., the probability of a violation depends on whether the previous observation was a violation or not).
         - $X_t$ is an indicator variable that is 1 if a violation occurs at time t, and 0 otherwise.

    II. **Main Logical Steps**:
         -  The Christoffersen test examines the transitions between violation and no-violation states using a likelihood ratio test.
         - Under $H_0$, the probability of a violation at time $t$ is independent of the occurrence of a violation at time $t-1$.
         - Under $H_1$, the probability of a violation depends on whether there was a violation in the previous period.
         - This dependence is expressed using a transition matrix:
        $$
        \begin{bmatrix}
          \pi_{00} & \pi_{01} \\
          \pi_{10} & \pi_{11}
        \end{bmatrix}
        $$
         where $\pi_{ij}$ is the probability of observing $X_t=j$ given $X_{t-1} = i$.
        
    III. **Key Transformations**:
         - The likelihood function under the null hypothesis (independence) is compared to the likelihood under the alternative hypothesis (Markov model).
         - The likelihood ratio is used to evaluate if the alternative hypothesis fits the data significantly better than the null hypothesis.
         - The test statistic is asymptotically chi-squared distributed.
        
    IV. **Conclusion**:
         -  The Christoffersen test determines if the observed transitions between violations and no-violations are consistent with the assumption of independence (i.e., if violations are clustered). ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que temos 252 dias de dados, e as viola√ß√µes do VAR ocorrem em sequ√™ncia. Por exemplo, se tivermos uma viola√ß√£o no dia $t-1$, a probabilidade de ter uma viola√ß√£o no dia $t$ √© muito maior do que se n√£o tivermos uma viola√ß√£o no dia $t-1$. O teste de Christoffersen verifica se essas transi√ß√µes entre estados (viola√ß√£o/n√£o-viola√ß√£o) s√£o estatisticamente significativas e inconsistentes com a hip√≥tese de independ√™ncia. Ele estima a matriz de transi√ß√£o e compara a probabilidade de os dados terem sido gerados por uma cadeia de Markov ou por um processo independente, calculando uma estat√≠stica de teste, que segue uma distribui√ß√£o $\chi^2$.

    
**Teorema 2.1**
    *O teste de Christoffersen tamb√©m avalia se a frequ√™ncia de viola√ß√µes √© consistente com o n√≠vel de confian√ßa $\alpha$, simultaneamente com a avalia√ß√£o da independ√™ncia das viola√ß√µes.*

    *Proof:*
        I. **Initial Setup**:
            - The null hypothesis for the Christoffersen test is that the model is well-calibrated and that the violations are independent of each other.
            - The alternative hypothesis is that either the violation frequency is not correct or the violations are not independent.
            -  The null hypothesis is given by $H_0: \pi_{01}=\pi_{11} = 1-\alpha$.

        II. **Main Logical Steps**:
            - The Christoffersen test is actually a joint test. It is composed of two likelihood ratio (LR) tests.
            -  The first LR test looks at whether the frequency of violations is compatible with the confidence level $\alpha$. This part of the test does not test independence.
            - The second LR test checks if there is statistical evidence of dependence on the previous state. This second test checks independence.
            - If we reject the null hypothesis in the Christoffersen test, it means that the data is incompatible with the assumption that the violations are both independent and have the correct frequency.
            
        III. **Key Transformations**:
            - The first test checks if $\pi_{01}=\pi_{11}=1-\alpha$ jointly. If not, then either the frequency or the independence is rejected.
            - The second test checks the independence of the violations, by testing if $\pi_{01}=\pi_{11}$.
            - The combination of both tests gives the Christoffersen test statistic.
            
        IV. **Conclusion**:
            -  Because of the structure of the test, the Christoffersen test assesses both the frequency of violations and the independence of the violations simultaneously. Therefore, it assesses if both the frequency of violations is consistent with $\alpha$ and if the violations are independent of each other, simultaneously.  ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Continuando o exemplo anterior, o teste de Christoffersen n√£o apenas verifica se a frequ√™ncia de viola√ß√µes √© aproximadamente 5% (se $\alpha=0.95$), mas tamb√©m se a ocorr√™ncia de uma viola√ß√£o em um dia aumenta a probabilidade de uma viola√ß√£o no dia seguinte. Ele faz isso de forma simult√¢nea. Isso √© especialmente importante porque um modelo pode ter a frequ√™ncia de viola√ß√µes correta, mas as viola√ß√µes ocorrem em *clusters*, o que o teste de Christoffersen √© capaz de detectar.
    
**Proposi√ß√£o 5**
   *Al√©m do teste de Kupiec e do teste de Christoffersen, existem outros testes de *backtesting* como o teste de Lopez, o teste de correla√ß√£o serial, e testes baseados em fun√ß√µes de perda, que podem complementar a an√°lise do desempenho do modelo VAR.*
   *Proof:*
        I. **Initial Setup**:
            - The Kupiec and Christoffersen tests are not exhaustive.
            - There are other ways to evaluate a VAR model through backtesting.
        II. **Main Logical Steps**:
            - The Lopez test assesses the magnitude of losses that violate the VAR, not just the frequency. It uses a loss function that considers both the number and the size of the violations.
            - Tests of serial correlation can detect if violations cluster or are predictable, which is undesirable. For example, the Ljung-Box test.
            - Test based on loss functions (such as the tick loss) can be tailored to capture specific properties that are relevant for the user.
        III. **Key Transformations**:
             - The Lopez test, tests of serial correlation, and loss function-based tests provide additional tests that measure aspects of the VAR model not assessed by the Kupiec and Christoffersen test.
       IV. **Conclusion**:
            -  These other tests are useful to evaluate if the VAR model is adequate to a certain situation, and offer a more complete picture of the VAR model‚Äôs quality. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que o teste de Kupiec tenha aprovado um modelo VAR com um n√≠vel de confian√ßa de 95% mas o teste de Christoffersen tenha rejeitado o modelo por apresentar autocorrela√ß√£o. Nesse caso, podemos aplicar outros testes de *backtesting*. Por exemplo, o teste de Lopez poder√° apontar
que as viola√ß√µes do VAR s√£o muito maiores do que o esperado. Um teste de correla√ß√£o serial poder√° confirmar que as viola√ß√µes est√£o clusterizadas. Um teste baseado em fun√ß√µes de perda poder√° indicar que as perdas acima doVAR causam um grande impacto no balan√ßo da institui√ß√£o.
que as viola√ß√µes do VAR s√£o muito maiores do que o esperado. Um teste de correla√ß√£o serial poder√° confirmar que as viola√ß√µes est√£o clusterizadas. Um teste baseado em fun√ß√µes de perda poder√° indicar que as perdas acima do VAR causam um grande impacto no balan√ßo da institui√ß√£o.
### Model Backtesting and Horizon Selection in VAR

### Introdu√ß√£o
Em continuidade ao estudo do Value at Risk (VAR) e suas aplica√ß√µes, este cap√≠tulo aborda um aspecto crucial para a valida√ß√£o e confiabilidade dos modelos: o *backtesting*. Como vimos anteriormente, o VAR √© uma medida de risco que resume a potencial perda em um determinado horizonte de tempo e n√≠vel de confian√ßa [^1]. No entanto, a precis√£o do VAR depende da qualidade dos dados e da adequa√ß√£o do modelo utilizado. O *backtesting* √© uma ferramenta essencial para avaliar a performance de um modelo VAR e identificar poss√≠veis vieses nas previs√µes [^1]. Esta se√ß√£o se aprofundar√° nos crit√©rios para realizar o *backtesting*, com foco especial na import√¢ncia do horizonte de tempo na efic√°cia dos testes.

### Conceitos Fundamentais
O *backtesting* consiste em comparar sistematicamente as previs√µes de perdas obtidas por meio do VAR com as perdas e lucros (P&L) efetivamente realizados posteriormente [^1]. O objetivo principal do *backtesting* √© detectar vieses ou inconsist√™ncias nos resultados do VAR, garantindo que o modelo esteja gerando previs√µes confi√°veis. A ideia central √© que um modelo VAR bem calibrado deve ser capaz de prever a frequ√™ncia com que as perdas efetivas excedem o VAR previsto, alinhando-se com o n√≠vel de confian√ßa estabelecido [^2].

Para realizar um *backtesting* eficaz, √© fundamental levar em considera√ß√£o o horizonte de tempo utilizado no c√°lculo do VAR. A escolha do horizonte de tempo influencia diretamente o n√∫mero de observa√ß√µes independentes dispon√≠veis para o teste, afetando o poder estat√≠stico do mesmo [^1]. O poder de um teste refere-se √† sua capacidade de detectar desvios significativos entre as previs√µes do VAR e os resultados reais.

Como mencionado anteriormente, o horizonte de tempo √© um dos fatores quantitativos que influenciam o c√°lculo do VAR. Em geral, um horizonte mais longo leva a um VAR maior. Ao usar o VAR como uma medida de risco potencial, o horizonte de tempo deve ser definido pela liquidez dos ativos, ou seja, o tempo necess√°rio para liquidar o portf√≥lio sem grandes impactos no mercado [^1].

#### O Impacto do Horizonte de Tempo no Backtesting
A escolha do horizonte de tempo tem um impacto significativo no n√∫mero de observa√ß√µes independentes dispon√≠veis para o *backtesting*. Um horizonte mais longo reduz o n√∫mero de observa√ß√µes independentes em um determinado per√≠odo. Por exemplo, se utilizarmos um horizonte de VAR de duas semanas, teremos apenas 26 observa√ß√µes independentes por ano [^1]. Por outro lado, um horizonte de um dia fornecer√° aproximadamente 252 observa√ß√µes independentes ao longo de um ano [^1].

O poder do teste, ou seja, a capacidade de detectar vieses no modelo, est√° diretamente relacionado ao n√∫mero de observa√ß√µes independentes. Com um n√∫mero maior de observa√ß√µes, o teste se torna mais sens√≠vel a desvios entre as previs√µes do VAR e as perdas efetivas [^1]. Por isso, para fins de *backtesting*, √© prefer√≠vel utilizar horizontes de tempo mais curtos, como um dia, para maximizar o poder dos testes [^1].

**Proposi√ß√£o 1**
   *A escolha de um horizonte de tempo $h$ para o c√°lculo do VAR implica que, em um per√≠odo de $T$ dias, temos aproximadamente $T/h$ observa√ß√µes independentes. Para um dado per√≠odo de tempo $T$, o n√∫mero de observa√ß√µes independentes √© inversamente proporcional ao tamanho do horizonte $h$.*
   
   *Proof:*

   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Each observation period for the VAR spans $h$ days.

   II. **Main Logical Steps**:
      - The total number of days, $T$, is divided by the length of each observation period, $h$, to determine the number of non-overlapping observation periods.
      - This gives the number of independent observations.

   III. **Key Transformations**:
      -  Number of independent observations $\approx \frac{T}{h}$

   IV. **Conclusion**:
      - As $h$ increases, $T/h$ decreases, implying an inverse relationship between $h$ and the number of independent observations for a fixed $T$.
      - This proves the statement: "the number of independent observations is inversely proportional to the size of the horizon $h$". ‚ñ†
> üí° **Exemplo Num√©rico:**
> Suponha que temos um per√≠odo de $T = 252$ dias (um ano de negocia√ß√£o). Se usarmos um horizonte de tempo $h = 1$ dia, teremos aproximadamente $252/1 = 252$ observa√ß√µes independentes. Se aumentarmos o horizonte para $h = 5$ dias (uma semana), teremos $252/5 \approx 50$ observa√ß√µes independentes. E se o horizonte for $h=21$ (aproximadamente um m√™s), teremos $252/21=12$ observa√ß√µes independentes. Este exemplo ilustra claramente a rela√ß√£o inversa entre o horizonte de tempo e o n√∫mero de observa√ß√µes independentes.

#### Rela√ß√£o com o N√≠vel de Confian√ßa
√â importante notar que o n√≠vel de confian√ßa tamb√©m influencia o n√∫mero de observa√ß√µes na cauda da distribui√ß√£o. N√≠veis de confian√ßa mais altos, como 99%, resultam em menos observa√ß√µes na cauda, dificultando a identifica√ß√£o de vieses no modelo. Em outras palavras, para confirmar a validade do modelo com um n√≠vel de confian√ßa de 99%, seria necess√°rio um longo per√≠odo de observa√ß√µes para coletar dados suficientes na cauda da distribui√ß√£o [^1]. Por isso, para o *backtesting*, n√≠veis de confian√ßa mais baixos, como 95%, podem ser prefer√≠veis, permitindo uma an√°lise mais frequente dos resultados do modelo [^1].

**Lema 1**
   *Para um n√≠vel de confian√ßa $\alpha$, o n√∫mero de observa√ß√µes esperadas na cauda da distribui√ß√£o em um per√≠odo $T$ com horizonte de tempo $h$ √© aproximadamente $(1-\alpha)T/h$.*

   *Proof:*
   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Let $\alpha$ be the confidence level.
      - The number of independent observations is approximately $T/h$.

   II. **Main Logical Steps**:
       - With a confidence level $\alpha$, the probability of an observation falling in the tail (exceeding the VAR) is $1 - \alpha$.
       - The expected number of observations in the tail is the product of the number of independent observations and the probability of falling in the tail.

   III. **Key Transformations**:
        - Expected number of observations in the tail $\approx \frac{T}{h} \times (1-\alpha) = (1-\alpha) \frac{T}{h}$

   IV. **Conclusion**:
      - This shows that the expected number of observations in the tail is approximately $(1-\alpha)T/h$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Usando o exemplo anterior com $T=252$ dias e um horizonte de $h=1$ dia, se o n√≠vel de confian√ßa for $\alpha = 0.95$ (95%), o n√∫mero esperado de observa√ß√µes na cauda √© $(1-0.95) \times 252/1 = 0.05 \times 252 = 12.6$. Isso significa que, em m√©dia, esperamos que o VAR seja violado aproximadamente 12 ou 13 vezes em um ano. Se o n√≠vel de confian√ßa for $\alpha=0.99$, o n√∫mero esperado de viola√ß√µes cai para $(1-0.99) \times 252 = 0.01 \times 252 = 2.52$, indicando que seria necess√°rio um per√≠odo muito maior de observa√ß√µes para testar o modelo de forma eficaz. Se, por outro lado, mantemos o n√≠vel de confian√ßa em 95% mas aumentamos o horizonte para $h=5$, o n√∫mero de observa√ß√µes na cauda ser√° $(1-0.95)\times 252/5 \approx 2.5$.
  
**Corol√°rio 1.1**
   *O n√∫mero de observa√ß√µes na cauda √© diretamente proporcional ao per√≠odo $T$ e inversamente proporcional ao horizonte $h$, e diminui com o aumento do n√≠vel de confian√ßa $\alpha$.*

   *Proof:*
   I. **Initial Setup**:
       - From Lema 1, the number of observations in the tail is approximately $(1-\alpha)T/h$.

   II. **Main Logical Steps**:
       - We analyze the effect of $T$, $h$, and $\alpha$ on this expression.

   III. **Key Transformations**:
        - As $T$ increases, the number of observations in the tail increases proportionally.
        - As $h$ increases, the number of observations in the tail decreases proportionally.
        - As $\alpha$ increases, $(1-\alpha)$ decreases, thus decreasing the number of observations in the tail.

   IV. **Conclusion**:
        -  This confirms the statement that the number of tail observations is directly proportional to $T$, inversely proportional to $h$, and decreases with an increase in $\alpha$. ‚ñ†

Al√©m disso, vale ressaltar que a escolha do n√≠vel de confian√ßa afeta o tipo de erros que o *backtesting* ser√° capaz de detectar. Um n√≠vel de confian√ßa mais alto prioriza a detec√ß√£o de erros na cauda da distribui√ß√£o, enquanto um n√≠vel de confian√ßa mais baixo permite uma detec√ß√£o mais frequente de erros, ainda que menos extremos.

**Proposi√ß√£o 2**
    *Um n√≠vel de confian√ßa mais baixo aumenta a frequ√™ncia com que os resultados do VAR s√£o comparados com os retornos realizados, e, consequentemente, aumenta a sensibilidade a potenciais vieses no modelo.*
  
  *Proof:*

  I. **Initial Setup**:
    - Let $\alpha$ be the confidence level.
    - A lower confidence level implies a smaller $\alpha$.
    - VAR is calculated for a given confidence level.

  II. **Main Logical Steps**:
    - A lower confidence level (smaller $\alpha$) corresponds to a lower VAR value (since the VAR is a quantile).
    - A lower VAR value means a greater chance of actual losses exceeding the VAR.
    - If the actual loss exceeds the VAR value, this is considered a violation in the backtesting process.
    - More violations mean more comparisons between VAR and actual returns.

  III. **Key Transformations**:
    - Lower $\alpha$  $\implies$ Lower VAR
    - Lower VAR $\implies$ More violations
    - More violations $\implies$ More frequent comparisons between VAR and actual returns

  IV. **Conclusion**:
    - This demonstrates that a lower confidence level results in more frequent comparisons between VAR predictions and actual returns. Therefore, the sensitivity of the backtesting to potential biases in the model increases.‚ñ†

> üí° **Exemplo Num√©rico:**
> Considere um modelo VAR com um horizonte de um dia ($h=1$). Se o n√≠vel de confian√ßa for $\alpha = 0.99$, espera-se que as viola√ß√µes sejam raras, e a cada 100 dias de negocia√ß√£o, apenas 1 dia, em m√©dia, apresentar√° uma perda que ultrapassa o VAR. Se o n√≠vel de confian√ßa for reduzido para $\alpha=0.95$, as viola√ß√µes tornam-se mais frequentes, com uma m√©dia de 5 dias a cada 100, e isso permite uma an√°lise mais detalhada e frequente do modelo.

**Teorema 1**
*Existe um trade-off entre o horizonte de tempo $h$ e o n√≠vel de confian√ßa $\alpha$ no *backtesting*. Diminuir $h$ aumenta o n√∫mero de observa√ß√µes independentes e, portanto, o poder do teste, enquanto diminuir $\alpha$ aumenta a frequ√™ncia de viola√ß√µes do VAR e, tamb√©m, aumenta o poder do teste.*
 *Proof:*
    I. **Initial Setup**:
        - The power of a backtesting test is directly related to the number of independent observations and the frequency of violations.
    
    II. **Main Logical Steps**:
         - From Proposi√ß√£o 1, reducing the time horizon $h$ increases the number of independent observations. An increase in independent observations leads to an increase in the power of the test.
         - From Proposi√ß√£o 2, reducing the confidence level $\alpha$ increases the frequency of violations. More frequent violations increase the data available to backtest, increasing the power of the test.
        
    III. **Key Transformations**:
        - $h \downarrow \implies \text{Number of Independent Observations} \uparrow \implies \text{Test Power} \uparrow$
        - $\alpha \downarrow \implies \text{Frequency of Violations} \uparrow \implies \text{Test Power} \uparrow$

    IV. **Conclusion**:
        - The theorem states that there is a trade-off. Both lowering $h$ and $\alpha$ increase the power of the backtest, supporting the claim. Therefore, this proves the existence of the trade-off.‚ñ†

**Lema 2**
*Seja $N$ o n√∫mero de observa√ß√µes independentes, e seja $X_i$ uma vari√°vel indicadora que vale 1 se a perda observada no per√≠odo $i$ excede o VAR previsto e 0 caso contr√°rio. Se o modelo VAR estiver bem calibrado, ent√£o $X_i$ s√£o vari√°veis aleat√≥rias independentes de Bernoulli com probabilidade de sucesso $1 - \alpha$.*

*Proof:*
   I. **Initial Setup**:
       - $N$ is the number of independent observations.
       - $X_i$ is an indicator variable, where $X_i = 1$ if the loss exceeds the predicted VAR at time $i$, and $X_i = 0$ otherwise.
       - $\alpha$ is the confidence level of the VAR.
       - A well-calibrated VAR model has a probability of $1-\alpha$ of the loss exceeding the VAR.
       - We assume independence between observations.

   II. **Main Logical Steps**:
       - For each observation $i$, there are only two outcomes: the loss exceeds the VAR ($X_i = 1$) or the loss does not exceed the VAR ($X_i = 0$).
       - Under a well-calibrated model, the probability of $X_i = 1$ (a loss exceeding the VAR) is $1 - \alpha$.
       - This is precisely the definition of a Bernoulli trial with a success probability of $1-\alpha$.
       - The independence of the $X_i$ variables comes from the assumption of independence of observations.

   III. **Key Transformations**:
       - $P(X_i=1) = 1-\alpha$.

   IV. **Conclusion**:
       - The variables $X_i$ are independent and follow a Bernoulli distribution with success probability $1-\alpha$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Vamos supor que estamos analisando 252 dias de negocia√ß√£o com um n√≠vel de confian√ßa de 95% ($\alpha=0.95$). Para cada dia $i$, definimos $X_i = 1$ se a perda naquele dia excedeu o VAR previsto e $X_i = 0$ caso contr√°rio. Se o modelo estiver bem calibrado, cada $X_i$ √© uma vari√°vel de Bernoulli com $p = 1 - 0.95 = 0.05$. Isso significa que a probabilidade de uma viola√ß√£o em qualquer dia √© de 5%.

**Teorema 1.1**
*Sob as condi√ß√µes do Lema 2, o n√∫mero de viola√ß√µes do VAR, $V = \sum_{i=1}^N X_i$, segue uma distribui√ß√£o binomial com par√¢metros $N$ e $1-\alpha$, ou seja, $V \sim Bin(N, 1 - \alpha)$.*

*Proof:*
   I. **Initial Setup**:
      - From Lema 2, $X_i$ are independent Bernoulli random variables with success probability $1-\alpha$.
      - $V$ is defined as the sum of these Bernoulli variables: $V = \sum_{i=1}^N X_i$.

   II. **Main Logical Steps**:
      - The sum of $N$ independent Bernoulli random variables with the same success probability follows a binomial distribution.
      - The parameters of the binomial distribution are $N$ (the number of trials) and $1-\alpha$ (the success probability).

   III. **Key Transformations**:
      - $V = \sum_{i=1}^N X_i \implies V \sim Bin(N, 1 - \alpha)$

   IV. **Conclusion**:
      - Therefore, the number of violations $V$ follows a binomial distribution with parameters $N$ and $1-\alpha$. ‚ñ†
> üí° **Exemplo Num√©rico:**
> Continuando o exemplo anterior, onde temos 252 observa√ß√µes independentes ($N=252$) e $\alpha = 0.95$, o n√∫mero total de viola√ß√µes $V$ segue uma distribui√ß√£o binomial com par√¢metros $N=252$ e $p=0.05$, ou seja, $V \sim Bin(252, 0.05)$. Isso nos permite calcular a probabilidade de observar um n√∫mero espec√≠fico de viola√ß√µes, assumindo que o modelo VAR est√° bem calibrado.

**Corol√°rio 1.2**
*A m√©dia e a vari√¢ncia do n√∫mero de viola√ß√µes $V$ s√£o dadas por $E[V] = N(1-\alpha)$ e $Var[V] = N(1-\alpha)\alpha$.*

*Proof:*
   I. **Initial Setup**:
      - From Theorem 1.1, $V \sim Bin(N, 1-\alpha)$.
      - We recall the mean and variance of a binomial distribution.
   II. **Main Logical Steps**:
        - The expected value (mean) of a binomial distribution $Bin(n,p)$ is given by $E[V]=np$.
        - The variance of a binomial distribution $Bin(n,p)$ is given by $Var[V]=np(1-p)$.
   III. **Key Transformations**:
      - Substituting $n = N$ and $p = 1 - \alpha$, we have
      -  $E[V] = N(1-\alpha)$.
      - $Var[V] = N(1-\alpha)(1-(1-\alpha)) = N(1-\alpha)\alpha$.

   IV. **Conclusion**:
     -  This shows that the mean and the variance of $V$ are given by $E[V] = N(1-\alpha)$ and $Var[V] = N(1-\alpha)\alpha$, respectively. ‚ñ†

> üí° **Exemplo Num√©rico:**
> No mesmo exemplo, com $N=252$ e $\alpha=0.95$, a m√©dia do n√∫mero de viola√ß√µes √© $E[V] = 252 \times (1 - 0.95) = 252 \times 0.05 = 12.6$, e a vari√¢ncia √© $Var[V] = 252 \times 0.05 \times 0.95 = 11.97$. Isso significa que, em m√©dia, esperamos 12.6 viola√ß√µes, com uma variabilidade em torno desse valor, quantificada pela vari√¢ncia.

Al√©m disso, √© crucial considerar a autocorrela√ß√£o das perdas. Se as perdas em per√≠odos sucessivos forem correlacionadas, a suposi√ß√£o de independ√™ncia das observa√ß√µes pode ser violada, comprometendo a validade do *backtesting*.

**Proposi√ß√£o 3**
    *A autocorrela√ß√£o positiva das perdas pode levar a um excesso de viola√ß√µes do VAR em clusters, o que pode reduzir o poder de um *backtesting* que assume independ√™ncia das observa√ß√µes.*
    *Proof:*
       I. **Initial Setup**:
        -  Assume positive autocorrelation in losses.
        -  Assume that we are using a backtesting method that assumes independence.
        
       II. **Main Logical Steps**:
           - Positive autocorrelation implies that if a loss exceeds the VAR in a given period, the probability of a loss exceeding the VAR in the next period is higher than expected under independence.
           - This causes violations to occur in clusters, i.e. if one violation occurs, the probability of seeing more violations in close succession is higher.
           - When violations cluster, the assumption of independent Bernoulli trials underlying most backtesting procedures is violated.
           - The methods assume that the number of violations is a realization of a binomial distribution, which does not hold under autocorrelation.
           - Since the number of observations is reduced, a clustered violation process has less power than an independent violation process.

       III. **Key Transformations**:
           - Autocorrelation $\implies$ violation clusters
           - Clusters $\implies$ violation of independence
           - Violation of independence $\implies$ Reduction in the power of the test

       IV. **Conclusion**:
        - Therefore, positive autocorrelation can lead to clustered violations, and reduce the effectiveness of backtesting.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
> Suponha que as perdas do dia atual sejam positivamente correlacionadas com as perdas do dia anterior. Se o VAR for violado hoje, √© mais prov√°vel que ele seja violado amanh√£ tamb√©m. Isso cria *clusters* de viola√ß√µes, onde v√°rios dias consecutivos apresentam perdas acima do VAR, em vez de viola√ß√µes aleat√≥rias e independentes. Um modelo que ignora essa autocorrela√ß√£o pode n√£o capturar a din√¢mica real do risco.
    
**Lema 3**
*Para detectar a presen√ßa de autocorrela√ß√£o nas viola√ß√µes do VAR, pode-se realizar um teste de raz√£o de verossimilhan√ßa (LR) de independ√™ncia de viola√ß√µes, ou similar, como o teste de Kupiec ou Christoffersen.*

    *Proof:*
     I. **Initial Setup**:
          - We want to detect if there is autocorrelation in the violations of the VAR model.
          - We know that violations of a well-calibrated VAR should be independent events.

     II. **Main Logical Steps**:
          - The test of the likelihood ratio (LR) is designed to test the hypothesis that the distribution of the violations is independent.
          - The Kupiec test checks if the overall violation rate is consistent with the confidence level, implicitly assuming independence over time.
          - The Christoffersen test is specifically designed to test for both correct violation rate and independence over time.

     III. **Key Transformations**:
          - These tests check the null hypothesis of independence against the alternative of an autocorrelation in the violations.

     IV. **Conclusion**:
          -  The LR test and specific tests such as Kupiec and Christoffersen can all detect the presence of autocorrelation, supporting the claim. ‚ñ†
> üí° **Exemplo Num√©rico:**
>  Se os resultados do *backtesting* mostram uma sequ√™ncia de viola√ß√µes em dias pr√≥ximos (por exemplo, viola√ß√µes nos dias 1, 2, 3, e depois nenhuma viola√ß√£o por v√°rias semanas, e em seguida viola√ß√µes nos dias 45 e 46) isso levanta suspeitas de autocorrela√ß√£o. Testes como o de Christoffersen ajudam a quantificar essa suspeita, e a verificar se os *clusters* de viola√ß√£o s√£o estatisticamente significativos ou apenas devidos ao acaso.

**Proposi√ß√£o 4**
    *A presen√ßa de *clusters* de viola√ß√µes, causada por autocorrela√ß√£o, implica que a vari√¢ncia do n√∫mero de viola√ß√µes pode ser maior do que o previsto pela distribui√ß√£o binomial sob a hip√≥tese de independ√™ncia.*
    
  *Proof:*
  
    I. **Initial Setup**:
        - Assume that the violations are positively autocorrelated, so that violations tend to cluster together.
        - Let $X_i$ be indicator variables such that $X_i = 1$ if there is a violation at time $i$ and 0 otherwise.
        - Let the number of violations be given by $V=\sum_{i=1}^N X_i$.
        
    II. **Main Logical Steps**:
        - If the violations were independent, then we could calculate the variance of the total number of violations using the fact that it follows a binomial distribution (as shown in Corol√°rio 1.2). In that case, $Var[V] = N(1-\alpha)\alpha$.
        - However, because of autocorrelation, the $X_i$ are not independent. The variance of the sum of correlated random variables is not the sum of the variances.
        - If $\text{Cov}(X_i,X_j) > 0$ for at least some $i \neq j$, then $Var[\sum X_i] > \sum Var[X_i]$.
        - The autocorrelation causes $\text{Cov}(X_i,X_j) > 0$, implying that the variance of the sum will be greater than if the $X_i$ were independent.

   III. **Key Transformations**:
       - Autocorrelation $\implies \text{Cov}(X_i,X_j) > 0$.
       -  $\text{Cov}(X_i,X_j) > 0$  $\implies$  $Var[\sum X_i] > \sum Var[X_i]$
       - $Var[\sum X_i] > \sum Var[X_i]$ $\implies$ $Var[V] > N(1-\alpha)\alpha$

   IV. **Conclusion**:
      -  The presence of autocorrelation increases the variance of the sum of violations over the case with independent variables.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
>  Usando o exemplo de 252 observa√ß√µes com $\alpha = 0.95$, sob a hip√≥tese de independ√™ncia, a vari√¢ncia do n√∫mero de viola√ß√µes √© de 11.97. No entanto, se houver autocorrela√ß√£o positiva, a vari√¢ncia real das viola√ß√µes pode ser muito maior. Por exemplo, se as viola√ß√µes ocorrem em *clusters*, a vari√¢ncia poderia ser 20 ou at√© mais. Isso significa que as viola√ß√µes ser√£o mais vari√°veis do que o esperado sob o modelo binomial, e o modelo de VAR pode estar subestimando o risco.
   
**Teorema 2**
 *O teste de Kupiec √© um teste de hip√≥tese para verificar se a frequ√™ncia de viola√ß√µes do VAR √© estatisticamente diferente do esperado dado o n√≠vel de confian√ßa $\alpha$. Ele testa a hip√≥tese nula de que a frequ√™ncia de viola√ß√µes observada √© consistente com a frequ√™ncia esperada sob um modelo bem calibrado.*

 *Proof:*
    I. **Initial Setup**:
      - The null hypothesis ($H_0$) is that the model is well-calibrated, i.e., the observed violation rate matches the expected violation rate.
      - The alternative hypothesis ($H_1$) is that the model is not well-calibrated, i.e., the observed violation rate is different from the expected rate.
      - Let $V$ be the observed number of violations, $N$ the number of independent observations, and $\alpha$ the confidence level.
      - We know that if the model is well-calibrated, the number of violations follows a binomial distribution $V \sim Bin(N, 1-\alpha)$.
      
    II. **Main Logical Steps**:
      -  The Kupiec test uses a likelihood ratio test to compare the likelihood under the null hypothesis (where $p = 1-\alpha$) with the likelihood of a model that admits a free violation probability $\hat{p}$ estimated from data (observed frequency of violations, i.e., $\hat{p} = V/N$).
      - The likelihood ratio statistic is constructed based on the binomial distribution.
      - The statistic is asymptotically chi-squared distributed, which allows for the construction of the test.
      
    III. **Key Transformations**:
      - Let $p$ be the expected probability of violation under the null hypothesis $p = 1-\alpha$.
      - The likelihood function is given by $L(p) = \binom{N}{V} p^V (1-p)^{N-V}$.
      - The test statistic is given by $-2ln\frac{L(1-\alpha)}{L(\hat{p})}$.
      - Under the null hypothesis, this statistic converges in distribution to a $\chi^2(1)$.

    IV. **Conclusion**:
      -  The Kupiec test checks if the frequency of violations is statistically different from that expected under the well-calibrated model hypothesis, using the distribution of the violations implied by a model with binomial violations. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que em 252 dias com um n√≠vel de confian√ßa de 95%, um modelo VAR tenha apresentado 20 viola√ß√µes. Sob a hip√≥tese nula de que o modelo est√° bem calibrado, o n√∫mero esperado de viola√ß√µes √© de 12.6. O teste de Kupiec calcula uma estat√≠stica de teste que compara a probabilidade de observar 20 viola√ß√µes se o modelo estiver bem calibrado com a probabilidade de observar 20 viola√ß√µes com a probabilidade de viola√ß√£o observada nos dados (20/252). Essa estat√≠stica de teste segue uma distribui√ß√£o $\chi^2$ com 1 grau de liberdade. Se o valor da estat√≠stica de teste for muito alto (e o p-valor correspondente for baixo), rejeita-se a hip√≥tese de que o modelo est√° bem calibrado e conclui-se que o modelo est√° subestimando o risco.
 
 **Lema 4**
 *O teste de Christoffersen testa se as viola√ß√µes do VAR s√£o independentes ao longo do tempo, e, portanto, se h√° *clusters* de viola√ß√µes. Ele testa a hip√≥tese nula de independ√™ncia das viola√ß√µes contra a hip√≥tese alternativa de que as viola√ß√µes seguem um processo de Markov de primeira ordem.*

    *Proof:*
    I. **Initial Setup**:
         - Null Hypothesis $H_0$: The violations are independent over time.
         - Alternative Hypothesis $H_1$: The violations follow a first-order Markov process (i.e., the probability of a violation depends on whether the previous observation was a violation or not).
         - $X_t$ is an indicator variable that is 1 if a violation occurs at time t, and 0 otherwise.

    II. **Main Logical Steps**:
         -  The Christoffersen test examines the transitions between violation and no-violation states using a likelihood ratio test.
         - Under $H_0$, the probability of a violation at time $t$ is independent of the occurrence of a violation at time $t-1$.
         - Under $H_1$, the probability of a violation depends on whether there was a violation in the previous period.
         - This dependence is expressed using a transition matrix:
        $$
        \begin{bmatrix}
          \pi_{00} & \pi_{01} \\
          \pi_{10} & \pi_{11}
        \end{bmatrix}
        $$
         where $\pi_{ij}$ is the probability of observing $X_t=j$ given $X_{t-1} = i$.
        
    III. **Key Transformations**:
         - The likelihood function under the null hypothesis (independence) is compared to the likelihood under the alternative hypothesis (Markov model).
         - The likelihood ratio is used to evaluate if the alternative hypothesis fits the data significantly better than the null hypothesis.
         - The test statistic is asymptotically chi-squared distributed.
        
    IV. **Conclusion**:
         -  The Christoffersen test determines if the observed transitions between violations and no-violations are consistent with the assumption of independence (i.e., if violations are clustered). ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que temos 252 dias de dados, e as viola√ß√µes do VAR ocorrem em sequ√™ncia. Por exemplo, se tivermos uma viola√ß√£o no dia $t-1$, a probabilidade de ter uma viola√ß√£o no dia $t$ √© muito maior do que se n√£o tivermos uma viola√ß√£o no dia $t-1$. O teste de Christoffersen verifica se essas transi√ß√µes entre estados (viola√ß√£o/n√£o-viola√ß√£o) s√£o estatisticamente significativas e inconsistentes com a hip√≥tese de independ√™ncia. Ele estima a matriz de transi√ß√£o e compara a probabilidade de os dados terem sido gerados por uma cadeia de Markov ou por um processo independente, calculando uma estat√≠stica de teste, que segue uma distribui√ß√£o $\chi^2$.

    
**Teorema 2.1**
    *O teste de Christoffersen tamb√©m avalia se a frequ√™ncia de viola√ß√µes √© consistente com o n√≠vel de confian√ßa $\alpha$, simultaneamente com a avalia√ß√£o da independ√™ncia das viola√ß√µes.*

    *Proof:*
        I. **Initial Setup**:
            - The null hypothesis for the Christoffersen test is that the model is well-calibrated and that the violations are independent of each other.
            - The alternative hypothesis is that either the violation frequency is not correct or the violations are not independent.
            -  The null hypothesis is given by $H_0: \pi_{01}=\pi_{11} = 1-\alpha$.

        II. **Main Logical Steps**:
            - The Christoffersen test is actually a joint test. It is composed of two likelihood ratio (LR) tests.
            -  The first LR test looks at whether the frequency of violations is compatible with the confidence level $\alpha$. This part of the test does not test independence.
            - The second LR test checks if there is statistical evidence of dependence on the previous state. This second test checks independence.
            - If we reject the null hypothesis in the Christoffersen test, it means that the data is incompatible with the assumption that the violations are both independent and have the correct frequency.
            
        III. **Key Transformations**:
            - The first test checks if $\pi_{01}=\pi_{11}=1-\alpha$ jointly. If not, then either the frequency or the independence is rejected.
            - The second test checks the independence of the violations, by testing if $\pi_{01}=\pi_{11}$.
            - The combination of both tests gives the Christoffersen test statistic.
            
        IV. **Conclusion**:
            -  Because of the structure of the test, the Christoffersen test assesses both the frequency of violations and the independence of the violations simultaneously. Therefore, it assesses if both the frequency of violations is consistent with $\alpha$ and if the violations are independent of each other, simultaneously.  ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Continuando o exemplo anterior, o teste de Christoffersen n√£o apenas verifica se a frequ√™ncia de viola√ß√µes √© aproximadamente 5% (se $\alpha=0.95$), mas tamb√©m se a ocorr√™ncia de uma viola√ß√£o em um dia aumenta a probabilidade de uma viola√ß√£o no dia seguinte. Ele faz isso de forma simult√¢nea. Isso √© especialmente importante porque um modelo pode ter a frequ√™ncia de viola√ß√µes correta, mas as viola√ß√µes ocorrem em *clusters*, o que o teste de Christoffersen √© capaz de detectar.
    
**Proposi√ß√£o 5**
   *Al√©m do teste de Kupiec e do teste de Christoffersen, existem outros testes de *backtesting* como o teste de Lopez, o teste de correla√ß√£o serial, e testes baseados em fun√ß√µes de perda, que podem complementar a an√°lise do desempenho do modelo VAR.*
   *Proof:*
        I. **Initial Setup**:
            - The Kupiec and Christoffersen tests are not exhaustive.
            - There are other ways to evaluate a VAR model through backtesting.
        II. **Main Logical Steps**:
            - The Lopez test assesses the magnitude of losses that violate the VAR, not just the frequency. It uses a loss function that considers both the number and the size of the violations.
            - Tests of serial correlation can detect if violations cluster or are predictable, which is undesirable. For example, the Ljung-Box test.
            - Test based on loss functions (such as the tick loss) can be tailored to capture specific properties that are relevant for the user.
        III. **Key Transformations**:
             - The Lopez test, tests of serial correlation, and loss function-based tests provide additional tests that measure aspects of the VAR model not assessed by the Kupiec and Christoffersen test.
       IV. **Conclusion**:
            -  These other tests are useful to evaluate if the VAR model is adequate to a certain situation, and offer a more complete picture of the VAR model‚Äôs quality. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que o teste de Kupiec tenha aprovado um modelo VAR com um n√≠vel de confian√ßa de 95% mas o teste de Christoffersen tenha rejeitado o modelo por apresentar autocorrela√ß√£o. Nesse caso, podemos aplicar outros testes de *backtesting*. Por exemplo, o teste de Lopez poder√° apontar
que as viola√ß√µes do VAR s√£o muito maiores do que o esperado. Um teste de correla√ß√£o serial poder√° confirmar que as viola√ß√µes est√£o clusterizadas. Um teste baseado em fun√ß√µes de perda poder√° indicar que as perdas acima do### Model Backtesting and Horizon Selection in VAR

### Introdu√ß√£o
Em continuidade ao estudo do Value at Risk (VAR) e suas aplica√ß√µes, este cap√≠tulo aborda um aspecto crucial para a valida√ß√£o e confiabilidade dos modelos: o *backtesting*. Como vimos anteriormente, o VAR √© uma medida de risco que resume a potencial perda em um determinado horizonte de tempo e n√≠vel de confian√ßa [^1]. No entanto, a precis√£o do VAR depende da qualidade dos dados e da adequa√ß√£o do modelo utilizado. O *backtesting* √© uma ferramenta essencial para avaliar a performance de um modelo VAR e identificar poss√≠veis vieses nas previs√µes [^1]. Esta se√ß√£o se aprofundar√° nos crit√©rios para realizar o *backtesting*, com foco especial na import√¢ncia do horizonte de tempo na efic√°cia dos testes.

### Conceitos Fundamentais
O *backtesting* consiste em comparar sistematicamente as previs√µes de perdas obtidas por meio do VAR com as perdas e lucros (P&L) efetivamente realizados posteriormente [^1]. O objetivo principal do *backtesting* √© detectar vieses ou inconsist√™ncias nos resultados do VAR, garantindo que o modelo esteja gerando previs√µes confi√°veis. A ideia central √© que um modelo VAR bem calibrado deve ser capaz de prever a frequ√™ncia com que as perdas efetivas excedem o VAR previsto, alinhando-se com o n√≠vel de confian√ßa estabelecido [^2].

Para realizar um *backtesting* eficaz, √© fundamental levar em considera√ß√£o o horizonte de tempo utilizado no c√°lculo do VAR. A escolha do horizonte de tempo influencia diretamente o n√∫mero de observa√ß√µes independentes dispon√≠veis para o teste, afetando o poder estat√≠stico do mesmo [^1]. O poder de um teste refere-se √† sua capacidade de detectar desvios significativos entre as previs√µes do VAR e os resultados reais.

Como mencionado anteriormente, o horizonte de tempo √© um dos fatores quantitativos que influenciam o c√°lculo do VAR. Em geral, um horizonte mais longo leva a um VAR maior. Ao usar o VAR como uma medida de risco potencial, o horizonte de tempo deve ser definido pela liquidez dos ativos, ou seja, o tempo necess√°rio para liquidar o portf√≥lio sem grandes impactos no mercado [^1].

#### O Impacto do Horizonte de Tempo no Backtesting
A escolha do horizonte de tempo tem um impacto significativo no n√∫mero de observa√ß√µes independentes dispon√≠veis para o *backtesting*. Um horizonte mais longo reduz o n√∫mero de observa√ß√µes independentes em um determinado per√≠odo. Por exemplo, se utilizarmos um horizonte de VAR de duas semanas, teremos apenas 26 observa√ß√µes independentes por ano [^1]. Por outro lado, um horizonte de um dia fornecer√° aproximadamente 252 observa√ß√µes independentes ao longo de um ano [^1].

O poder do teste, ou seja, a capacidade de detectar vieses no modelo, est√° diretamente relacionado ao n√∫mero de observa√ß√µes independentes. Com um n√∫mero maior de observa√ß√µes, o teste se torna mais sens√≠vel a desvios entre as previs√µes do VAR e as perdas efetivas [^1]. Por isso, para fins de *backtesting*, √© prefer√≠vel utilizar horizontes de tempo mais curtos, como um dia, para maximizar o poder dos testes [^1].

**Proposi√ß√£o 1**
   *A escolha de um horizonte de tempo $h$ para o c√°lculo do VAR implica que, em um per√≠odo de $T$ dias, temos aproximadamente $T/h$ observa√ß√µes independentes. Para um dado per√≠odo de tempo $T$, o n√∫mero de observa√ß√µes independentes √© inversamente proporcional ao tamanho do horizonte $h$.*
   
   *Proof:*

   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Each observation period for the VAR spans $h$ days.

   II. **Main Logical Steps**:
      - The total number of days, $T$, is divided by the length of each observation period, $h$, to determine the number of non-overlapping observation periods.
      - This gives the number of independent observations.

   III. **Key Transformations**:
      -  Number of independent observations $\approx \frac{T}{h}$

   IV. **Conclusion**:
      - As $h$ increases, $T/h$ decreases, implying an inverse relationship between $h$ and the number of independent observations for a fixed $T$.
      - This proves the statement: "the number of independent observations is inversely proportional to the size of the horizon $h$". ‚ñ†
> üí° **Exemplo Num√©rico:**
> Suponha que temos um per√≠odo de $T = 252$ dias (um ano de negocia√ß√£o). Se usarmos um horizonte de tempo $h = 1$ dia, teremos aproximadamente $252/1 = 252$ observa√ß√µes independentes. Se aumentarmos o horizonte para $h = 5$ dias (uma semana), teremos $252/5 \approx 50$ observa√ß√µes independentes. E se o horizonte for $h=21$ (aproximadamente um m√™s), teremos $252/21=12$ observa√ß√µes independentes. Este exemplo ilustra claramente a rela√ß√£o inversa entre o horizonte de tempo e o n√∫mero de observa√ß√µes independentes.

#### Rela√ß√£o com o N√≠vel de Confian√ßa
√â importante notar que o n√≠vel de confian√ßa tamb√©m influencia o n√∫mero de observa√ß√µes na cauda da distribui√ß√£o. N√≠veis de confian√ßa mais altos, como 99%, resultam em menos observa√ß√µes na cauda, dificultando a identifica√ß√£o de vieses no modelo. Em outras palavras, para confirmar a validade do modelo com um n√≠vel de confian√ßa de 99%, seria necess√°rio um longo per√≠odo de observa√ß√µes para coletar dados suficientes na cauda da distribui√ß√£o [^1]. Por isso, para o *backtesting*, n√≠veis de confian√ßa mais baixos, como 95%, podem ser prefer√≠veis, permitindo uma an√°lise mais frequente dos resultados do modelo [^1].

**Lema 1**
   *Para um n√≠vel de confian√ßa $\alpha$, o n√∫mero de observa√ß√µes esperadas na cauda da distribui√ß√£o em um per√≠odo $T$ com horizonte de tempo $h$ √© aproximadamente $(1-\alpha)T/h$.*

   *Proof:*
   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Let $\alpha$ be the confidence level.
      - The number of independent observations is approximately $T/h$.

   II. **Main Logical Steps**:
       - With a confidence level $\alpha$, the probability of an observation falling in the tail (exceeding the VAR) is $1 - \alpha$.
       - The expected number of observations in the tail is the product of the number of independent observations and the probability of falling in the tail.

   III. **Key Transformations**:
        - Expected number of observations in the tail $\approx \frac{T}{h} \times (1-\alpha) = (1-\alpha) \frac{T}{h}$

   IV. **Conclusion**:
      - This shows that the expected number of observations in the tail is approximately $(1-\alpha)T/h$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Usando o exemplo anterior com $T=252$ dias e um horizonte de $h=1$ dia, se o n√≠vel de confian√ßa for $\alpha = 0.95$ (95%), o n√∫mero esperado de observa√ß√µes na cauda √© $(1-0.95) \times 252/1 = 0.05 \times 252 = 12.6$. Isso significa que, em m√©dia, esperamos que o VAR seja violado aproximadamente 12 ou 13 vezes em um ano. Se o n√≠vel de confian√ßa for $\alpha=0.99$, o n√∫mero esperado de viola√ß√µes cai para $(1-0.99) \times 252 = 0.01 \times 252 = 2.52$, indicando que seria necess√°rio um per√≠odo muito maior de observa√ß√µes para testar o modelo de forma eficaz. Se, por outro lado, mantemos o n√≠vel de confian√ßa em 95% mas aumentamos o horizonte para $h=5$, o n√∫mero de observa√ß√µes na cauda ser√° $(1-0.95)\times 252/5 \approx 2.5$.
  
**Corol√°rio 1.1**
   *O n√∫mero de observa√ß√µes na cauda √© diretamente proporcional ao per√≠odo $T$ e inversamente proporcional ao horizonte $h$, e diminui com o aumento do n√≠vel de confian√ßa $\alpha$.*

   *Proof:*
   I. **Initial Setup**:
       - From Lema 1, the number of observations in the tail is approximately $(1-\alpha)T/h$.

   II. **Main Logical Steps**:
       - We analyze the effect of $T$, $h$, and $\alpha$ on this expression.

   III. **Key Transformations**:
        - As $T$ increases, the number of observations in the tail increases proportionally.
        - As $h$ increases, the number of observations in the tail decreases proportionally.
        - As $\alpha$ increases, $(1-\alpha)$ decreases, thus decreasing the number of observations in the tail.

   IV. **Conclusion**:
        -  This confirms the statement that the number of tail observations is directly proportional to $T$, inversely proportional to $h$, and decreases with an increase in $\alpha$. ‚ñ†

Al√©m disso, vale ressaltar que a escolha do n√≠vel de confian√ßa afeta o tipo de erros que o *backtesting* ser√° capaz de detectar. Um n√≠vel de confian√ßa mais alto prioriza a detec√ß√£o de erros na cauda da distribui√ß√£o, enquanto um n√≠vel de confian√ßa mais baixo permite uma detec√ß√£o mais frequente de erros, ainda que menos extremos.

**Proposi√ß√£o 2**
    *Um n√≠vel de confian√ßa mais baixo aumenta a frequ√™ncia com que os resultados do VAR s√£o comparados com os retornos realizados, e, consequentemente, aumenta a sensibilidade a potenciais vieses no modelo.*
  
  *Proof:*

  I. **Initial Setup**:
    - Let $\alpha$ be the confidence level.
    - A lower confidence level implies a smaller $\alpha$.
    - VAR is calculated for a given confidence level.

  II. **Main Logical Steps**:
    - A lower confidence level (smaller $\alpha$) corresponds to a lower VAR value (since the VAR is a quantile).
    - A lower VAR value means a greater chance of actual losses exceeding the VAR.
    - If the actual loss exceeds the VAR value, this is considered a violation in the backtesting process.
    - More violations mean more comparisons between VAR and actual returns.

  III. **Key Transformations**:
    - Lower $\alpha$  $\implies$ Lower VAR
    - Lower VAR $\implies$ More violations
    - More violations $\implies$ More frequent comparisons between VAR and actual returns

  IV. **Conclusion**:
    - This demonstrates that a lower confidence level results in more frequent comparisons between VAR predictions and actual returns. Therefore, the sensitivity of the backtesting to potential biases in the model increases.‚ñ†

> üí° **Exemplo Num√©rico:**
> Considere um modelo VAR com um horizonte de um dia ($h=1$). Se o n√≠vel de confian√ßa for $\alpha = 0.99$, espera-se que as viola√ß√µes sejam raras, e a cada 100 dias de negocia√ß√£o, apenas 1 dia, em m√©dia, apresentar√° uma perda que ultrapassa o VAR. Se o n√≠vel de confian√ßa for reduzido para $\alpha=0.95$, as viola√ß√µes tornam-se mais frequentes, com uma m√©dia de 5 dias a cada 100, e isso permite uma an√°lise mais detalhada e frequente do modelo.

**Teorema 1**
*Existe um trade-off entre o horizonte de tempo $h$ e o n√≠vel de confian√ßa $\alpha$ no *backtesting*. Diminuir $h$ aumenta o n√∫mero de observa√ß√µes independentes e, portanto, o poder do teste, enquanto diminuir $\alpha$ aumenta a frequ√™ncia de viola√ß√µes do VAR e, tamb√©m, aumenta o poder do teste.*
 *Proof:*
    I. **Initial Setup**:
        - The power of a backtesting test is directly related to the number of independent observations and the frequency of violations.
    
    II. **Main Logical Steps**:
         - From Proposi√ß√£o 1, reducing the time horizon $h$ increases the number of independent observations. An increase in independent observations leads to an increase in the power of the test.
         - From Proposi√ß√£o 2, reducing the confidence level $\alpha$ increases the frequency of violations. More frequent violations increase the data available to backtest, increasing the power of the test.
        
    III. **Key Transformations**:
        - $h \downarrow \implies \text{Number of Independent Observations} \uparrow \implies \text{Test Power} \uparrow$
        - $\alpha \downarrow \implies \text{Frequency of Violations} \uparrow \implies \text{Test Power} \uparrow$

    IV. **Conclusion**:
        - The theorem states that there is a trade-off. Both lowering $h$ and $\alpha$ increase the power of the backtest, supporting the claim. Therefore, this proves the existence of the trade-off.‚ñ†

**Lema 2**
*Seja $N$ o n√∫mero de observa√ß√µes independentes, e seja $X_i$ uma vari√°vel indicadora que vale 1 se a perda observada no per√≠odo $i$ excede o VAR previsto e 0 caso contr√°rio. Se o modelo VAR estiver bem calibrado, ent√£o $X_i$ s√£o vari√°veis aleat√≥rias independentes de Bernoulli com probabilidade de sucesso $1 - \alpha$.*

*Proof:*
   I. **Initial Setup**:
       - $N$ is the number of independent observations.
       - $X_i$ is an indicator variable, where $X_i = 1$ if the loss exceeds the predicted VAR at time $i$, and $X_i = 0$ otherwise.
       - $\alpha$ is the confidence level of the VAR.
       - A well-calibrated VAR model has a probability of $1-\alpha$ of the loss exceeding the VAR.
       - We assume independence between observations.

   II. **Main Logical Steps**:
       - For each observation $i$, there are only two outcomes: the loss exceeds the VAR ($X_i = 1$) or the loss does not exceed the VAR ($X_i = 0$).
       - Under a well-calibrated model, the probability of $X_i = 1$ (a loss exceeding the VAR) is $1 - \alpha$.
       - This is precisely the definition of a Bernoulli trial with a success probability of $1-\alpha$.
       - The independence of the $X_i$ variables comes from the assumption of independence of observations.

   III. **Key Transformations**:
       - $P(X_i=1) = 1-\alpha$.

   IV. **Conclusion**:
       - The variables $X_i$ are independent and follow a Bernoulli distribution with success probability $1-\alpha$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Vamos supor que estamos analisando 252 dias de negocia√ß√£o com um n√≠vel de confian√ßa de 95% ($\alpha=0.95$). Para cada dia $i$, definimos $X_i = 1$ se a perda naquele dia excedeu o VAR previsto e $X_i = 0$ caso contr√°rio. Se o modelo estiver bem calibrado, cada $X_i$ √© uma vari√°vel de Bernoulli com $p = 1 - 0.95 = 0.05$. Isso significa que a probabilidade de uma viola√ß√£o em qualquer dia √© de 5%.

**Teorema 1.1**
*Sob as condi√ß√µes do Lema 2, o n√∫mero de viola√ß√µes do VAR, $V = \sum_{i=1}^N X_i$, segue uma distribui√ß√£o binomial com par√¢metros $N$ e $1-\alpha$, ou seja, $V \sim Bin(N, 1 - \alpha)$.*

*Proof:*
   I. **Initial Setup**:
      - From Lema 2, $X_i$ are independent Bernoulli random variables with success probability $1-\alpha$.
      - $V$ is defined as the sum of these Bernoulli variables: $V = \sum_{i=1}^N X_i$.

   II. **Main Logical Steps**:
      - The sum of $N$ independent Bernoulli random variables with the same success probability follows a binomial distribution.
      - The parameters of the binomial distribution are $N$ (the number of trials) and $1-\alpha$ (the success probability).

   III. **Key Transformations**:
      - $V = \sum_{i=1}^N X_i \implies V \sim Bin(N, 1 - \alpha)$

   IV. **Conclusion**:
      - Therefore, the number of violations $V$ follows a binomial distribution with parameters $N$ and $1-\alpha$. ‚ñ†
> üí° **Exemplo Num√©rico:**
> Continuando o exemplo anterior, onde temos 252 observa√ß√µes independentes ($N=252$) e $\alpha = 0.95$, o n√∫mero total de viola√ß√µes $V$ segue uma distribui√ß√£o binomial com par√¢metros $N=252$ e $p=0.05$, ou seja, $V \sim Bin(252, 0.05)$. Isso nos permite calcular a probabilidade de observar um n√∫mero espec√≠fico de viola√ß√µes, assumindo que o modelo VAR est√° bem calibrado.

**Corol√°rio 1.2**
*A m√©dia e a vari√¢ncia do n√∫mero de viola√ß√µes $V$ s√£o dadas por $E[V] = N(1-\alpha)$ e $Var[V] = N(1-\alpha)\alpha$.*

*Proof:*
   I. **Initial Setup**:
      - From Theorem 1.1, $V \sim Bin(N, 1-\alpha)$.
      - We recall the mean and variance of a binomial distribution.
   II. **Main Logical Steps**:
        - The expected value (mean) of a binomial distribution $Bin(n,p)$ is given by $E[V]=np$.
        - The variance of a binomial distribution $Bin(n,p)$ is given by $Var[V]=np(1-p)$.
   III. **Key Transformations**:
      - Substituting $n = N$ and $p = 1 - \alpha$, we have
      -  $E[V] = N(1-\alpha)$.
      - $Var[V] = N(1-\alpha)(1-(1-\alpha)) = N(1-\alpha)\alpha$.

   IV. **Conclusion**:
     -  This shows that the mean and the variance of $V$ are given by $E[V] = N(1-\alpha)$ and $Var[V] = N(1-\alpha)\alpha$, respectively. ‚ñ†

> üí° **Exemplo Num√©rico:**
> No mesmo exemplo, com $N=252$ e $\alpha=0.95$, a m√©dia do n√∫mero de viola√ß√µes √© $E[V] = 252 \times (1 - 0.95) = 252 \times 0.05 = 12.6$, e a vari√¢ncia √© $Var[V] = 252 \times 0.05 \times 0.95 = 11.97$. Isso significa que, em m√©dia, esperamos 12.6 viola√ß√µes, com uma variabilidade em torno desse valor, quantificada pela vari√¢ncia.

Al√©m disso, √© crucial considerar a autocorrela√ß√£o das perdas. Se as perdas em per√≠odos sucessivos forem correlacionadas, a suposi√ß√£o de independ√™ncia das observa√ß√µes pode ser violada, comprometendo a validade do *backtesting*.

**Proposi√ß√£o 3**
    *A autocorrela√ß√£o positiva das perdas pode levar a um excesso de viola√ß√µes do VAR em clusters, o que pode reduzir o poder de um *backtesting* que assume independ√™ncia das observa√ß√µes.*
    *Proof:*
       I. **Initial Setup**:
        -  Assume positive autocorrelation in losses.
        -  Assume that we are using a backtesting method that assumes independence.
        
       II. **Main Logical Steps**:
           - Positive autocorrelation implies that if a loss exceeds the VAR in a given period, the probability of a loss exceeding the VAR in the next period is higher than expected under independence.
           - This causes violations to occur in clusters, i.e. if one violation occurs, the probability of seeing more violations in close succession is higher.
           - When violations cluster, the assumption of independent Bernoulli trials underlying most backtesting procedures is violated.
           - The methods assume that the number of violations is a realization of a binomial distribution, which does not hold under autocorrelation.
           - Since the number of observations is reduced, a clustered violation process has less power than an independent violation process.

       III. **Key Transformations**:
           - Autocorrelation $\implies$ violation clusters
           - Clusters $\implies$ violation of independence
           - Violation of independence $\implies$ Reduction in the power of the test

       IV. **Conclusion**:
        - Therefore, positive autocorrelation can lead to clustered violations, and reduce the effectiveness of backtesting.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
> Suponha que as perdas do dia atual sejam positivamente correlacionadas com as perdas do dia anterior. Se o VAR for violado hoje, √© mais prov√°vel que ele seja violado amanh√£ tamb√©m. Isso cria *clusters* de viola√ß√µes, onde v√°rios dias consecutivos apresentam perdas acima do VAR, em vez de viola√ß√µes aleat√≥rias e independentes. Um modelo que ignora essa autocorrela√ß√£o pode n√£o capturar a din√¢mica real do risco.
    
**Lema 3**
*Para detectar a presen√ßa de autocorrela√ß√£o nas viola√ß√µes do VAR, pode-se realizar um teste de raz√£o de verossimilhan√ßa (LR) de independ√™ncia de viola√ß√µes, ou similar, como o teste de Kupiec ou Christoffersen.*

    *Proof:*
     I. **Initial Setup**:
          - We want to detect if there is autocorrelation in the violations of the VAR model.
          - We know that violations of a well-calibrated VAR should be independent events.

     II. **Main Logical Steps**:
          - The test of the likelihood ratio (LR) is designed to test the hypothesis that the distribution of the violations is independent.
          - The Kupiec test checks if the overall violation rate is consistent with the confidence level, implicitly assuming independence over time.
          - The Christoffersen test is specifically designed to test for both correct violation rate and independence over time.

     III. **Key Transformations**:
          - These tests check the null hypothesis of independence against the alternative of an autocorrelation in the violations.

     IV. **Conclusion**:
          -  The LR test and specific tests such as Kupiec and Christoffersen can all detect the presence of autocorrelation, supporting the claim. ‚ñ†
> üí° **Exemplo Num√©rico:**
>  Se os resultados do *backtesting* mostram uma sequ√™ncia de viola√ß√µes em dias pr√≥ximos (por exemplo, viola√ß√µes nos dias 1, 2, 3, e depois nenhuma viola√ß√£o por v√°rias semanas, e em seguida viola√ß√µes nos dias 45 e 46) isso levanta suspeitas de autocorrela√ß√£o. Testes como o de Christoffersen ajudam a quantificar essa suspeita, e a verificar se os *clusters* de viola√ß√£o s√£o estatisticamente significativos ou apenas devidos ao acaso.

**Proposi√ß√£o 4**
    *A presen√ßa de *clusters* de viola√ß√µes, causada por autocorrela√ß√£o, implica que a vari√¢ncia do n√∫mero de viola√ß√µes pode ser maior do que o previsto pela distribui√ß√£o binomial sob a hip√≥tese de independ√™ncia.*
    
  *Proof:*
  
    I. **Initial Setup**:
        - Assume that the violations are positively autocorrelated, so that violations tend to cluster together.
        - Let $X_i$ be indicator variables such that $X_i = 1$ if there is a violation at time $i$ and 0 otherwise.
        - Let the number of violations be given by $V=\sum_{i=1}^N X_i$.
        
    II. **Main Logical Steps**:
        - If the violations were independent, then we could calculate the variance of the total number of violations using the fact that it follows a binomial distribution (as shown in Corol√°rio 1.2). In that case, $Var[V] = N(1-\alpha)\alpha$.
        - However, because of autocorrelation, the $X_i$ are not independent. The variance of the sum of correlated random variables is not the sum of the variances.
        - If $\text{Cov}(X_i,X_j) > 0$ for at least some $i \neq j$, then $Var[\sum X_i] > \sum Var[X_i]$.
        - The autocorrelation causes $\text{Cov}(X_i,X_j) > 0$, implying that the variance of the sum will be greater than if the $X_i$ were independent.

   III. **Key Transformations**:
       - Autocorrelation $\implies \text{Cov}(X_i,X_j) > 0$.
       -  $\text{Cov}(X_i,X_j) > 0$  $\implies$  $Var[\sum X_i] > \sum Var[X_i]$
       - $Var[\sum X_i] > \sum Var[X_i]$ $\implies$ $Var[V] > N(1-\alpha)\alpha$

   IV. **Conclusion**:
      -  The presence of autocorrelation increases the variance of the sum of violations over the case with independent variables.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
>  Usando o exemplo de 252 observa√ß√µes com $\alpha = 0.95$, sob a hip√≥tese de independ√™ncia, a vari√¢ncia do n√∫mero de viola√ß√µes √© de 11.97. No entanto, se houver autocorrela√ß√£o positiva, a vari√¢ncia real das viola√ß√µes pode ser muito maior. Por exemplo, se as viola√ß√µes ocorrem em *clusters*, a vari√¢ncia poderia ser 20 ou at√© mais. Isso significa que as viola√ß√µes ser√£o mais vari√°veis do que o esperado sob o modelo binomial, e o modelo de VAR pode estar subestimando o risco.
   
**Teorema 2**
 *O teste de Kupiec √© um teste de hip√≥tese para verificar se a frequ√™ncia de viola√ß√µes do VAR √© estatisticamente diferente do esperado dado o n√≠vel de confian√ßa $\alpha$. Ele testa a hip√≥tese nula de que a frequ√™ncia de viola√ß√µes observada √© consistente com a frequ√™ncia esperada sob um modelo bem calibrado.*

 *Proof:*
    I. **Initial Setup**:
      - The null hypothesis ($H_0$) is that the model is well-calibrated, i.e., the observed violation rate matches the expected violation rate.
      - The alternative hypothesis ($H_1$) is that the model is not well-calibrated, i.e., the observed violation rate is different from the expected rate.
      - Let $V$ be the observed number of violations, $N$ the number of independent observations, and $\alpha$ the confidence level.
      - We know that if the model is well-calibrated, the number of violations follows a binomial distribution $V \sim Bin(N, 1-\alpha)$.
      
    II. **Main Logical Steps**:
      -  The Kupiec test uses a likelihood ratio test to compare the likelihood under the null hypothesis (where $p = 1-\alpha$) with the likelihood of a model that admits a free violation probability $\hat{p}$ estimated from data (observed frequency of violations, i.e., $\hat{p} = V/N$).
      - The likelihood ratio statistic is constructed based on the binomial distribution.
      - The statistic is asymptotically chi-squared distributed, which allows for the construction of the test.
      
    III. **Key Transformations**:
      - Let $p$ be the expected probability of violation under the null hypothesis $p = 1-\alpha$.
      - The likelihood function is given by $L(p) = \binom{N}{V} p^V (1-p)^{N-V}$.
      - The test statistic is given by $-2ln\frac{L(1-\alpha)}{L(\hat{p})}$.
      - Under the null hypothesis, this statistic converges in distribution to a $\chi^2(1)$.

    IV. **Conclusion**:
      -  The Kupiec test checks if the frequency of violations is statistically different from that expected under the well-calibrated model hypothesis, using the distribution of the violations implied by a model with binomial violations. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que em 252 dias com um n√≠vel de confian√ßa de 95%, um modelo VAR tenha apresentado 20 viola√ß√µes. Sob a hip√≥tese nula de que o modelo est√° bem calibrado, o n√∫mero esperado de viola√ß√µes √© de 12.6. O teste de Kupiec calcula uma estat√≠stica de teste que compara a probabilidade de observar 20 viola√ß√µes se o modelo estiver bem calibrado com a probabilidade de observar 20 viola√ß√µes com a probabilidade de viola√ß√£o observada nos dados (20/252). Essa estat√≠stica de teste segue uma distribui√ß√£o $\chi^2$ com 1 grau de liberdade. Se o valor da estat√≠stica de teste for muito alto (e o p-valor correspondente for baixo), rejeita-se a hip√≥tese de que o modelo est√° bem calibrado e conclui-se que o modelo est√° subestimando o risco.
 
 **Lema 4**
 *O teste de Christoffersen testa se as viola√ß√µes do VAR s√£o independentes ao longo do tempo, e, portanto, se h√° *clusters* de viola√ß√µes. Ele testa a hip√≥tese nula de independ√™ncia das viola√ß√µes contra a hip√≥tese alternativa de que as viola√ß√µes seguem um processo de Markov de primeira ordem.*

    *Proof:*
    I. **Initial Setup**:
         - Null Hypothesis $H_0$: The violations are independent over time.
         - Alternative Hypothesis $H_1$: The violations follow a first-order Markov process (i.e., the probability of a violation depends on whether the previous observation was a violation or not).
         - $X_t$ is an indicator variable that is 1 if a violation occurs at time t, and 0 otherwise.

    II. **Main Logical Steps**:
         -  The Christoffersen test examines the transitions between violation and no-violation states using a likelihood ratio test.
         - Under $H_0$, the probability of a violation at time $t$ is independent of the occurrence of a violation at time $t-1$.
         - Under $H_1$, the probability of a violation depends on whether there was a violation in the previous period.
         - This dependence is expressed using a transition matrix:
        $$
        \begin{bmatrix}
          \pi_{00} & \pi_{01} \\
          \pi_{10} & \pi_{11}
        \end{bmatrix}
        $$
         where $\pi_{ij}$ is the probability of observing $X_t=j$ given $X_{t-1} = i$.
        
    III. **Key Transformations**:
         - The likelihood function under the null hypothesis (independence) is compared to the likelihood under the alternative hypothesis (Markov model).
         - The likelihood ratio is used to evaluate if the alternative hypothesis fits the data significantly better than the null hypothesis.
         - The test statistic is asymptotically chi-squared distributed.
        
    IV. **Conclusion**:
         -  The Christoffersen test determines if the observed transitions between violations and no-violations are consistent with the assumption of independence (i.e., if violations are clustered). ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que temos 252 dias de dados, e as viola√ß√µes do VAR ocorrem em sequ√™ncia. Por exemplo, se tivermos uma viola√ß√£o no dia $t-1$, a probabilidade de ter uma viola√ß√£o no dia $t$ √© muito maior do que se n√£o tivermos uma viola√ß√£o no dia $t-1$. O teste de Christoffersen verifica se essas transi√ß√µes entre estados (viola√ß√£o/n√£o-viola√ß√£o) s√£o estatisticamente significativas e inconsistentes com a hip√≥tese de independ√™ncia. Ele estima a matriz de transi√ß√£o e compara a probabilidade de os dados terem sido gerados por uma cadeia de Markov ou por um processo independente, calculando uma estat√≠stica de teste, que segue uma distribui√ß√£o $\chi^2$.

    
**Teorema 2.1**
    *O teste de Christoffersen tamb√©m avalia se a frequ√™ncia de viola√ß√µes √© consistente com o n√≠vel de confian√ßa $\alpha$, simultaneamente com a avalia√ß√£o da independ√™ncia das viola√ß√µes.*

    *Proof:*
        I. **Initial Setup**:
            - The null hypothesis for the Christoffersen test is that the model is well-calibrated and that the violations are independent of each other.
            - The alternative hypothesis is that either the violation frequency is not correct or the violations are not independent.
            -  The null hypothesis is given by $H_0: \pi_{01}=\pi_{11} = 1-\alpha$.

        II. **Main Logical Steps**:
            - The Christoffersen test is actually a joint test. It is composed of two likelihood ratio (LR) tests.
            -  The first LR test looks at whether the frequency of violations is compatible with the confidence level $\alpha$. This part of the test does not test independence.
            - The second LR test checks if there is statistical evidence of dependence on the previous state. This second test checks independence.
            - If we reject the null hypothesis in the Christoffersen test, it means that the data is incompatible with the assumption that the violations are both independent and have the correct frequency.
            
        III. **Key Transformations**:
            - The first test checks if $\pi_{01}=\pi_{11}=1-\alpha$ jointly. If not, then either the frequency or the independence is rejected.
            - The second test checks the independence of the violations, by testing if $\pi_{01}=\pi_{11}$.
            - The combination of both tests gives the Christoffersen test statistic.
            
        IV. **Conclusion**:
            -  Because of the structure of the test, the Christoffersen test assesses both the frequency of violations and the independence of the violations simultaneously. Therefore, it assesses if both the frequency of violations is consistent with $\alpha$ and if the violations are independent of each other, simultaneously.  ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Continuando o exemplo anterior, o teste de Christoffersen n√£o apenas verifica se a frequ√™ncia de viola√ß√µes √© aproximadamente 5% (se $\alpha=0.95$), mas tamb√©m se a ocorr√™ncia de uma viola√ß√£o em um dia aumenta a probabilidade de uma viola√ß√£o no dia seguinte. Ele faz isso de forma simult√¢nea. Isso √© especialmente importante porque um modelo pode ter a frequ√™ncia de viola√ß√µes correta, mas as viola√ß√µes ocorrem em *clusters*, o que o teste de Christoffersen √© capaz de detectar.
    
**Proposi√ß√£o 5**
   *Al√©m do teste de Kupiec e do teste de Christoffersen, existem outros testes de *backtesting* como o teste de Lopez, o teste de correla√ß√£o serial, e testes baseados em fun√ß√µes de perda, que podem complementar a an√°lise do desempenho do modelo VAR.*
   *Proof:*
        I. **Initial Setup**:
            - The Kupiec and Christoffersen tests are not exhaustive.
            - There are other ways to evaluate a VAR model through backtesting.
        II. **Main Logical Steps**:
            - The Lopez test assesses the magnitude of losses that violate the VAR, not just the frequency. It uses a loss function that considers both the number and the size of the violations.
            - Tests of serial correlation can detect if violations cluster or are predictable, which is undesirable. For example, the Ljung-Box test.
            - Test based on loss functions (such as the tick loss) can be tailored to capture specific properties that are relevant for the user.
        III. **Key Transformations**:
             - The Lopez test, tests of serial correlation, and loss function-based tests provide additional tests that measure aspects of the VAR model not assessed by the Kupiec and Christoffersen test.
       IV. **Conclusion**:
            -  These other tests are useful to evaluate if the VAR model is adequate to a certain situation, and offer a more complete picture of the VAR model‚Äôs quality. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que o teste de Kupiec tenha aprovado um modelo VAR com um n√≠vel de confian√ßa de 95% mas o teste de Christoffersen tenha rejeitado o modelo por apresentar autocorrela√ß√£o. Nesse caso, podemos aplicar outros testes de *backtesting*. Por exemplo, o teste de Lopez poder√° apontar
que as viola√ß√µes do VAR s√£o muito maiores do que o esperado. Um teste de correla√ß√£o serial poder√° confirmar que as viola√ß√µes est√£o clusterizadas. Um teste baseado em fun√ß√µes de perda poder√° indicar que as perdas acima do### Model Backtesting and Horizon Selection in VAR

### Introdu√ß√£o
Em continuidade ao estudo do Value at Risk (VAR) e suas aplica√ß√µes, este cap√≠tulo aborda um aspecto crucial para a valida√ß√£o e confiabilidade dos modelos: o *backtesting*. Como vimos anteriormente, o VAR √© uma medida de risco que resume a potencial perda em um determinado horizonte de tempo e n√≠vel de confian√ßa [^1]. No entanto, a precis√£o do VAR depende da qualidade dos dados e da adequa√ß√£o do modelo utilizado. O *backtesting* √© uma ferramenta essencial para avaliar a performance de um modelo VAR e identificar poss√≠veis vieses nas previs√µes [^1]. Esta se√ß√£o se aprofundar√° nos crit√©rios para realizar o *backtesting*, com foco especial na import√¢ncia do horizonte de tempo na efic√°cia dos testes.

### Conceitos Fundamentais
O *backtesting* consiste em comparar sistematicamente as previs√µes de perdas obtidas por meio do VAR com as perdas e lucros (P&L) efetivamente realizados posteriormente [^1]. O objetivo principal do *backtesting* √© detectar vieses ou inconsist√™ncias nos resultados do VAR, garantindo que o modelo esteja gerando previs√µes confi√°veis. A ideia central √© que um modelo VAR bem calibrado deve ser capaz de prever a frequ√™ncia com que as perdas efetivas excedem o VAR previsto, alinhando-se com o n√≠vel de confian√ßa estabelecido [^2].

Para realizar um *backtesting* eficaz, √© fundamental levar em considera√ß√£o o horizonte de tempo utilizado no c√°lculo do VAR. A escolha do horizonte de tempo influencia diretamente o n√∫mero de observa√ß√µes independentes dispon√≠veis para o teste, afetando o poder estat√≠stico do mesmo [^1]. O poder de um teste refere-se √† sua capacidade de detectar desvios significativos entre as previs√µes do VAR e os resultados reais.

Como mencionado anteriormente, o horizonte de tempo √© um dos fatores quantitativos que influenciam o c√°lculo do VAR. Em geral, um horizonte mais longo leva a um VAR maior. Ao usar o VAR como uma medida de risco potencial, o horizonte de tempo deve ser definido pela liquidez dos ativos, ou seja, o tempo necess√°rio para liquidar o portf√≥lio sem grandes impactos no mercado [^1].

#### O Impacto do Horizonte de Tempo no Backtesting
A escolha do horizonte de tempo tem um impacto significativo no n√∫mero de observa√ß√µes independentes dispon√≠veis para o *backtesting*. Um horizonte mais longo reduz o n√∫mero de observa√ß√µes independentes em um determinado per√≠odo. Por exemplo, se utilizarmos um horizonte de VAR de duas semanas, teremos apenas 26 observa√ß√µes independentes por ano [^1]. Por outro lado, um horizonte de um dia fornecer√° aproximadamente 252 observa√ß√µes independentes ao longo de um ano [^1].

O poder do teste, ou seja, a capacidade de detectar vieses no modelo, est√° diretamente relacionado ao n√∫mero de observa√ß√µes independentes. Com um n√∫mero maior de observa√ß√µes, o teste se torna mais sens√≠vel a desvios entre as previs√µes do VAR e as perdas efetivas [^1]. Por isso, para fins de *backtesting*, √© prefer√≠vel utilizar horizontes de tempo mais curtos, como um dia, para maximizar o poder dos testes [^1].

**Proposi√ß√£o 1**
   *A escolha de um horizonte de tempo $h$ para o c√°lculo do VAR implica que, em um per√≠odo de $T$ dias, temos aproximadamente $T/h$ observa√ß√µes independentes. Para um dado per√≠odo de tempo $T$, o n√∫mero de observa√ß√µes independentes √© inversamente proporcional ao tamanho do horizonte $h$.*
   
   *Proof:*

   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Each observation period for the VAR spans $h$ days.

   II. **Main Logical Steps**:
      - The total number of days, $T$, is divided by the length of each observation period, $h$, to determine the number of non-overlapping observation periods.
      - This gives the number of independent observations.

   III. **Key Transformations**:
      -  Number of independent observations $\approx \frac{T}{h}$

   IV. **Conclusion**:
      - As $h$ increases, $T/h$ decreases, implying an inverse relationship between $h$ and the number of independent observations for a fixed $T$.
      - This proves the statement: "the number of independent observations is inversely proportional to the size of the horizon $h$". ‚ñ†
> üí° **Exemplo Num√©rico:**
> Suponha que temos um per√≠odo de $T = 252$ dias (um ano de negocia√ß√£o). Se usarmos um horizonte de tempo $h = 1$ dia, teremos aproximadamente $252/1 = 252$ observa√ß√µes independentes. Se aumentarmos o horizonte para $h = 5$ dias (uma semana), teremos $252/5 \approx 50$ observa√ß√µes independentes. E se o horizonte for $h=21$ (aproximadamente um m√™s), teremos $252/21=12$ observa√ß√µes independentes. Este exemplo ilustra claramente a rela√ß√£o inversa entre o horizonte de tempo e o n√∫mero de observa√ß√µes independentes.

#### Rela√ß√£o com o N√≠vel de Confian√ßa
√â importante notar que o n√≠vel de confian√ßa tamb√©m influencia o n√∫mero de observa√ß√µes na cauda da distribui√ß√£o. N√≠veis de confian√ßa mais altos, como 99%, resultam em menos observa√ß√µes na cauda, dificultando a identifica√ß√£o de vieses no modelo. Em outras palavras, para confirmar a validade do modelo com um n√≠vel de confian√ßa de 99%, seria necess√°rio um longo per√≠odo de observa√ß√µes para coletar dados suficientes na cauda da distribui√ß√£o [^1]. Por isso, para o *backtesting*, n√≠veis de confian√ßa mais baixos, como 95%, podem ser prefer√≠veis, permitindo uma an√°lise mais frequente dos resultados do modelo [^1].

**Lema 1**
   *Para um n√≠vel de confian√ßa $\alpha$, o n√∫mero de observa√ß√µes esperadas na cauda da distribui√ß√£o em um per√≠odo $T$ com horizonte de tempo $h$ √© aproximadamente $(1-\alpha)T/h$.*

   *Proof:*
   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Let $\alpha$ be the confidence level.
      - The number of independent observations is approximately $T/h$.

   II. **Main Logical Steps**:
       - With a confidence level $\alpha$, the probability of an observation falling in the tail (exceeding the VAR) is $1 - \alpha$.
       - The expected number of observations in the tail is the product of the number of independent observations and the probability of falling in the tail.

   III. **Key Transformations**:
        - Expected number of observations in the tail $\approx \frac{T}{h} \times (1-\alpha) = (1-\alpha) \frac{T}{h}$

   IV. **Conclusion**:
      - This shows that the expected number of observations in the tail is approximately $(1-\alpha)T/h$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Usando o exemplo anterior com $T=252$ dias e um horizonte de $h=1$ dia, se o n√≠vel de confian√ßa for $\alpha = 0.95$ (95%), o n√∫mero esperado de observa√ß√µes na cauda √© $(1-0.95) \times 252/1 = 0.05 \times 252 = 12.6$. Isso significa que, em m√©dia, esperamos que o VAR seja violado aproximadamente 12 ou 13 vezes em um ano. Se o n√≠vel de confian√ßa for $\alpha=0.99$, o n√∫mero esperado de viola√ß√µes cai para $(1-0.99) \times 252 = 0.01 \times 252 = 2.52$, indicando que seria necess√°rio um per√≠odo muito maior de observa√ß√µes para testar o modelo de forma eficaz. Se, por outro lado, mantemos o n√≠vel de confian√ßa em 95% mas aumentamos o horizonte para $h=5$, o n√∫mero de observa√ß√µes na cauda ser√° $(1-0.95)\times 252/5 \approx 2.5$.
  
**Corol√°rio 1.1**
   *O n√∫mero de observa√ß√µes na cauda √© diretamente proporcional ao per√≠odo $T$ e inversamente proporcional ao horizonte $h$, e diminui com o aumento do n√≠vel de confian√ßa $\alpha$.*

   *Proof:*
   I. **Initial Setup**:
       - From Lema 1, the number of observations in the tail is approximately $(1-\alpha)T/h$.

   II. **Main Logical Steps**:
       - We analyze the effect of $T$, $h$, and $\alpha$ on this expression.

   III. **Key Transformations**:
        - As $T$ increases, the number of observations in the tail increases proportionally.
        - As $h$ increases, the number of observations in the tail decreases proportionally.
        - As $\alpha$ increases, $(1-\alpha)$ decreases, thus decreasing the number of observations in the tail.

   IV. **Conclusion**:
        -  This confirms the statement that the number of tail observations is directly proportional to $T$, inversely proportional to $h$, and decreases with an increase in $\alpha$. ‚ñ†

Al√©m disso, vale ressaltar que a escolha do n√≠vel de confian√ßa afeta o tipo de erros que o *backtesting* ser√° capaz de detectar. Um n√≠vel de confian√ßa mais alto prioriza a detec√ß√£o de erros na cauda da distribui√ß√£o, enquanto um n√≠vel de confian√ßa mais baixo permite uma detec√ß√£o mais frequente de erros, ainda que menos extremos.

**Proposi√ß√£o 2**
    *Um n√≠vel de confian√ßa mais baixo aumenta a frequ√™ncia com que os resultados do VAR s√£o comparados com os retornos realizados, e, consequentemente, aumenta a sensibilidade a potenciais vieses no modelo.*
  
  *Proof:*

  I. **Initial Setup**:
    - Let $\alpha$ be the confidence level.
    - A lower confidence level implies a smaller $\alpha$.
    - VAR is calculated for a given confidence level.

  II. **Main Logical Steps**:
    - A lower confidence level (smaller $\alpha$) corresponds to a lower VAR value (since the VAR is a quantile).
    - A lower VAR value means a greater chance of actual losses exceeding the VAR.
    - If the actual loss exceeds the VAR value, this is considered a violation in the backtesting process.
    - More violations mean more comparisons between VAR and actual returns.

  III. **Key Transformations**:
    - Lower $\alpha$  $\implies$ Lower VAR
    - Lower VAR $\implies$ More violations
    - More violations $\implies$ More frequent comparisons between VAR and actual returns

  IV. **Conclusion**:
    - This demonstrates that a lower confidence level results in more frequent comparisons between VAR predictions and actual returns. Therefore, the sensitivity of the backtesting to potential biases in the model increases.‚ñ†

> üí° **Exemplo Num√©rico:**
> Considere um modelo VAR com um horizonte de um dia ($h=1$). Se o n√≠vel de confian√ßa for $\alpha = 0.99$, espera-se que as viola√ß√µes sejam raras, e a cada 100 dias de negocia√ß√£o, apenas 1 dia, em m√©dia, apresentar√° uma perda que ultrapassa o VAR. Se o n√≠vel de confian√ßa for reduzido para $\alpha=0.95$, as viola√ß√µes tornam-se mais frequentes, com uma m√©dia de 5 dias a cada 100, e isso permite uma an√°lise mais detalhada e frequente do modelo.

**Teorema 1**
*Existe um trade-off entre o horizonte de tempo $h$ e o n√≠vel de confian√ßa $\alpha$ no *backtesting*. Diminuir $h$ aumenta o n√∫mero de observa√ß√µes independentes e, portanto, o poder do teste, enquanto diminuir $\alpha$ aumenta a frequ√™ncia de viola√ß√µes do VAR e, tamb√©m, aumenta o poder do teste.*
 *Proof:*
    I. **Initial Setup**:
        - The power of a backtesting test is directly related to the number of independent observations and the frequency of violations.
    
    II. **Main Logical Steps**:
         - From Proposi√ß√£o 1, reducing the time horizon $h$ increases the number of independent observations. An increase in independent observations leads to an increase in the power of the test.
         - From Proposi√ß√£o 2, reducing the confidence level $\alpha$ increases the frequency of violations. More frequent violations increase the data available to backtest, increasing the power of the test.
        
    III. **Key Transformations**:
        - $h \downarrow \implies \text{Number of Independent Observations} \uparrow \implies \text{Test Power} \uparrow$
        - $\alpha \downarrow \implies \text{Frequency of Violations} \uparrow \implies \text{Test Power} \uparrow$

    IV. **Conclusion**:
        - The theorem states that there is a trade-off. Both lowering $h$ and $\alpha$ increase the power of the backtest, supporting the claim. Therefore, this proves the existence of the trade-off.‚ñ†

**Lema 2**
*Seja $N$ o n√∫mero de observa√ß√µes independentes, e seja $X_i$ uma vari√°vel indicadora que vale 1 se a perda observada no per√≠odo $i$ excede o VAR previsto e 0 caso contr√°rio. Se o modelo VAR estiver bem calibrado, ent√£o $X_i$ s√£o vari√°veis aleat√≥rias independentes de Bernoulli com probabilidade de sucesso $1 - \alpha$.*

*Proof:*
   I. **Initial Setup**:
       - $N$ is the number of independent observations.
       - $X_i$ is an indicator variable, where $X_i = 1$ if the loss exceeds the predicted VAR at time $i$, and $X_i = 0$ otherwise.
       - $\alpha$ is the confidence level of the VAR.
       - A well-calibrated VAR model has a probability of $1-\alpha$ of the loss exceeding the VAR.
       - We assume independence between observations.

   II. **Main Logical Steps**:
       - For each observation $i$, there are only two outcomes: the loss exceeds the VAR ($X_i = 1$) or the loss does not exceed the VAR ($X_i = 0$).
       - Under a well-calibrated model, the probability of $X_i = 1$ (a loss exceeding the VAR) is $1 - \alpha$.
       - This is precisely the definition of a Bernoulli trial with a success probability of $1-\alpha$.
       - The independence of the $X_i$ variables comes from the assumption of independence of observations.

   III. **Key Transformations**:
       - $P(X_i=1) = 1-\alpha$.

   IV. **Conclusion**:
       - The variables $X_i$ are independent and follow a Bernoulli distribution with success probability $1-\alpha$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Vamos supor que estamos analisando 252 dias de negocia√ß√£o com um n√≠vel de confian√ßa de 95% ($\alpha=0.95$). Para cada dia $i$, definimos $X_i = 1$ se a perda naquele dia excedeu o VAR previsto e $X_i = 0$ caso contr√°rio. Se o modelo estiver bem calibrado, cada $X_i$ √© uma vari√°vel de Bernoulli com $p = 1 - 0.95 = 0.05$. Isso significa que a probabilidade de uma viola√ß√£o em qualquer dia √© de 5%.

**Teorema 1.1**
*Sob as condi√ß√µes do Lema 2, o n√∫mero de viola√ß√µes do VAR, $V = \sum_{i=1}^N X_i$, segue uma distribui√ß√£o binomial com par√¢metros $N$ e $1-\alpha$, ou seja, $V \sim Bin(N, 1 - \alpha)$.*

*Proof:*
   I. **Initial Setup**:
      - From Lema 2, $X_i$ are independent Bernoulli random variables with success probability $1-\alpha$.
      - $V$ is defined as the sum of these Bernoulli variables: $V = \sum_{i=1}^N X_i$.

   II. **Main Logical Steps**:
      - The sum of $N$ independent Bernoulli random variables with the same success probability follows a binomial distribution.
      - The parameters of the binomial distribution are $N$ (the number of trials) and $1-\alpha$ (the success probability).

   III. **Key Transformations**:
      - $V = \sum_{i=1}^N X_i \implies V \sim Bin(N, 1 - \alpha)$

   IV. **Conclusion**:
      - Therefore, the number of violations $V$ follows a binomial distribution with parameters $N$ and $1-\alpha$. ‚ñ†
> üí° **Exemplo Num√©rico:**
> Continuando o exemplo anterior, onde temos 252 observa√ß√µes independentes ($N=252$) e $\alpha = 0.95$, o n√∫mero total de viola√ß√µes $V$ segue uma distribui√ß√£o binomial com par√¢metros $N=252$ e $p=0.05$, ou seja, $V \sim Bin(252, 0.05)$. Isso nos permite calcular a probabilidade de observar um n√∫mero espec√≠fico de viola√ß√µes, assumindo que o modelo VAR est√° bem calibrado.

**Corol√°rio 1.2**
*A m√©dia e a vari√¢ncia do n√∫mero de viola√ß√µes $V$ s√£o dadas por $E[V] = N(1-\alpha)$ e $Var[V] = N(1-\alpha)\alpha$.*

*Proof:*
   I. **Initial Setup**:
      - From Theorem 1.1, $V \sim Bin(N, 1-\alpha)$.
      - We recall the mean and variance of a binomial distribution.
   II. **Main Logical Steps**:
        - The expected value (mean) of a binomial distribution $Bin(n,p)$ is given by $E[V]=np$.
        - The variance of a binomial distribution $Bin(n,p)$ is given by $Var[V]=np(1-p)$.
   III. **Key Transformations**:
      - Substituting $n = N$ and $p = 1 - \alpha$, we have
      -  $E[V] = N(1-\alpha)$.
      - $Var[V] = N(1-\alpha)(1-(1-\alpha)) = N(1-\alpha)\alpha$.

   IV. **Conclusion**:
     -  This shows that the mean and the variance of $V$ are given by $E[V] = N(1-\alpha)$ and $Var[V] = N(1-\alpha)\alpha$, respectively. ‚ñ†

> üí° **Exemplo Num√©rico:**
> No mesmo exemplo, com $N=252$ e $\alpha=0.95$, a m√©dia do n√∫mero de viola√ß√µes √© $E[V] = 252 \times (1 - 0.95) = 252 \times 0.05 = 12.6$, e a vari√¢ncia √© $Var[V] = 252 \times 0.05 \times 0.95 = 11.97$. Isso significa que, em m√©dia, esperamos 12.6 viola√ß√µes, com uma variabilidade em torno desse valor, quantificada pela vari√¢ncia.

Al√©m disso, √© crucial considerar a autocorrela√ß√£o das perdas. Se as perdas em per√≠odos sucessivos forem correlacionadas, a suposi√ß√£o de independ√™ncia das observa√ß√µes pode ser violada, comprometendo a validade do *backtesting*.

**Proposi√ß√£o 3**
    *A autocorrela√ß√£o positiva das perdas pode levar a um excesso de viola√ß√µes do VAR em clusters, o que pode reduzir o poder de um *backtesting* que assume independ√™ncia das observa√ß√µes.*
    *Proof:*
       I. **Initial Setup**:
        -  Assume positive autocorrelation in losses.
        -  Assume that we are using a backtesting method that assumes independence.
        
       II. **Main Logical Steps**:
           - Positive autocorrelation implies that if a loss exceeds the VAR in a given period, the probability of a loss exceeding the VAR in the next period is higher than expected under independence.
           - This causes violations to occur in clusters, i.e. if one violation occurs, the probability of seeing more violations in close succession is higher.
           - When violations cluster, the assumption of independent Bernoulli trials underlying most backtesting procedures is violated.
           - The methods assume that the number of violations is a realization of a binomial distribution, which does not hold under autocorrelation.
           - Since the number of observations is reduced, a clustered violation process has less power than an independent violation process.

       III. **Key Transformations**:
           - Autocorrelation $\implies$ violation clusters
           - Clusters $\implies$ violation of independence
           - Violation of independence $\implies$ Reduction in the power of the test

       IV. **Conclusion**:
        - Therefore, positive autocorrelation can lead to clustered violations, and reduce the effectiveness of backtesting.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
> Suponha que as perdas do dia atual sejam positivamente correlacionadas com as perdas do dia anterior. Se o VAR for violado hoje, √© mais prov√°vel que ele seja violado amanh√£ tamb√©m. Isso cria *clusters* de viola√ß√µes, onde v√°rios dias consecutivos apresentam perdas acima do VAR, em vez de viola√ß√µes aleat√≥rias e independentes. Um modelo que ignora essa autocorrela√ß√£o pode n√£o capturar a din√¢mica real do risco.
    
**Lema 3**
*Para detectar a presen√ßa de autocorrela√ß√£o nas viola√ß√µes do VAR, pode-se realizar um teste de raz√£o de verossimilhan√ßa (LR) de independ√™ncia de viola√ß√µes, ou similar, como o teste de Kupiec ou Christoffersen.*

    *Proof:*
     I. **Initial Setup**:
          - We want to detect if there is autocorrelation in the violations of the VAR model.
          - We know that violations of a well-calibrated VAR should be independent events.

     II. **Main Logical Steps**:
          - The test of the likelihood ratio (LR) is designed to test the hypothesis that the distribution of the violations is independent.
          - The Kupiec test checks if the overall violation rate is consistent with the confidence level, implicitly assuming independence over time.
          - The Christoffersen test is specifically designed to test for both correct violation rate and independence over time.

     III. **Key Transformations**:
          - These tests check the null hypothesis of independence against the alternative of an autocorrelation in the violations.

     IV. **Conclusion**:
          -  The LR test and specific tests such as Kupiec and Christoffersen can all detect the presence of autocorrelation, supporting the claim. ‚ñ†
> üí° **Exemplo Num√©rico:**
>  Se os resultados do *backtesting* mostram uma sequ√™ncia de viola√ß√µes em dias pr√≥ximos (por exemplo, viola√ß√µes nos dias 1, 2, 3, e depois nenhuma viola√ß√£o por v√°rias semanas, e em seguida viola√ß√µes nos dias 45 e 46) isso levanta suspeitas de autocorrela√ß√£o. Testes como o de Christoffersen ajudam a quantificar essa suspeita, e a verificar se os *clusters* de viola√ß√£o s√£o estatisticamente significativos ou apenas devidos ao acaso.

**Proposi√ß√£o 4**
    *A presen√ßa de *clusters* de viola√ß√µes, causada por autocorrela√ß√£o, implica que a vari√¢ncia do n√∫mero de viola√ß√µes pode ser maior do que o previsto pela distribui√ß√£o binomial sob a hip√≥tese de independ√™ncia.*
    
  *Proof:*
  
    I. **Initial Setup**:
        - Assume that the violations are positively autocorrelated, so that violations tend to cluster together.
        - Let $X_i$ be indicator variables such that $X_i = 1$ if there is a violation at time $i$ and 0 otherwise.
        - Let the number of violations be given by $V=\sum_{i=1}^N X_i$.
        
    II. **Main Logical Steps**:
        - If the violations were independent, then we could calculate the variance of the total number of violations using the fact that it follows a binomial distribution (as shown in Corol√°rio 1.2). In that case, $Var[V] = N(1-\alpha)\alpha$.
        - However, because of autocorrelation, the $X_i$ are not independent. The variance of the sum of correlated random variables is not the sum of the variances.
        - If $\text{Cov}(X_i,X_j) > 0$ for at least some $i \neq j$, then $Var[\sum X_i] > \sum Var[X_i]$.
        - The autocorrelation causes $\text{Cov}(X_i,X_j) > 0$, implying that the variance of the sum will be greater than if the $X_i$ were independent.

   III. **Key Transformations**:
       - Autocorrelation $\implies \text{Cov}(X_i,X_j) > 0$.
       -  $\text{Cov}(X_i,X_j) > 0$  $\implies$  $Var[\sum X_i] > \sum Var[X_i]$
       - $Var[\sum X_i] > \sum Var[X_i]$ $\implies$ $Var[V] > N(1-\alpha)\alpha$

   IV. **Conclusion**:
      -  The presence of autocorrelation increases the variance of the sum of violations over the case with independent variables.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
>  Usando o exemplo de 252 observa√ß√µes com $\alpha = 0.95$, sob a hip√≥tese de independ√™ncia, a vari√¢ncia do n√∫mero de viola√ß√µes √© de 11.97. No entanto, se houver autocorrela√ß√£o positiva, a vari√¢ncia real das viola√ß√µes pode ser muito maior. Por exemplo, se as viola√ß√µes ocorrem em *clusters*, a vari√¢ncia poderia ser 20 ou at√© mais. Isso significa que as viola√ß√µes ser√£o mais vari√°veis do que o esperado sob o modelo binomial, e o modelo de VAR pode estar subestimando o risco.
   
**Teorema 2**
 *O teste de Kupiec √© um teste de hip√≥tese para verificar se a frequ√™ncia de viola√ß√µes do VAR √© estatisticamente diferente do esperado dado o n√≠vel de confian√ßa $\alpha$. Ele testa a hip√≥tese nula de que a frequ√™ncia de viola√ß√µes observada √© consistente com a frequ√™ncia esperada sob um modelo bem calibrado.*

 *Proof:*
    I. **Initial Setup**:
      - The null hypothesis ($H_0$) is that the model is well-calibrated, i.e., the observed violation rate matches the expected violation rate.
      - The alternative hypothesis ($H_1$) is that the model is not well-calibrated, i.e., the observed violation rate is different from the expected rate.
      - Let $V$ be the observed number of violations, $N$ the number of independent observations, and $\alpha$ the confidence level.
      - We know that if the model is well-calibrated, the number of violations follows a binomial distribution $V \sim Bin(N, 1-\alpha)$.
      
    II. **Main Logical Steps**:
      -  The Kupiec test uses a likelihood ratio test to compare the likelihood under the null hypothesis (where $p = 1-\alpha$) with the likelihood of a model that admits a free violation probability $\hat{p}$ estimated from data (observed frequency of violations, i.e., $\hat{p} = V/N$).
      - The likelihood ratio statistic is constructed based on the binomial distribution.
      - The statistic is asymptotically chi-squared distributed, which allows for the construction of the test.
      
    III. **Key Transformations**:
      - Let $p$ be the expected probability of violation under the null hypothesis $p = 1-\alpha$.
      - The likelihood function is given by $L(p) = \binom{N}{V} p^V (1-p)^{N-V}$.
      - The test statistic is given by $-2ln\frac{L(1-\alpha)}{L(\hat{p})}$.
      - Under the null hypothesis, this statistic converges in distribution to a $\chi^2(1)$.

    IV. **Conclusion**:
      -  The Kupiec test checks if the frequency of violations is statistically different from that expected under the well-calibrated model hypothesis, using the distribution of the violations implied by a model with binomial violations. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que em 252 dias com um n√≠vel de confian√ßa de 95%, um modelo VAR tenha apresentado 20 viola√ß√µes. Sob a hip√≥tese nula de que o modelo est√° bem calibrado, o n√∫mero esperado de viola√ß√µes √© de 12.6. O teste de Kupiec calcula uma estat√≠stica de teste que compara a probabilidade de observar 20 viola√ß√µes se o modelo estiver bem calibrado com a probabilidade de observar 20 viola√ß√µes com a probabilidade de viola√ß√£o observada nos dados (20/252). Essa estat√≠stica de teste segue uma distribui√ß√£o $\chi^2$ com 1 grau de liberdade. Se o valor da estat√≠stica de teste for muito alto (e o p-valor correspondente for baixo), rejeita-se a hip√≥tese de que o modelo est√° bem calibrado e conclui-se que o modelo est√° subestimando o risco.
 
 **Lema 4**
 *O teste de Christoffersen testa se as viola√ß√µes do VAR s√£o independentes ao longo do tempo, e, portanto, se h√° *clusters* de viola√ß√µes. Ele testa a hip√≥tese nula de independ√™ncia das viola√ß√µes contra a hip√≥tese alternativa de que as viola√ß√µes seguem um processo de Markov de primeira ordem.*

    *Proof:*
    I. **Initial Setup**:
         - Null Hypothesis $H_0$: The violations are independent over time.
         - Alternative Hypothesis $H_1$: The violations follow a first-order Markov process (i.e., the probability of a violation depends on whether the previous observation was a violation or not).
         - $X_t$ is an indicator variable that is 1 if a violation occurs at time t, and 0 otherwise.

    II. **Main Logical Steps**:
         -  The Christoffersen test examines the transitions between violation and no-violation states using a likelihood ratio test.
         - Under $H_0$, the probability of a violation at time $t$ is independent of the occurrence of a violation at time $t-1$.
         - Under $H_1$, the probability of a violation depends on whether there was a violation in the previous period.
         - This dependence is expressed using a transition matrix:
        $$
        \begin{bmatrix}
          \pi_{00} & \pi_{01} \\
          \pi_{10} & \pi_{11}
        \end{bmatrix}
        $$
         where $\pi_{ij}$ is the probability of observing $X_t=j$ given $X_{t-1} = i$.
        
    III. **Key Transformations**:
         - The likelihood function under the null hypothesis (independence) is compared to the likelihood under the alternative hypothesis (Markov model).
         - The likelihood ratio is used to evaluate if the alternative hypothesis fits the data significantly better than the null hypothesis.
         - The test statistic is asymptotically chi-squared distributed.
        
    IV. **Conclusion**:
         -  The Christoffersen test determines if the observed transitions between violations and no-violations are consistent with the assumption of independence (i.e., if violations are clustered). ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que temos 252 dias de dados, e as viola√ß√µes do VAR ocorrem em sequ√™ncia. Por exemplo, se tivermos uma viola√ß√£o no dia $t-1$, a probabilidade de ter uma viola√ß√£o no dia $t$ √© muito maior do que se n√£o tivermos uma viola√ß√£o no dia $t-1$. O teste de Christoffersen verifica se essas transi√ß√µes entre estados (viola√ß√£o/n√£o-viola√ß√£o) s√£o estatisticamente significativas e inconsistentes com a hip√≥tese de independ√™ncia. Ele estima a matriz de transi√ß√£o e compara a probabilidade de os dados terem sido gerados por uma cadeia de Markov ou por um processo independente, calculando uma estat√≠stica de teste, que segue uma distribui√ß√£o $\chi^2$.

    
**Teorema 2.1**
    *O teste de Christoffersen tamb√©m avalia se a frequ√™ncia de viola√ß√µes √© consistente com o n√≠vel de confian√ßa $\alpha$, simultaneamente com a avalia√ß√£o da independ√™ncia das viola√ß√µes.*

    *Proof:*
        I. **Initial Setup**:
            - The null hypothesis for the Christoffersen test is that the model is well-calibrated and that the violations are independent of each other.
            - The alternative hypothesis is that either the violation frequency is not correct or the violations are not independent.
            -  The null hypothesis is given by $H_0: \pi_{01}=\pi_{11} = 1-\alpha$.

        II. **Main Logical Steps**:
            - The Christoffersen test is actually a joint test. It is composed of two likelihood ratio (LR) tests.
            -  The first LR test looks at whether the frequency of violations is compatible with the confidence level $\alpha$. This part of the test does not test independence.
            - The second LR test checks if there is statistical evidence of dependence on the previous state. This second test checks independence.
            - If we reject the null hypothesis in the Christoffersen test, it means that the data is incompatible with the assumption that the violations are both independent and have the correct frequency.
            
        III. **Key Transformations**:
            - The first test checks if $\pi_{01}=\pi_{11}=1-\alpha$ jointly. If not, then either the frequency or the independence is rejected.
            - The second test checks the independence of the violations, by testing if $\pi_{01}=\pi_{11}$.
            - The combination of both tests gives the Christoffersen test statistic.
            
        IV. **Conclusion**:
            -  Because of the structure of the test, the Christoffersen test assesses both the frequency of violations and the independence of the violations simultaneously. Therefore, it assesses if both the frequency of violations is consistent with $\alpha$ and if the violations are independent of each other, simultaneously.  ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Continuando o exemplo anterior, o teste de Christoffersen n√£o apenas verifica se a frequ√™ncia de viola√ß√µes √© aproximadamente 5% (se $\alpha=0.95$), mas tamb√©m se a ocorr√™ncia de uma viola√ß√£o em um dia aumenta a probabilidade de uma viola√ß√£o no dia seguinte. Ele faz isso de forma simult√¢nea. Isso √© especialmente importante porque um modelo pode ter a frequ√™ncia de viola√ß√µes correta, mas as viola√ß√µes ocorrem em *clusters*, o que o teste de Christoffersen √© capaz de detectar.
    
**Proposi√ß√£o 5**
   *Al√©m do teste de Kupiec e do teste de Christoffersen, existem outros testes de *backtesting* como o teste de Lopez, o teste de correla√ß√£o serial, e testes baseados em fun√ß√µes de perda, que podem complementar a an√°lise do desempenho do modelo VAR.*
   *Proof:*
        I. **Initial Setup**:
            - The Kupiec and Christoffersen tests are not exhaustive.
            - There are other ways to evaluate a VAR model through backtesting.
        II. **Main Logical Steps**:
            - The Lopez test assesses the magnitude of losses that violate the VAR, not just the frequency. It uses a loss function that considers both the number and the size of the violations.
            - Tests of serial correlation can detect if violations cluster or are predictable, which is undesirable. For example, the Ljung-Box test.
            - Test based on loss functions (such as the tick loss) can be tailored to capture specific properties that are relevant for the user.
        III. **Key Transformations**:
             - The Lopez test, tests of serial correlation, and loss function-based tests provide additional tests that measure aspects of the VAR model not assessed by the Kupiec and Christoffersen test.
       IV. **Conclusion**:
            -  These other tests are useful to evaluate if the VAR model is adequate to a certain situation, and offer a more complete picture of the VAR model‚Äôs quality. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que o teste de Kupiec tenha aprovado um modelo VAR com um n√≠vel de confian√ßa de 95% mas o teste de Christoffersen tenha rejeitado o modelo por apresentar autocorrela√ß√£o. Nesse caso, podemos aplicar outros testes de *backtesting*. Por exemplo, o teste de Lopez poder√° apontar
que as viola√ß√µes do VAR s√£o muito maiores do que o esperado. Um teste de correla√ß√£o serial poder√° confirmar que as viola√ß√µes est√£o clusterizadas. Um teste baseado em fun√ß√µes de perda poder√° indicar que as perdas acima do### Model Backtesting and Horizon Selection in VAR

### Introdu√ß√£o
Em continuidade ao estudo do Value at Risk (VAR) e suas aplica√ß√µes, este cap√≠tulo aborda um aspecto crucial para a valida√ß√£o e confiabilidade dos modelos: o *backtesting*. Como vimos anteriormente, o VAR √© uma medida de risco que resume a potencial perda em um determinado horizonte de tempo e n√≠vel de confian√ßa [^1]. No entanto, a precis√£o do VAR depende da qualidade dos dados e da adequa√ß√£o do modelo utilizado. O *backtesting* √© uma ferramenta essencial para avaliar a performance de um modelo VAR e identificar poss√≠veis vieses nas previs√µes [^1]. Esta se√ß√£o se aprofundar√° nos crit√©rios para realizar o *backtesting*, com foco especial na import√¢ncia do horizonte de tempo na efic√°cia dos testes.

### Conceitos Fundamentais
O *backtesting* consiste em comparar sistematicamente as previs√µes de perdas obtidas por meio do VAR com as perdas e lucros (P&L) efetivamente realizados posteriormente [^1]. O objetivo principal do *backtesting* √© detectar vieses ou inconsist√™ncias nos resultados do VAR, garantindo que o modelo esteja gerando previs√µes confi√°veis. A ideia central √© que um modelo VAR bem calibrado deve ser capaz de prever a frequ√™ncia com que as perdas efetivas excedem o VAR previsto, alinhando-se com o n√≠vel de confian√ßa estabelecido [^2].

Para realizar um *backtesting* eficaz, √© fundamental levar em considera√ß√£o o horizonte de tempo utilizado no c√°lculo do VAR. A escolha do horizonte de tempo influencia diretamente o n√∫mero de observa√ß√µes independentes dispon√≠veis para o teste, afetando o poder estat√≠stico do mesmo [^1]. O poder de um teste refere-se √† sua capacidade de detectar desvios significativos entre as previs√µes do VAR e os resultados reais.

Como mencionado anteriormente, o horizonte de tempo √© um dos fatores quantitativos que influenciam o c√°lculo do VAR. Em geral, um horizonte mais longo leva a um VAR maior. Ao usar o VAR como uma medida de risco potencial, o horizonte de tempo deve ser definido pela liquidez dos ativos, ou seja, o tempo necess√°rio para liquidar o portf√≥lio sem grandes impactos no mercado [^1].

#### O Impacto do Horizonte de Tempo no Backtesting
A escolha do horizonte de tempo tem um impacto significativo no n√∫mero de observa√ß√µes independentes dispon√≠veis para o *backtesting*. Um horizonte mais longo reduz o n√∫mero de observa√ß√µes independentes em um determinado per√≠odo. Por exemplo, se utilizarmos um horizonte de VAR de duas semanas, teremos apenas 26 observa√ß√µes independentes por ano [^1]. Por outro lado, um horizonte de um dia fornecer√° aproximadamente 252 observa√ß√µes independentes ao longo de um ano [^1].

O poder do teste, ou seja, a capacidade de detectar vieses no modelo, est√° diretamente relacionado ao n√∫mero de observa√ß√µes independentes. Com um n√∫mero maior de observa√ß√µes, o teste se torna mais sens√≠vel a desvios entre as previs√µes do VAR e as perdas efetivas [^1]. Por isso, para fins de *backtesting*, √© prefer√≠vel utilizar horizontes de tempo mais curtos, como um dia, para maximizar o poder dos testes [^1].

**Proposi√ß√£o 1**
   *A escolha de um horizonte de tempo $h$ para o c√°lculo do VAR implica que, em um per√≠odo de $T$ dias, temos aproximadamente $T/h$ observa√ß√µes independentes. Para um dado per√≠odo de tempo $T$, o n√∫mero de observa√ß√µes independentes √© inversamente proporcional ao tamanho do horizonte $h$.*
   
   *Proof:*

   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Each observation period for the VAR spans $h$ days.

   II. **Main Logical Steps**:
      - The total number of days, $T$, is divided by the length of each observation period, $h$, to determine the number of non-overlapping observation periods.
      - This gives the number of independent observations.

   III. **Key Transformations**:
      -  Number of independent observations $\approx \frac{T}{h}$

   IV. **Conclusion**:
      - As $h$ increases, $T/h$ decreases, implying an inverse relationship between $h$ and the number of independent observations for a fixed $T$.
      - This proves the statement: "the number of independent observations is inversely proportional to the size of the horizon $h$". ‚ñ†
> üí° **Exemplo Num√©rico:**
> Suponha que temos um per√≠odo de $T = 252$ dias (um ano de negocia√ß√£o). Se usarmos um horizonte de tempo $h = 1$ dia, teremos aproximadamente $252/1 = 252$ observa√ß√µes independentes. Se aumentarmos o horizonte para $h = 5$ dias (uma semana), teremos $252/5 \approx 50$ observa√ß√µes independentes. E se o horizonte for $h=21$ (aproximadamente um m√™s), teremos $252/21=12$ observa√ß√µes independentes. Este exemplo ilustra claramente a rela√ß√£o inversa entre o horizonte de tempo e o n√∫mero de observa√ß√µes independentes.

#### Rela√ß√£o com o N√≠vel de Confian√ßa
√â importante notar que o n√≠vel de confian√ßa tamb√©m influencia o n√∫mero de observa√ß√µes na cauda da distribui√ß√£o. N√≠veis de confian√ßa mais altos, como 99%, resultam em menos observa√ß√µes na cauda, dificultando a identifica√ß√£o de vieses no modelo. Em outras palavras, para confirmar a validade do modelo com um n√≠vel de confian√ßa de 99%, seria necess√°rio um longo per√≠odo de observa√ß√µes para coletar dados suficientes na cauda da distribui√ß√£o [^1]. Por isso, para o *backtesting*, n√≠veis de confian√ßa mais baixos, como 95%, podem ser prefer√≠veis, permitindo uma an√°lise mais frequente dos resultados do modelo [^1].

**Lema 1**
   *Para um n√≠vel de confian√ßa $\alpha$, o n√∫mero de observa√ß√µes esperadas na cauda da distribui√ß√£o em um per√≠odo $T$ com horizonte de tempo $h$ √© aproximadamente $(1-\alpha)T/h$.*

   *Proof:*
   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Let $\alpha$ be the confidence level.
      - The number of independent observations is approximately $T/h$.

   II. **Main Logical Steps**:
       - With a confidence level $\alpha$, the probability of an observation falling in the tail (exceeding the VAR) is $1 - \alpha$.
       - The expected number of observations in the tail is the product of the number of independent observations and the probability of falling in the tail.

   III. **Key Transformations**:
        - Expected number of observations in the tail $\approx \frac{T}{h} \times (1-\alpha) = (1-\alpha) \frac{T}{h}$

   IV. **Conclusion**:
      - This shows that the expected number of observations in the tail is approximately $(1-\alpha)T/h$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Usando o exemplo anterior com $T=252$ dias e um horizonte de $h=1$ dia, se o n√≠vel de confian√ßa for $\alpha = 0.95$ (95%), o n√∫mero esperado de observa√ß√µes na cauda √© $(1-0.95) \times 252/1 = 0.05 \times 252 = 12.6$. Isso significa que, em m√©dia, esperamos que o VAR seja violado aproximadamente 12 ou 13 vezes em um ano. Se o n√≠vel de confian√ßa for $\alpha=0.99$, o n√∫mero esperado de viola√ß√µes cai para $(1-0.99) \times 252 = 0.01 \times 252 = 2.52$, indicando que seria necess√°rio um per√≠odo muito maior de observa√ß√µes para testar o modelo de forma eficaz. Se, por outro lado, mantemos o n√≠vel de confian√ßa em 95% mas aumentamos o horizonte para $h=5$, o n√∫mero de observa√ß√µes na cauda ser√° $(1-0.95)\times 252/5 \approx 2.5$.
  
**Corol√°rio 1.1**
   *O n√∫mero de observa√ß√µes na cauda √© diretamente proporcional ao per√≠odo $T$ e inversamente proporcional ao horizonte $h$, e diminui com o aumento do n√≠vel de confian√ßa $\alpha$.*

   *Proof:*
   I. **Initial Setup**:
       - From Lema 1, the number of observations in the tail is approximately $(1-\alpha)T/h$.

   II. **Main Logical Steps**:
       - We analyze the effect of $T$, $h$, and $\alpha$ on this expression.

   III. **Key Transformations**:
        - As $T$ increases, the number of observations in the tail increases proportionally.
        - As $h$ increases, the number of observations in the tail decreases proportionally.
        - As $\alpha$ increases, $(1-\alpha)$ decreases, thus decreasing the number of observations in the tail.

   IV. **Conclusion**:
        -  This confirms the statement that the number of tail observations is directly proportional to $T$, inversely proportional to $h$, and decreases with an increase in $\alpha$. ‚ñ†

Al√©m disso, vale ressaltar que a escolha do n√≠vel de confian√ßa afeta o tipo de erros que o *backtesting* ser√° capaz de detectar. Um n√≠vel de confian√ßa mais alto prioriza a detec√ß√£o de erros na cauda da distribui√ß√£o, enquanto um n√≠vel de confian√ßa mais baixo permite uma detec√ß√£o mais frequente de erros, ainda que menos extremos.

**Proposi√ß√£o 2**
    *Um n√≠vel de confian√ßa mais baixo aumenta a frequ√™ncia com que os resultados do VAR s√£o comparados com os retornos realizados, e, consequentemente, aumenta a sensibilidade a potenciais vieses no modelo.*
  
  *Proof:*

  I. **Initial Setup**:
    - Let $\alpha$ be the confidence level.
    - A lower confidence level implies a smaller $\alpha$.
    - VAR is calculated for a given confidence level.

  II. **Main Logical Steps**:
    - A lower confidence level (smaller $\alpha$) corresponds to a lower VAR value (since the VAR is a quantile).
    - A lower VAR value means a greater chance of actual losses exceeding the VAR.
    - If the actual loss exceeds the VAR value, this is considered a violation in the backtesting process.
    - More violations mean more comparisons between VAR and actual returns.

  III. **Key Transformations**:
    - Lower $\alpha$  $\implies$ Lower VAR
    - Lower VAR $\implies$ More violations
    - More violations $\implies$ More frequent comparisons between VAR and actual returns

  IV. **Conclusion**:
    - This demonstrates that a lower confidence level results in more frequent comparisons between VAR predictions and actual returns. Therefore, the sensitivity of the backtesting to potential biases in the model increases.‚ñ†

> üí° **Exemplo Num√©rico:**
> Considere um modelo VAR com um horizonte de um dia ($h=1$). Se o n√≠vel de confian√ßa for $\alpha = 0.99$, espera-se que as viola√ß√µes sejam raras, e a cada 100 dias de negocia√ß√£o, apenas 1 dia, em m√©dia, apresentar√° uma perda que ultrapassa o VAR. Se o n√≠vel de confian√ßa for reduzido para $\alpha=0.95$, as viola√ß√µes tornam-se mais frequentes, com uma m√©dia de 5 dias a cada 100, e isso permite uma an√°lise mais detalhada e frequente do modelo.

**Teorema 1**
*Existe um trade-off entre o horizonte de tempo $h$ e o n√≠vel de confian√ßa $\alpha$ no *backtesting*. Diminuir $h$ aumenta o n√∫mero de observa√ß√µes independentes e, portanto, o poder do teste, enquanto diminuir $\alpha$ aumenta a frequ√™ncia de viola√ß√µes do VAR e, tamb√©m, aumenta o poder do teste.*
 *Proof:*
    I. **Initial Setup**:
        - The power of a backtesting test is directly related to the number of independent observations and the frequency of violations.
    
    II. **Main Logical Steps**:
         - From Proposi√ß√£o 1, reducing the time horizon $h$ increases the number of independent observations. An increase in independent observations leads to an increase in the power of the test.
         - From Proposi√ß√£o 2, reducing the confidence level $\alpha$ increases the frequency of violations. More frequent violations increase the data available to backtest, increasing the power of the test.
        
    III. **Key Transformations**:
        - $h \downarrow \implies \text{Number of Independent Observations} \uparrow \implies \text{Test Power} \uparrow$
        - $\alpha \downarrow \implies \text{Frequency of Violations} \uparrow \implies \text{Test Power} \uparrow$

    IV. **Conclusion**:
        - The theorem states that there is a trade-off. Both lowering $h$ and $\alpha$ increase the power of the backtest, supporting the claim. Therefore, this proves the existence of the trade-off.‚ñ†

**Lema 2**
*Seja $N$ o n√∫mero de observa√ß√µes independentes, e seja $X_i$ uma vari√°vel indicadora que vale 1 se a perda observada no per√≠odo $i$ excede o VAR previsto e 0 caso contr√°rio. Se o modelo VAR estiver bem calibrado, ent√£o $X_i$ s√£o vari√°veis aleat√≥rias independentes de Bernoulli com probabilidade de sucesso $1 - \alpha$.*

*Proof:*
   I. **Initial Setup**:
       - $N$ is the number of independent observations.
       - $X_i$ is an indicator variable, where $X_i = 1$ if the loss exceeds the predicted VAR at time $i$, and $X_i = 0$ otherwise.
       - $\alpha$ is the confidence level of the VAR.
       - A well-calibrated VAR model has a probability of $1-\alpha$ of the loss exceeding the VAR.
       - We assume independence between observations.

   II. **Main Logical Steps**:
       - For each observation $i$, there are only two outcomes: the loss exceeds the VAR ($X_i = 1$) or the loss does not exceed the VAR ($X_i = 0$).
       - Under a well-calibrated model, the probability of $X_i = 1$ (a loss exceeding the VAR) is $1 - \alpha$.
       - This is precisely the definition of a Bernoulli trial with a success probability of $1-\alpha$.
       - The independence of the $X_i$ variables comes from the assumption of independence of observations.

   III. **Key Transformations**:
       - $P(X_i=1) = 1-\alpha$.

   IV. **Conclusion**:
       - The variables $X_i$ are independent and follow a Bernoulli distribution with success probability $1-\alpha$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Vamos supor que estamos analisando 252 dias de negocia√ß√£o com um n√≠vel de confian√ßa de 95% ($\alpha=0.95$). Para cada dia $i$, definimos $X_i = 1$ se a perda naquele dia excedeu o VAR previsto e $X_i = 0$ caso contr√°rio. Se o modelo estiver bem calibrado, cada $X_i$ √© uma vari√°vel de Bernoulli com $p = 1 - 0.95 = 0.05$. Isso significa que a probabilidade de uma viola√ß√£o em qualquer dia √© de 5%.

**Teorema 1.1**
*Sob as condi√ß√µes do Lema 2, o n√∫mero de viola√ß√µes do VAR, $V = \sum_{i=1}^N X_i$, segue uma distribui√ß√£o binomial com par√¢metros $N$ e $1-\alpha$, ou seja, $V \sim Bin(N, 1 - \alpha)$.*

*Proof:*
   I. **Initial Setup**:
      - From Lema 2, $X_i$ are independent Bernoulli random variables with success probability $1-\alpha$.
      - $V$ is defined as the sum of these Bernoulli variables: $V = \sum_{i=1}^N X_i$.

   II. **Main Logical Steps**:
      - The sum of $N$ independent Bernoulli random variables with the same success probability follows a binomial distribution.
      - The parameters of the binomial distribution are $N$ (the number of trials) and $1-\alpha$ (the success probability).

   III. **Key Transformations**:
      - $V = \sum_{i=1}^N X_i \implies V \sim Bin(N, 1 - \alpha)$

   IV. **Conclusion**:
      - Therefore, the number of violations $V$ follows a binomial distribution with parameters $N$ and $1-\alpha$. ‚ñ†
> üí° **Exemplo Num√©rico:**
> Continuando o exemplo anterior, onde temos 252 observa√ß√µes independentes ($N=252$) e $\alpha = 0.95$, o n√∫mero total de viola√ß√µes $V$ segue uma distribui√ß√£o binomial com par√¢metros $N=252$ e $p=0.05$, ou seja, $V \sim Bin(252, 0.05)$. Isso nos permite calcular a probabilidade de observar um n√∫mero espec√≠fico de viola√ß√µes, assumindo que o modelo VAR est√° bem calibrado.

**Corol√°rio 1.2**
*A m√©dia e a vari√¢ncia do n√∫mero de viola√ß√µes $V$ s√£o dadas por $E[V] = N(1-\alpha)$ e $Var[V] = N(1-\alpha)\alpha$.*

*Proof:*
   I. **Initial Setup**:
      - From Theorem 1.1, $V \sim Bin(N, 1-\alpha)$.
      - We recall the mean and variance of a binomial distribution.
   II. **Main Logical Steps**:
        - The expected value (mean) of a binomial distribution $Bin(n,p)$ is given by $E[V]=np$.
        - The variance of a binomial distribution $Bin(n,p)$ is given by $Var[V]=np(1-p)$.
   III. **Key Transformations**:
      - Substituting $n = N$ and $p = 1 - \alpha$, we have
      -  $E[V] = N(1-\alpha)$.
      - $Var[V] = N(1-\alpha)(1-(1-\alpha)) = N(1-\alpha)\alpha$.

   IV. **Conclusion**:
     -  This shows that the mean and the variance of $V$ are given by $E[V] = N(1-\alpha)$ and $Var[V] = N(1-\alpha)\alpha$, respectively. ‚ñ†

> üí° **Exemplo Num√©rico:**
> No mesmo exemplo, com $N=252$ e $\alpha=0.95$, a m√©dia do n√∫mero de viola√ß√µes √© $E[V] = 252 \times (1 - 0.95) = 252 \times 0.05 = 12.6$, e a vari√¢ncia √© $Var[V] = 252 \times 0.05 \times 0.95 = 11.97$. Isso significa que, em m√©dia, esperamos 12.6 viola√ß√µes, com uma variabilidade em torno desse valor, quantificada pela vari√¢ncia.

Al√©m disso, √© crucial considerar a autocorrela√ß√£o das perdas. Se as perdas em per√≠odos sucessivos forem correlacionadas, a suposi√ß√£o de independ√™ncia das observa√ß√µes pode ser violada, comprometendo a validade do *backtesting*.

**Proposi√ß√£o 3**
    *A autocorrela√ß√£o positiva das perdas pode levar a um excesso de viola√ß√µes do VAR em clusters, o que pode reduzir o poder de um *backtesting* que assume independ√™ncia das observa√ß√µes.*
    *Proof:*
       I. **Initial Setup**:
        -  Assume positive autocorrelation in losses.
        -  Assume that we are using a backtesting method that assumes independence.
        
       II. **Main Logical Steps**:
           - Positive autocorrelation implies that if a loss exceeds the VAR in a given period, the probability of a loss exceeding the VAR in the next period is higher than expected under independence.
           - This causes violations to occur in clusters, i.e. if one violation occurs, the probability of seeing more violations in close succession is higher.
           - When violations cluster, the assumption of independent Bernoulli trials underlying most backtesting procedures is violated.
           - The methods assume that the number of violations is a realization of a binomial distribution, which does not hold under autocorrelation.
           - Since the number of observations is reduced, a clustered violation process has less power than an independent violation process.

       III. **Key Transformations**:
           - Autocorrelation $\implies$ violation clusters
           - Clusters $\implies$ violation of independence
           - Violation of independence $\implies$ Reduction in the power of the test

       IV. **Conclusion**:
        - Therefore, positive autocorrelation can lead to clustered violations, and reduce the effectiveness of backtesting.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
> Suponha que as perdas do dia atual sejam positivamente correlacionadas com as perdas do dia anterior. Se o VAR for violado hoje, √© mais prov√°vel que ele seja violado amanh√£ tamb√©m. Isso cria *clusters* de viola√ß√µes, onde v√°rios dias consecutivos apresentam perdas acima do VAR, em vez de viola√ß√µes aleat√≥rias e independentes. Um modelo que ignora essa autocorrela√ß√£o pode n√£o capturar a din√¢mica real do risco.
    
**Lema 3**
*Para detectar a presen√ßa de autocorrela√ß√£o nas viola√ß√µes do VAR, pode-se realizar um teste de raz√£o de verossimilhan√ßa (LR) de independ√™ncia de viola√ß√µes, ou similar, como o teste de Kupiec ou Christoffersen.*

    *Proof:*
     I. **Initial Setup**:
          - We want to detect if there is autocorrelation in the violations of the VAR model.
          - We know that violations of a well-calibrated VAR should be independent events.

     II. **Main Logical Steps**:
          - The test of the likelihood ratio (LR) is designed to test the hypothesis that the distribution of the violations is independent.
          - The Kupiec test checks if the overall violation rate is consistent with the confidence level, implicitly assuming independence over time.
          - The Christoffersen test is specifically designed to test for both correct violation rate and independence over time.

     III. **Key Transformations**:
          - These tests check the null hypothesis of independence against the alternative of an autocorrelation in the violations.

     IV. **Conclusion**:
          -  The LR test and specific tests such as Kupiec and Christoffersen can all detect the presence of autocorrelation, supporting the claim. ‚ñ†
> üí° **Exemplo Num√©rico:**
>  Se os resultados do *backtesting* mostram uma sequ√™ncia de viola√ß√µes em dias pr√≥ximos (por exemplo, viola√ß√µes nos dias 1, 2, 3, e depois nenhuma viola√ß√£o por v√°rias semanas, e em seguida viola√ß√µes nos dias 45 e 46) isso levanta suspeitas de autocorrela√ß√£o. Testes como o de Christoffersen ajudam a quantificar essa suspeita, e a verificar se os *clusters* de viola√ß√£o s√£o estatisticamente significativos ou apenas devidos ao acaso.

**Proposi√ß√£o 4**
    *A presen√ßa de *clusters* de viola√ß√µes, causada por autocorrela√ß√£o, implica que a vari√¢ncia do n√∫mero de viola√ß√µes pode ser maior do que o previsto pela distribui√ß√£o binomial sob a hip√≥tese de independ√™ncia.*
    
  *Proof:*
  
    I. **Initial Setup**:
        - Assume that the violations are positively autocorrelated, so that violations tend to cluster together.
        - Let $X_i$ be indicator variables such that $X_i = 1$ if there is a violation at time $i$ and 0 otherwise.
        - Let the number of violations be given by $V=\sum_{i=1}^N X_i$.
        
    II. **Main Logical Steps**:
        - If the violations were independent, then we could calculate the variance of the total number of violations using the fact that it follows a binomial distribution (as shown in Corol√°rio 1.2). In that case, $Var[V] = N(1-\alpha)\alpha$.
        - However, because of autocorrelation, the $X_i$ are not independent. The variance of the sum of correlated random variables is not the sum of the variances.
        - If $\text{Cov}(X_i,X_j) > 0$ for at least some $i \neq j$, then $Var[\sum X_i] > \sum Var[X_i]$.
        - The autocorrelation causes $\text{Cov}(X_i,X_j) > 0$, implying that the variance of the sum will be greater than if the $X_i$ were independent.

   III. **Key Transformations**:
       - Autocorrelation $\implies \text{Cov}(X_i,X_j) > 0$.
       -  $\text{Cov}(X_i,X_j) > 0$  $\implies$  $Var[\sum X_i] > \sum Var[X_i]$
       - $Var[\sum X_i] > \sum Var[X_i]$ $\implies$ $Var[V] > N(1-\alpha)\alpha$

   IV. **Conclusion**:
      -  The presence of autocorrelation increases the variance of the sum of violations over the case with independent variables.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
>  Usando o exemplo de 252 observa√ß√µes com $\alpha = 0.95$, sob a hip√≥tese de independ√™ncia, a vari√¢ncia do n√∫mero de viola√ß√µes √© de 11.97. No entanto, se houver autocorrela√ß√£o positiva, a vari√¢ncia real das viola√ß√µes pode ser muito maior. Por exemplo, se as viola√ß√µes ocorrem em *clusters*, a vari√¢ncia poderia ser 20 ou at√© mais. Isso significa que as viola√ß√µes ser√£o mais vari√°veis do que o esperado sob o modelo binomial, e o modelo de VAR pode estar subestimando o risco.
   
**Teorema 2**
 *O teste de Kupiec √© um teste de hip√≥tese para verificar se a frequ√™ncia de viola√ß√µes do VAR √© estatisticamente diferente do esperado dado o n√≠vel de confian√ßa $\alpha$. Ele testa a hip√≥tese nula de que a frequ√™ncia de viola√ß√µes observada √© consistente com a frequ√™ncia esperada sob um modelo bem calibrado.*

 *Proof:*
    I. **Initial Setup**:
      - The null hypothesis ($H_0$) is that the model is well-calibrated, i.e., the observed violation rate matches the expected violation rate.
      - The alternative hypothesis ($H_1$) is that the model is not well-calibrated, i.e., the observed violation rate is different from the expected rate.
      - Let $V$ be the observed number of violations, $N$ the number of independent observations, and $\alpha$ the confidence level.
      - We know that if the model is well-calibrated, the number of violations follows a binomial distribution $V \sim Bin(N, 1-\alpha)$.
      
    II. **Main Logical Steps**:
      -  The Kupiec test uses a likelihood ratio test to compare the likelihood under the null hypothesis (where $p = 1-\alpha$) with the likelihood of a model that admits a free violation probability $\hat{p}$ estimated from data (observed frequency of violations, i.e., $\hat{p} = V/N$).
      - The likelihood ratio statistic is constructed based on the binomial distribution.
      - The statistic is asymptotically chi-squared distributed, which allows for the construction of the test.
      
    III. **Key Transformations**:
      - Let $p$ be the expected probability of violation under the null hypothesis $p = 1-\alpha$.
      - The likelihood function is given by $L(p) = \binom{N}{V} p^V (1-p)^{N-V}$.
      - The test statistic is given by $-2ln\frac{L(1-\alpha)}{L(\hat{p})}$.
      - Under the null hypothesis, this statistic converges in distribution to a $\chi^2(1)$.

    IV. **Conclusion**:
      -  The Kupiec test checks if the frequency of violations is statistically different from that expected under the well-calibrated model hypothesis, using the distribution of the violations implied by a model with binomial violations. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que em 252 dias com um n√≠vel de confian√ßa de 95%, um modelo VAR tenha apresentado 20 viola√ß√µes. Sob a hip√≥tese nula de que o modelo est√° bem calibrado, o n√∫mero esperado de viola√ß√µes √© de 12.6. O teste de Kupiec calcula uma estat√≠stica de teste que compara a probabilidade de observar 20 viola√ß√µes se o modelo estiver bem calibrado com a probabilidade de observar 20 viola√ß√µes com a probabilidade de viola√ß√£o observada nos dados (20/252). Essa estat√≠stica de teste segue uma distribui√ß√£o $\chi^2$ com 1 grau de liberdade. Se o valor da estat√≠stica de teste for muito alto (e o p-valor correspondente for baixo), rejeita-se a hip√≥tese de que o modelo est√° bem calibrado e conclui-se que o modelo est√° subestimando o risco.
 
 **Lema 4**
 *O teste de Christoffersen testa se as viola√ß√µes do VAR s√£o independentes ao longo do tempo, e, portanto, se h√° *clusters* de viola√ß√µes. Ele testa a hip√≥tese nula de independ√™ncia das viola√ß√µes contra a hip√≥tese alternativa de que as viola√ß√µes seguem um processo de Markov de primeira ordem.*

    *Proof:*
    I. **Initial Setup**:
         - Null Hypothesis $H_0$: The violations are independent over time.
         - Alternative Hypothesis $H_1$: The violations follow a first-order Markov process (i.e., the probability of a violation depends on whether the previous observation was a violation or not).
         - $X_t$ is an indicator variable that is 1 if a violation occurs at time t, and 0 otherwise.

    II. **Main Logical Steps**:
         -  The Christoffersen test examines the transitions between violation and no-violation states using a likelihood ratio test.
         - Under $H_0$, the probability of a violation at time $t$ is independent of the occurrence of a violation at time $t-1$.
         - Under $H_1$, the probability of a violation depends on whether there was a violation in the previous period.
         - This dependence is expressed using a transition matrix:
        $$
        \begin{bmatrix}
          \pi_{00} & \pi_{01} \\
          \pi_{10} & \pi_{11}
        \end{bmatrix}
        $$
         where $\pi_{ij}$ is the probability of observing $X_t=j$ given $X_{t-1} = i$.
        
    III. **Key Transformations**:
         - The likelihood function under the null hypothesis (independence) is compared to the likelihood under the alternative hypothesis (Markov model).
         - The likelihood ratio is used to evaluate if the alternative hypothesis fits the data significantly better than the null hypothesis.
         - The test statistic is asymptotically chi-squared distributed.
        
    IV. **Conclusion**:
         -  The Christoffersen test determines if the observed transitions between violations and no-violations are consistent with the assumption of independence (i.e., if violations are clustered). ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que temos 252 dias de dados, e as viola√ß√µes do VAR ocorrem em sequ√™ncia. Por exemplo, se tivermos uma viola√ß√£o no dia $t-1$, a probabilidade de ter uma viola√ß√£o no dia $t$ √© muito maior do que se n√£o tivermos uma viola√ß√£o no dia $t-1$. O teste de Christoffersen verifica se essas transi√ß√µes entre estados (viola√ß√£o/n√£o-viola√ß√£o) s√£o estatisticamente significativas e inconsistentes com a hip√≥tese de independ√™ncia. Ele estima a matriz de transi√ß√£o e compara a probabilidade de os dados terem sido gerados por uma cadeia de Markov ou por um processo independente, calculando uma estat√≠stica de teste, que segue uma distribui√ß√£o $\chi^2$.

    
**Teorema 2.1**
    *O teste de Christoffersen tamb√©m avalia se a frequ√™ncia de viola√ß√µes √© consistente com o n√≠vel de confian√ßa $\alpha$, simultaneamente com a avalia√ß√£o da independ√™ncia das viola√ß√µes.*

    *Proof:*
        I. **Initial Setup**:
            - The null hypothesis for the Christoffersen test is that the model is well-calibrated and that the violations are independent of each other.
            - The alternative hypothesis is that either the violation frequency is not correct or the violations are not independent.
            -  The null hypothesis is given by $H_0: \pi_{01}=\pi_{11} = 1-\alpha$.

        II. **Main Logical Steps**:
            - The Christoffersen test is actually a joint test. It is composed of two likelihood ratio (LR) tests.
            -  The first LR test looks at whether the frequency of violations is compatible with the confidence level $\alpha$. This part of the test does not test independence.
            - The second LR test checks if there is statistical evidence of dependence on the previous state. This second test checks independence.
            - If we reject the null hypothesis in the Christoffersen test, it means that the data is incompatible with the assumption that the violations are both independent and have the correct frequency.
            
        III. **Key Transformations**:
            - The first test checks if $\pi_{01}=\pi_{11}=1-\alpha$ jointly. If not, then either the frequency or the independence is rejected.
            - The second test checks the independence of the violations, by testing if $\pi_{01}=\pi_{11}$.
            - The combination of both tests gives the Christoffersen test statistic.
            
        IV. **Conclusion**:
            -  Because of the structure of the test, the Christoffersen test assesses both the frequency of violations and the independence of the violations simultaneously. Therefore, it assesses if both the frequency of violations is consistent with $\alpha$ and if the violations are independent of each other, simultaneously.  ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Continuando o exemplo anterior, o teste de Christoffersen n√£o apenas verifica se a frequ√™ncia de viola√ß√µes √© aproximadamente 5% (se $\alpha=0.95$), mas tamb√©m se a ocorr√™ncia de uma viola√ß√£o em um dia aumenta a probabilidade de uma viola√ß√£o no dia seguinte. Ele faz isso de forma simult√¢nea. Isso √© especialmente importante porque um modelo pode ter a frequ√™ncia de viola√ß√µes correta, mas as viola√ß√µes ocorrem em *clusters*, o que o teste de Christoffersen √© capaz de detectar.
    
**Proposi√ß√£o 5**
   *Al√©m do teste de Kupiec e do teste de Christoffersen, existem outros testes de *backtesting* como o teste de Lopez, o teste de correla√ß√£o serial, e testes baseados em fun√ß√µes de perda, que podem complementar a an√°lise do desempenho do modelo VAR.*
   *Proof:*
        I. **Initial Setup**:
            - The Kupiec and Christoffersen tests are not exhaustive.
            - There are other ways to evaluate a VAR model through backtesting.
        II. **Main Logical Steps**:
            - The Lopez test assesses the magnitude of losses that violate the VAR, not just the frequency. It uses a loss function that considers both the number and the size of the violations.
            - Tests of serial correlation can detect if violations cluster or are predictable, which is undesirable. For example, the Ljung-Box test.
            - Test based on loss functions (such as the tick loss) can be tailored to capture specific properties that are relevant for the user.
        III. **Key Transformations**:
             - The Lopez test, tests of serial correlation, and loss function-based tests provide additional tests that measure aspects of the VAR model not assessed by the Kupiec and Christoffersen test.
       IV. **Conclusion**:
            -  These other tests are useful to evaluate if the VAR model is adequate to a certain situation, and offer a more complete picture of the VAR model‚Äôs quality. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que o teste de Kupiec tenha aprovado um modelo VAR com um n√≠vel de confian√ßa de 95% mas o teste de Christoffersen tenha rejeitado o modelo por apresentar autocorrela√ß√£o. Nesse caso, podemos aplicar outros testes de *backtesting*. Por exemplo, o teste de Lopez poder√° apontar
que as viola√ß√µes do VAR s√£o muito maiores do que o esperado. Um teste de correla√ß√£o serial poder√° confirmar que as viola√ß√µes est√£o clusterizadas. Um teste baseado em fun√ß√µes de perda poder√° indicar que as perdas acima do### Model Backtesting and Horizon Selection in VAR

### Introdu√ß√£o
Em continuidade ao estudo do Value at Risk (VAR) e suas aplica√ß√µes, este cap√≠tulo aborda um aspecto crucial para a valida√ß√£o e confiabilidade dos modelos: o *backtesting*. Como vimos anteriormente, o VAR √© uma medida de risco que resume a potencial perda em um determinado horizonte de tempo e n√≠vel de confian√ßa [^1]. No entanto, a precis√£o do VAR depende da qualidade dos dados e da adequa√ß√£o do modelo utilizado. O *backtesting* √© uma ferramenta essencial para avaliar a performance de um modelo VAR e identificar poss√≠veis vieses nas previs√µes [^1]. Esta se√ß√£o se aprofundar√° nos crit√©rios para realizar o *backtesting*, com foco especial na import√¢ncia do horizonte de tempo na efic√°cia dos testes.

### Conceitos Fundamentais
O *backtesting* consiste em comparar sistematicamente as previs√µes de perdas obtidas por meio do VAR com as perdas e lucros (P&L) efetivamente realizados posteriormente [^1]. O objetivo principal do *backtesting* √© detectar vieses ou inconsist√™ncias nos resultados do VAR, garantindo que o modelo esteja gerando previs√µes confi√°veis. A ideia central √© que um modelo VAR bem calibrado deve ser capaz de prever a frequ√™ncia com que as perdas efetivas excedem o VAR previsto, alinhando-se com o n√≠vel de confian√ßa estabelecido [^2].

Para realizar um *backtesting* eficaz, √© fundamental levar em considera√ß√£o o horizonte de tempo utilizado no c√°lculo do VAR. A escolha do horizonte de tempo influencia diretamente o n√∫mero de observa√ß√µes independentes dispon√≠veis para o teste, afetando o poder estat√≠stico do mesmo [^1]. O poder de um teste refere-se √† sua capacidade de detectar desvios significativos entre as previs√µes do VAR e os resultados reais.

Como mencionado anteriormente, o horizonte de tempo √© um dos fatores quantitativos que influenciam o c√°lculo do VAR. Em geral, um horizonte mais longo leva a um VAR maior. Ao usar o VAR como uma medida de risco potencial, o horizonte de tempo deve ser definido pela liquidez dos ativos, ou seja, o tempo necess√°rio para liquidar o portf√≥lio sem grandes impactos no mercado [^1].

#### O Impacto do Horizonte de Tempo no Backtesting
A escolha do horizonte de tempo tem um impacto significativo no n√∫mero de observa√ß√µes independentes dispon√≠veis para o *backtesting*. Um horizonte mais longo reduz o n√∫mero de observa√ß√µes independentes em um determinado per√≠odo. Por exemplo, se utilizarmos um horizonte de VAR de duas semanas, teremos apenas 26 observa√ß√µes independentes por ano [^1]. Por outro lado, um horizonte de um dia fornecer√° aproximadamente 252 observa√ß√µes independentes ao longo de um ano [^1].

O poder do teste, ou seja, a capacidade de detectar vieses no modelo, est√° diretamente relacionado ao n√∫mero de observa√ß√µes independentes. Com um n√∫mero maior de observa√ß√µes, o teste se torna mais sens√≠vel a desvios entre as previs√µes do VAR e as perdas efetivas [^1]. Por isso, para fins de *backtesting*, √© prefer√≠vel utilizar horizontes de tempo mais curtos, como um dia, para maximizar o poder dos testes [^1].

**Proposi√ß√£o 1**
   *A escolha de um horizonte de tempo $h$ para o c√°lculo do VAR implica que, em um per√≠odo de $T$ dias, temos aproximadamente $T/h$ observa√ß√µes independentes. Para um dado per√≠odo de tempo $T$, o n√∫mero de observa√ß√µes independentes √© inversamente proporcional ao tamanho do horizonte $h$.*
   
   *Proof:*

   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Each observation period for the VAR spans $h$ days.

   II. **Main Logical Steps**:
      - The total number of days, $T$, is divided by the length of each observation period, $h$, to determine the number of non-overlapping observation periods.
      - This gives the number of independent observations.

   III. **Key Transformations**:
      -  Number of independent observations $\approx \frac{T}{h}$

   IV. **Conclusion**:
      - As $h$ increases, $T/h$ decreases, implying an inverse relationship between $h$ and the number of independent observations for a fixed $T$.
      - This proves the statement: "the number of independent observations is inversely proportional to the size of the horizon $h$". ‚ñ†
> üí° **Exemplo Num√©rico:**
> Suponha que temos um per√≠odo de $T = 252$ dias (um ano de negocia√ß√£o). Se usarmos um horizonte de tempo $h = 1$ dia, teremos aproximadamente $252/1 = 252$ observa√ß√µes independentes. Se aumentarmos o horizonte para $h = 5$ dias (uma semana), teremos $252/5 \approx 50$ observa√ß√µes independentes. E se o horizonte for $h=21$ (aproximadamente um m√™s), teremos $252/21=12$ observa√ß√µes independentes. Este exemplo ilustra claramente a rela√ß√£o inversa entre o horizonte de tempo e o n√∫mero de observa√ß√µes independentes.

#### Rela√ß√£o com o N√≠vel de Confian√ßa
√â importante notar que o n√≠vel de confian√ßa tamb√©m influencia o n√∫mero de observa√ß√µes na cauda da distribui√ß√£o. N√≠veis de confian√ßa mais altos, como 99%, resultam em menos observa√ß√µes na cauda, dificultando a identifica√ß√£o de vieses no modelo. Em outras palavras, para confirmar a validade do modelo com um n√≠vel de confian√ßa de 99%, seria necess√°rio um longo per√≠odo de observa√ß√µes para coletar dados suficientes na cauda da distribui√ß√£o [^1]. Por isso, para o *backtesting*, n√≠veis de confian√ßa mais baixos, como 95%, podem ser prefer√≠veis, permitindo uma an√°lise mais frequente dos resultados do modelo [^1].

**Lema 1**
   *Para um n√≠vel de confian√ßa $\alpha$, o n√∫mero de observa√ß√µes esperadas na cauda da distribui√ß√£o em um per√≠odo $T$ com horizonte de tempo $h$ √© aproximadamente $(1-\alpha)T/h$.*

   *Proof:*
   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Let $\alpha$ be the confidence level.
      - The number of independent observations is approximately $T/h$.

   II. **Main Logical Steps**:
       - With a confidence level $\alpha$, the probability of an observation falling in the tail (exceeding the VAR) is $1 - \alpha$.
       - The expected number of observations in the tail is the product of the number of independent observations and the probability of falling in the tail.

   III. **Key Transformations**:
        - Expected number of observations in the tail $\approx \frac{T}{h} \times (1-\alpha) = (1-\alpha) \frac{T}{h}$

   IV. **Conclusion**:
      - This shows that the expected number of observations in the tail is approximately $(1-\alpha)T/h$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Usando o exemplo anterior com $T=252$ dias e um horizonte de $h=1$ dia, se o n√≠vel de confian√ßa for $\alpha = 0.95$ (95%), o n√∫mero esperado de observa√ß√µes na cauda √© $(1-0.95) \times 252/1 = 0.05 \times 252 = 12.6$. Isso significa que, em m√©dia, esperamos que o VAR seja violado aproximadamente 12 ou 13 vezes em um ano. Se o n√≠vel de confian√ßa for $\alpha=0.99$, o n√∫mero esperado de viola√ß√µes cai para $(1-0.99) \times 252 = 0.01 \times 252 = 2.52$, indicando que seria necess√°rio um per√≠odo muito maior de observa√ß√µes para testar o modelo de forma eficaz. Se, por outro lado, mantemos o n√≠vel de confian√ßa em 95% mas aumentamos o horizonte para $h=5$, o n√∫mero de observa√ß√µes na cauda ser√° $(1-0.95)\times 252/5 \approx 2.5$.
  
**Corol√°rio 1.1**
   *O n√∫mero de observa√ß√µes na cauda √© diretamente proporcional ao per√≠odo $T$ e inversamente proporcional ao horizonte $h$, e diminui com o aumento do n√≠vel de confian√ßa $\alpha$.*

   *Proof:*
   I. **Initial Setup**:
       - From Lema 1, the number of observations in the tail is approximately $(1-\alpha)T/h$.

   II. **Main Logical Steps**:
       - We analyze the effect of $T$, $h$, and $\alpha$ on this expression.

   III. **Key Transformations**:
        - As $T$ increases, the number of observations in the tail increases proportionally.
        - As $h$ increases, the number of observations in the tail decreases proportionally.
        - As $\alpha$ increases, $(1-\alpha)$ decreases, thus decreasing the number of observations in the tail.

   IV. **Conclusion**:
        -  This confirms the statement that the number of tail observations is directly proportional to $T$, inversely proportional to $h$, and decreases with an increase in $\alpha$. ‚ñ†

Al√©m disso, vale ressaltar que a escolha do n√≠vel de confian√ßa afeta o tipo de erros que o *backtesting* ser√° capaz de detectar. Um n√≠vel de confian√ßa mais alto prioriza a detec√ß√£o de erros na cauda da distribui√ß√£o, enquanto um n√≠vel de confian√ßa mais baixo permite uma detec√ß√£o mais frequente de erros, ainda que menos extremos.

**Proposi√ß√£o 2**
    *Um n√≠vel de confian√ßa mais baixo aumenta a frequ√™ncia com que os resultados do VAR s√£o comparados com os retornos realizados, e, consequentemente, aumenta a sensibilidade a potenciais vieses no modelo.*
  
  *Proof:*

  I. **Initial Setup**:
    - Let $\alpha$ be the confidence level.
    - A lower confidence level implies a smaller $\alpha$.
    - VAR is calculated for a given confidence level.

  II. **Main Logical Steps**:
    - A lower confidence level (smaller $\alpha$) corresponds to a lower VAR value (since the VAR is a quantile).
    - A lower VAR value means a greater chance of actual losses exceeding the VAR.
    - If the actual loss exceeds the VAR value, this is considered a violation in the backtesting process.
    - More violations mean more comparisons between VAR and actual returns.

  III. **Key Transformations**:
    - Lower $\alpha$  $\implies$ Lower VAR
    - Lower VAR $\implies$ More violations
    - More violations $\implies$ More frequent comparisons between VAR and actual returns

  IV. **Conclusion**:
    - This demonstrates that a lower confidence level results in more frequent comparisons between VAR predictions and actual returns. Therefore, the sensitivity of the backtesting to potential biases in the model increases.‚ñ†

> üí° **Exemplo Num√©rico:**
> Considere um modelo VAR com um horizonte de um dia ($h=1$). Se o n√≠vel de confian√ßa for $\alpha = 0.99$, espera-se que as viola√ß√µes sejam raras, e a cada 100 dias de negocia√ß√£o, apenas 1 dia, em m√©dia, apresentar√° uma perda que ultrapassa o VAR. Se o n√≠vel de confian√ßa for reduzido para $\alpha=0.95$, as viola√ß√µes tornam-se mais frequentes, com uma m√©dia de 5 dias a cada 100, e isso permite uma an√°lise mais detalhada e frequente do modelo.

**Teorema 1**
*Existe um trade-off entre o horizonte de tempo $h$ e o n√≠vel de confian√ßa $\alpha$ no *backtesting*. Diminuir $h$ aumenta o n√∫mero de observa√ß√µes independentes e, portanto, o poder do teste, enquanto diminuir $\alpha$ aumenta a frequ√™ncia de viola√ß√µes do VAR e, tamb√©m, aumenta o poder do teste.*
 *Proof:*
    I. **Initial Setup**:
        - The power of a backtesting test is directly related to the number of independent observations and the frequency of violations.
    
    II. **Main Logical Steps**:
         - From Proposi√ß√£o 1, reducing the time horizon $h$ increases the number of independent observations. An increase in independent observations leads to an increase in the power of the test.
         - From Proposi√ß√£o 2, reducing the confidence level $\alpha$ increases the frequency of violations. More frequent violations increase the data available to backtest, increasing the power of the test.
        
    III. **Key Transformations**:
        - $h \downarrow \implies \text{Number of Independent Observations} \uparrow \implies \text{Test Power} \uparrow$
        - $\alpha \downarrow \implies \text{Frequency of Violations} \uparrow \implies \text{Test Power} \uparrow$

    IV. **Conclusion**:
        - The theorem states that there is a trade-off. Both lowering $h$ and $\alpha$ increase the power of the backtest, supporting the claim. Therefore, this proves the existence of the trade-off.‚ñ†

**Lema 2**
*Seja $N$ o n√∫mero de observa√ß√µes independentes, e seja $X_i$ uma vari√°vel indicadora que vale 1 se a perda observada no per√≠odo $i$ excede o VAR previsto e 0 caso contr√°rio. Se o modelo VAR estiver bem calibrado, ent√£o $X_i$ s√£o vari√°veis aleat√≥rias independentes de Bernoulli com probabilidade de sucesso $1 - \alpha$.*

*Proof:*
   I. **Initial Setup**:
       - $N$ is the number of independent observations.
       - $X_i$ is an indicator variable, where $X_i = 1$ if the loss exceeds the predicted VAR at time $i$, and $X_i = 0$ otherwise.
       - $\alpha$ is the confidence level of the VAR.
       - A well-calibrated VAR model has a probability of $1-\alpha$ of the loss exceeding the VAR.
       - We assume independence between observations.

   II. **Main Logical Steps**:
       - For each observation $i$, there are only two outcomes: the loss exceeds the VAR ($X_i = 1$) or the loss does not exceed the VAR ($X_i = 0$).
       - Under a well-calibrated model, the probability of $X_i = 1$ (a loss exceeding the VAR) is $1 - \alpha$.
       - This is precisely the definition of a Bernoulli trial with a success probability of $1-\alpha$.
       - The independence of the $X_i$ variables comes from the assumption of independence of observations.

   III. **Key Transformations**:
       - $P(X_i=1) = 1-\alpha$.

   IV. **Conclusion**:
       - The variables $X_i$ are independent and follow a Bernoulli distribution with success probability $1-\alpha$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Vamos supor que estamos analisando 252 dias de negocia√ß√£o com um n√≠vel de confian√ßa de 95% ($\alpha=0.95$). Para cada dia $i$, definimos $X_i = 1$ se a perda naquele dia excedeu o VAR previsto e $X_i = 0$ caso contr√°rio. Se o modelo estiver bem calibrado, cada $X_i$ √© uma vari√°vel de Bernoulli com $p = 1 - 0.95 = 0.05$. Isso significa que a probabilidade de uma viola√ß√£o em qualquer dia √© de 5%.

**Teorema 1.1**
*Sob as condi√ß√µes do Lema 2, o n√∫mero de viola√ß√µes do VAR, $V = \sum_{i=1}^N X_i$, segue uma distribui√ß√£o binomial com par√¢metros $N$ e $1-\alpha$, ou seja, $V \sim Bin(N, 1 - \alpha)$.*

*Proof:*
   I. **Initial Setup**:
      - From Lema 2, $X_i$ are independent Bernoulli random variables with success probability $1-\alpha$.
      - $V$ is defined as the sum of these Bernoulli variables: $V = \sum_{i=1}^N X_i$.

   II. **Main Logical Steps**:
      - The sum of $N$ independent Bernoulli random variables with the same success probability follows a binomial distribution.
      - The parameters of the binomial distribution are $N$ (the number of trials) and $1-\alpha$ (the success probability).

   III. **Key Transformations**:
      - $V = \sum_{i=1}^N X_i \implies V \sim Bin(N, 1 - \alpha)$

   IV. **Conclusion**:
      - Therefore, the number of violations $V$ follows a binomial distribution with parameters $N$ and $1-\alpha$. ‚ñ†
> üí° **Exemplo Num√©rico:**
> Continuando o exemplo anterior, onde temos 252 observa√ß√µes independentes ($N=252$) e $\alpha = 0.95$, o n√∫mero total de viola√ß√µes $V$ segue uma distribui√ß√£o binomial com par√¢metros $N=252$ e $p=0.05$, ou seja, $V \sim Bin(252, 0.05)$. Isso nos permite calcular a probabilidade de observar um n√∫mero espec√≠fico de viola√ß√µes, assumindo que o modelo VAR est√° bem calibrado.

**Corol√°rio 1.2**
*A m√©dia e a vari√¢ncia do n√∫mero de viola√ß√µes $V$ s√£o dadas por $E[V] = N(1-\alpha)$ e $Var[V] = N(1-\alpha)\alpha$.*

*Proof:*
   I. **Initial Setup**:
      - From Theorem 1.1, $V \sim Bin(N, 1-\alpha)$.
      - We recall the mean and variance of a binomial distribution.
   II. **Main Logical Steps**:
        - The expected value (mean) of a binomial distribution $Bin(n,p)$ is given by $E[V]=np$.
        - The variance of a binomial distribution $Bin(n,p)$ is given by $Var[V]=np(1-p)$.
   III. **Key Transformations**:
      - Substituting $n = N$ and $p = 1 - \alpha$, we have
      -  $E[V] = N(1-\alpha)$.
      - $Var[V] = N(1-\alpha)(1-(1-\alpha)) = N(1-\alpha)\alpha$.

   IV. **Conclusion**:
     -  This shows that the mean and the variance of $V$ are given by $E[V] = N(1-\alpha)$ and $Var[V] = N(1-\alpha)\alpha$, respectively. ‚ñ†

> üí° **Exemplo Num√©rico:**
> No mesmo exemplo, com $N=252$ e $\alpha=0.95$, a m√©dia do n√∫mero de viola√ß√µes √© $E[V] = 252 \times (1 - 0.95) = 252 \times 0.05 = 12.6$, e a vari√¢ncia √© $Var[V] = 252 \times 0.05 \times 0.95 = 11.97$. Isso significa que, em m√©dia, esperamos 12.6 viola√ß√µes, com uma variabilidade em torno desse valor, quantificada pela vari√¢ncia.

Al√©m disso, √© crucial considerar a autocorrela√ß√£o das perdas. Se as perdas em per√≠odos sucessivos forem correlacionadas, a suposi√ß√£o de independ√™ncia das observa√ß√µes pode ser violada, comprometendo a validade do *backtesting*.

**Proposi√ß√£o 3**
    *A autocorrela√ß√£o positiva das perdas pode levar a um excesso de viola√ß√µes do VAR em clusters, o que pode reduzir o poder de um *backtesting* que assume independ√™ncia das observa√ß√µes.*
    *Proof:*
       I. **Initial Setup**:
        -  Assume positive autocorrelation in losses.
        -  Assume that we are using a backtesting method that assumes independence.
        
       II. **Main Logical Steps**:
           - Positive autocorrelation implies that if a loss exceeds the VAR in a given period, the probability of a loss exceeding the VAR in the next period is higher than expected under independence.
           - This causes violations to occur in clusters, i.e. if one violation occurs, the probability of seeing more violations in close succession is higher.
           - When violations cluster, the assumption of independent Bernoulli trials underlying most backtesting procedures is violated.
           - The methods assume that the number of violations is a realization of a binomial distribution, which does not hold under autocorrelation.
           - Since the number of observations is reduced, a clustered violation process has less power than an independent violation process.

       III. **Key Transformations**:
           - Autocorrelation $\implies$ violation clusters
           - Clusters $\implies$ violation of independence
           - Violation of independence $\implies$ Reduction in the power of the test

       IV. **Conclusion**:
        - Therefore, positive autocorrelation can lead to clustered violations, and reduce the effectiveness of backtesting.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
> Suponha que as perdas do dia atual sejam positivamente correlacionadas com as perdas do dia anterior. Se o VAR for violado hoje, √© mais prov√°vel que ele seja violado amanh√£ tamb√©m. Isso cria *clusters* de viola√ß√µes, onde v√°rios dias consecutivos apresentam perdas acima do VAR, em vez de viola√ß√µes aleat√≥rias e independentes. Um modelo que ignora essa autocorrela√ß√£o pode n√£o capturar a din√¢mica real do risco.
    
**Lema 3**
*Para detectar a presen√ßa de autocorrela√ß√£o nas viola√ß√µes do VAR, pode-se realizar um teste de raz√£o de verossimilhan√ßa (LR) de independ√™ncia de viola√ß√µes, ou similar, como o teste de Kupiec ou Christoffersen.*

    *Proof:*
     I. **Initial Setup**:
          - We want to detect if there is autocorrelation in the violations of the VAR model.
          - We know that violations of a well-calibrated VAR should be independent events.

     II. **Main Logical Steps**:
          - The test of the likelihood ratio (LR) is designed to test the hypothesis that the distribution of the violations is independent.
          - The Kupiec test checks if the overall violation rate is consistent with the confidence level, implicitly assuming independence over time.
          - The Christoffersen test is specifically designed to test for both correct violation rate and independence over time.

     III. **Key Transformations**:
          - These tests check the null hypothesis of independence against the alternative of an autocorrelation in the violations.

     IV. **Conclusion**:
          -  The LR test and specific tests such as Kupiec and Christoffersen can all detect the presence of autocorrelation, supporting the claim. ‚ñ†
> üí° **Exemplo Num√©rico:**
>  Se os resultados do *backtesting* mostram uma sequ√™ncia de viola√ß√µes em dias pr√≥ximos (por exemplo, viola√ß√µes nos dias 1, 2, 3, e depois nenhuma viola√ß√£o por v√°rias semanas, e em seguida viola√ß√µes nos dias 45 e 46) isso levanta suspeitas de autocorrela√ß√£o. Testes como o de Christoffersen ajudam a quantificar essa suspeita, e a verificar se os *clusters* de viola√ß√£o s√£o estatisticamente significativos ou apenas devidos ao acaso.

**Proposi√ß√£o 4**
    *A presen√ßa de *clusters* de viola√ß√µes, causada por autocorrela√ß√£o, implica que a vari√¢ncia do n√∫mero de viola√ß√µes pode ser maior do que o previsto pela distribui√ß√£o binomial sob a hip√≥tese de independ√™ncia.*
    
  *Proof:*
  
    I. **Initial Setup**:
        - Assume that the violations are positively autocorrelated, so that violations tend to cluster together.
        - Let $X_i$ be indicator variables such that $X_i = 1$ if there is a violation at time $i$ and 0 otherwise.
        - Let the number of violations be given by $V=\sum_{i=1}^N X_i$.
        
    II. **Main Logical Steps**:
        - If the violations were independent, then we could calculate the variance of the total number of violations using the fact that it follows a binomial distribution (as shown in Corol√°rio 1.2). In that case, $Var[V] = N(1-\alpha)\alpha$.
        - However, because of autocorrelation, the $X_i$ are not independent. The variance of the sum of correlated random variables is not the sum of the variances.
        - If $\text{Cov}(X_i,X_j) > 0$ for at least some $i \neq j$, then $Var[\sum X_i] > \sum Var[X_i]$.
        - The autocorrelation causes $\text{Cov}(X_i,X_j) > 0$, implying that the variance of the sum will be greater than if the $X_i$ were independent.

   III. **Key Transformations**:
       - Autocorrelation $\implies \text{Cov}(X_i,X_j) > 0$.
       -  $\text{Cov}(X_i,X_j) > 0$  $\implies$  $Var[\sum X_i] > \sum Var[X_i]$
       - $Var[\sum X_i] > \sum Var[X_i]$ $\implies$ $Var[V] > N(1-\alpha)\alpha$

   IV. **Conclusion**:
      -  The presence of autocorrelation increases the variance of the sum of violations over the case with independent variables.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
>  Usando o exemplo de 252 observa√ß√µes com $\alpha = 0.95$, sob a hip√≥tese de independ√™ncia, a vari√¢ncia do n√∫mero de viola√ß√µes √© de 11.97. No entanto, se houver autocorrela√ß√£o positiva, a vari√¢ncia real das viola√ß√µes pode ser muito maior. Por exemplo, se as viola√ß√µes ocorrem em *clusters*, a vari√¢ncia poderia ser 20 ou at√© mais. Isso significa que as viola√ß√µes ser√£o mais vari√°veis do que o esperado sob o modelo binomial, e o modelo de VAR pode estar subestimando o risco.
   
**Teorema 2**
 *O teste de Kupiec √© um teste de hip√≥tese para verificar se a frequ√™ncia de viola√ß√µes do VAR √© estatisticamente diferente do esperado dado o n√≠vel de confian√ßa $\alpha$. Ele testa a hip√≥tese nula de que a frequ√™ncia de viola√ß√µes observada √© consistente com a frequ√™ncia esperada sob um modelo bem calibrado.*

 *Proof:*
    I. **Initial Setup**:
      - The null hypothesis ($H_0$) is that the model is well-calibrated, i.e., the observed violation rate matches the expected violation rate.
      - The alternative hypothesis ($H_1$) is that the model is not well-calibrated, i.e., the observed violation rate is different from the expected rate.
      - Let $V$ be the observed number of violations, $N$ the number of independent observations, and $\alpha$ the confidence level.
      - We know that if the model is well-calibrated, the number of violations follows a binomial distribution $V \sim Bin(N, 1-\alpha)$.
      
    II. **Main Logical Steps**:
      -  The Kupiec test uses a likelihood ratio test to compare the likelihood under the null hypothesis (where $p = 1-\alpha$) with the likelihood of a model that admits a free violation probability $\hat{p}$ estimated from data (observed frequency of violations, i.e., $\hat{p} = V/N$).
      - The likelihood ratio statistic is constructed based on the binomial distribution.
      - The statistic is asymptotically chi-squared distributed, which allows for the construction of the test.
      
    III. **Key Transformations**:
      - Let $p$ be the expected probability of violation under the null hypothesis $p = 1-\alpha$.
      - The likelihood function is given by $L(p) = \binom{N}{V} p^V (1-p)^{N-V}$.
      - The test statistic is given by $-2ln\frac{L(1-\alpha)}{L(\hat{p})}$.
      - Under the null hypothesis, this statistic converges in distribution to a $\chi^2(1)$.

    IV. **Conclusion**:
      -  The Kupiec test checks if the frequency of violations is statistically different from that expected under the well-calibrated model hypothesis, using the distribution of the violations implied by a model with binomial violations. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que em 252 dias com um n√≠vel de confian√ßa de 95%, um modelo VAR tenha apresentado 20 viola√ß√µes. Sob a hip√≥tese nula de que o modelo est√° bem calibrado, o n√∫mero esperado de viola√ß√µes √© de 12.6. O teste de Kupiec calcula uma estat√≠stica de teste que compara a probabilidade de observar 20 viola√ß√µes se o modelo estiver bem calibrado com a probabilidade de observar 20 viola√ß√µes com a probabilidade de viola√ß√£o observada nos dados (20/252). Essa estat√≠stica de teste segue uma distribui√ß√£o $\chi^2$ com 1 grau de liberdade. Se o valor da estat√≠stica de teste for muito alto (e o p-valor correspondente for baixo), rejeita-se a hip√≥tese de que o modelo est√° bem calibrado e conclui-se que o modelo est√° subestimando o risco.
 
 **Lema 4**
 *O teste de Christoffersen testa se as viola√ß√µes do VAR s√£o independentes ao longo do tempo, e, portanto, se h√° *clusters* de viola√ß√µes. Ele testa a hip√≥tese nula de independ√™ncia das viola√ß√µes contra a hip√≥tese alternativa de que as viola√ß√µes seguem um processo de Markov de primeira ordem.*

    *Proof:*
    I. **Initial Setup**:
         - Null Hypothesis $H_0$: The violations are independent over time.
         - Alternative Hypothesis $H_1$: The violations follow a first-order Markov process (i.e., the probability of a violation depends on whether the previous observation was a violation or not).
         - $X_t$ is an indicator variable that is 1 if a violation occurs at time t, and 0 otherwise.

    II. **Main Logical Steps**:
         -  The Christoffersen test examines the transitions between violation and no-violation states using a likelihood ratio test.
         - Under $H_0$, the probability of a violation at time $t$ is independent of the occurrence of a violation at time $t-1$.
         - Under $H_1$, the probability of a violation depends on whether there was a violation in the previous period.
         - This dependence is expressed using a transition matrix:
        $$
        \begin{bmatrix}
          \pi_{00} & \pi_{01} \\
          \pi_{10} & \pi_{11}
        \end{bmatrix}
        $$
         where $\pi_{ij}$ is the probability of observing $X_t=j$ given $X_{t-1} = i$.
        
    III. **Key Transformations**:
         - The likelihood function under the null hypothesis (independence) is compared to the likelihood under the alternative hypothesis (Markov model).
         - The likelihood ratio is used to evaluate if the alternative hypothesis fits the data significantly better than the null hypothesis.
         - The test statistic is asymptotically chi-squared distributed.
        
    IV. **Conclusion**:
         -  The Christoffersen test determines if the observed transitions between violations and no-violations are consistent with the assumption of independence (i.e., if violations are clustered). ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que temos 252 dias de dados, e as viola√ß√µes do VAR ocorrem em sequ√™ncia. Por exemplo, se tivermos uma viola√ß√£o no dia $t-1$, a probabilidade de ter uma viola√ß√£o no dia $t$ √© muito maior do que se n√£o tivermos uma viola√ß√£o no dia $t-1$. O teste de Christoffersen verifica se essas transi√ß√µes entre estados (viola√ß√£o/n√£o-viola√ß√£o) s√£o estatisticamente significativas e inconsistentes com a hip√≥tese de independ√™ncia. Ele estima a matriz de transi√ß√£o e compara a probabilidade de os dados terem sido gerados por uma cadeia de Markov ou por um processo independente, calculando uma estat√≠stica de teste, que segue uma distribui√ß√£o $\chi^2$.

    
**Teorema 2.1**
    *O teste de Christoffersen tamb√©m avalia se a frequ√™ncia de viola√ß√µes √© consistente com o n√≠vel de confian√ßa $\alpha$, simultaneamente com a avalia√ß√£o da independ√™ncia das viola√ß√µes.*

    *Proof:*
        I. **Initial Setup**:
            - The null hypothesis for the Christoffersen test is that the model is well-calibrated and that the violations are independent of each other.
            - The alternative hypothesis is that either the violation frequency is not correct or the violations are not independent.
            -  The null hypothesis is given by $H_0: \pi_{01}=\pi_{11} = 1-\alpha$.

        II. **Main Logical Steps**:
            - The Christoffersen test is actually a joint test. It is composed of two likelihood ratio (LR) tests.
            -  The first LR test looks at whether the frequency of violations is compatible with the confidence level $\alpha$. This part of the test does not test independence.
            - The second LR test checks if there is statistical evidence of dependence on the previous state. This second test checks independence.
            - If we reject the null hypothesis in the Christoffersen test, it means that the data is incompatible with the assumption that the violations are both independent and have the correct frequency.
            
        III. **Key Transformations**:
            - The first test checks if $\pi_{01}=\pi_{11}=1-\alpha$ jointly. If not, then either the frequency or the independence is rejected.
            - The second test checks the independence of the violations, by testing if $\pi_{01}=\pi_{11}$.
            - The combination of both tests gives the Christoffersen test statistic.
            
        IV. **Conclusion**:
            -  Because of the structure of the test, the Christoffersen test assesses both the frequency of violations and the independence of the violations simultaneously. Therefore, it assesses if both the frequency of violations is consistent with $\alpha$ and if the violations are independent of each other, simultaneously.  ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Continuando o exemplo anterior, o teste de Christoffersen n√£o apenas verifica se a frequ√™ncia de viola√ß√µes √© aproximadamente 5% (se $\alpha=0.95$), mas tamb√©m se a ocorr√™ncia de uma viola√ß√£o em um dia aumenta a probabilidade de uma viola√ß√£o no dia seguinte. Ele faz isso de forma simult√¢nea. Isso √© especialmente importante porque um modelo pode ter a frequ√™ncia de viola√ß√µes correta, mas as viola√ß√µes ocorrem em *clusters*, o que o teste de Christoffersen √© capaz de detectar.
    
**Proposi√ß√£o 5**
   *Al√©m do teste de Kupiec e do teste de Christoffersen, existem outros testes de *backtesting* como o teste de Lopez, o teste de correla√ß√£o serial, e testes baseados em fun√ß√µes de perda, que podem complementar a an√°lise do desempenho do modelo VAR.*
   *Proof:*
        I. **Initial Setup**:
            - The Kupiec and Christoffersen tests are not exhaustive.
            - There are other ways to evaluate a VAR model through backtesting.
        II. **Main Logical Steps**:
            - The Lopez test assesses the magnitude of losses that violate the VAR, not just the frequency. It uses a loss function that considers both the number and the size of the violations.
            - Tests of serial correlation can detect if violations cluster or are predictable, which is undesirable. For example, the Ljung-Box test.
            - Test based on loss functions (such as the tick loss) can be tailored to capture specific properties that are relevant for the user.
        III. **Key Transformations**:
             - The Lopez test, tests of serial correlation, and loss function-based tests provide additional tests that measure aspects of the VAR model not assessed by the Kupiec and Christoffersen test.
       IV. **Conclusion**:
            -  These other tests are useful to evaluate if the VAR model is adequate to a certain situation, and offer a more complete picture of the VAR model‚Äôs quality. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que o teste de Kupiec tenha aprovado um modelo VAR com um n√≠vel de confian√ßa de 95% mas o teste de Christoffersen tenha rejeitado o modelo por apresentar autocorrela√ß√£o. Nesse caso, podemos aplicar outros testes de *backtesting*. Por exemplo, o teste de Lopez poder√° apontar
que as viola√ß√µes do VAR s√£o muito maiores do que o esperado. Um teste de correla√ß√£o serial poder√° confirmar que as viola√ß√µes est√£o clusterizadas. Um teste baseado em fun√ß√µes de perda poder√° indicar que as perdas acima do### Model Backtesting and Horizon Selection in VAR

### Introdu√ß√£o
Em continuidade ao estudo do Value at Risk (VAR) e suas aplica√ß√µes, este cap√≠tulo aborda um aspecto crucial para a valida√ß√£o e confiabilidade dos modelos: o *backtesting*. Como vimos anteriormente, o VAR √© uma medida de risco que resume a potencial perda em um determinado horizonte de tempo e n√≠vel de confian√ßa [^1]. No entanto, a precis√£o do VAR depende da qualidade dos dados e da adequa√ß√£o do modelo utilizado. O *backtesting* √© uma ferramenta essencial para avaliar a performance de um modelo VAR e identificar poss√≠veis vieses nas previs√µes [^1]. Esta se√ß√£o se aprofundar√° nos crit√©rios para realizar o *backtesting*, com foco especial na import√¢ncia do horizonte de tempo na efic√°cia dos testes.

### Conceitos Fundamentais
O *backtesting* consiste em comparar sistematicamente as previs√µes de perdas obtidas por meio do VAR com as perdas e lucros (P&L) efetivamente realizados posteriormente [^1]. O objetivo principal do *backtesting* √© detectar vieses ou inconsist√™ncias nos resultados do VAR, garantindo que o modelo esteja gerando previs√µes confi√°veis. A ideia central √© que um modelo VAR bem calibrado deve ser capaz de prever a frequ√™ncia com que as perdas efetivas excedem o VAR previsto, alinhando-se com o n√≠vel de confian√ßa estabelecido [^2].

Para realizar um *backtesting* eficaz, √© fundamental levar em considera√ß√£o o horizonte de tempo utilizado no c√°lculo do VAR. A escolha do horizonte de tempo influencia diretamente o n√∫mero de observa√ß√µes independentes dispon√≠veis para o teste, afetando o poder estat√≠stico do mesmo [^1]. O poder de um teste refere-se √† sua capacidade de detectar desvios significativos entre as previs√µes do VAR e os resultados reais.

Como mencionado anteriormente, o horizonte de tempo √© um dos fatores quantitativos que influenciam o c√°lculo do VAR. Em geral, um horizonte mais longo leva a um VAR maior. Ao usar o VAR como uma medida de risco potencial, o horizonte de tempo deve ser definido pela liquidez dos ativos, ou seja, o tempo necess√°rio para liquidar o portf√≥lio sem grandes impactos no mercado [^1].

#### O Impacto do Horizonte de Tempo no Backtesting
A escolha do horizonte de tempo tem um impacto significativo no n√∫mero de observa√ß√µes independentes dispon√≠veis para o *backtesting*. Um horizonte mais longo reduz o n√∫mero de observa√ß√µes independentes em um determinado per√≠odo. Por exemplo, se utilizarmos um horizonte de VAR de duas semanas, teremos apenas 26 observa√ß√µes independentes por ano [^1]. Por outro lado, um horizonte de um dia fornecer√° aproximadamente 252 observa√ß√µes independentes ao longo de um ano [^1].

O poder do teste, ou seja, a capacidade de detectar vieses no modelo, est√° diretamente relacionado ao n√∫mero de observa√ß√µes independentes. Com um n√∫mero maior de observa√ß√µes, o teste se torna mais sens√≠vel a desvios entre as previs√µes do VAR e as perdas efetivas [^1]. Por isso, para fins de *backtesting*, √© prefer√≠vel utilizar horizontes de tempo mais curtos, como um dia, para maximizar o poder dos testes [^1].

**Proposi√ß√£o 1**
   *A escolha de um horizonte de tempo $h$ para o c√°lculo do VAR implica que, em um per√≠odo de $T$ dias, temos aproximadamente $T/h$ observa√ß√µes independentes. Para um dado per√≠odo de tempo $T$, o n√∫mero de observa√ß√µes independentes √© inversamente proporcional ao tamanho do horizonte $h$.*
   
   *Proof:*

   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Each observation period for the VAR spans $h$ days.

   II. **Main Logical Steps**:
      - The total number of days, $T$, is divided by the length of each observation period, $h$, to determine the number of non-overlapping observation periods.
      - This gives the number of independent observations.

   III. **Key Transformations**:
      -  Number of independent observations $\approx \frac{T}{h}$

   IV. **Conclusion**:
      - As $h$ increases, $T/h$ decreases, implying an inverse relationship between $h$ and the number of independent observations for a fixed $T$.
      - This proves the statement: "the number of independent observations is inversely proportional to the size of the horizon $h$". ‚ñ†
> üí° **Exemplo Num√©rico:**
> Suponha que temos um per√≠odo de $T = 252$ dias (um ano de negocia√ß√£o). Se usarmos um horizonte de tempo $h = 1$ dia, teremos aproximadamente $252/1 = 252$ observa√ß√µes independentes. Se aumentarmos o horizonte para $h = 5$ dias (uma semana), teremos $252/5 \approx 50$ observa√ß√µes independentes. E se o horizonte for $h=21$ (aproximadamente um m√™s), teremos $252/21=12$ observa√ß√µes independentes. Este exemplo ilustra claramente a rela√ß√£o inversa entre o horizonte de tempo e o n√∫mero de observa√ß√µes independentes.

#### Rela√ß√£o com o N√≠vel de Confian√ßa
√â importante notar que o n√≠vel de confian√ßa tamb√©m influencia o n√∫mero de observa√ß√µes na cauda da distribui√ß√£o. N√≠veis de confian√ßa mais altos, como 99%, resultam em menos observa√ß√µes na cauda, dificultando a identifica√ß√£o de vieses no modelo. Em outras palavras, para confirmar a validade do modelo com um n√≠vel de confian√ßa de 99%, seria necess√°rio um longo per√≠odo de observa√ß√µes para coletar dados suficientes na cauda da distribui√ß√£o [^1]. Por isso, para o *backtesting*, n√≠veis de confian√ßa mais baixos, como 95%, podem ser prefer√≠veis, permitindo uma an√°lise mais frequente dos resultados do modelo [^1].

**Lema 1**
   *Para um n√≠vel de confian√ßa $\alpha$, o n√∫mero de observa√ß√µes esperadas na cauda da distribui√ß√£o em um per√≠odo $T$ com horizonte de tempo $h$ √© aproximadamente $(1-\alpha)T/h$.*

   *Proof:*
   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Let $\alpha$ be the confidence level.
      - The number of independent observations is approximately $T/h$.

   II. **Main Logical Steps**:
       - With a confidence level $\alpha$, the probability of an observation falling in the tail (exceeding the VAR) is $1 - \alpha$.
       - The expected number of observations in the tail is the product of the number of independent observations and the probability of falling in the tail.

   III. **Key Transformations**:
        - Expected number of observations in the tail $\approx \frac{T}{h} \times (1-\alpha) = (1-\alpha) \frac{T}{h}$

   IV. **Conclusion**:
      - This shows that the expected number of observations in the tail is approximately $(1-\alpha)T/h$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Usando o exemplo anterior com $T=252$ dias e um horizonte de $h=1$ dia, se o n√≠vel de confian√ßa for $\alpha = 0.95$ (95%), o n√∫mero esperado de observa√ß√µes na cauda √© $(1-0.95) \times 252/1 = 0.05 \times 252 = 12.6$. Isso significa que, em m√©dia, esperamos que o VAR seja violado aproximadamente 12 ou 13 vezes em um ano. Se o n√≠vel de confian√ßa for $\alpha=0.99$, o n√∫mero esperado de viola√ß√µes cai para $(1-0.99) \times 252 = 0.01 \times 252 = 2.52$, indicando que seria necess√°rio um per√≠odo muito maior de observa√ß√µes para testar o modelo de forma eficaz. Se, por outro lado, mantemos o n√≠vel de confian√ßa em 95% mas aumentamos o horizonte para $h=5$, o n√∫mero de observa√ß√µes na cauda ser√° $(1-0.95)\times 252/5 \approx 2.5$.
  
**Corol√°rio 1.1**
   *O n√∫mero de observa√ß√µes na cauda √© diretamente proporcional ao per√≠odo $T$ e inversamente proporcional ao horizonte $h$, e diminui com o aumento do n√≠vel de confian√ßa $\alpha$.*

   *Proof:*
   I. **Initial Setup**:
       - From Lema 1, the number of observations in the tail is approximately $(1-\alpha)T/h$.

   II. **Main Logical Steps**:
       - We analyze the effect of $T$, $h$, and $\alpha$ on this expression.

   III. **Key Transformations**:
        - As $T$ increases, the number of observations in the tail increases proportionally.
        - As $h$ increases, the number of observations in the tail decreases proportionally.
        - As $\alpha$ increases, $(1-\alpha)$ decreases, thus decreasing the number of observations in the tail.

   IV. **Conclusion**:
        -  This confirms the statement that the number of tail observations is directly proportional to $T$, inversely proportional to $h$, and decreases with an increase in $\alpha$. ‚ñ†

Al√©m disso, vale ressaltar que a escolha do n√≠vel de confian√ßa afeta o tipo de erros que o *backtesting* ser√° capaz de detectar. Um n√≠vel de confian√ßa mais alto prioriza a detec√ß√£o de erros na cauda da distribui√ß√£o, enquanto um n√≠vel de confian√ßa mais baixo permite uma detec√ß√£o mais frequente de erros, ainda que menos extremos.

**Proposi√ß√£o 2**
    *Um n√≠vel de confian√ßa mais baixo aumenta a frequ√™ncia com que os resultados do VAR s√£o comparados com os retornos realizados, e, consequentemente, aumenta a sensibilidade a potenciais vieses no modelo.*
  
  *Proof:*

  I. **Initial Setup**:
    - Let $\alpha$ be the confidence level.
    - A lower confidence level implies a smaller $\alpha$.
    - VAR is calculated for a given confidence level.

  II. **Main Logical Steps**:
    - A lower confidence level (smaller $\alpha$) corresponds to a lower VAR value (since the VAR is a quantile).
    - A lower VAR value means a greater chance of actual losses exceeding the VAR.
    - If the actual loss exceeds the VAR value, this is considered a violation in the backtesting process.
    - More violations mean more comparisons between VAR and actual returns.

  III. **Key Transformations**:
    - Lower $\alpha$  $\implies$ Lower VAR
    - Lower VAR $\implies$ More violations
    - More violations $\implies$ More frequent comparisons between VAR and actual returns

  IV. **Conclusion**:
    - This demonstrates that a lower confidence level results in more frequent comparisons between VAR predictions and actual returns. Therefore, the sensitivity of the backtesting to potential biases in the model increases.‚ñ†

> üí° **Exemplo Num√©rico:**
> Considere um modelo VAR com um horizonte de um dia ($h=1$). Se o n√≠vel de confian√ßa for $\alpha = 0.99$, espera-se que as viola√ß√µes sejam raras, e a cada 100 dias de negocia√ß√£o, apenas 1 dia, em m√©dia, apresentar√° uma perda que ultrapassa o VAR. Se o n√≠vel de confian√ßa for reduzido para $\alpha=0.95$, as viola√ß√µes tornam-se mais frequentes, com uma m√©dia de 5 dias a cada 100, e isso permite uma an√°lise mais detalhada e frequente do modelo.

**Teorema 1**
*Existe um trade-off entre o horizonte de tempo $h$ e o n√≠vel de confian√ßa $\alpha$ no *backtesting*. Diminuir $h$ aumenta o n√∫mero de observa√ß√µes independentes e, portanto, o poder do teste, enquanto diminuir $\alpha$ aumenta a frequ√™ncia de viola√ß√µes do VAR e, tamb√©m, aumenta o poder do teste.*
 *Proof:*
    I. **Initial Setup**:
        - The power of a backtesting test is directly related to the number of independent observations and the frequency of violations.
    
    II. **Main Logical Steps**:
         - From Proposi√ß√£o 1, reducing the time horizon $h$ increases the number of independent observations. An increase in independent observations leads to an increase in the power of the test.
         - From Proposi√ß√£o 2, reducing the confidence level $\alpha$ increases the frequency of violations. More frequent violations increase the data available to backtest, increasing the power of the test.
        
    III. **Key Transformations**:
        - $h \downarrow \implies \text{Number of Independent Observations} \uparrow \implies \text{Test Power} \uparrow$
        - $\alpha \downarrow \implies \text{Frequency of Violations} \uparrow \implies \text{Test Power} \uparrow$

    IV. **Conclusion**:
        - The theorem states that there is a trade-off. Both lowering $h$ and $\alpha$ increase the power of the backtest, supporting the claim. Therefore, this proves the existence of the trade-off.‚ñ†

**Lema 2**
*Seja $N$ o n√∫mero de observa√ß√µes independentes, e seja $X_i$ uma vari√°vel indicadora que vale 1 se a perda observada no per√≠odo $i$ excede o VAR previsto e 0 caso contr√°rio. Se o modelo VAR estiver bem calibrado, ent√£o $X_i$ s√£o vari√°veis aleat√≥rias independentes de Bernoulli com probabilidade de sucesso $1 - \alpha$.*

*Proof:*
   I. **Initial Setup**:
       - $N$ is the number of independent observations.
       - $X_i$ is an indicator variable, where $X_i = 1$ if the loss exceeds the predicted VAR at time $i$, and $X_i = 0$ otherwise.
       - $\alpha$ is the confidence level of the VAR.
       - A well-calibrated VAR model has a probability of $1-\alpha$ of the loss exceeding the VAR.
       - We assume independence between observations.

   II. **Main Logical Steps**:
       - For each observation $i$, there are only two outcomes: the loss exceeds the VAR ($X_i = 1$) or the loss does not exceed the VAR ($X_i = 0$).
       - Under a well-calibrated model, the probability of $X_i = 1$ (a loss exceeding the VAR) is $1 - \alpha$.
       - This is precisely the definition of a Bernoulli trial with a success probability of $1-\alpha$.
       - The independence of the $X_i$ variables comes from the assumption of independence of observations.

   III. **Key Transformations**:
       - $P(X_i=1) = 1-\alpha$.

   IV. **Conclusion**:
       - The variables $X_i$ are independent and follow a Bernoulli distribution with success probability $1-\alpha$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Vamos supor que estamos analisando 252 dias de negocia√ß√£o com um n√≠vel de confian√ßa de 95% ($\alpha=0.95$). Para cada dia $i$, definimos $X_i = 1$ se a perda naquele dia excedeu o VAR previsto e $X_i = 0$ caso contr√°rio. Se o modelo estiver bem calibrado, cada $X_i$ √© uma vari√°vel de Bernoulli com $p = 1 - 0.95 = 0.05$. Isso significa que a probabilidade de uma viola√ß√£o em qualquer dia √© de 5%.

**Teorema 1.1**
*Sob as condi√ß√µes do Lema 2, o n√∫mero de viola√ß√µes do VAR, $V = \sum_{i=1}^N X_i$, segue uma distribui√ß√£o binomial com par√¢metros $N$ e $1-\alpha$, ou seja, $V \sim Bin(N, 1 - \alpha)$.*

*Proof:*
   I. **Initial Setup**:
      - From Lema 2, $X_i$ are independent Bernoulli random variables with success probability $1-\alpha$.
      - $V$ is defined as the sum of these Bernoulli variables: $V = \sum_{i=1}^N X_i$.

   II. **Main Logical Steps**:
      - The sum of $N$ independent Bernoulli random variables with the same success probability follows a binomial distribution.
      - The parameters of the binomial distribution are $N$ (the number of trials) and $1-\alpha$ (the success probability).

   III. **Key Transformations**:
      - $V = \sum_{i=1}^N X_i \implies V \sim Bin(N, 1 - \alpha)$

   IV. **Conclusion**:
      - Therefore, the number of violations $V$ follows a binomial distribution with parameters $N$ and $1-\alpha$. ‚ñ†
> üí° **Exemplo Num√©rico:**
> Continuando o exemplo anterior, onde temos 252 observa√ß√µes independentes ($N=252$) e $\alpha = 0.95$, o n√∫mero total de viola√ß√µes $V$ segue uma distribui√ß√£o binomial com par√¢metros $N=252$ e $p=0.05$, ou seja, $V \sim Bin(252, 0.05)$. Isso nos permite calcular a probabilidade de observar um n√∫mero espec√≠fico de viola√ß√µes, assumindo que o modelo VAR est√° bem calibrado.

**Corol√°rio 1.2**
*A m√©dia e a vari√¢ncia do n√∫mero de viola√ß√µes $V$ s√£o dadas por $E[V] = N(1-\alpha)$ e $Var[V] = N(1-\alpha)\alpha$.*

*Proof:*
   I. **Initial Setup**:
      - From Theorem 1.1, $V \sim Bin(N, 1-\alpha)$.
      - We recall the mean and variance of a binomial distribution.
   II. **Main Logical Steps**:
        - The expected value (mean) of a binomial distribution $Bin(n,p)$ is given by $E[V]=np$.
        - The variance of a binomial distribution $Bin(n,p)$ is given by $Var[V]=np(1-p)$.
   III. **Key Transformations**:
      - Substituting $n = N$ and $p = 1 - \alpha$, we have
      -  $E[V] = N(1-\alpha)$.
      - $Var[V] = N(1-\alpha)(1-(1-\alpha)) = N(1-\alpha)\alpha$.

   IV. **Conclusion**:
     -  This shows that the mean and the variance of $V$ are given by $E[V] = N(1-\alpha)$ and $Var[V] = N(1-\alpha)\alpha$, respectively. ‚ñ†

> üí° **Exemplo Num√©rico:**
> No mesmo exemplo, com $N=252$ e $\alpha=0.95$, a m√©dia do n√∫mero de viola√ß√µes √© $E[V] = 252 \times (1 - 0.95) = 252 \times 0.05 = 12.6$, e a vari√¢ncia √© $Var[V] = 252 \times 0.05 \times 0.95 = 11.97$. Isso significa que, em m√©dia, esperamos 12.6 viola√ß√µes, com uma variabilidade em torno desse valor, quantificada pela vari√¢ncia.

Al√©m disso, √© crucial considerar a autocorrela√ß√£o das perdas. Se as perdas em per√≠odos sucessivos forem correlacionadas, a suposi√ß√£o de independ√™ncia das observa√ß√µes pode ser violada, comprometendo a validade do *backtesting*.

**Proposi√ß√£o 3**
    *A autocorrela√ß√£o positiva das perdas pode levar a um excesso de viola√ß√µes do VAR em clusters, o que pode reduzir o poder de um *backtesting* que assume independ√™ncia das observa√ß√µes.*
    *Proof:*
       I. **Initial Setup**:
        -  Assume positive autocorrelation in losses.
        -  Assume that we are using a backtesting method that assumes independence.
        
       II. **Main Logical Steps**:
           - Positive autocorrelation implies that if a loss exceeds the VAR in a given period, the probability of a loss exceeding the VAR in the next period is higher than expected under independence.
           - This causes violations to occur in clusters, i.e. if one violation occurs, the probability of seeing more violations in close succession is higher.
           - When violations cluster, the assumption of independent Bernoulli trials underlying most backtesting procedures is violated.
           - The methods assume that the number of violations is a realization of a binomial distribution, which does not hold under autocorrelation.
           - Since the number of observations is reduced, a clustered violation process has less power than an independent violation process.

       III. **Key Transformations**:
           - Autocorrelation $\implies$ violation clusters
           - Clusters $\implies$ violation of independence
           - Violation of independence $\implies$ Reduction in the power of the test

       IV. **Conclusion**:
        - Therefore, positive autocorrelation can lead to clustered violations, and reduce the effectiveness of backtesting.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
> Suponha que as perdas do dia atual sejam positivamente correlacionadas com as perdas do dia anterior. Se o VAR for violado hoje, √© mais prov√°vel que ele seja violado amanh√£ tamb√©m. Isso cria *clusters* de viola√ß√µes, onde v√°rios dias consecutivos apresentam perdas acima do VAR, em vez de viola√ß√µes aleat√≥rias e independentes. Um modelo que ignora essa autocorrela√ß√£o pode n√£o capturar a din√¢mica real do risco.
    
**Lema 3**
*Para detectar a presen√ßa de autocorrela√ß√£o nas viola√ß√µes do VAR, pode-se realizar um teste de raz√£o de verossimilhan√ßa (LR) de independ√™ncia de viola√ß√µes, ou similar, como o teste de Kupiec ou Christoffersen.*

    *Proof:*
     I. **Initial Setup**:
          - We want to detect if there is autocorrelation in the violations of the VAR model.
          - We know that violations of a well-calibrated VAR should be independent events.

     II. **Main Logical Steps**:
          - The test of the likelihood ratio (LR) is designed to test the hypothesis that the distribution of the violations is independent.
          - The Kupiec test checks if the overall violation rate is consistent with the confidence level, implicitly assuming independence over time.
          - The Christoffersen test is specifically designed to test for both correct violation rate and independence over time.

     III. **Key Transformations**:
          - These tests check the null hypothesis of independence against the alternative of an autocorrelation in the violations.

     IV. **Conclusion**:
          -  The LR test and specific tests such as Kupiec and Christoffersen can all detect the presence of autocorrelation, supporting the claim. ‚ñ†
> üí° **Exemplo Num√©rico:**
>  Se os resultados do *backtesting* mostram uma sequ√™ncia de viola√ß√µes em dias pr√≥ximos (por exemplo, viola√ß√µes nos dias 1, 2, 3, e depois nenhuma viola√ß√£o por v√°rias semanas, e em seguida viola√ß√µes nos dias 45 e 46) isso levanta suspeitas de autocorrela√ß√£o. Testes como o de Christoffersen ajudam a quantificar essa suspeita, e a verificar se os *clusters* de viola√ß√£o s√£o estatisticamente significativos ou apenas devidos ao acaso.

**Proposi√ß√£o 4**
    *A presen√ßa de *clusters* de viola√ß√µes, causada por autocorrela√ß√£o, implica que a vari√¢ncia do n√∫mero de viola√ß√µes pode ser maior do que o previsto pela distribui√ß√£o binomial sob a hip√≥tese de independ√™ncia.*
    
  *Proof:*
  
    I. **Initial Setup**:
        - Assume that the violations are positively autocorrelated, so that violations tend to cluster together.
        - Let $X_i$ be indicator variables such that $X_i = 1$ if there is a violation at time $i$ and 0 otherwise.
        - Let the number of violations be given by $V=\sum_{i=1}^N X_i$.
        
    II. **Main Logical Steps**:
        - If the violations were independent, then we could calculate the variance of the total number of violations using the fact that it follows a binomial distribution (as shown in Corol√°rio 1.2). In that case, $Var[V] = N(1-\alpha)\alpha$.
        - However, because of autocorrelation, the $X_i$ are not independent. The variance of the sum of correlated random variables is not the sum of the variances.
        - If $\text{Cov}(X_i,X_j) > 0$ for at least some $i \neq j$, then $Var[\sum X_i] > \sum Var[X_i]$.
        - The autocorrelation causes $\text{Cov}(X_i,X_j) > 0$, implying that the variance of the sum will be greater than if the $X_i$ were independent.

   III. **Key Transformations**:
       - Autocorrelation $\implies \text{Cov}(X_i,X_j) > 0$.
       -  $\text{Cov}(X_i,X_j) > 0$  $\implies$  $Var[\sum X_i] > \sum Var[X_i]$
       - $Var[\sum X_i] > \sum Var[X_i]$ $\implies$ $Var[V] > N(1-\alpha)\alpha$

   IV. **Conclusion**:
      -  The presence of autocorrelation increases the variance of the sum of violations over the case with independent variables.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
>  Usando o exemplo de 252 observa√ß√µes com $\alpha = 0.95$, sob a hip√≥tese de independ√™ncia, a vari√¢ncia do n√∫mero de viola√ß√µes √© de 11.97. No entanto, se houver autocorrela√ß√£o positiva, a vari√¢ncia real das viola√ß√µes pode ser muito maior. Por exemplo, se as viola√ß√µes ocorrem em *clusters*, a vari√¢ncia poderia ser 20 ou at√© mais. Isso significa que as viola√ß√µes ser√£o mais vari√°veis do que o esperado sob o modelo binomial, e o modelo de VAR pode estar subestimando o risco.
   
**Teorema 2**
 *O teste de Kupiec √© um teste de hip√≥tese para verificar se a frequ√™ncia de viola√ß√µes do VAR √© estatisticamente diferente do esperado dado o n√≠vel de confian√ßa $\alpha$. Ele testa a hip√≥tese nula de que a frequ√™ncia de viola√ß√µes observada √© consistente com a frequ√™ncia esperada sob um modelo bem calibrado.*

 *Proof:*
    I. **Initial Setup**:
      - The null hypothesis ($H_0$) is that the model is well-calibrated, i.e., the observed violation rate matches the expected violation rate.
      - The alternative hypothesis ($H_1$) is that the model is not well-calibrated, i.e., the observed violation rate is different from the expected rate.
      - Let $V$ be the observed number of violations, $N$ the number of independent observations, and $\alpha$ the confidence level.
      - We know that if the model is well-calibrated, the number of violations follows a binomial distribution $V \sim Bin(N, 1-\alpha)$.
      
    II. **Main Logical Steps**:
      -  The Kupiec test uses a likelihood ratio test to compare the likelihood under the null hypothesis (where $p = 1-\alpha$) with the likelihood of a model that admits a free violation probability $\hat{p}$ estimated from data (observed frequency of violations, i.e., $\hat{p} = V/N$).
      - The likelihood ratio statistic is constructed based on the binomial distribution.
      - The statistic is asymptotically chi-squared distributed, which allows for the construction of the test.
      
    III. **Key Transformations**:
      - Let $p$ be the expected probability of violation under the null hypothesis $p = 1-\alpha$.
      - The likelihood function is given by $L(p) = \binom{N}{V} p^V (1-p)^{N-V}$.
      - The test statistic is given by $-2ln\frac{L(1-\alpha)}{L(\hat{p})}$.
      - Under the null hypothesis, this statistic converges in distribution to a $\chi^2(1)$.

    IV. **Conclusion**:
      -  The Kupiec test checks if the frequency of violations is statistically different from that expected under the well-calibrated model hypothesis, using the distribution of the violations implied by a model with binomial violations. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que em 252 dias com um n√≠vel de confian√ßa de 95%, um modelo VAR tenha apresentado 20 viola√ß√µes. Sob a hip√≥tese nula de que o modelo est√° bem calibrado, o n√∫mero esperado de viola√ß√µes √© de 12.6. O teste de Kupiec calcula uma estat√≠stica de teste que compara a probabilidade de observar 20 viola√ß√µes se o modelo estiver bem calibrado com a probabilidade de observar 20 viola√ß√µes com a probabilidade de viola√ß√£o observada nos dados (20/252). Essa estat√≠stica de teste segue uma distribui√ß√£o $\chi^2$ com 1 grau de liberdade. Se o valor da estat√≠stica de teste for muito alto (e o p-valor correspondente for baixo), rejeita-se a hip√≥tese de que o modelo est√° bem calibrado e conclui-se que o modelo est√° subestimando o risco.
 
 **Lema 4**
 *O teste de Christoffersen testa se as viola√ß√µes do VAR s√£o independentes ao longo do tempo, e, portanto, se h√° *clusters* de viola√ß√µes. Ele testa a hip√≥tese nula de independ√™ncia das viola√ß√µes contra a hip√≥tese alternativa de que as viola√ß√µes seguem um processo de Markov de primeira ordem.*

    *Proof:*
    I. **Initial Setup**:
         - Null Hypothesis $H_0$: The violations are independent over time.
         - Alternative Hypothesis $H_1$: The violations follow a first-order Markov process (i.e., the probability of a violation depends on whether the previous observation was a violation or not).
         - $X_t$ is an indicator variable that is 1 if a violation occurs at time t, and 0 otherwise.

    II. **Main Logical Steps**:
         -  The Christoffersen test examines the transitions between violation and no-violation states using a likelihood ratio test.
         - Under $H_0$, the probability of a violation at time $t$ is independent of the occurrence of a violation at time $t-1$.
         - Under $H_1$, the probability of a violation depends on whether there was a violation in the previous period.
         - This dependence is expressed using a transition matrix:
        $$
        \begin{bmatrix}
          \pi_{00} & \pi_{01} \\
          \pi_{10} & \pi_{11}
        \end{bmatrix}
        $$
         where $\pi_{ij}$ is the probability of observing $X_t=j$ given $X_{t-1} = i$.
        
    III. **Key Transformations**:
         - The likelihood function under the null hypothesis (independence) is compared to the likelihood under the alternative hypothesis (Markov model).
         - The likelihood ratio is used to evaluate if the alternative hypothesis fits the data significantly better than the null hypothesis.
         - The test statistic is asymptotically chi-squared distributed.
        
    IV. **Conclusion**:
         -  The Christoffersen test determines if the observed transitions between violations and no-violations are consistent with the assumption of independence (i.e., if violations are clustered). ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que temos 252 dias de dados, e as viola√ß√µes do VAR ocorrem em sequ√™ncia. Por exemplo, se tivermos uma viola√ß√£o no dia $t-1$, a probabilidade de ter uma viola√ß√£o no dia $t$ √© muito maior do que se n√£o tivermos uma viola√ß√£o no dia $t-1$. O teste de Christoffersen verifica se essas transi√ß√µes entre estados (viola√ß√£o/n√£o-viola√ß√£o) s√£o estatisticamente significativas e inconsistentes com a hip√≥tese de independ√™ncia. Ele estima a matriz de transi√ß√£o e compara a probabilidade de os dados terem sido gerados por uma cadeia de Markov ou por um processo independente, calculando uma estat√≠stica de teste, que segue uma distribui√ß√£o $\chi^2$.

    
**Teorema 2.1**
    *O teste de Christoffersen tamb√©m avalia se a frequ√™ncia de viola√ß√µes √© consistente com o n√≠vel de confian√ßa $\alpha$, simultaneamente com a avalia√ß√£o da independ√™ncia das viola√ß√µes.*

    *Proof:*
        I. **Initial Setup**:
            - The null hypothesis for the Christoffersen test is that the model is well-calibrated and that the violations are independent of each other.
            - The alternative hypothesis is that either the violation frequency is not correct or the violations are not independent.
            -  The null hypothesis is given by $H_0: \pi_{01}=\pi_{11} = 1-\alpha$.

        II. **Main Logical Steps**:
            - The Christoffersen test is actually a joint test. It is composed of two likelihood ratio (LR) tests.
            -  The first LR test looks at whether the frequency of violations is compatible with the confidence level $\alpha$. This part of the test does not test independence.
            - The second LR test checks if there is statistical evidence of dependence on the previous state. This second test checks independence.
            - If we reject the null hypothesis in the Christoffersen test, it means that the data is incompatible with the assumption that the violations are both independent and have the correct frequency.
            
        III. **Key Transformations**:
            - The first test checks if $\pi_{01}=\pi_{11}=1-\alpha$ jointly. If not, then either the frequency or the independence is rejected.
            - The second test checks the independence of the violations, by testing if $\pi_{01}=\pi_{11}$.
            - The combination of both tests gives the Christoffersen test statistic.
            
        IV. **Conclusion**:
            -  Because of the structure of the test, the Christoffersen test assesses both the frequency of violations and the independence of the violations simultaneously. Therefore, it assesses if both the frequency of violations is consistent with $\alpha$ and if the violations are independent of each other, simultaneously.  ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Continuando o exemplo anterior, o teste de Christoffersen n√£o apenas verifica se a frequ√™ncia de viola√ß√µes √© aproximadamente 5% (se $\alpha=0.95$), mas tamb√©m se a ocorr√™ncia de uma viola√ß√£o em um dia aumenta a probabilidade de uma viola√ß√£o no dia seguinte. Ele faz isso de forma simult√¢nea. Isso √© especialmente importante porque um modelo pode ter a frequ√™ncia de viola√ß√µes correta, mas as viola√ß√µes ocorrem em *clusters*, o que o teste de Christoffersen √© capaz de detectar.
    
**Proposi√ß√£o 5**
   *Al√©m do teste de Kupiec e do teste de Christoffersen, existem outros testes de *backtesting* como o teste de Lopez, o teste de correla√ß√£o serial, e testes baseados em fun√ß√µes de perda, que podem complementar a an√°lise do desempenho do modelo VAR.*
   *Proof:*
        I. **Initial Setup**:
            - The Kupiec e Christoffersen tests are not exhaustive.
            - There are other ways to evaluate a VAR model through backtesting.
        II. **Main Logical Steps**:
            - The Lopez test assesses the magnitude of losses that violate the VAR, not just the frequency. It uses a loss function that considers both the number and the size of the violations.
            - Tests of serial correlation can detect if violations cluster or are predictable, which is undesirable. For example, the Ljung-Box test.
            - Test based on loss functions (such as the tick loss) can be tailored to capture specific properties that are relevant for the user.
        III. **Key Transformations**:
             - The Lopez test, tests of serial correlation, and loss function-based tests provide additional tests that measure aspects of the VAR model not assessed by the Kupiec and Christoffersen test.
       IV. **Conclusion**:
            -  These other tests are useful to evaluate if the VAR model is adequate to a certain situation, and offer a more complete picture of the VAR model‚Äôs quality. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que o teste de Kupiec tenha aprovado um modelo VAR com um n√≠vel de confian√ßa de 95% mas o teste de Christoffersen tenha rejeitado o modelo por apresentar autocorrela√ß√£o. Nesse caso, podemos aplicar outros testes de *backtesting*. Por exemplo, o teste de Lopez poder√° apontar
que as viola√ß√µes do VAR s√£o muito maiores do que o esperado. Um teste de correla√ß√£o serial poder√° confirmar que as viola√ß√µes est√£o clusterizadas. Um teste baseado em fun√ß√µes de perda poder√° indicar que as perdas acima do### Model Backtesting and Horizon Selection in VAR

### Introdu√ß√£o
Em continuidade ao estudo do Value at Risk (VAR) e suas aplica√ß√µes, este cap√≠tulo aborda um aspecto crucial para a valida√ß√£o e confiabilidade dos modelos: o *backtesting*. Como vimos anteriormente, o VAR √© uma medida de risco que resume a potencial perda em um determinado horizonte de tempo e n√≠vel de confian√ßa [^1]. No entanto, a precis√£o do VAR depende da qualidade dos dados e da adequa√ß√£o do modelo utilizado. O *backtesting* √© uma ferramenta essencial para avaliar a performance de um modelo VAR e identificar poss√≠veis vieses nas previs√µes [^1]. Esta se√ß√£o se aprofundar√° nos crit√©rios para realizar o *backtesting*, com foco especial na import√¢ncia do horizonte de tempo na efic√°cia dos testes.

### Conceitos Fundamentais
O *backtesting* consiste em comparar sistematicamente as previs√µes de perdas obtidas por meio do VAR com as perdas e lucros (P&L) efetivamente realizados posteriormente [^1]. O objetivo principal do *backtesting* √© detectar vieses ou inconsist√™ncias nos resultados do VAR, garantindo que o modelo esteja gerando previs√µes confi√°veis. A ideia central √© que um modelo VAR bem calibrado deve ser capaz de prever a frequ√™ncia com que as perdas efetivas excedem o VAR previsto, alinhando-se com o n√≠vel de confian√ßa estabelecido [^2].

Para realizar um *backtesting* eficaz, √© fundamental levar em considera√ß√£o o horizonte de tempo utilizado no c√°lculo do VAR. A escolha do horizonte de tempo influencia diretamente o n√∫mero de observa√ß√µes independentes dispon√≠veis para o teste, afetando o poder estat√≠stico do mesmo [^1]. O poder de um teste refere-se √† sua capacidade de detectar desvios significativos entre as previs√µes do VAR e os resultados reais.

Como mencionado anteriormente, o horizonte de tempo √© um dos fatores quantitativos que influenciam o c√°lculo do VAR. Em geral, um horizonte mais longo leva a um VAR maior. Ao usar o VAR como uma medida de risco potencial, o horizonte de tempo deve ser definido pela liquidez dos ativos, ou seja, o tempo necess√°rio para liquidar o portf√≥lio sem grandes impactos no mercado [^1].

#### O Impacto do Horizonte de Tempo no Backtesting
A escolha do horizonte de tempo tem um impacto significativo no n√∫mero de observa√ß√µes independentes dispon√≠veis para o *backtesting*. Um horizonte mais longo reduz o n√∫mero de observa√ß√µes independentes em um determinado per√≠odo. Por exemplo, se utilizarmos um horizonte de VAR de duas semanas, teremos apenas 26 observa√ß√µes independentes por ano [^1]. Por outro lado, um horizonte de um dia fornecer√° aproximadamente 252 observa√ß√µes independentes ao longo de um ano [^1].

O poder do teste, ou seja, a capacidade de detectar vieses no modelo, est√° diretamente relacionado ao n√∫mero de observa√ß√µes independentes. Com um n√∫mero maior de observa√ß√µes, o teste se torna mais sens√≠vel a desvios entre as previs√µes do VAR e as perdas efetivas [^1]. Por isso, para fins de *backtesting*, √© prefer√≠vel utilizar horizontes de tempo mais curtos, como um dia, para maximizar o poder dos testes [^1].

**Proposi√ß√£o 1**
   *A escolha de um horizonte de tempo $h$ para o c√°lculo do VAR implica que, em um per√≠odo de $T$ dias, temos aproximadamente $T/h$ observa√ß√µes independentes. Para um dado per√≠odo de tempo $T$, o n√∫mero de observa√ß√µes independentes √© inversamente proporcional ao tamanho do horizonte $h$.*
   
   *Proof:*

   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Each observation period for the VAR spans $h$ days.

   II. **Main Logical Steps**:
      - The total number of days, $T$, is divided by the length of each observation period, $h$, to determine the number of non-overlapping observation periods.
      - This gives the number of independent observations.

   III. **Key Transformations**:
      -  Number of independent observations $\approx \frac{T}{h}$

   IV. **Conclusion**:
      - As $h$ increases, $T/h$ decreases, implying an inverse relationship between $h$ and the number of independent observations for a fixed $T$.
      - This proves the statement: "the number of independent observations is inversely proportional to the size of the horizon $h$". ‚ñ†
> üí° **Exemplo Num√©rico:**
> Suponha que temos um per√≠odo de $T = 252$ dias (um ano de negocia√ß√£o). Se usarmos um horizonte de tempo $h = 1$ dia, teremos aproximadamente $252/1 = 252$ observa√ß√µes independentes. Se aumentarmos o horizonte para $h = 5$ dias (uma semana), teremos $252/5 \approx 50$ observa√ß√µes independentes. E se o horizonte for $h=21$ (aproximadamente um m√™s), teremos $252/21=12$ observa√ß√µes independentes. Este exemplo ilustra claramente a rela√ß√£o inversa entre o horizonte de tempo e o n√∫mero de observa√ß√µes independentes.

#### Rela√ß√£o com o N√≠vel de Confian√ßa
√â importante notar que o n√≠vel de confian√ßa tamb√©m influencia o n√∫mero de observa√ß√µes na cauda da distribui√ß√£o. N√≠veis de confian√ßa mais altos, como 99%, resultam em menos observa√ß√µes na cauda, dificultando a identifica√ß√£o de vieses no modelo. Em outras palavras, para confirmar a validade do modelo com um n√≠vel de confian√ßa de 99%, seria necess√°rio um longo per√≠odo de observa√ß√µes para coletar dados suficientes na cauda da distribui√ß√£o [^1]. Por isso, para o *backtesting*, n√≠veis de confian√ßa mais baixos, como 95%, podem ser prefer√≠veis, permitindo uma an√°lise mais frequente dos resultados do modelo [^1].

**Lema 1**
   *Para um n√≠vel de confian√ßa $\alpha$, o n√∫mero de observa√ß√µes esperadas na cauda da distribui√ß√£o em um per√≠odo $T$ com horizonte de tempo $h$ √© aproximadamente $(1-\alpha)T/h$.*

   *Proof:*
   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Let $\alpha$ be the confidence level.
      - The number of independent observations is approximately $T/h$.

   II. **Main Logical Steps**:
       - With a confidence level $\alpha$, the probability of an observation falling in the tail (exceeding the VAR) is $1 - \alpha$.
       - The expected number of observations in the tail is the product of the number of independent observations and the probability of falling in the tail.

   III. **Key Transformations**:
        - Expected number of observations in the tail $\approx \frac{T}{h} \times (1-\alpha) = (1-\alpha) \frac{T}{h}$

   IV. **Conclusion**:
      - This shows that the expected number of observations in the tail is approximately $(1-\alpha)T/h$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Usando o exemplo anterior com $T=252$ dias e um horizonte de $h=1$ dia, se o n√≠vel de confian√ßa for $\alpha = 0.95$ (95%), o n√∫mero esperado de observa√ß√µes na cauda √© $(1-0.95) \times 252/1 = 0.05 \times 252 = 12.6$. Isso significa que, em m√©dia, esperamos que o VAR seja violado aproximadamente 12 ou 13 vezes em um ano. Se o n√≠vel de confian√ßa for $\alpha=0.99$, o n√∫mero esperado de viola√ß√µes cai para $(1-0.99) \times 252 = 0.01 \times 252 = 2.52$, indicando que seria necess√°rio um per√≠odo muito maior de observa√ß√µes para testar o modelo de forma eficaz. Se, por outro lado, mantemos o n√≠vel de confian√ßa em 95% mas aumentamos o horizonte para $h=5$, o n√∫mero de observa√ß√µes na cauda ser√° $(1-0.95)\times 252/5 \approx 2.5$.
  
**Corol√°rio 1.1**
   *O n√∫mero de observa√ß√µes na cauda √© diretamente proporcional ao per√≠odo $T$ e inversamente proporcional ao horizonte $h$, e diminui com o aumento do n√≠vel de confian√ßa $\alpha$.*

   *Proof:*
   I. **Initial Setup**:
       - From Lema 1, the number of observations in the tail is approximately $(1-\alpha)T/h$.

   II. **Main Logical Steps**:
       - We analyze the effect of $T$, $h$, and $\alpha$ on this expression.

   III. **Key Transformations**:
        - As $T$ increases, the number of observations in the tail increases proportionally.
        - As $h$ increases, the number of observations in the tail decreases proportionally.
        - As $\alpha$ increases, $(1-\alpha)$ decreases, thus decreasing the number of observations in the tail.

   IV. **Conclusion**:
        -  This confirms the statement that the number of tail observations is directly proportional to $T$, inversely proportional to $h$, and decreases with an increase in $\alpha$. ‚ñ†

Al√©m disso, vale ressaltar que a escolha do n√≠vel de confian√ßa afeta o tipo de erros que o *backtesting* ser√° capaz de detectar. Um n√≠vel de confian√ßa mais alto prioriza a detec√ß√£o de erros na cauda da distribui√ß√£o, enquanto um n√≠vel de confian√ßa mais baixo permite uma detec√ß√£o mais frequente de erros, ainda que menos extremos.

**Proposi√ß√£o 2**
    *Um n√≠vel de confian√ßa mais baixo aumenta a frequ√™ncia com que os resultados do VAR s√£o comparados com os retornos realizados, e, consequentemente, aumenta a sensibilidade a potenciais vieses no modelo.*
  
  *Proof:*

  I. **Initial Setup**:
    - Let $\alpha$ be the confidence level.
    - A lower confidence level implies a smaller $\alpha$.
    - VAR is calculated for a given confidence level.

  II. **Main Logical Steps**:
    - A lower confidence level (smaller $\alpha$) corresponds to a lower VAR value (since the VAR is a quantile).
    - A lower VAR value means a greater chance of actual losses exceeding the VAR.
    - If the actual loss exceeds the VAR value, this is considered a violation in the backtesting process.
    - More violations mean more comparisons between VAR and actual returns.

  III. **Key Transformations**:
    - Lower $\alpha$  $\implies$ Lower VAR
    - Lower VAR $\implies$ More violations
    - More violations $\implies$ More frequent comparisons between VAR and actual returns

  IV. **Conclusion**:
    - This demonstrates that a lower confidence level results in more frequent comparisons between VAR predictions and actual returns. Therefore, the sensitivity of the backtesting to potential biases in the model increases.‚ñ†

> üí° **Exemplo Num√©rico:**
> Considere um modelo VAR com um horizonte de um dia ($h=1$). Se o n√≠vel de confian√ßa for $\alpha = 0.99$, espera-se que as viola√ß√µes sejam raras, e a cada 100 dias de negocia√ß√£o, apenas 1 dia, em m√©dia, apresentar√° uma perda que ultrapassa o VAR. Se o n√≠vel de confian√ßa for reduzido para $\alpha=0.95$, as viola√ß√µes tornam-se mais frequentes, com uma m√©dia de 5 dias a cada 100, e isso permite uma an√°lise mais detalhada e frequente do modelo.

**Teorema 1**
*Existe um trade-off entre o horizonte de tempo $h$ e o n√≠vel de confian√ßa $\alpha$ no *backtesting*. Diminuir $h$ aumenta o n√∫mero de observa√ß√µes independentes e, portanto, o poder do teste, enquanto diminuir $\alpha$ aumenta a frequ√™ncia de viola√ß√µes do VAR e, tamb√©m, aumenta o poder do teste.*
 *Proof:*
    I. **Initial Setup**:
        - The power of a backtesting test is directly related to the number of independent observations and the frequency of violations.
    
    II. **Main Logical Steps**:
         - From Proposi√ß√£o 1, reducing the time horizon $h$ increases the number of independent observations. An increase in independent observations leads to an increase in the power of the test.
         - From Proposi√ß√£o 2, reducing the confidence level $\alpha$ increases the frequency of violations. More frequent violations increase the data available to backtest, increasing the power of the test.
        
    III. **Key Transformations**:
        - $h \downarrow \implies \text{Number of Independent Observations} \uparrow \implies \text{Test Power} \uparrow$
        - $\alpha \downarrow \implies \text{Frequency of Violations} \uparrow \implies \text{Test Power} \uparrow$

    IV. **Conclusion**:
        - The theorem states that there is a trade-off. Both lowering $h$ and $\alpha$ increase the power of the backtest, supporting the claim. Therefore, this proves the existence of the trade-off.‚ñ†

**Lema 2**
*Seja $N$ o n√∫mero de observa√ß√µes independentes, e seja $X_i$ uma vari√°vel indicadora que vale 1 se a perda observada no per√≠odo $i$ excede o VAR previsto e 0 caso contr√°rio. Se o modelo VAR estiver bem calibrado, ent√£o $X_i$ s√£o vari√°veis aleat√≥rias independentes de Bernoulli com probabilidade de sucesso $1 - \alpha$.*

*Proof:*
   I. **Initial Setup**:
       - $N$ is the number of independent observations.
       - $X_i$ is an indicator variable, where $X_i = 1$ if the loss exceeds the predicted VAR at time $i$, and $X_i = 0$ otherwise.
       - $\alpha$ is the confidence level of the VAR.
       - A well-calibrated VAR model has a probability of $1-\alpha$ of the loss exceeding the VAR.
       - We assume independence between observations.

   II. **Main Logical Steps**:
       - For each observation $i$, there are only two outcomes: the loss exceeds the VAR ($X_i = 1$) or the loss does not exceed the VAR ($X_i = 0$).
       - Under a well-calibrated model, the probability of $X_i = 1$ (a loss exceeding the VAR) is $1 - \alpha$.
       - This is precisely the definition of a Bernoulli trial with a success probability of $1-\alpha$.
       - The independence of the $X_i$ variables comes from the assumption of independence of observations.

   III. **Key Transformations**:
       - $P(X_i=1) = 1-\alpha$.

   IV. **Conclusion**:
       - The variables $X_i$ are independent and follow a Bernoulli distribution with success probability $1-\alpha$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Vamos supor que estamos analisando 252 dias de negocia√ß√£o com um n√≠vel de confian√ßa de 95% ($\alpha=0.95$). Para cada dia $i$, definimos $X_i = 1$ se a perda naquele dia excedeu o VAR previsto e $X_i = 0$ caso contr√°rio. Se o modelo estiver bem calibrado, cada $X_i$ √© uma vari√°vel de Bernoulli com $p = 1 - 0.95 = 0.05$. Isso significa que a probabilidade de uma viola√ß√£o em qualquer dia √© de 5%.

**Teorema 1.1**
*Sob as condi√ß√µes do Lema 2, o n√∫mero de viola√ß√µes do VAR, $V = \sum_{i=1}^N X_i$, segue uma distribui√ß√£o binomial com par√¢metros $N$ e $1-\alpha$, ou seja, $V \sim Bin(N, 1 - \alpha)$.*

*Proof:*
   I. **Initial Setup**:
      - From Lema 2, $X_i$ are independent Bernoulli random variables with success probability $1-\alpha$.
      - $V$ is defined as the sum of these Bernoulli variables: $V = \sum_{i=1}^N X_i$.

   II. **Main Logical Steps**:
      - The sum of $N$ independent Bernoulli random variables with the same success probability follows a binomial distribution.
      - The parameters of the binomial distribution are $N$ (the number of trials) and $1-\alpha$ (the success probability).

   III. **Key Transformations**:
      - $V = \sum_{i=1}^N X_i \implies V \sim Bin(N, 1 - \alpha)$

   IV. **Conclusion**:
      - Therefore, the number of violations $V$ follows a binomial distribution with parameters $N$ and $1-\alpha$. ‚ñ†
> üí° **Exemplo Num√©rico:**
> Continuando o exemplo anterior, onde temos 252 observa√ß√µes independentes ($N=252$) e $\alpha = 0.95$, o n√∫mero total de viola√ß√µes $V$ segue uma distribui√ß√£o binomial com par√¢metros $N=252$ e $p=0.05$, ou seja, $V \sim Bin(252, 0.05)$. Isso nos permite calcular a probabilidade de observar um n√∫mero espec√≠fico de viola√ß√µes, assumindo que o modelo VAR est√° bem calibrado.

**Corol√°rio 1.2**
*A m√©dia e a vari√¢ncia do n√∫mero de viola√ß√µes $V$ s√£o dadas por $E[V] = N(1-\alpha)$ e $Var[V] = N(1-\alpha)\alpha$.*

*Proof:*
   I. **Initial Setup**:
      - From Theorem 1.1, $V \sim Bin(N, 1-\alpha)$.
      - We recall the mean and variance of a binomial distribution.
   II. **Main Logical Steps**:
        - The expected value (mean) of a binomial distribution $Bin(n,p)$ is given by $E[V]=np$.
        - The variance of a binomial distribution $Bin(n,p)$ is given by $Var[V]=np(1-p)$.
   III. **Key Transformations**:
      - Substituting $n = N$ and $p = 1 - \alpha$, we have
      -  $E[V] = N(1-\alpha)$.
      - $Var[V] = N(1-\alpha)(1-(1-\alpha)) = N(1-\alpha)\alpha$.

   IV. **Conclusion**:
     -  This shows that the mean and the variance of $V$ are given by $E[V] = N(1-\alpha)$ and $Var[V] = N(1-\alpha)\alpha$, respectively. ‚ñ†

> üí° **Exemplo Num√©rico:**
> No mesmo exemplo, com $N=252$ e $\alpha=0.95$, a m√©dia do n√∫mero de viola√ß√µes √© $E[V] = 252 \times (1 - 0.95) = 252 \times 0.05 = 12.6$, e a vari√¢ncia √© $Var[V] = 252 \times 0.05 \times 0.95 = 11.97$. Isso significa que, em m√©dia, esperamos 12.6 viola√ß√µes, com uma variabilidade em torno desse valor, quantificada pela vari√¢ncia.

Al√©m disso, √© crucial considerar a autocorrela√ß√£o das perdas. Se as perdas em per√≠odos sucessivos forem correlacionadas, a suposi√ß√£o de independ√™ncia das observa√ß√µes pode ser violada, comprometendo a validade do *backtesting*.

**Proposi√ß√£o 3**
    *A autocorrela√ß√£o positiva das perdas pode levar a um excesso de viola√ß√µes do VAR em clusters, o que pode reduzir o poder de um *backtesting* que assume independ√™ncia das observa√ß√µes.*
    *Proof:*
       I. **Initial Setup**:
        -  Assume positive autocorrelation in losses.
        -  Assume that we are using a backtesting method that assumes independence.
        
       II. **Main Logical Steps**:
           - Positive autocorrelation implies that if a loss exceeds the VAR in a given period, the probability of a loss exceeding the VAR in the next period is higher than expected under independence.
           - This causes violations to occur in clusters, i.e. if one violation occurs, the probability of seeing more violations in close succession is higher.
           - When violations cluster, the assumption of independent Bernoulli trials underlying most backtesting procedures is violated.
           - The methods assume that the number of violations is a realization of a binomial distribution, which does not hold under autocorrelation.
           - Since the number of observations is reduced, a clustered violation process has less power than an independent violation process.

       III. **Key Transformations**:
           - Autocorrelation $\implies$ violation clusters
           - Clusters $\implies$ violation of independence
           - Violation of independence $\implies$ Reduction in the power of the test

       IV. **Conclusion**:
        - Therefore, positive autocorrelation can lead to clustered violations, and reduce the effectiveness of backtesting.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
> Suponha que as perdas do dia atual sejam positivamente correlacionadas com as perdas do dia anterior. Se o VAR for violado hoje, √© mais prov√°vel que ele seja violado amanh√£ tamb√©m. Isso cria *clusters* de viola√ß√µes, onde v√°rios dias consecutivos apresentam perdas acima do VAR, em vez de viola√ß√µes aleat√≥rias e independentes. Um modelo que ignora essa autocorrela√ß√£o pode n√£o capturar a din√¢mica real do risco.
    
**Lema 3**
*Para detectar a presen√ßa de autocorrela√ß√£o nas viola√ß√µes do VAR, pode-se realizar um teste de raz√£o de verossimilhan√ßa (LR) de independ√™ncia de viola√ß√µes, ou similar, como o teste de Kupiec ou Christoffersen.*

    *Proof:*
     I. **Initial Setup**:
          - We want to detect if there is autocorrelation in the violations of the VAR model.
          - We know that violations of a well-calibrated VAR should be independent events.

     II. **Main Logical Steps**:
          - The test of the likelihood ratio (LR) is designed to test the hypothesis that the distribution of the violations is independent.
          - The Kupiec test checks if the overall violation rate is consistent with the confidence level, implicitly assuming independence over time.
          - The Christoffersen test is specifically designed to test for both correct violation rate and independence over time.

     III. **Key Transformations**:
          - These tests check the null hypothesis of independence against the alternative of an autocorrelation in the violations.

     IV. **Conclusion**:
          -  The LR test and specific tests such as Kupiec and Christoffersen can all detect the presence of autocorrelation, supporting the claim. ‚ñ†
> üí° **Exemplo Num√©rico:**
>  Se os resultados do *backtesting* mostram uma sequ√™ncia de viola√ß√µes em dias pr√≥ximos (por exemplo, viola√ß√µes nos dias 1, 2, 3, e depois nenhuma viola√ß√£o por v√°rias semanas, e em seguida viola√ß√µes nos dias 45 e 46) isso levanta suspeitas de autocorrela√ß√£o. Testes como o de Christoffersen ajudam a quantificar essa suspeita, e a verificar se os *clusters* de viola√ß√£o s√£o estatisticamente significativos ou apenas devidos ao acaso.

**Proposi√ß√£o 4**
    *A presen√ßa de *clusters* de viola√ß√µes, causada por autocorrela√ß√£o, implica que a vari√¢ncia do n√∫mero de viola√ß√µes pode ser maior do que o previsto pela distribui√ß√£o binomial sob a hip√≥tese de independ√™ncia.*
    
  *Proof:*
  
    I. **Initial Setup**:
        - Assume that the violations are positively autocorrelated, so that violations tend to cluster together.
        - Let $X_i$ be indicator variables such that $X_i = 1$ if there is a violation at time $i$ and 0 otherwise.
        - Let the number of violations be given by $V=\sum_{i=1}^N X_i$.
        
    II. **Main Logical Steps**:
        - If the violations were independent, then we could calculate the variance of the total number of violations using the fact that it follows a binomial distribution (as shown in Corol√°rio 1.2). In that case, $Var[V] = N(1-\alpha)\alpha$.
        - However, because of autocorrelation, the $X_i$ are not independent. The variance of the sum of correlated random variables is not the sum of the variances.
        - If $\text{Cov}(X_i,X_j) > 0$ for at least some $i \neq j$, then $Var[\sum X_i] > \sum Var[X_i]$.
        - The autocorrelation causes $\text{Cov}(X_i,X_j) > 0$, implying that the variance of the sum will be greater than if the $X_i$ were independent.

   III. **Key Transformations**:
       - Autocorrelation $\implies \text{Cov}(X_i,X_j) > 0$.
       -  $\text{Cov}(X_i,X_j) > 0$  $\implies$  $Var[\sum X_i] > \sum Var[X_i]$
       - $Var[\sum X_i] > \sum Var[X_i]$ $\implies$ $Var[V] > N(1-\alpha)\alpha$

   IV. **Conclusion**:
      -  The presence of autocorrelation increases the variance of the sum of violations over the case with independent variables.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
>  Usando o exemplo de 252 observa√ß√µes com $\alpha = 0.95$, sob a hip√≥tese de independ√™ncia, a vari√¢ncia do n√∫mero de viola√ß√µes √© de 11.97. No entanto, se houver autocorrela√ß√£o positiva, a vari√¢ncia real das viola√ß√µes pode ser muito maior. Por exemplo, se as viola√ß√µes ocorrem em *clusters*, a vari√¢ncia poderia ser 20 ou at√© mais. Isso significa que as viola√ß√µes ser√£o mais vari√°veis do que o esperado sob o modelo binomial, e o modelo de VAR pode estar subestimando o risco.
   
**Teorema 2**
 *O teste de Kupiec √© um teste de hip√≥tese para verificar se a frequ√™ncia de viola√ß√µes do VAR √© estatisticamente diferente do esperado dado o n√≠vel de confian√ßa $\alpha$. Ele testa a hip√≥tese nula de que a frequ√™ncia de viola√ß√µes observada √© consistente com a frequ√™ncia esperada sob um modelo bem calibrado.*

 *Proof:*
    I. **Initial Setup**:
      - The null hypothesis ($H_0$) is that the model is well-calibrated, i.e., the observed violation rate matches the expected violation rate.
      - The alternative hypothesis ($H_1$) is that the model is not well-calibrated, i.e., the observed violation rate is different from the expected rate.
      - Let $V$ be the observed number of violations, $N$ the number of independent observations, and $\alpha$ the confidence level.
      - We know that if the model is well-calibrated, the number of violations follows a binomial distribution $V \sim Bin(N, 1-\alpha)$.
      
    II. **Main Logical Steps**:
      -  The Kupiec test uses a likelihood ratio test to compare the likelihood under the null hypothesis (where $p = 1-\alpha$) with the likelihood of a model that admits a free violation probability $\hat{p}$ estimated from data (observed frequency of violations, i.e., $\hat{p} = V/N$).
      - The likelihood ratio statistic is constructed based on the binomial distribution.
      - The statistic is asymptotically chi-squared distributed, which allows for the construction of the test.
      
    III. **Key Transformations**:
      - Let $p$ be the expected probability of violation under the null hypothesis $p = 1-\alpha$.
      - The likelihood function is given by $L(p) = \binom{N}{V} p^V (1-p)^{N-V}$.
      - The test statistic is given by $-2ln\frac{L(1-\alpha)}{L(\hat{p})}$.
      - Under the null hypothesis, this statistic converges in distribution to a $\chi^2(1)$.

    IV. **Conclusion**:
      -  The Kupiec test checks if the frequency of violations is statistically different from that expected under the well-calibrated model hypothesis, using the distribution of the violations implied by a model with binomial violations. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que em 252 dias com um n√≠vel de confian√ßa de 95%, um modelo VAR tenha apresentado 20 viola√ß√µes. Sob a hip√≥tese nula de que o modelo est√° bem calibrado, o n√∫mero esperado de viola√ß√µes √© de 12.6. O teste de Kupiec calcula uma estat√≠stica de teste que compara a probabilidade de observar 20 viola√ß√µes se o modelo estiver bem calibrado com a probabilidade de observar 20 viola√ß√µes com a probabilidade de viola√ß√£o observada nos dados (20/252). Essa estat√≠stica de teste segue uma distribui√ß√£o $\chi^2$ com 1 grau de liberdade. Se o valor da estat√≠stica de teste for muito alto (e o p-valor correspondente for baixo), rejeita-se a hip√≥tese de que o modelo est√° bem calibrado e conclui-se que o modelo est√° subestimando o risco.
 
 **Lema 4**
 *O teste de Christoffersen testa se as viola√ß√µes do VAR s√£o independentes ao longo do tempo, e, portanto, se h√° *clusters* de viola√ß√µes. Ele testa a hip√≥tese nula de independ√™ncia das viola√ß√µes contra a hip√≥tese alternativa de que as viola√ß√µes seguem um processo de Markov de primeira ordem.*

    *Proof:*
    I. **Initial Setup**:
         - Null Hypothesis $H_0$: The violations are independent over time.
         - Alternative Hypothesis $H_1$: The violations follow a first-order Markov process (i.e., the probability of a violation depends on whether the previous observation was a violation or not).
         - $X_t$ is an indicator variable that is 1 if a violation occurs at time t, and 0 otherwise.

    II. **Main Logical Steps**:
         -  The Christoffersen test examines the transitions between violation and no-violation states using a likelihood ratio test.
         - Under $H_0$, the probability of a violation at time $t$ is independent of the occurrence of a violation at time $t-1$.
         - Under $H_1$, the probability of a violation depends on whether there was a violation in the previous period.
         - This dependence is expressed using a transition matrix:
        $$
        \begin{bmatrix}
          \pi_{00} & \pi_{01} \\
          \pi_{10} & \pi_{11}
        \end{bmatrix}
        $$
         where $\pi_{ij}$ is the probability of observing $X_t=j$ given $X_{t-1} = i$.
        
    III. **Key Transformations**:
         - The likelihood function under the null hypothesis (independence) is compared to the likelihood under the alternative hypothesis (Markov model).
         - The likelihood ratio is used to evaluate if the alternative hypothesis fits the data significantly better than the null hypothesis.
         - The test statistic is asymptotically chi-squared distributed.
        
    IV. **Conclusion**:
         -  The Christoffersen test determines if the observed transitions between violations and no-violations are consistent with the assumption of independence (i.e., if violations are clustered). ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que temos 252 dias de dados, e as viola√ß√µes do VAR ocorrem em sequ√™ncia. Por exemplo, se tivermos uma viola√ß√£o no dia $t-1$, a probabilidade de ter uma viola√ß√£o no dia $t$ √© muito maior do que se n√£o tivermos uma viola√ß√£o no dia $t-1$. O teste de Christoffersen verifica se essas transi√ß√µes entre estados (viola√ß√£o/n√£o-viola√ß√£o) s√£o estatisticamente significativas e inconsistentes com a hip√≥tese de independ√™ncia. Ele estima a matriz de transi√ß√£o e compara a probabilidade de os dados terem sido gerados por uma cadeia de Markov ou por um processo independente, calculando uma estat√≠stica de teste, que segue uma distribui√ß√£o $\chi^2$.

    
**Teorema 2.1**
    *O teste de Christoffersen tamb√©m avalia se a frequ√™ncia de viola√ß√µes √© consistente com o n√≠vel de confian√ßa $\alpha$, simultaneamente com a avalia√ß√£o da independ√™ncia das viola√ß√µes.*

    *Proof:*
        I. **Initial Setup**:
            - The null hypothesis for the Christoffersen test is that the model is well-calibrated and that the violations are independent of each other.
            - The alternative hypothesis is that either the violation frequency is not correct or the violations are not independent.
            -  The null hypothesis is given by $H_0: \pi_{01}=\pi_{11} = 1-\alpha$.

        II. **Main Logical Steps**:
            - The Christoffersen test is actually a joint test. It is composed of two likelihood ratio (LR) tests.
            -  The first LR test looks at whether the frequency of violations is compatible with the confidence level $\alpha$. This part of the test does not test independence.
            - The second LR test checks if there is statistical evidence of dependence on the previous state. This second test checks independence.
            - If we reject the null hypothesis in the Christoffersen test, it means that the data is incompatible with the assumption that the violations are both independent and have the correct frequency.
            
        III. **Key Transformations**:
            - The first test checks if $\pi_{01}=\pi_{11}=1-\alpha$ jointly. If not, then either the frequency or the independence is rejected.
            - The second test checks the independence of the violations, by testing if $\pi_{01}=\pi_{11}$.
            - The combination of both tests gives the Christoffersen test statistic.
            
        IV. **Conclusion**:
            -  Because of the structure of the test, the Christoffersen test assesses both the frequency of violations and the independence of the violations simultaneously. Therefore, it assesses if both the frequency of violations is consistent with $\alpha$ and if the violations are independent of each other, simultaneously.  ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Continuando o exemplo anterior, o teste de Christoffersen n√£o apenas verifica se a frequ√™ncia de viola√ß√µes √© aproximadamente 5% (se $\alpha=0.95$), mas tamb√©m se a ocorr√™ncia de uma viola√ß√£o em um dia aumenta a probabilidade de uma viola√ß√£o no dia seguinte. Ele faz isso de forma simult√¢nea. Isso √© especialmente importante porque um modelo pode ter a frequ√™ncia de viola√ß√µes correta, mas as viola√ß√µes ocorrem em *clusters*, o que o teste de Christoffersen √© capaz de detectar.
    
**Proposi√ß√£o 5**
   *Al√©m do teste de Kupiec e do teste de Christoffersen, existem outros testes de *backtesting* como o teste de Lopez, o teste de correla√ß√£o serial, e testes baseados em fun√ß√µes de perda, que podem complementar a an√°lise do desempenho do modelo VAR.*
   *Proof:*
        I. **Initial Setup**:
            - The Kupiec and Christoffersen tests are not exhaustive.
            - There are other ways to evaluate a VAR model through backtesting.
        II. **Main Logical Steps**:
            - The Lopez test assesses the magnitude of losses that violate the VAR, not just the frequency. It uses a loss function that considers both the number and the size of the violations.
            - Tests of serial correlation can detect if violations cluster or are predictable, which is undesirable. For example, the Ljung-Box test.
            - Test based on loss functions (such as the tick loss) can be tailored to capture specific properties that are relevant for the user.
        III. **Key Transformations**:
             - The Lopez test, tests of serial correlation, and loss function-based tests provide additional tests that measure aspects of the VAR model not assessed by the Kupiec and Christoffersen test.
       IV. **Conclusion**:
            -  These other tests are useful to evaluate if the VAR model is adequate to a certain situation, and offer a more complete picture of the VAR model‚Äôs quality. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que o teste de Kupiec tenha aprovado um modelo VAR com um n√≠vel de confian√ßa de 95% mas o teste de Christoffersen tenha rejeitado o modelo por apresentar autocorrela√ß√£o. Nesse caso, podemos aplicar outros testes de *backtesting*. Por exemplo, o teste de Lopez poder√° apontar
que as viola√ß√µes do VAR s√£o muito maiores do que o esperado. Um teste de correla√ß√£o serial poder√° confirmar que as viola√ß√µes est√£o clusterizadas. Um teste baseado em fun√ß√µes de perda poder√° indicar que as perdas acima do### Model Backtesting and Horizon Selection in VAR

### Introdu√ß√£o
Em continuidade ao estudo do Value at Risk (VAR) e suas aplica√ß√µes, este cap√≠tulo aborda um aspecto crucial para a valida√ß√£o e confiabilidade dos modelos: o *backtesting*. Como vimos anteriormente, o VAR √© uma medida de risco que resume a potencial perda em um determinado horizonte de tempo e n√≠vel de confian√ßa [^1]. No entanto, a precis√£o do VAR depende da qualidade dos dados e da adequa√ß√£o do modelo utilizado. O *backtesting* √© uma ferramenta essencial para avaliar a performance de um modelo VAR e identificar poss√≠veis vieses nas previs√µes [^1]. Esta se√ß√£o se aprofundar√° nos crit√©rios para realizar o *backtesting*, com foco especial na import√¢ncia do horizonte de tempo na efic√°cia dos testes.

### Conceitos Fundamentais
O *backtesting* consiste em comparar sistematicamente as previs√µes de perdas obtidas por meio do VAR com as perdas e lucros (P&L) efetivamente realizados posteriormente [^1]. O objetivo principal do *backtesting* √© detectar vieses ou inconsist√™ncias nos resultados do VAR, garantindo que o modelo esteja gerando previs√µes confi√°veis. A ideia central √© que um modelo VAR bem calibrado deve ser capaz de prever a frequ√™ncia com que as perdas efetivas excedem o VAR previsto, alinhando-se com o n√≠vel de confian√ßa estabelecido [^2].

Para realizar um *backtesting* eficaz, √© fundamental levar em considera√ß√£o o horizonte de tempo utilizado no c√°lculo do VAR. A escolha do horizonte de tempo influencia diretamente o n√∫mero de observa√ß√µes independentes dispon√≠veis para o teste, afetando o poder estat√≠stico do mesmo [^1]. O poder de um teste refere-se √† sua capacidade de detectar desvios significativos entre as previs√µes do VAR e os resultados reais.

Como mencionado anteriormente, o horizonte de tempo √© um dos fatores quantitativos que influenciam o c√°lculo do VAR. Em geral, um horizonte mais longo leva a um VAR maior. Ao usar o VAR como uma medida de risco potencial, o horizonte de tempo deve ser definido pela liquidez dos ativos, ou seja, o tempo necess√°rio para liquidar o portf√≥lio sem grandes impactos no mercado [^1].

#### O Impacto do Horizonte de Tempo no Backtesting
A escolha do horizonte de tempo tem um impacto significativo no n√∫mero de observa√ß√µes independentes dispon√≠veis para o *backtesting*. Um horizonte mais longo reduz o n√∫mero de observa√ß√µes independentes em um determinado per√≠odo. Por exemplo, se utilizarmos um horizonte de VAR de duas semanas, teremos apenas 26 observa√ß√µes independentes por ano [^1]. Por outro lado, um horizonte de um dia fornecer√° aproximadamente 252 observa√ß√µes independentes ao longo de um ano [^1].

O poder do teste, ou seja, a capacidade de detectar vieses no modelo, est√° diretamente relacionado ao n√∫mero de observa√ß√µes independentes. Com um n√∫mero maior de observa√ß√µes, o teste se torna mais sens√≠vel a desvios entre as previs√µes do VAR e as perdas efetivas [^1]. Por isso, para fins de *backtesting*, √© prefer√≠vel utilizar horizontes de tempo mais curtos, como um dia, para maximizar o poder dos testes [^1].

**Proposi√ß√£o 1**
   *A escolha de um horizonte de tempo $h$ para o c√°lculo do VAR implica que, em um per√≠odo de $T$ dias, temos aproximadamente $T/h$ observa√ß√µes independentes. Para um dado per√≠odo de tempo $T$, o n√∫mero de observa√ß√µes independentes √© inversamente proporcional ao tamanho do horizonte $h$.*
   
   *Proof:*

   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Each observation period for the VAR spans $h$ days.

   II. **Main Logical Steps**:
      - The total number of days, $T$, is divided by the length of each observation period, $h$, to determine the number of non-overlapping observation periods.
      - This gives the number of independent observations.

   III. **Key Transformations**:
      -  Number of independent observations $\approx \frac{T}{h}$

   IV. **Conclusion**:
      - As $h$ increases, $T/h$ decreases, implying an inverse relationship between $h$ and the number of independent observations for a fixed $T$.
      - This proves the statement: "the number of independent observations is inversely proportional to the size of the horizon $h$". ‚ñ†
> üí° **Exemplo Num√©rico:**
> Suponha que temos um per√≠odo de $T = 252$ dias (um ano de negocia√ß√£o). Se usarmos um horizonte de tempo $h = 1$ dia, teremos aproximadamente $252/1 = 252$ observa√ß√µes independentes. Se aumentarmos o horizonte para $h = 5$ dias (uma semana), teremos $252/5 \approx 50$ observa√ß√µes independentes. E se o horizonte for $h=21$ (aproximadamente um m√™s), teremos $252/21=12$ observa√ß√µes independentes. Este exemplo ilustra claramente a rela√ß√£o inversa entre o horizonte de tempo e o n√∫mero de observa√ß√µes independentes.

#### Rela√ß√£o com o N√≠vel de Confian√ßa
√â importante notar que o n√≠vel de confian√ßa tamb√©m influencia o n√∫mero de observa√ß√µes na cauda da distribui√ß√£o. N√≠veis de confian√ßa mais altos, como 99%, resultam em menos observa√ß√µes na cauda, dificultando a identifica√ß√£o de vieses no modelo. Em outras palavras, para confirmar a validade do modelo com um n√≠vel de confian√ßa de 99%, seria necess√°rio um longo per√≠odo de observa√ß√µes para coletar dados suficientes na cauda da distribui√ß√£o [^1]. Por isso, para o *backtesting*, n√≠veis de confian√ßa mais baixos, como 95%, podem ser prefer√≠veis, permitindo uma an√°lise mais frequente dos resultados do modelo [^1].

**Lema 1**
   *Para um n√≠vel de confian√ßa $\alpha$, o n√∫mero de observa√ß√µes esperadas na cauda da distribui√ß√£o em um per√≠odo $T$ com horizonte de tempo $h$ √© aproximadamente $(1-\alpha)T/h$.*

   *Proof:*
   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Let $\alpha$ be the confidence level.
      - The number of independent observations is approximately $T/h$.

   II. **Main Logical Steps**:
       - With a confidence level $\alpha$, the probability of an observation falling in the tail (exceeding the VAR) is $1 - \alpha$.
       - The expected number of observations in the tail is the product of the number of independent observations and the probability of falling in the tail.

   III. **Key Transformations**:
        - Expected number of observations in the tail $\approx \frac{T}{h} \times (1-\alpha) = (1-\alpha) \frac{T}{h}$

   IV. **Conclusion**:
      - This shows that the expected number of observations in the tail is approximately $(1-\alpha)T/h$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Usando o exemplo anterior com $T=252$ dias e um horizonte de $h=1$ dia, se o n√≠vel de confian√ßa for $\alpha = 0.95$ (95%), o n√∫mero esperado de observa√ß√µes na cauda √© $(1-0.95) \times 252/1 = 0.05 \times 252 = 12.6$. Isso significa que, em m√©dia, esperamos que o VAR seja violado aproximadamente 12 ou 13 vezes em um ano. Se o n√≠vel de confian√ßa for $\alpha=0.99$, o n√∫mero esperado de viola√ß√µes cai para $(1-0.99) \times 252 = 0.01 \times 252 = 2.52$, indicando que seria necess√°rio um per√≠odo muito maior de observa√ß√µes para testar o modelo de forma eficaz. Se, por outro lado, mantemos o n√≠vel de confian√ßa em 95% mas aumentamos o horizonte para $h=5$, o n√∫mero de observa√ß√µes na cauda ser√° $(1-0.95)\times 252/5 \approx 2.5$.
  
**Corol√°rio 1.1**
   *O n√∫mero de observa√ß√µes na cauda √© diretamente proporcional ao per√≠odo $T$ e inversamente proporcional ao horizonte $h$, e diminui com o aumento do n√≠vel de confian√ßa $\alpha$.*

   *Proof:*
   I. **Initial Setup**:
       - From Lema 1, the number of observations in the tail is approximately $(1-\alpha)T/h$.

   II. **Main Logical Steps**:
       - We analyze the effect of $T$, $h$, and $\alpha$ on this expression.

   III. **Key Transformations**:
        - As $T$ increases, the number of observations in the tail increases proportionally.
        - As $h$ increases, the number of observations in the tail decreases proportionally.
        - As $\alpha$ increases, $(1-\alpha)$ decreases, thus decreasing the number of observations in the tail.

   IV. **Conclusion**:
        -  This confirms the statement that the number of tail observations is directly proportional to $T$, inversely proportional to $h$, and decreases with an increase in $\alpha$. ‚ñ†

Al√©m disso, vale ressaltar que a escolha do n√≠vel de confian√ßa afeta o tipo de erros que o *backtesting* ser√° capaz de detectar. Um n√≠vel de confian√ßa mais alto prioriza a detec√ß√£o de erros na cauda da distribui√ß√£o, enquanto um n√≠vel de confian√ßa mais baixo permite uma detec√ß√£o mais frequente de erros, ainda que menos extremos.

**Proposi√ß√£o 2**
    *Um n√≠vel de confian√ßa mais baixo aumenta a frequ√™ncia com que os resultados do VAR s√£o comparados com os retornos realizados, e, consequentemente, aumenta a sensibilidade a potenciais vieses no modelo.*
  
  *Proof:*

  I. **Initial Setup**:
    - Let $\alpha$ be the confidence level.
    - A lower confidence level implies a smaller $\alpha$.
    - VAR is calculated for a given confidence level.

  II. **Main Logical Steps**:
    - A lower confidence level (smaller $\alpha$) corresponds to a lower VAR value (since the VAR is a quantile).
    - A lower VAR value means a greater chance of actual losses exceeding the VAR.
    - If the actual loss exceeds the VAR value, this is considered a violation in the backtesting process.
    - More violations mean more comparisons between VAR and actual returns.

  III. **Key Transformations**:
    - Lower $\alpha$  $\implies$ Lower VAR
    - Lower VAR $\implies$ More violations
    - More violations $\implies$ More frequent comparisons between VAR and actual returns

  IV. **Conclusion**:
    - This demonstrates that a lower confidence level results in more frequent comparisons between VAR predictions and actual returns. Therefore, the sensitivity of the backtesting to potential biases in the model increases.‚ñ†

> üí° **Exemplo Num√©rico:**
> Considere um modelo VAR com um horizonte de um dia ($h=1$). Se o n√≠vel de confian√ßa for $\alpha = 0.99$, espera-se que as viola√ß√µes sejam raras, e a cada 100 dias de negocia√ß√£o, apenas 1 dia, em m√©dia, apresentar√° uma perda que ultrapassa o VAR. Se o n√≠vel de confian√ßa for reduzido para $\alpha=0.95$, as viola√ß√µes tornam-se mais frequentes, com uma m√©dia de 5 dias a cada 100, e isso permite uma an√°lise mais detalhada e frequente do modelo.

**Teorema 1**
*Existe um trade-off entre o horizonte de tempo $h$ e o n√≠vel de confian√ßa $\alpha$ no *backtesting*. Diminuir $h$ aumenta o n√∫mero de observa√ß√µes independentes e, portanto, o poder do teste, enquanto diminuir $\alpha$ aumenta a frequ√™ncia de viola√ß√µes do VAR e, tamb√©m, aumenta o poder do teste.*
 *Proof:*
    I. **Initial Setup**:
        - The power of a backtesting test is directly related to the number of independent observations and the frequency of violations.
    
    II. **Main Logical Steps**:
         - From Proposi√ß√£o 1, reducing the time horizon $h$ increases the number of independent observations. An increase in independent observations leads to an increase in the power of the test.
         - From Proposi√ß√£o 2, reducing the confidence level $\alpha$ increases the frequency of violations. More frequent violations increase the data available to backtest, increasing the power of the test.
        
    III. **Key Transformations**:
        - $h \downarrow \implies \text{Number of Independent Observations} \uparrow \implies \text{Test Power} \uparrow$
        - $\alpha \downarrow \implies \text{Frequency of Violations} \uparrow \implies \text{Test Power} \uparrow$

    IV. **Conclusion**:
        - The theorem states that there is a trade-off. Both lowering $h$ and $\alpha$ increase the power of the backtest, supporting the claim. Therefore, this proves the existence of the trade-off.‚ñ†

**Lema 2**
*Seja $N$ o n√∫mero de observa√ß√µes independentes, e seja $X_i$ uma vari√°vel indicadora que vale 1 se a perda observada no per√≠odo $i$ excede o VAR previsto e 0 caso contr√°rio. Se o modelo VAR estiver bem calibrado, ent√£o $X_i$ s√£o vari√°veis aleat√≥rias independentes de Bernoulli com probabilidade de sucesso $1 - \alpha$.*

*Proof:*
   I. **Initial Setup**:
       - $N$ is the number of independent observations.
       - $X_i$ is an indicator variable, where $X_i = 1$ if the loss exceeds the predicted VAR at time $i$, and $X_i = 0$ otherwise.
       - $\alpha$ is the confidence level of the VAR.
       - A well-calibrated VAR model has a probability of $1-\alpha$ of the loss exceeding the VAR.
       - We assume independence between observations.

   II. **Main Logical Steps**:
       - For each observation $i$, there are only two outcomes: the loss exceeds the VAR ($X_i = 1$) or the loss does not exceed the VAR ($X_i = 0$).
       - Under a well-calibrated model, the probability of $X_i = 1$ (a loss exceeding the VAR) is $1 - \alpha$.
       - This is precisely the definition of a Bernoulli trial with a success probability of $1-\alpha$.
       - The independence of the $X_i$ variables comes from the assumption of independence of observations.

   III. **Key Transformations**:
       - $P(X_i=1) = 1-\alpha$.

   IV. **Conclusion**:
       - The variables $X_i$ are independent and follow a Bernoulli distribution with success probability $1-\alpha$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Vamos supor que estamos analisando 252 dias de negocia√ß√£o com um n√≠vel de confian√ßa de 95% ($\alpha=0.95$). Para cada dia $i$, definimos $X_i = 1$ se a perda naquele dia excedeu o VAR previsto e $X_i = 0$ caso contr√°rio. Se o modelo estiver bem calibrado, cada $X_i$ √© uma vari√°vel de Bernoulli com $p = 1 - 0.95 = 0.05$. Isso significa que a probabilidade de uma viola√ß√£o em qualquer dia √© de 5%.

**Teorema 1.1**
*Sob as condi√ß√µes do Lema 2, o n√∫mero de viola√ß√µes do VAR, $V = \sum_{i=1}^N X_i$, segue uma distribui√ß√£o binomial com par√¢metros $N$ e $1-\alpha$, ou seja, $V \sim Bin(N, 1 - \alpha)$.*

*Proof:*
   I. **Initial Setup**:
      - From Lema 2, $X_i$ are independent Bernoulli random variables with success probability $1-\alpha$.
      - $V$ is defined as the sum of these Bernoulli variables: $V = \sum_{i=1}^N X_i$.

   II. **Main Logical Steps**:
      - The sum of $N$ independent Bernoulli random variables with the same success probability follows a binomial distribution.
      - The parameters of the binomial distribution are $N$ (the number of trials) and $1-\alpha$ (the success probability).

   III. **Key Transformations**:
      - $V = \sum_{i=1}^N X_i \implies V \sim Bin(N, 1 - \alpha)$

   IV. **Conclusion**:
      - Therefore, the number of violations $V$ follows a binomial distribution with parameters $N$ and $1-\alpha$. ‚ñ†
> üí° **Exemplo Num√©rico:**
> Continuando o exemplo anterior, onde temos 252 observa√ß√µes independentes ($N=252$) e $\alpha = 0.95$, o n√∫mero total de viola√ß√µes $V$ segue uma distribui√ß√£o binomial com par√¢metros $N=252$ e $p=0.05$, ou seja, $V \sim Bin(252, 0.05)$. Isso nos permite calcular a probabilidade de observar um n√∫mero espec√≠fico de viola√ß√µes, assumindo que o modelo VAR est√° bem calibrado.

**Corol√°rio 1.2**
*A m√©dia e a vari√¢ncia do n√∫mero de viola√ß√µes $V$ s√£o dadas por $E[V] = N(1-\alpha)$ e $Var[V] = N(1-\alpha)\alpha$.*

*Proof:*
   I. **Initial Setup**:
      - From Theorem 1.1, $V \sim Bin(N, 1-\alpha)$.
      - We recall the mean and variance of a binomial distribution.
   II. **Main Logical Steps**:
        - The expected value (mean) of a binomial distribution $Bin(n,p)$ is given by $E[V]=np$.
        - The variance of a binomial distribution $Bin(n,p)$ is given by $Var[V]=np(1-p)$.
   III. **Key Transformations**:
      - Substituting $n = N$ and $p = 1 - \alpha$, we have
      -  $E[V] = N(1-\alpha)$.
      - $Var[V] = N(1-\alpha)(1-(1-\alpha)) = N(1-\alpha)\alpha$.

   IV. **Conclusion**:
     -  This shows that the mean and the variance of $V$ are given by $E[V] = N(1-\alpha)$ and $Var[V] = N(1-\alpha)\alpha$, respectively. ‚ñ†

> üí° **Exemplo Num√©rico:**
> No mesmo exemplo, com $N=252$ e $\alpha=0.95$, a m√©dia do n√∫mero de viola√ß√µes √© $E[V] = 252 \times (1 - 0.95) = 252 \times 0.05 = 12.6$, e a vari√¢ncia √© $Var[V] = 252 \times 0.05 \times 0.95 = 11.97$. Isso significa que, em m√©dia, esperamos 12.6 viola√ß√µes, com uma variabilidade em torno desse valor, quantificada pela vari√¢ncia.

Al√©m disso, √© crucial considerar a autocorrela√ß√£o das perdas. Se as perdas em per√≠odos sucessivos forem correlacionadas, a suposi√ß√£o de independ√™ncia das observa√ß√µes pode ser violada, comprometendo a validade do *backtesting*.

**Proposi√ß√£o 3**
    *A autocorrela√ß√£o positiva das perdas pode levar a um excesso de viola√ß√µes do VAR em clusters, o que pode reduzir o poder de um *backtesting* que assume independ√™ncia das observa√ß√µes.*
    *Proof:*
       I. **Initial Setup**:
        -  Assume positive autocorrelation in losses.
        -  Assume that we are using a backtesting method that assumes independence.
        
       II. **Main Logical Steps**:
           - Positive autocorrelation implies that if a loss exceeds the VAR in a given period, the probability of a loss exceeding the VAR in the next period is higher than expected under independence.
           - This causes violations to occur in clusters, i.e. if one violation occurs, the probability of seeing more violations in close succession is higher.
           - When violations cluster, the assumption of independent Bernoulli trials underlying most backtesting procedures is violated.
           - The methods assume that the number of violations is a realization of a binomial distribution, which does not hold under autocorrelation.
           - Since the number of observations is reduced, a clustered violation process has less power than an independent violation process.

       III. **Key Transformations**:
           - Autocorrelation $\implies$ violation clusters
           - Clusters $\implies$ violation of independence
           - Violation of independence $\implies$ Reduction in the power of the test

       IV. **Conclusion**:
        - Therefore, positive autocorrelation can lead to clustered violations, and reduce the effectiveness of backtesting.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
> Suponha que as perdas do dia atual sejam positivamente correlacionadas com as perdas do dia anterior. Se o VAR for violado hoje, √© mais prov√°vel que ele seja violado amanh√£ tamb√©m. Isso cria *clusters* de viola√ß√µes, onde v√°rios dias consecutivos apresentam perdas acima do VAR, em vez de viola√ß√µes aleat√≥rias e independentes. Um modelo que ignora essa autocorrela√ß√£o pode n√£o capturar a din√¢mica real do risco.
    
**Lema 3**
*Para detectar a presen√ßa de autocorrela√ß√£o nas viola√ß√µes do VAR, pode-se realizar um teste de raz√£o de verossimilhan√ßa (LR) de independ√™ncia de viola√ß√µes, ou similar, como o teste de Kupiec ou Christoffersen.*

    *Proof:*
     I. **Initial Setup**:
          - We want to detect if there is autocorrelation in the violations of the VAR model.
          - We know that violations of a well-calibrated VAR should be independent events.

     II. **Main Logical Steps**:
          - The test of the likelihood ratio (LR) is designed to test the hypothesis that the distribution of the violations is independent.
          - The Kupiec test checks if the overall violation rate is consistent with the confidence level, implicitly assuming independence over time.
          - The Christoffersen test is specifically designed to test for both correct violation rate and independence over time.

     III. **Key Transformations**:
          - These tests check the null hypothesis of independence against the alternative of an autocorrelation in the violations.

     IV. **Conclusion**:
          -  The LR test and specific tests such as Kupiec and Christoffersen can all detect the presence of autocorrelation, supporting the claim. ‚ñ†
> üí° **Exemplo Num√©rico:**
>  Se os resultados do *backtesting* mostram uma sequ√™ncia de viola√ß√µes em dias pr√≥ximos (por exemplo, viola√ß√µes nos dias 1, 2, 3, e depois nenhuma viola√ß√£o por v√°rias semanas, e em seguida viola√ß√µes nos dias 45 e 46) isso levanta suspeitas de autocorrela√ß√£o. Testes como o de Christoffersen ajudam a quantificar essa suspeita, e a verificar se os *clusters* de viola√ß√£o s√£o estatisticamente significativos ou apenas devidos ao acaso.

**Proposi√ß√£o 4**
    *A presen√ßa de *clusters* de viola√ß√µes, causada por autocorrela√ß√£o, implica que a vari√¢ncia do n√∫mero de viola√ß√µes pode ser maior do que o previsto pela distribui√ß√£o binomial sob a hip√≥tese de independ√™ncia.*
    
  *Proof:*
  
    I. **Initial Setup**:
        - Assume that the violations are positively autocorrelated, so that violations tend to cluster together.
        - Let $X_i$ be indicator variables such that $X_i = 1$ if there is a violation at time $i$ and 0 otherwise.
        - Let the number of violations be given by $V=\sum_{i=1}^N X_i$.
        
    II. **Main Logical Steps**:
        - If the violations were independent, then we could calculate the variance of the total number of violations using the fact that it follows a binomial distribution (as shown in Corol√°rio 1.2). In that case, $Var[V] = N(1-\alpha)\alpha$.
        - However, because of autocorrelation, the $X_i$ are not independent. The variance of the sum of correlated random variables is not the sum of the variances.
        - If $\text{Cov}(X_i,X_j) > 0$ for at least some $i \neq j$, then $Var[\sum X_i] > \sum Var[X_i]$.
        - The autocorrelation causes $\text{Cov}(X_i,X_j) > 0$, implying that the variance of the sum will be greater than if the $X_i$ were independent.

   III. **Key Transformations**:
       - Autocorrelation $\implies \text{Cov}(X_i,X_j) > 0$.
       -  $\text{Cov}(X_i,X_j) > 0$  $\implies$  $Var[\sum X_i] > \sum Var[X_i]$
       - $Var[\sum X_i] > \sum Var[X_i]$ $\implies$ $Var[V] > N(1-\alpha)\alpha$

   IV. **Conclusion**:
      -  The presence of autocorrelation increases the variance of the sum of violations over the case with independent variables.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
>  Usando o exemplo de 252 observa√ß√µes com $\alpha = 0.95$, sob a hip√≥tese de independ√™ncia, a vari√¢ncia do n√∫mero de viola√ß√µes √© de 11.97. No entanto, se houver autocorrela√ß√£o positiva, a vari√¢ncia real das viola√ß√µes pode ser muito maior. Por exemplo, se as viola√ß√µes ocorrem em *clusters*, a vari√¢ncia poderia ser 20 ou at√© mais. Isso significa que as viola√ß√µes ser√£o mais vari√°veis do que o esperado sob o modelo binomial, e o modelo de VAR pode estar subestimando o risco.
   
**Teorema 2**
 *O teste de Kupiec √© um teste de hip√≥tese para verificar se a frequ√™ncia de viola√ß√µes do VAR √© estatisticamente diferente do esperado dado o n√≠vel de confian√ßa $\alpha$. Ele testa a hip√≥tese nula de que a frequ√™ncia de viola√ß√µes observada √© consistente com a frequ√™ncia esperada sob um modelo bem calibrado.*

 *Proof:*
    I. **Initial Setup**:
      - The null hypothesis ($H_0$) is that the model is well-calibrated, i.e., the observed violation rate matches the expected violation rate.
      - The alternative hypothesis ($H_1$) is that the model is not well-calibrated, i.e., the observed violation rate is different from the expected rate.
      - Let $V$ be the observed number of violations, $N$ the number of independent observations, and $\alpha$ the confidence level.
      - We know that if the model is well-calibrated, the number of violations follows a binomial distribution $V \sim Bin(N, 1-\alpha)$.
      
    II. **Main Logical Steps**:
      -  The Kupiec test uses a likelihood ratio test to compare the likelihood under the null hypothesis (where $p = 1-\alpha$) with the likelihood of a model that admits a free violation probability $\hat{p}$ estimated from data (observed frequency of violations, i.e., $\hat{p} = V/N$).
      - The likelihood ratio statistic is constructed based on the binomial distribution.
      - The statistic is asymptotically chi-squared distributed, which allows for the construction of the test.
      
    III. **Key Transformations**:
      - Let $p$ be the expected probability of violation under the null hypothesis $p = 1-\alpha$.
      - The likelihood function is given by $L(p) = \binom{N}{V} p^V (1-p)^{N-V}$.
      - The test statistic is given by $-2ln\frac{L(1-\alpha)}{L(\hat{p})}$.
      - Under the null hypothesis, this statistic converges in distribution to a $\chi^2(1)$.

    IV. **Conclusion**:
      -  The Kupiec test checks if the frequency of violations is statistically different from that expected under the well-calibrated model hypothesis, using the distribution of the violations implied by a model with binomial violations. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que em 252 dias com um n√≠vel de confian√ßa de 95%, um modelo VAR tenha apresentado 20 viola√ß√µes. Sob a hip√≥tese nula de que o modelo est√° bem calibrado, o n√∫mero esperado de viola√ß√µes √© de 12.6. O teste de Kupiec calcula uma estat√≠stica de teste que compara a probabilidade de observar 20 viola√ß√µes se o modelo estiver bem calibrado com a probabilidade de observar 20 viola√ß√µes com a probabilidade de viola√ß√£o observada nos dados (20/252). Essa estat√≠stica de teste segue uma distribui√ß√£o $\chi^2$ com 1 grau de liberdade. Se o valor da estat√≠stica de teste for muito alto (e o p-valor correspondente for baixo), rejeita-se a hip√≥tese de que o modelo est√° bem calibrado e conclui-se que o modelo est√° subestimando o risco.
 
 **Lema 4**
 *O teste de Christoffersen testa se as viola√ß√µes do VAR s√£o independentes ao longo do tempo, e, portanto, se h√° *clusters* de viola√ß√µes. Ele testa a hip√≥tese nula de independ√™ncia das viola√ß√µes contra a hip√≥tese alternativa de que as viola√ß√µes seguem um processo de Markov de primeira ordem.*

    *Proof:*
    I. **Initial Setup**:
         - Null Hypothesis $H_0$: The violations are independent over time.
         - Alternative Hypothesis $H_1$: The violations follow a first-order Markov process (i.e., the probability of a violation depends on whether the previous observation was a violation or not).
         - $X_t$ is an indicator variable that is 1 if a violation occurs at time t, and 0 otherwise.

    II. **Main Logical Steps**:
         -  The Christoffersen test examines the transitions between violation and no-violation states using a likelihood ratio test.
         - Under $H_0$, the probability of a violation at time $t$ is independent of the occurrence of a violation at time $t-1$.
         - Under $H_1$, the probability of a violation depends on whether there was a violation in the previous period.
         - This dependence is expressed using a transition matrix:
        $$
        \begin{bmatrix}
          \pi_{00} & \pi_{01} \\
          \pi_{10} & \pi_{11}
        \end{bmatrix}
        $$
         where $\pi_{ij}$ is the probability of observing $X_t=j$ given $X_{t-1} = i$.
        
    III. **Key Transformations**:
         - The likelihood function under the null hypothesis (independence) is compared to the likelihood under the alternative hypothesis (Markov model).
         - The likelihood ratio is used to evaluate if the alternative hypothesis fits the data significantly better than the null hypothesis.
         - The test statistic is asymptotically chi-squared distributed.
        
    IV. **Conclusion**:
         -  The Christoffersen test determines if the observed transitions between violations and no-violations are consistent with the assumption of independence (i.e., if violations are clustered). ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que temos 252 dias de dados, e as viola√ß√µes do VAR ocorrem em sequ√™ncia. Por exemplo, se tivermos uma viola√ß√£o no dia $t-1$, a probabilidade de ter uma viola√ß√£o no dia $t$ √© muito maior do que se n√£o tivermos uma viola√ß√£o no dia $t-1$. O teste de Christoffersen verifica se essas transi√ß√µes entre estados (viola√ß√£o/n√£o-viola√ß√£o) s√£o estatisticamente significativas e inconsistentes com a hip√≥tese de independ√™ncia. Ele estima a matriz de transi√ß√£o e compara a probabilidade de os dados terem sido gerados por uma cadeia de Markov ou por um processo independente, calculando uma estat√≠stica de teste, que segue uma distribui√ß√£o $\chi^2$.

    
**Teorema 2.1**
    *O teste de Christoffersen tamb√©m avalia se a frequ√™ncia de viola√ß√µes √© consistente com o n√≠vel de confian√ßa $\alpha$, simultaneamente com a avalia√ß√£o da independ√™ncia das viola√ß√µes.*

    *Proof:*
        I. **Initial Setup**:
            - The null hypothesis for the Christoffersen test is that the model is well-calibrated and that the violations are independent of each other.
            - The alternative hypothesis is that either the violation frequency is not correct or the violations are not independent.
            -  The null hypothesis is given by $H_0: \pi_{01}=\pi_{11} = 1-\alpha$.

        II. **Main Logical Steps**:
            - The Christoffersen test is actually a joint test. It is composed of two likelihood ratio (LR) tests.
            -  The first LR test looks at whether the frequency of violations is compatible with the confidence level $\alpha$. This part of the test does not test independence.
            - The second LR test checks if there is statistical evidence of dependence on the previous state. This second test checks independence.
            - If we reject the null hypothesis in the Christoffersen test, it means that the data is incompatible with the assumption that the violations are both independent and have the correct frequency.
            
        III. **Key Transformations**:
            - The first test checks if $\pi_{01}=\pi_{11}=1-\alpha$ jointly. If not, then either the frequency or the independence is rejected.
            - The second test checks the independence of the violations, by testing if $\pi_{01}=\pi_{11}$.
            - The combination of both tests gives the Christoffersen test statistic.
            
        IV. **Conclusion**:
            -  Because of the structure of the test, the Christoffersen test assesses both the frequency of violations and the independence of the violations simultaneously. Therefore, it assesses if both the frequency of violations is consistent with $\alpha$ and if the violations are independent of each other, simultaneously.  ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Continuando o exemplo anterior, o teste de Christoffersen n√£o apenas verifica se a frequ√™ncia de viola√ß√µes √© aproximadamente 5% (se $\alpha=0.95$), mas tamb√©m se a ocorr√™ncia de uma viola√ß√£o em um dia aumenta a probabilidade de uma viola√ß√£o no dia seguinte. Ele faz isso de forma simult√¢nea. Isso √© especialmente importante porque um modelo pode ter a frequ√™ncia de viola√ß√µes correta, mas as viola√ß√µes ocorrem em *clusters*, o que o teste de Christoffersen √© capaz de detectar.
    
**Proposi√ß√£o 5**
   *Al√©m do teste de Kupiec e do teste de Christoffersen, existem outros testes de *backtesting* como o teste de Lopez, o teste de correla√ß√£o serial, e testes baseados em fun√ß√µes de perda, que podem complementar a an√°lise do desempenho do modelo VAR.*
   *Proof:*
        I. **Initial Setup**:
            - The Kupiec and Christoffersen tests are not exhaustive.
            - There are other ways to evaluate a VAR model through backtesting.
        II. **Main Logical Steps**:
            - The Lopez test assesses the magnitude of losses that violate the VAR, not just the frequency. It uses a loss function that considers both the number and the size of the violations.
            - Tests of serial correlation can detect if violations cluster or are predictable, which is undesirable. For example, the Ljung-Box test.
            - Test based on loss functions (such as the tick loss) can be tailored to capture specific properties that are relevant for the user.
        III. **Key Transformations**:
             - The Lopez test, tests of serial correlation, and loss function-based tests provide additional tests that measure aspects of the VAR model not assessed by the Kupiec and Christoffersen test.
       IV. **Conclusion**:
            -  These other tests are useful to evaluate if the VAR model is adequate to a certain situation, and offer a more complete picture of the VAR model‚Äôs quality. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que o teste de Kupiec tenha aprovado um modelo VAR com um n√≠vel de confian√ßa de 95% mas o teste de Christoffersen tenha rejeitado o modelo por apresentar autocorrela√ß√£o. Nesse caso, podemos aplicar outros testes de *backtesting*. Por exemplo, o teste de Lopez poder√° apontar
que as viola√ß√µes do VAR s√£o muito maiores do que o esperado. Um teste de correla√ß√£o serial poder√° confirmar que as viola√ß√µes est√£o clusterizadas. Um teste baseado em fun√ß√µes de perda poder√° indicar que as perdas acima do### Model Backtesting and Horizon Selection in VAR

### Introdu√ß√£o
Em continuidade ao estudo do Value at Risk (VAR) e suas aplica√ß√µes, este cap√≠tulo aborda um aspecto crucial para a valida√ß√£o e confiabilidade dos modelos: o *backtesting*. Como vimos anteriormente, o VAR √© uma medida de risco que resume a potencial perda em um determinado horizonte de tempo e n√≠vel de confian√ßa [^1]. No entanto, a precis√£o do VAR depende da qualidade dos dados e da adequa√ß√£o do modelo utilizado. O *backtesting* √© uma ferramenta essencial para avaliar a performance de um modelo VAR e identificar poss√≠veis vieses nas previs√µes [^1]. Esta se√ß√£o se aprofundar√° nos crit√©rios para realizar o *backtesting*, com foco especial na import√¢ncia do horizonte de tempo na efic√°cia dos testes.

### Conceitos Fundamentais
O *backtesting* consiste em comparar sistematicamente as previs√µes de perdas obtidas por meio do VAR com as perdas e lucros (P&L) efetivamente realizados posteriormente [^1]. O objetivo principal do *backtesting* √© detectar vieses ou inconsist√™ncias nos resultados do VAR, garantindo que o modelo esteja gerando previs√µes confi√°veis. A ideia central √© que um modelo VAR bem calibrado deve ser capaz de prever a frequ√™ncia com que as perdas efetivas excedem o VAR previsto, alinhando-se com o n√≠vel de confian√ßa estabelecido [^2].

Para realizar um *backtesting* eficaz, √© fundamental levar em considera√ß√£o o horizonte de tempo utilizado no c√°lculo do VAR. A escolha do horizonte de tempo influencia diretamente o n√∫mero de observa√ß√µes independentes dispon√≠veis para o teste, afetando o poder estat√≠stico do mesmo [^1]. O poder de um teste refere-se √† sua capacidade de detectar desvios significativos entre as previs√µes do VAR e os resultados reais.

Como mencionado anteriormente, o horizonte de tempo √© um dos fatores quantitativos que influenciam o c√°lculo do VAR. Em geral, um horizonte mais longo leva a um VAR maior. Ao usar o VAR como uma medida de risco potencial, o horizonte de tempo deve ser definido pela liquidez dos ativos, ou seja, o tempo necess√°rio para liquidar o portf√≥lio sem grandes impactos no mercado [^1].

#### O Impacto do Horizonte de Tempo no Backtesting
A escolha do horizonte de tempo tem um impacto significativo no n√∫mero de observa√ß√µes independentes dispon√≠veis para o *backtesting*. Um horizonte mais longo reduz o n√∫mero de observa√ß√µes independentes em um determinado per√≠odo. Por exemplo, se utilizarmos um horizonte de VAR de duas semanas, teremos apenas 26 observa√ß√µes independentes por ano [^1]. Por outro lado, um horizonte de um dia fornecer√° aproximadamente 252 observa√ß√µes independentes ao longo de um ano [^1].

O poder do teste, ou seja, a capacidade de detectar vieses no modelo, est√° diretamente relacionado ao n√∫mero de observa√ß√µes independentes. Com um n√∫mero maior de observa√ß√µes, o teste se torna mais sens√≠vel a desvios entre as previs√µes do VAR e as perdas efetivas [^1]. Por isso, para fins de *backtesting*, √© prefer√≠vel utilizar horizontes de tempo mais curtos, como um dia, para maximizar o poder dos testes [^1].

**Proposi√ß√£o 1**
   *A escolha de um horizonte de tempo $h$ para o c√°lculo do VAR implica que, em um per√≠odo de $T$ dias, temos aproximadamente $T/h$ observa√ß√µes independentes. Para um dado per√≠odo de tempo $T$, o n√∫mero de observa√ß√µes independentes √© inversamente proporcional ao tamanho do horizonte $h$.*
   
   *Proof:*

   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Each observation period for the VAR spans $h$ days.

   II. **Main Logical Steps**:
      - The total number of days, $T$, is divided by the length of each observation period, $h$, to determine the number of non-overlapping observation periods.
      - This gives the number of independent observations.

   III. **Key Transformations**:
      -  Number of independent observations $\approx \frac{T}{h}$

   IV. **Conclusion**:
      - As $h$ increases, $T/h$ decreases, implying an inverse relationship between $h$ and the number of independent observations for a fixed $T$.
      - This proves the statement: "the number of independent observations is inversely proportional to the size of the horizon $h$". ‚ñ†
> üí° **Exemplo Num√©rico:**
> Suponha que temos um per√≠odo de $T = 252$ dias (um ano de negocia√ß√£o). Se usarmos um horizonte de tempo $h = 1$ dia, teremos aproximadamente $252/1 = 252$ observa√ß√µes independentes. Se aumentarmos o horizonte para $h = 5$ dias (uma semana), teremos $252/5 \approx 50$ observa√ß√µes independentes. E se o horizonte for $h=21$ (aproximadamente um m√™s), teremos $252/21=12$ observa√ß√µes independentes. Este exemplo ilustra claramente a rela√ß√£o inversa entre o horizonte de tempo e o n√∫mero de observa√ß√µes independentes.

#### Rela√ß√£o com o N√≠vel de Confian√ßa
√â importante notar que o n√≠vel de confian√ßa tamb√©m influencia o n√∫mero de observa√ß√µes na cauda da distribui√ß√£o. N√≠veis de confian√ßa mais altos, como 99%, resultam em menos observa√ß√µes na cauda, dificultando a identifica√ß√£o de vieses no modelo. Em outras palavras, para confirmar a validade do modelo com um n√≠vel de confian√ßa de 99%, seria necess√°rio um longo per√≠odo de observa√ß√µes para coletar dados suficientes na cauda da distribui√ß√£o [^1]. Por isso, para o *backtesting*, n√≠veis de confian√ßa mais baixos, como 95%, podem ser prefer√≠veis, permitindo uma an√°lise mais frequente dos resultados do modelo [^1].

**Lema 1**
   *Para um n√≠vel de confian√ßa $\alpha$, o n√∫mero de observa√ß√µes esperadas na cauda da distribui√ß√£o em um per√≠odo $T$ com horizonte de tempo $h$ √© aproximadamente $(1-\alpha)T/h$.*

   *Proof:*
   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Let $\alpha$ be the confidence level.
      - The number of independent observations is approximately $T/h$.

   II. **Main Logical Steps**:
       - With a confidence level $\alpha$, the probability of an observation falling in the tail (exceeding the VAR) is $1 - \alpha$.
       - The expected number of observations in the tail is the product of the number of independent observations and the probability of falling in the tail.

   III. **Key Transformations**:
        - Expected number of observations in the tail $\approx \frac{T}{h} \times (1-\alpha) = (1-\alpha) \frac{T}{h}$

   IV. **Conclusion**:
      - This shows that the expected number of observations in the tail is approximately $(1-\alpha)T/h$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Usando o exemplo anterior com $T=252$ dias e um horizonte de $h=1$ dia, se o n√≠vel de confian√ßa for $\alpha = 0.95$ (95%), o n√∫mero esperado de observa√ß√µes na cauda √© $(1-0.95) \times 252/1 = 0.05 \times 252 = 12.6$. Isso significa que, em m√©dia, esperamos que o VAR seja violado aproximadamente 12 ou 13 vezes em um ano. Se o n√≠vel de confian√ßa for $\alpha=0.99$, o n√∫mero esperado de viola√ß√µes cai para $(1-0.99) \times 252 = 0.01 \times 252 = 2.52$, indicando que seria necess√°rio um per√≠odo muito maior de observa√ß√µes para testar o modelo de forma eficaz. Se, por outro lado, mantemos o n√≠vel de confian√ßa em 95% mas aumentamos o horizonte para $h=5$, o n√∫mero de observa√ß√µes na cauda ser√° $(1-0.95)\times 252/5 \approx 2.5$.
  
**Corol√°rio 1.1**
   *O n√∫mero de observa√ß√µes na cauda √© diretamente proporcional ao per√≠odo $T$ e inversamente proporcional ao horizonte $h$, e diminui com o aumento do n√≠vel de confian√ßa $\alpha$.*

   *Proof:*
   I. **Initial Setup**:
       - From Lema 1, the number of observations in the tail is approximately $(1-\alpha)T/h$.

   II. **Main Logical Steps**:
       - We analyze the effect of $T$, $h$, and $\alpha$ on this expression.

   III. **Key Transformations**:
        - As $T$ increases, the number of observations in the tail increases proportionally.
        - As $h$ increases, the number of observations in the tail decreases proportionally.
        - As $\alpha$ increases, $(1-\alpha)$ decreases, thus decreasing the number of observations in the tail.

   IV. **Conclusion**:
        -  This confirms the statement that the number of tail observations is directly proportional to $T$, inversely proportional to $h$, and decreases with an increase in $\alpha$. ‚ñ†

Al√©m disso, vale ressaltar que a escolha do n√≠vel de confian√ßa afeta o tipo de erros que o *backtesting* ser√° capaz de detectar. Um n√≠vel de confian√ßa mais alto prioriza a detec√ß√£o de erros na cauda da distribui√ß√£o, enquanto um n√≠vel de confian√ßa mais baixo permite uma detec√ß√£o mais frequente de erros, ainda que menos extremos.

**Proposi√ß√£o 2**
    *Um n√≠vel de confian√ßa mais baixo aumenta a frequ√™ncia com que os resultados do VAR s√£o comparados com os retornos realizados, e, consequentemente, aumenta a sensibilidade a potenciais vieses no modelo.*
  
  *Proof:*

  I. **Initial Setup**:
    - Let $\alpha$ be the confidence level.
    - A lower confidence level implies a smaller $\alpha$.
    - VAR is calculated for a given confidence level.

  II. **Main Logical Steps**:
    - A lower confidence level (smaller $\alpha$) corresponds to a lower VAR value (since the VAR is a quantile).
    - A lower VAR value means a greater chance of actual losses exceeding the VAR.
    - If the actual loss exceeds the VAR value, this is considered a violation in the backtesting process.
    - More violations mean more comparisons between VAR and actual returns.

  III. **Key Transformations**:
    - Lower $\alpha$  $\implies$ Lower VAR
    - Lower VAR $\implies$ More violations
    - More violations $\implies$ More frequent comparisons between VAR and actual returns

  IV. **Conclusion**:
    - This demonstrates that a lower confidence level results in more frequent comparisons between VAR predictions and actual returns. Therefore, the sensitivity of the backtesting to potential biases in the model increases.‚ñ†

> üí° **Exemplo Num√©rico:**
> Considere um modelo VAR com um horizonte de um dia ($h=1$). Se o n√≠vel de confian√ßa for $\alpha = 0.99$, espera-se que as viola√ß√µes sejam raras, e a cada 100 dias de negocia√ß√£o, apenas 1 dia, em m√©dia, apresentar√° uma perda que ultrapassa o VAR. Se o n√≠vel de confian√ßa for reduzido para $\alpha=0.95$, as viola√ß√µes tornam-se mais frequentes, com uma m√©dia de 5 dias a cada 100, e isso permite uma an√°lise mais detalhada e frequente do modelo.

**Teorema 1**
*Existe um trade-off entre o horizonte de tempo $h$ e o n√≠vel de confian√ßa $\alpha$ no *backtesting*. Diminuir $h$ aumenta o n√∫mero de observa√ß√µes independentes e, portanto, o poder do teste, enquanto diminuir $\alpha$ aumenta a frequ√™ncia de viola√ß√µes do VAR e, tamb√©m, aumenta o poder do teste.*
 *Proof:*
    I. **Initial Setup**:
        - The power of a backtesting test is directly related to the number of independent observations and the frequency of violations.
    
    II. **Main Logical Steps**:
         - From Proposi√ß√£o 1, reducing the time horizon $h$ increases the number of independent observations. An increase in independent observations leads to an increase in the power of the test.
         - From Proposi√ß√£o 2, reducing the confidence level $\alpha$ increases the frequency of violations. More frequent violations increase the data available to backtest, increasing the power of the test.
        
    III. **Key Transformations**:
        - $h \downarrow \implies \text{Number of Independent Observations} \uparrow \implies \text{Test Power} \uparrow$
        - $\alpha \downarrow \implies \text{Frequency of Violations} \uparrow \implies \text{Test Power} \uparrow$

    IV. **Conclusion**:
        - The theorem states that there is a trade-off. Both lowering $h$ and $\alpha$ increase the power of the backtest, supporting the claim. Therefore, this proves the existence of the trade-off.‚ñ†

**Lema 2**
*Seja $N$ o n√∫mero de observa√ß√µes independentes, e seja $X_i$ uma vari√°vel indicadora que vale 1 se a perda observada no per√≠odo $i$ excede o VAR previsto e 0 caso contr√°rio. Se o modelo VAR estiver bem calibrado, ent√£o $X_i$ s√£o vari√°veis aleat√≥rias independentes de Bernoulli com probabilidade de sucesso $1 - \alpha$.*

*Proof:*
   I. **Initial Setup**:
       - $N$ is the number of independent observations.
       - $X_i$ is an indicator variable, where $X_i = 1$ if the loss exceeds the predicted VAR at time $i$, and $X_i = 0$ otherwise.
       - $\alpha$ is the confidence level of the VAR.
       - A well-calibrated VAR model has a probability of $1-\alpha$ of the loss exceeding the VAR.
       - We assume independence between observations.

   II. **Main Logical Steps**:
       - For each observation $i$, there are only two outcomes: the loss exceeds the VAR ($X_i = 1$) or the loss does not exceed the VAR ($X_i = 0$).
       - Under a well-calibrated model, the probability of $X_i = 1$ (a loss exceeding the VAR) is $1 - \alpha$.
       - This is precisely the definition of a Bernoulli trial with a success probability of $1-\alpha$.
       - The independence of the $X_i$ variables comes from the assumption of independence of observations.

   III. **Key Transformations**:
       - $P(X_i=1) = 1-\alpha$.

   IV. **Conclusion**:
       - The variables $X_i$ are independent and follow a Bernoulli distribution with success probability $1-\alpha$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Vamos supor que estamos analisando 252 dias de negocia√ß√£o com um n√≠vel de confian√ßa de 95% ($\alpha=0.95$). Para cada dia $i$, definimos $X_i = 1$ se a perda naquele dia excedeu o VAR previsto e $X_i = 0$ caso contr√°rio. Se o modelo estiver bem calibrado, cada $X_i$ √© uma vari√°vel de Bernoulli com $p = 1 - 0.95 = 0.05$. Isso significa que a probabilidade de uma viola√ß√£o em qualquer dia √© de 5%.

**Teorema 1.1**
*Sob as condi√ß√µes do Lema 2, o n√∫mero de viola√ß√µes do VAR, $V = \sum_{i=1}^N X_i$, segue uma distribui√ß√£o binomial com par√¢metros $N$ e $1-\alpha$, ou seja, $V \sim Bin(N, 1 - \alpha)$.*

*Proof:*
   I. **Initial Setup**:
      - From Lema 2, $X_i$ are independent Bernoulli random variables with success probability $1-\alpha$.
      - $V$ is defined as the sum of these Bernoulli variables: $V = \sum_{i=1}^N X_i$.

   II. **Main Logical Steps**:
      - The sum of $N$ independent Bernoulli random variables with the same success probability follows a binomial distribution.
      - The parameters of the binomial distribution are $N$ (the number of trials) and $1-\alpha$ (the success probability).

   III. **Key Transformations**:
      - $V = \sum_{i=1}^N X_i \implies V \sim Bin(N, 1 - \alpha)$

   IV. **Conclusion**:
      - Therefore, the number of violations $V$ follows a binomial distribution with parameters $N$ and $1-\alpha$. ‚ñ†
> üí° **Exemplo Num√©rico:**
> Continuando o exemplo anterior, onde temos 252 observa√ß√µes independentes ($N=252$) e $\alpha = 0.95$, o n√∫mero total de viola√ß√µes $V$ segue uma distribui√ß√£o binomial com par√¢metros $N=252$ e $p=0.05$, ou seja, $V \sim Bin(252, 0.05)$. Isso nos permite calcular a probabilidade de observar um n√∫mero espec√≠fico de viola√ß√µes, assumindo que o modelo VAR est√° bem calibrado.

**Corol√°rio 1.2**
*A m√©dia e a vari√¢ncia do n√∫mero de viola√ß√µes $V$ s√£o dadas por $E[V] = N(1-\alpha)$ e $Var[V] = N(1-\alpha)\alpha$.*

*Proof:*
   I. **Initial Setup**:
      - From Theorem 1.1, $V \sim Bin(N, 1-\alpha)$.
      - We recall the mean and variance of a binomial distribution.
   II. **Main Logical Steps**:
        - The expected value (mean) of a binomial distribution $Bin(n,p)$ is given by $E[V]=np$.
        - The variance of a binomial distribution $Bin(n,p)$ is given by $Var[V]=np(1-p)$.
   III. **Key Transformations**:
      - Substituting $n = N$ and $p = 1 - \alpha$, we have
      -  $E[V] = N(1-\alpha)$.
      - $Var[V] = N(1-\alpha)(1-(1-\alpha)) = N(1-\alpha)\alpha$.

   IV. **Conclusion**:
     -  This shows that the mean and the variance of $V$ are given by $E[V] = N(1-\alpha)$ and $Var[V] = N(1-\alpha)\alpha$, respectively. ‚ñ†

> üí° **Exemplo Num√©rico:**
> No mesmo exemplo, com $N=252$ e $\alpha=0.95$, a m√©dia do n√∫mero de viola√ß√µes √© $E[V] = 252 \times (1 - 0.95) = 252 \times 0.05 = 12.6$, e a vari√¢ncia √© $Var[V] = 252 \times 0.05 \times 0.95 = 11.97$. Isso significa que, em m√©dia, esperamos 12.6 viola√ß√µes, com uma variabilidade em torno desse valor, quantificada pela vari√¢ncia.

Al√©m disso, √© crucial considerar a autocorrela√ß√£o das perdas. Se as perdas em per√≠odos sucessivos forem correlacionadas, a suposi√ß√£o de independ√™ncia das observa√ß√µes pode ser violada, comprometendo a validade do *backtesting*.

**Proposi√ß√£o 3**
    *A autocorrela√ß√£o positiva das perdas pode levar a um excesso de viola√ß√µes do VAR em clusters, o que pode reduzir o poder de um *backtesting* que assume independ√™ncia das observa√ß√µes.*
    *Proof:*
       I. **Initial Setup**:
        -  Assume positive autocorrelation in losses.
        -  Assume that we are using a backtesting method that assumes independence.
        
       II. **Main Logical Steps**:
           - Positive autocorrelation implies that if a loss exceeds the VAR in a given period, the probability of a loss exceeding the VAR in the next period is higher than expected under independence.
           - This causes violations to occur in clusters, i.e. if one violation occurs, the probability of seeing more violations in close succession is higher.
           - When violations cluster, the assumption of independent Bernoulli trials underlying most backtesting procedures is violated.
           - The methods assume that the number of violations is a realization of a binomial distribution, which does not hold under autocorrelation.
           - Since the number of observations is reduced, a clustered violation process has less power than an independent violation process.

       III. **Key Transformations**:
           - Autocorrelation $\implies$ violation clusters
           - Clusters $\implies$ violation of independence
           - Violation of independence $\implies$ Reduction in the power of the test

       IV. **Conclusion**:
        - Therefore, positive autocorrelation can lead to clustered violations, and reduce the effectiveness of backtesting.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
> Suponha que as perdas do dia atual sejam positivamente correlacionadas com as perdas do dia anterior. Se o VAR for violado hoje, √© mais prov√°vel que ele seja violado amanh√£ tamb√©m. Isso cria *clusters* de viola√ß√µes, onde v√°rios dias consecutivos apresentam perdas acima do VAR, em vez de viola√ß√µes aleat√≥rias e independentes. Um modelo que ignora essa autocorrela√ß√£o pode n√£o capturar a din√¢mica real do risco.
    
**Lema 3**
*Para detectar a presen√ßa de autocorrela√ß√£o nas viola√ß√µes do VAR, pode-se realizar um teste de raz√£o de verossimilhan√ßa (LR) de independ√™ncia de viola√ß√µes, ou similar, como o teste de Kupiec ou Christoffersen.*

    *Proof:*
     I. **Initial Setup**:
          - We want to detect if there is autocorrelation in the violations of the VAR model.
          - We know that violations of a well-calibrated VAR should be independent events.

     II. **Main Logical Steps**:
          - The test of the likelihood ratio (LR) is designed to test the hypothesis that the distribution of the violations is independent.
          - The Kupiec test checks if the overall violation rate is consistent with the confidence level, implicitly assuming independence over time.
          - The Christoffersen test is specifically designed to test for both correct violation rate and independence over time.

     III. **Key Transformations**:
          - These tests check the null hypothesis of independence against the alternative of an autocorrelation in the violations.

     IV. **Conclusion**:
          -  The LR test and specific tests such as Kupiec and Christoffersen can all detect the presence of autocorrelation, supporting the claim. ‚ñ†
> üí° **Exemplo Num√©rico:**
>  Se os resultados do *backtesting* mostram uma sequ√™ncia de viola√ß√µes em dias pr√≥ximos (por exemplo, viola√ß√µes nos dias 1, 2, 3, e depois nenhuma viola√ß√£o por v√°rias semanas, e em seguida viola√ß√µes nos dias 45 e 46) isso levanta suspeitas de autocorrela√ß√£o. Testes como o de Christoffersen ajudam a quantificar essa suspeita, e a verificar se os *clusters* de viola√ß√£o s√£o estatisticamente significativos ou apenas devidos ao acaso.

**Proposi√ß√£o 4**
    *A presen√ßa de *clusters* de viola√ß√µes, causada por autocorrela√ß√£o, implica que a vari√¢ncia do n√∫mero de viola√ß√µes pode ser maior do que o previsto pela distribui√ß√£o binomial sob a hip√≥tese de independ√™ncia.*
    
  *Proof:*
  
    I. **Initial Setup**:
        - Assume that the violations are positively autocorrelated, so that violations tend to cluster together.
        - Let $X_i$ be indicator variables such that $X_i = 1$ if there is a violation at time $i$ and 0 otherwise.
        - Let the number of violations be given by $V=\sum_{i=1}^N X_i$.
        
    II. **Main Logical Steps**:
        - If the violations were independent, then we could calculate the variance of the total number of violations using the fact that it follows a binomial distribution (as shown in Corol√°rio 1.2). In that case, $Var[V] = N(1-\alpha)\alpha$.
        - However, because of autocorrelation, the $X_i$ are not independent. The variance of the sum of correlated random variables is not the sum of the variances.
        - If $\text{Cov}(X_i,X_j) > 0$ for at least some $i \neq j$, then $Var[\sum X_i] > \sum Var[X_i]$.
        - The autocorrelation causes $\text{Cov}(X_i,X_j) > 0$, implying that the variance of the sum will be greater than if the $X_i$ were independent.

   III. **Key Transformations**:
       - Autocorrelation $\implies \text{Cov}(X_i,X_j) > 0$.
       -  $\text{Cov}(X_i,X_j) > 0$  $\implies$  $Var[\sum X_i] > \sum Var[X_i]$
       - $Var[\sum X_i] > \sum Var[X_i]$ $\implies$ $Var[V] > N(1-\alpha)\alpha$

   IV. **Conclusion**:
      -  The presence of autocorrelation increases the variance of the sum of violations over the case with independent variables.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
>  Usando o exemplo de 252 observa√ß√µes com $\alpha = 0.95$, sob a hip√≥tese de independ√™ncia, a vari√¢ncia do n√∫mero de viola√ß√µes √© de 11.97. No entanto, se houver autocorrela√ß√£o positiva, a vari√¢ncia real das viola√ß√µes pode ser muito maior. Por exemplo, se as viola√ß√µes ocorrem em *clusters*, a vari√¢ncia poderia ser 20 ou at√© mais. Isso significa que as viola√ß√µes ser√£o mais vari√°veis do que o esperado sob o modelo binomial, e o modelo de VAR pode estar subestimando o risco.
   
**Teorema 2**
 *O teste de Kupiec √© um teste de hip√≥tese para verificar se a frequ√™ncia de viola√ß√µes do VAR √© estatisticamente diferente do esperado dado o n√≠vel de confian√ßa $\alpha$. Ele testa a hip√≥tese nula de que a frequ√™ncia de viola√ß√µes observada √© consistente com a frequ√™ncia esperada sob um modelo bem calibrado.*

 *Proof:*
    I. **Initial Setup**:
      - The null hypothesis ($H_0$) is that the model is well-calibrated, i.e., the observed violation rate matches the expected violation rate.
      - The alternative hypothesis ($H_1$) is that the model is not well-calibrated, i.e., the observed violation rate is different from the expected rate.
      - Let $V$ be the observed number of violations, $N$ the number of independent observations, and $\alpha$ the confidence level.
      - We know that if the model is well-calibrated, the number of violations follows a binomial distribution $V \sim Bin(N, 1-\alpha)$.
      
    II. **Main Logical Steps**:
      -  The Kupiec test uses a likelihood ratio test to compare the likelihood under the null hypothesis (where $p = 1-\alpha$) with the likelihood of a model that admits a free violation probability $\hat{p}$ estimated from data (observed frequency of violations, i.e., $\hat{p} = V/N$).
      - The likelihood ratio statistic is constructed based on the binomial distribution.
      - The statistic is asymptotically chi-squared distributed, which allows for the construction of the test.
      
    III. **Key Transformations**:
      - Let $p$ be the expected probability of violation under the null hypothesis $p = 1-\alpha$.
      - The likelihood function is given by $L(p) = \binom{N}{V} p^V (1-p)^{N-V}$.
      - The test statistic is given by $-2ln\frac{L(1-\alpha)}{L(\hat{p})}$.
      - Under the null hypothesis, this statistic converges in distribution to a $\chi^2(1)$.

    IV. **Conclusion**:
      -  The Kupiec test checks if the frequency of violations is statistically different from that expected under the well-calibrated model hypothesis, using the distribution of the violations implied by a model with binomial violations. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que em 252 dias com um n√≠vel de confian√ßa de 95%, um modelo VAR tenha apresentado 20 viola√ß√µes. Sob a hip√≥tese nula de que o modelo est√° bem calibrado, o n√∫mero esperado de viola√ß√µes √© de 12.6. O teste de Kupiec calcula uma estat√≠stica de teste que compara a probabilidade de observar 20 viola√ß√µes se o modelo estiver bem calibrado com a probabilidade de observar 20 viola√ß√µes com a probabilidade de viola√ß√£o observada nos dados (20/252). Essa estat√≠stica de teste segue uma distribui√ß√£o $\chi^2$ com 1 grau de liberdade. Se o valor da estat√≠stica de teste for muito alto (e o p-valor correspondente for baixo), rejeita-se a hip√≥tese de que o modelo est√° bem calibrado e conclui-se que o modelo est√° subestimando o risco.
 
 **Lema 4**
 *O teste de Christoffersen testa se as viola√ß√µes do VAR s√£o independentes ao longo do tempo, e, portanto, se h√° *clusters* de viola√ß√µes. Ele testa a hip√≥tese nula de independ√™ncia das viola√ß√µes contra a hip√≥tese alternativa de que as viola√ß√µes seguem um processo de Markov de primeira ordem.*

    *Proof:*
    I. **Initial Setup**:
         - Null Hypothesis $H_0$: The violations are independent over time.
         - Alternative Hypothesis $H_1$: The violations follow a first-order Markov process (i.e., the probability of a violation depends on whether the previous observation was a violation or not).
         - $X_t$ is an indicator variable that is 1 if a violation occurs at time t, and 0 otherwise.

    II. **Main Logical Steps**:
         -  The Christoffersen test examines the transitions between violation and no-violation states using a likelihood ratio test.
         - Under $H_0$, the probability of a violation at time $t$ is independent of the occurrence of a violation at time $t-1$.
         - Under $H_1$, the probability of a violation depends on whether there was a violation in the previous period.
         - This dependence is expressed using a transition matrix:
        $$
        \begin{bmatrix}
          \pi_{00} & \pi_{01} \\
          \pi_{10} & \pi_{11}
        \end{bmatrix}
        $$
         where $\pi_{ij}$ is the probability of observing $X_t=j$ given $X_{t-1} = i$.
        
    III. **Key Transformations**:
         - The likelihood function under the null hypothesis (independence) is compared to the likelihood under the alternative hypothesis (Markov model).
         - The likelihood ratio is used to evaluate if the alternative hypothesis fits the data significantly better than the null hypothesis.
         - The test statistic is asymptotically chi-squared distributed.
        
    IV. **Conclusion**:
         -  The Christoffersen test determines if the observed transitions between violations and no-violations are consistent with the assumption of independence (i.e., if violations are clustered). ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que temos 252 dias de dados, e as viola√ß√µes do VAR ocorrem em sequ√™ncia. Por exemplo, se tivermos uma viola√ß√£o no dia $t-1$, a probabilidade de ter uma viola√ß√£o no dia $t$ √© muito maior do que se n√£o tivermos uma viola√ß√£o no dia $t-1$. O teste de Christoffersen verifica se essas transi√ß√µes entre estados (viola√ß√£o/n√£o-viola√ß√£o) s√£o estatisticamente significativas e inconsistentes com a hip√≥tese de independ√™ncia. Ele estima a matriz de transi√ß√£o e compara a probabilidade de os dados terem sido gerados por uma cadeia de Markov ou por um processo independente, calculando uma estat√≠stica de teste, que segue uma distribui√ß√£o $\chi^2$.

    
**Teorema 2.1**
    *O teste de Christoffersen tamb√©m avalia se a frequ√™ncia de viola√ß√µes √© consistente com o n√≠vel de confian√ßa $\alpha$, simultaneamente com a avalia√ß√£o da independ√™ncia das viola√ß√µes.*

    *Proof:*
        I. **Initial Setup**:
            - The null hypothesis for the Christoffersen test is that the model is well-calibrated and that the violations are independent of each other.
            - The alternative hypothesis is that either the violation frequency is not correct or the violations are not independent.
            -  The null hypothesis is given by $H_0: \pi_{01}=\pi_{11} = 1-\alpha$.

        II. **Main Logical Steps**:
            - The Christoffersen test is actually a joint test. It is composed of two likelihood ratio (LR) tests.
            -  The first LR test looks at whether the frequency of violations is compatible with the confidence level $\alpha$. This part of the test does not test independence.
            - The second LR test checks if there is statistical evidence of dependence on the previous state. This second test checks independence.
            - If we reject the null hypothesis in the Christoffersen test, it means that the data is incompatible with the assumption that the violations are both independent and have the correct frequency.
            
        III. **Key Transformations**:
            - The first test checks if $\pi_{01}=\pi_{11}=1-\alpha$ jointly. If not, then either the frequency or the independence is rejected.
            - The second test checks the independence of the violations, by testing if $\pi_{01}=\pi_{11}$.
            - The combination of both tests gives the Christoffersen test statistic.
            
        IV. **Conclusion**:
            -  Because of the structure of the test, the Christoffersen test assesses both the frequency of violations and the independence of the violations simultaneously. Therefore, it assesses if both the frequency of violations is consistent with $\alpha$ and if the violations are independent of each other, simultaneously.  ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Continuando o exemplo anterior, o teste de Christoffersen n√£o apenas verifica se a frequ√™ncia de viola√ß√µes √© aproximadamente 5% (se $\alpha=0.95$), mas tamb√©m se a ocorr√™ncia de uma viola√ß√£o em um dia aumenta a probabilidade de uma viola√ß√£o no dia seguinte. Ele faz isso de forma simult√¢nea. Isso √© especialmente importante porque um modelo pode ter a frequ√™ncia de viola√ß√µes correta, mas as viola√ß√µes ocorrem em *clusters*, o que o teste de Christoffersen √© capaz de detectar.
    
**Proposi√ß√£o 5**
   *Al√©m do teste de Kupiec e do teste de Christoffersen, existem outros testes de *backtesting* como o teste de Lopez, o teste de correla√ß√£o serial, e testes baseados em fun√ß√µes de perda, que podem complementar a an√°lise do desempenho do modelo VAR.*
   *Proof:*
        I. **Initial Setup**:
            - The Kupiec and Christoffersen tests are not exhaustive.
            - There are other ways to evaluate a VAR model through backtesting.
        II. **Main Logical Steps**:
            - The Lopez test assesses the magnitude of losses that violate the VAR, not just the frequency. It uses a loss function that considers both the number and the size of the violations.
            - Tests of serial correlation can detect if violations cluster or are predictable, which is undesirable. For example, the Ljung-Box test.
            - Test based on loss functions (such as the tick loss) can be tailored to capture specific properties that are relevant for the user.
        III. **Key Transformations**:
             - The Lopez test, tests of serial correlation, and loss function-based tests provide additional tests that measure aspects of the VAR model not assessed by the Kupiec and Christoffersen test.
       IV. **Conclusion**:
            -  These other tests are useful to evaluate if the VAR model is adequate to a certain situation, and offer a more complete picture of the VAR model‚Äôs quality. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que o teste de Kupiec tenha aprovado um modelo VAR com um n√≠vel de confian√ßa de 95% mas o teste de Christoffersen tenha rejeitado o modelo por apresentar autocorrela√ß√£o. Nesse caso, podemos aplicar outros testes de *backtesting*. Por exemplo, o teste de Lopez poder√° apontar
que as viola√ß√µes do VAR s√£o muito maiores do que o esperado. Um teste de correla√ß√£o serial poder√° confirmar que as viola√ß√µes est√£o clusterizadas. Um teste baseado em fun√ß√µes de perda poder√° indicar que as perdas acima do### Model Backtesting and Horizon Selection in VAR

### Introdu√ß√£o
Em continuidade ao estudo do Value at Risk (VAR) e suas aplica√ß√µes, este cap√≠tulo aborda um aspecto crucial para a valida√ß√£o e confiabilidade dos modelos: o *backtesting*. Como vimos anteriormente, o VAR √© uma medida de risco que resume a potencial perda em um determinado horizonte de tempo e n√≠vel de confian√ßa [^1]. No entanto, a precis√£o do VAR depende da qualidade dos dados e da adequa√ß√£o do modelo utilizado. O *backtesting* √© uma ferramenta essencial para avaliar a performance de um modelo VAR e identificar poss√≠veis vieses nas previs√µes [^1]. Esta se√ß√£o se aprofundar√° nos crit√©rios para realizar o *backtesting*, com foco especial na import√¢ncia do horizonte de tempo na efic√°cia dos testes.

### Conceitos Fundamentais
O *backtesting* consiste em comparar sistematicamente as previs√µes de perdas obtidas por meio do VAR com as perdas e lucros (P&L) efetivamente realizados posteriormente [^1]. O objetivo principal do *backtesting* √© detectar vieses ou inconsist√™ncias nos resultados do VAR, garantindo que o modelo esteja gerando previs√µes confi√°veis. A ideia central √© que um modelo VAR bem calibrado deve ser capaz de prever a frequ√™ncia com que as perdas efetivas excedem o VAR previsto, alinhando-se com o n√≠vel de confian√ßa estabelecido [^2].

Para realizar um *backtesting* eficaz, √© fundamental levar em considera√ß√£o o horizonte de tempo utilizado no c√°lculo do VAR. A escolha do horizonte de tempo influencia diretamente o n√∫mero de observa√ß√µes independentes dispon√≠veis para o teste, afetando o poder estat√≠stico do mesmo [^1]. O poder de um teste refere-se √† sua capacidade de detectar desvios significativos entre as previs√µes do VAR e os resultados reais.

Como mencionado anteriormente, o horizonte de tempo √© um dos fatores quantitativos que influenciam o c√°lculo do VAR. Em geral, um horizonte mais longo leva a um VAR maior. Ao usar o VAR como uma medida de risco potencial, o horizonte de tempo deve ser definido pela liquidez dos ativos, ou seja, o tempo necess√°rio para liquidar o portf√≥lio sem grandes impactos no mercado [^1].

#### O Impacto do Horizonte de Tempo no Backtesting
A escolha do horizonte de tempo tem um impacto significativo no n√∫mero de observa√ß√µes independentes dispon√≠veis para o *backtesting*. Um horizonte mais longo reduz o n√∫mero de observa√ß√µes independentes em um determinado per√≠odo. Por exemplo, se utilizarmos um horizonte de VAR de duas semanas, teremos apenas 26 observa√ß√µes independentes por ano [^1]. Por outro lado, um horizonte de um dia fornecer√° aproximadamente 252 observa√ß√µes independentes ao longo de um ano [^1].

O poder do teste, ou seja, a capacidade de detectar vieses no modelo, est√° diretamente relacionado ao n√∫mero de observa√ß√µes independentes. Com um n√∫mero maior de observa√ß√µes, o teste se torna mais sens√≠vel a desvios entre as previs√µes do VAR e as perdas efetivas [^1]. Por isso, para fins de *backtesting*, √© prefer√≠vel utilizar horizontes de tempo mais curtos, como um dia, para maximizar o poder dos testes [^1].

**Proposi√ß√£o 1**
   *A escolha de um horizonte de tempo $h$ para o c√°lculo do VAR implica que, em um per√≠odo de $T$ dias, temos aproximadamente $T/h$ observa√ß√µes independentes. Para um dado per√≠odo de tempo $T$, o n√∫mero de observa√ß√µes independentes √© inversamente proporcional ao tamanho do horizonte $h$.*
   
   *Proof:*

   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Each observation period for the VAR spans $h$ days.

   II. **Main Logical Steps**:
      - The total number of days, $T$, is divided by the length of each observation period, $h$, to determine the number of non-overlapping observation periods.
      - This gives the number of independent observations.

   III. **Key Transformations**:
      -  Number of independent observations $\approx \frac{T}{h}$

   IV. **Conclusion**:
      - As $h$ increases, $T/h$ decreases, implying an inverse relationship between $h$ and the number of independent observations for a fixed $T$.
      - This proves the statement: "the number of independent observations is inversely proportional to the size of the horizon $h$". ‚ñ†
> üí° **Exemplo Num√©rico:**
> Suponha que temos um per√≠odo de $T = 252$ dias (um ano de negocia√ß√£o). Se usarmos um horizonte de tempo $h = 1$ dia, teremos aproximadamente $252/1 = 252$ observa√ß√µes independentes. Se aumentarmos o horizonte para $h = 5$ dias (uma semana), teremos $252/5 \approx 50$ observa√ß√µes independentes. E se o horizonte for $h=21$ (aproximadamente um m√™s), teremos $252/21=12$ observa√ß√µes independentes. Este exemplo ilustra claramente a rela√ß√£o inversa entre o horizonte de tempo e o n√∫mero de observa√ß√µes independentes.

#### Rela√ß√£o com o N√≠vel de Confian√ßa
√â importante notar que o n√≠vel de confian√ßa tamb√©m influencia o n√∫mero de observa√ß√µes na cauda da distribui√ß√£o. N√≠veis de confian√ßa mais altos, como 99%, resultam em menos observa√ß√µes na cauda, dificultando a identifica√ß√£o de vieses no modelo. Em outras palavras, para confirmar a validade do modelo com um n√≠vel de confian√ßa de 99%, seria necess√°rio um longo per√≠odo de observa√ß√µes para coletar dados suficientes na cauda da distribui√ß√£o [^1]. Por isso, para o *backtesting*, n√≠veis de confian√ßa mais baixos, como 95%, podem ser prefer√≠veis, permitindo uma an√°lise mais frequente dos resultados do modelo [^1].

**Lema 1**
   *Para um n√≠vel de confian√ßa $\alpha$, o n√∫mero de observa√ß√µes esperadas na cauda da distribui√ß√£o em um per√≠odo $T$ com horizonte de tempo $h$ √© aproximadamente $(1-\alpha)T/h$.*

   *Proof:*
   I. **Initial Setup**:
      - Let $T$ be the total number of days in the period.
      - Let $h$ be the length of the time horizon in days.
      - Let $\alpha$ be the confidence level.
      - The number of independent observations is approximately $T/h$.

   II. **Main Logical Steps**:
       - With a confidence level $\alpha$, the probability of an observation falling in the tail (exceeding the VAR) is $1 - \alpha$.
       - The expected number of observations in the tail is the product of the number of independent observations and the probability of falling in the tail.

   III. **Key Transformations**:
        - Expected number of observations in the tail $\approx \frac{T}{h} \times (1-\alpha) = (1-\alpha) \frac{T}{h}$

   IV. **Conclusion**:
      - This shows that the expected number of observations in the tail is approximately $(1-\alpha)T/h$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Usando o exemplo anterior com $T=252$ dias e um horizonte de $h=1$ dia, se o n√≠vel de confian√ßa for $\alpha = 0.95$ (95%), o n√∫mero esperado de observa√ß√µes na cauda √© $(1-0.95) \times 252/1 = 0.05 \times 252 = 12.6$. Isso significa que, em m√©dia, esperamos que o VAR seja violado aproximadamente 12 ou 13 vezes em um ano. Se o n√≠vel de confian√ßa for $\alpha=0.99$, o n√∫mero esperado de viola√ß√µes cai para $(1-0.99) \times 252 = 0.01 \times 252 = 2.52$, indicando que seria necess√°rio um per√≠odo muito maior de observa√ß√µes para testar o modelo de forma eficaz. Se, por outro lado, mantemos o n√≠vel de confian√ßa em 95% mas aumentamos o horizonte para $h=5$, o n√∫mero de observa√ß√µes na cauda ser√° $(1-0.95)\times 252/5 \approx 2.5$.
  
**Corol√°rio 1.1**
   *O n√∫mero de observa√ß√µes na cauda √© diretamente proporcional ao per√≠odo $T$ e inversamente proporcional ao horizonte $h$, e diminui com o aumento do n√≠vel de confian√ßa $\alpha$.*

   *Proof:*
   I. **Initial Setup**:
       - From Lema 1, the number of observations in the tail is approximately $(1-\alpha)T/h$.

   II. **Main Logical Steps**:
       - We analyze the effect of $T$, $h$, and $\alpha$ on this expression.

   III. **Key Transformations**:
        - As $T$ increases, the number of observations in the tail increases proportionally.
        - As $h$ increases, the number of observations in the tail decreases proportionally.
        - As $\alpha$ increases, $(1-\alpha)$ decreases, thus decreasing the number of observations in the tail.

   IV. **Conclusion**:
        -  This confirms the statement that the number of tail observations is directly proportional to $T$, inversely proportional to $h$, and decreases with an increase in $\alpha$. ‚ñ†

Al√©m disso, vale ressaltar que a escolha do n√≠vel de confian√ßa afeta o tipo de erros que o *backtesting* ser√° capaz de detectar. Um n√≠vel de confian√ßa mais alto prioriza a detec√ß√£o de erros na cauda da distribui√ß√£o, enquanto um n√≠vel de confian√ßa mais baixo permite uma detec√ß√£o mais frequente de erros, ainda que menos extremos.

**Proposi√ß√£o 2**
    *Um n√≠vel de confian√ßa mais baixo aumenta a frequ√™ncia com que os resultados do VAR s√£o comparados com os retornos realizados, e, consequentemente, aumenta a sensibilidade a potenciais vieses no modelo.*
  
  *Proof:*

  I. **Initial Setup**:
    - Let $\alpha$ be the confidence level.
    - A lower confidence level implies a smaller $\alpha$.
    - VAR is calculated for a given confidence level.

  II. **Main Logical Steps**:
    - A lower confidence level (smaller $\alpha$) corresponds to a lower VAR value (since the VAR is a quantile).
    - A lower VAR value means a greater chance of actual losses exceeding the VAR.
    - If the actual loss exceeds the VAR value, this is considered a violation in the backtesting process.
    - More violations mean more comparisons between VAR and actual returns.

  III. **Key Transformations**:
    - Lower $\alpha$  $\implies$ Lower VAR
    - Lower VAR $\implies$ More violations
    - More violations $\implies$ More frequent comparisons between VAR and actual returns

  IV. **Conclusion**:
    - This demonstrates that a lower confidence level results in more frequent comparisons between VAR predictions and actual returns. Therefore, the sensitivity of the backtesting to potential biases in the model increases.‚ñ†

> üí° **Exemplo Num√©rico:**
> Considere um modelo VAR com um horizonte de um dia ($h=1$). Se o n√≠vel de confian√ßa for $\alpha = 0.99$, espera-se que as viola√ß√µes sejam raras, e a cada 100 dias de negocia√ß√£o, apenas 1 dia, em m√©dia, apresentar√° uma perda que ultrapassa o VAR. Se o n√≠vel de confian√ßa for reduzido para $\alpha=0.95$, as viola√ß√µes tornam-se mais frequentes, com uma m√©dia de 5 dias a cada 100, e isso permite uma an√°lise mais detalhada e frequente do modelo.

**Teorema 1**
*Existe um trade-off entre o horizonte de tempo $h$ e o n√≠vel de confian√ßa $\alpha$ no *backtesting*. Diminuir $h$ aumenta o n√∫mero de observa√ß√µes independentes e, portanto, o poder do teste, enquanto diminuir $\alpha$ aumenta a frequ√™ncia de viola√ß√µes do VAR e, tamb√©m, aumenta o poder do teste.*
 *Proof:*
    I. **Initial Setup**:
        - The power of a backtesting test is directly related to the number of independent observations and the frequency of violations.
    
    II. **Main Logical Steps**:
         - From Proposi√ß√£o 1, reducing the time horizon $h$ increases the number of independent observations. An increase in independent observations leads to an increase in the power of the test.
         - From Proposi√ß√£o 2, reducing the confidence level $\alpha$ increases the frequency of violations. More frequent violations increase the data available to backtest, increasing the power of the test.
        
    III. **Key Transformations**:
        - $h \downarrow \implies \text{Number of Independent Observations} \uparrow \implies \text{Test Power} \uparrow$
        - $\alpha \downarrow \implies \text{Frequency of Violations} \uparrow \implies \text{Test Power} \uparrow$

    IV. **Conclusion**:
        - The theorem states that there is a trade-off. Both lowering $h$ and $\alpha$ increase the power of the backtest, supporting the claim. Therefore, this proves the existence of the trade-off.‚ñ†

**Lema 2**
*Seja $N$ o n√∫mero de observa√ß√µes independentes, e seja $X_i$ uma vari√°vel indicadora que vale 1 se a perda observada no per√≠odo $i$ excede o VAR previsto e 0 caso contr√°rio. Se o modelo VAR estiver bem calibrado, ent√£o $X_i$ s√£o vari√°veis aleat√≥rias independentes de Bernoulli com probabilidade de sucesso $1 - \alpha$.*

*Proof:*
   I. **Initial Setup**:
       - $N$ is the number of independent observations.
       - $X_i$ is an indicator variable, where $X_i = 1$ if the loss exceeds the predicted VAR at time $i$, and $X_i = 0$ otherwise.
       - $\alpha$ is the confidence level of the VAR.
       - A well-calibrated VAR model has a probability of $1-\alpha$ of the loss exceeding the VAR.
       - We assume independence between observations.

   II. **Main Logical Steps**:
       - For each observation $i$, there are only two outcomes: the loss exceeds the VAR ($X_i = 1$) or the loss does not exceed the VAR ($X_i = 0$).
       - Under a well-calibrated model, the probability of $X_i = 1$ (a loss exceeding the VAR) is $1 - \alpha$.
       - This is precisely the definition of a Bernoulli trial with a success probability of $1-\alpha$.
       - The independence of the $X_i$ variables comes from the assumption of independence of observations.

   III. **Key Transformations**:
       - $P(X_i=1) = 1-\alpha$.

   IV. **Conclusion**:
       - The variables $X_i$ are independent and follow a Bernoulli distribution with success probability $1-\alpha$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Vamos supor que estamos analisando 252 dias de negocia√ß√£o com um n√≠vel de confian√ßa de 95% ($\alpha=0.95$). Para cada dia $i$, definimos $X_i = 1$ se a perda naquele dia excedeu o VAR previsto e $X_i = 0$ caso contr√°rio. Se o modelo estiver bem calibrado, cada $X_i$ √© uma vari√°vel de Bernoulli com $p = 1 - 0.95 = 0.05$. Isso significa que a probabilidade de uma viola√ß√£o em qualquer dia √© de 5%.

**Teorema 1.1**
*Sob as condi√ß√µes do Lema 2, o n√∫mero de viola√ß√µes do VAR, $V = \sum_{i=1}^N X_i$, segue uma distribui√ß√£o binomial com par√¢metros $N$ e $1-\alpha$, ou seja, $V \sim Bin(N, 1 - \alpha)$.*

*Proof:*
   I. **Initial Setup**:
      - From Lema 2, $X_i$ are independent Bernoulli random variables with success probability $1-\alpha$.
      - $V$ is defined as the sum of these Bernoulli variables: $V = \sum_{i=1}^N X_i$.

   II. **Main Logical Steps**:
      - The sum of $N$ independent Bernoulli random variables with the same success probability follows a binomial distribution.
      - The parameters of the binomial distribution are $N$ (the number of trials) and $1-\alpha$ (the success probability).

   III. **Key Transformations**:
      - $V = \sum_{i=1}^N X_i \implies V \sim Bin(N, 1 - \alpha)$

   IV. **Conclusion**:
      - Therefore, the number of violations $V$ follows a binomial distribution with parameters $N$ and $1-\alpha$. ‚ñ†
> üí° **Exemplo Num√©rico:**
> Continuando o exemplo anterior, onde temos 252 observa√ß√µes independentes ($N=252$) e $\alpha = 0.95$, o n√∫mero total de viola√ß√µes $V$ segue uma distribui√ß√£o binomial com par√¢metros $N=252$ e $p=0.05$, ou seja, $V \sim Bin(252, 0.05)$. Isso nos permite calcular a probabilidade de observar um n√∫mero espec√≠fico de viola√ß√µes, assumindo que o modelo VAR est√° bem calibrado.

**Corol√°rio 1.2**
*A m√©dia e a vari√¢ncia do n√∫mero de viola√ß√µes $V$ s√£o dadas por $E[V] = N(1-\alpha)$ e $Var[V] = N(1-\alpha)\alpha$.*

*Proof:*
   I. **Initial Setup**:
      - From Theorem 1.1, $V \sim Bin(N, 1-\alpha)$.
      - We recall the mean and variance of a binomial distribution.
   II. **Main Logical Steps**:
        - The expected value (mean) of a binomial distribution $Bin(n,p)$ is given by $E[V]=np$.
        - The variance of a binomial distribution $Bin(n,p)$ is given by $Var[V]=np(1-p)$.
   III. **Key Transformations**:
      - Substituting $n = N$ and $p = 1 - \alpha$, we have
      -  $E[V] = N(1-\alpha)$.
      - $Var[V] = N(1-\alpha)(1-(1-\alpha)) = N(1-\alpha)\alpha$.

   IV. **Conclusion**:
     -  This shows that the mean and the variance of $V$ are given by $E[V] = N(1-\alpha)$ and $Var[V] = N(1-\alpha)\alpha$, respectively. ‚ñ†

> üí° **Exemplo Num√©rico:**
> No mesmo exemplo, com $N=252$ e $\alpha=0.95$, a m√©dia do n√∫mero de viola√ß√µes √© $E[V] = 252 \times (1 - 0.95) = 252 \times 0.05 = 12.6$, e a vari√¢ncia √© $Var[V] = 252 \times 0.05 \times 0.95 = 11.97$. Isso significa que, em m√©dia, esperamos 12.6 viola√ß√µes, com uma variabilidade em torno desse valor, quantificada pela vari√¢ncia.

Al√©m disso, √© crucial considerar a autocorrela√ß√£o das perdas. Se as perdas em per√≠odos sucessivos forem correlacionadas, a suposi√ß√£o de independ√™ncia das observa√ß√µes pode ser violada, comprometendo a validade do *backtesting*.

**Proposi√ß√£o 3**
    *A autocorrela√ß√£o positiva das perdas pode levar a um excesso de viola√ß√µes do VAR em clusters, o que pode reduzir o poder de um *backtesting* que assume independ√™ncia das observa√ß√µes.*
    *Proof:*
       I. **Initial Setup**:
        -  Assume positive autocorrelation in losses.
        -  Assume that we are using a backtesting method that assumes independence.
        
       II. **Main Logical Steps**:
           - Positive autocorrelation implies that if a loss exceeds the VAR in a given period, the probability of a loss exceeding the VAR in the next period is higher than expected under independence.
           - This causes violations to occur in clusters, i.e. if one violation occurs, the probability of seeing more violations in close succession is higher.
           - When violations cluster, the assumption of independent Bernoulli trials underlying most backtesting procedures is violated.
           - The methods assume that the number of violations is a realization of a binomial distribution, which does not hold under autocorrelation.
           - Since the number of observations is reduced, a clustered violation process has less power than an independent violation process.

       III. **Key Transformations**:
           - Autocorrelation $\implies$ violation clusters
           - Clusters $\implies$ violation of independence
           - Violation of independence $\implies$ Reduction in the power of the test

       IV. **Conclusion**:
        - Therefore, positive autocorrelation can lead to clustered violations, and reduce the effectiveness of backtesting.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
> Suponha que as perdas do dia atual sejam positivamente correlacionadas com as perdas do dia anterior. Se o VAR for violado hoje, √© mais prov√°vel que ele seja violado amanh√£ tamb√©m. Isso cria *clusters* de viola√ß√µes, onde v√°rios dias consecutivos apresentam perdas acima do VAR, em vez de viola√ß√µes aleat√≥rias e independentes. Um modelo que ignora essa autocorrela√ß√£o pode n√£o capturar a din√¢mica real do risco.
    
**Lema 3**
*Para detectar a presen√ßa de autocorrela√ß√£o nas viola√ß√µes do VAR, pode-se realizar um teste de raz√£o de verossimilhan√ßa (LR) de independ√™ncia de viola√ß√µes, ou similar, como o teste de Kupiec ou Christoffersen.*

    *Proof:*
     I. **Initial Setup**:
          - We want to detect if there is autocorrelation in the violations of the VAR model.
          - We know that violations of a well-calibrated VAR should be independent events.

     II. **Main Logical Steps**:
          - The test of the likelihood ratio (LR) is designed to test the hypothesis that the distribution of the violations is independent.
          - The Kupiec test checks if the overall violation rate is consistent with the confidence level, implicitly assuming independence over time.
          - The Christoffersen test is specifically designed to test for both correct violation rate and independence over time.

     III. **Key Transformations**:
          - These tests check the null hypothesis of independence against the alternative of an autocorrelation in the violations.

     IV. **Conclusion**:
          -  The LR test and specific tests such as Kupiec and Christoffersen can all detect the presence of autocorrelation, supporting the claim. ‚ñ†
> üí° **Exemplo Num√©rico:**
>  Se os resultados do *backtesting* mostram uma sequ√™ncia de viola√ß√µes em dias pr√≥ximos (por exemplo, viola√ß√µes nos dias 1, 2, 3, e depois nenhuma viola√ß√£o por v√°rias semanas, e em seguida viola√ß√µes nos dias 45 e 46) isso levanta suspeitas de autocorrela√ß√£o. Testes como o de Christoffersen ajudam a quantificar essa suspeita, e a verificar se os *clusters* de viola√ß√£o s√£o estatisticamente significativos ou apenas devidos ao acaso.

**Proposi√ß√£o 4**
    *A presen√ßa de *clusters* de viola√ß√µes, causada por autocorrela√ß√£o, implica que a vari√¢ncia do n√∫mero de viola√ß√µes pode ser maior do que o previsto pela distribui√ß√£o binomial sob a hip√≥tese de independ√™ncia.*
    
  *Proof:*
  
    I. **Initial Setup**:
        - Assume that the violations are positively autocorrelated, so that violations tend to cluster together.
        - Let $X_i$ be indicator variables such that $X_i = 1$ if there is a violation at time $i$ and 0 otherwise.
        - Let the number of violations be given by $V=\sum_{i=1}^N X_i$.
        
    II. **Main Logical Steps**:
        - If the violations were independent, then we could calculate the variance of the total number of violations using the fact that it follows a binomial distribution (as shown in Corol√°rio 1.2). In that case, $Var[V] = N(1-\alpha)\alpha$.
        - However, because of autocorrelation, the $X_i$ are not independent. The variance of the sum of correlated random variables is not the sum of the variances.
        - If $\text{Cov}(X_i,X_j) > 0$ for at least some $i \neq j$, then $Var[\sum X_i] > \sum Var[X_i]$.
        - The autocorrelation causes $\text{Cov}(X_i,X_j) > 0$, implying that the variance of the sum will be greater than if the $X_i$ were independent.

   III. **Key Transformations**:
       - Autocorrelation $\implies \text{Cov}(X_i,X_j) > 0$.
       -  $\text{Cov}(X_i,X_j) > 0$  $\implies$  $Var[\sum X_i] > \sum Var[X_i]$
       - $Var[\sum X_i] > \sum Var[X_i]$ $\implies$ $Var[V] > N(1-\alpha)\alpha$

   IV. **Conclusion**:
      -  The presence of autocorrelation increases the variance of the sum of violations over the case with independent variables.  ‚ñ†
    
> üí° **Exemplo Num√©rico:**
>  Usando o exemplo de 252 observa√ß√µes com $\alpha = 0.95$, sob a hip√≥tese de independ√™ncia, a vari√¢ncia do n√∫mero de viola√ß√µes √© de 11.97. No entanto, se houver autocorrela√ß√£o positiva, a vari√¢ncia real das viola√ß√µes pode ser muito maior. Por exemplo, se as viola√ß√µes ocorrem em *clusters*, a vari√¢ncia poderia ser 20 ou at√© mais. Isso significa que as viola√ß√µes ser√£o mais vari√°veis do que o esperado sob o modelo binomial, e o modelo de VAR pode estar subestimando o risco.
   
**Teorema 2**
 *O teste de Kupiec √© um teste de hip√≥tese para verificar se a frequ√™ncia de viola√ß√µes do VAR √© estatisticamente diferente do esperado dado o n√≠vel de confian√ßa $\alpha$. Ele testa a hip√≥tese nula de que a frequ√™ncia de viola√ß√µes observada √© consistente com a frequ√™ncia esperada sob um modelo bem calibrado.*

 *Proof:*
    I. **Initial Setup**:
      - The null hypothesis ($H_0$) is that the model is well-calibrated, i.e., the observed violation rate matches the expected violation rate.
      - The alternative hypothesis ($H_1$) is that the model is not well-calibrated, i.e., the observed violation rate is different from the expected rate.
      - Let $V$ be the observed number of violations, $N$ the number of independent observations, and $\alpha$ the confidence level.
      - We know that if the model is well-calibrated, the number of violations follows a binomial distribution $V \sim Bin(N, 1-\alpha)$.
      
    II. **Main Logical Steps**:
      -  The Kupiec test uses a likelihood ratio test to compare the likelihood under the null hypothesis (where $p = 1-\alpha$) with the likelihood of a model that admits a free violation probability $\hat{p}$ estimated from data (observed frequency of violations, i.e., $\hat{p} = V/N$).
      - The likelihood ratio statistic is constructed based on the binomial distribution.
      - The statistic is asymptotically chi-squared distributed, which allows for the construction of the test.
      
    III. **Key Transformations**:
      - Let $p$ be the expected probability of violation under the null hypothesis $p = 1-\alpha$.
      - The likelihood function is given by $L(p) = \binom{N}{V} p^V (1-p)^{N-V}$.
      - The test statistic is given by $-2ln\frac{L(1-\alpha)}{L(\hat{p})}$.
      - Under the null hypothesis, this statistic converges in distribution to a $\chi^2(1)$.

    IV. **Conclusion**:
      -  The Kupiec test checks if the frequency of violations is statistically different from that expected under the well-calibrated model hypothesis, using the distribution of the violations implied by a model with binomial violations. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que em 252 dias com um n√≠vel de confian√ßa de 95%, um modelo VAR tenha apresentado 20 viola√ß√µes. Sob a hip√≥tese nula de que o modelo est√° bem calibrado, o n√∫mero esperado de viola√ß√µes √© de 12.6. O teste de Kupiec calcula uma estat√≠stica de teste que compara a probabilidade de observar 20 viola√ß√µes se o modelo estiver bem calibrado com a probabilidade de observar 20 viola√ß√µes com a probabilidade de viola√ß√£o observada nos dados (20/252). Essa estat√≠stica de teste segue uma distribui√ß√£o $\chi^2$ com 1 grau de liberdade. Se o valor da estat√≠stica de teste for muito alto (e o p-valor correspondente for baixo), rejeita-se a hip√≥tese de que o modelo est√° bem calibrado e conclui-se que o modelo est√° subestimando o risco.
 
 **Lema 4**
 *O teste de Christoffersen testa se as viola√ß√µes do VAR s√£o independentes ao longo do tempo, e, portanto, se h√° *clusters* de viola√ß√µes. Ele testa a hip√≥tese nula de independ√™ncia das viola√ß√µes contra a hip√≥tese alternativa de que as viola√ß√µes seguem um processo de Markov de primeira ordem.*

    *Proof:*
    I. **Initial Setup**:
         - Null Hypothesis $H_0$: The violations are independent over time.
         - Alternative Hypothesis $H_1$: The violations follow a first-order Markov process (i.e., the probability of a violation depends on whether the previous observation was a violation or not).
         - $X_t$ is an indicator variable that is 1 if a violation occurs at time t, and 0 otherwise.

    II. **Main Logical Steps**:
         -  The Christoffersen test examines the transitions between violation and no-violation states using a likelihood ratio test.
         - Under $H_0$, the probability of a violation at time $t$ is independent of the occurrence of a violation at time $t-1$.
         - Under $H_1$, the probability of a violation depends on whether there was a violation in the previous period.
         - This dependence is expressed using a transition matrix:
        $$
        \begin{bmatrix}
          \pi_{00} & \pi_{01} \\
          \pi_{10} & \pi_{11}
        \end{bmatrix}
        $$
         where $\pi_{ij}$ is the probability of observing $X_t=j$ given $X_{t-1} = i$.
        
    III. **Key Transformations**:
         - The likelihood function under the null hypothesis (independence) is compared to the likelihood under the alternative hypothesis (Markov model).
         - The likelihood ratio is used to evaluate if the alternative hypothesis fits the data significantly better than the null hypothesis.
         - The test statistic is asymptotically chi-squared distributed.
        
    IV. **Conclusion**:
         -  The Christoffersen test determines if the observed transitions between violations and no-violations are consistent with the assumption of independence (i.e., if violations are clustered). ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que temos 252 dias de dados, e as viola√ß√µes do VAR ocorrem em sequ√™ncia. Por exemplo, se tivermos uma viola√ß√£o no dia $t-1$, a probabilidade de ter uma viola√ß√£o no dia $t$ √© muito maior do que se n√£o tivermos uma viola√ß√£o no dia $t-1$. O teste de Christoffersen verifica se essas transi√ß√µes entre estados (viola√ß√£o/n√£o-viola√ß√£o) s√£o estatisticamente significativas e inconsistentes com a hip√≥tese de independ√™ncia. Ele estima a matriz de transi√ß√£o e compara a probabilidade de os dados terem sido gerados por uma cadeia de Markov ou por um processo independente, calculando uma estat√≠stica de teste, que segue uma distribui√ß√£o $\chi^2$.

    
**Teorema 2.1**
    *O teste de Christoffersen tamb√©m avalia se a frequ√™ncia de viola√ß√µes √© consistente com o n√≠vel de confian√ßa $\alpha$, simultaneamente com a avalia√ß√£o da independ√™ncia das viola√ß√µes.*

    *Proof:*
        I. **Initial Setup**:
            - The null hypothesis for the Christoffersen test is that the model is well-calibrated and that the violations are independent of each other.
            - The alternative hypothesis is that either the violation frequency is not correct or the violations are not independent.
            -  The null hypothesis is given by $H_0: \pi_{01}=\pi_{11} = 1-\alpha$.

        II. **Main Logical Steps**:
            - The Christoffersen test is actually a joint test. It is composed of two likelihood ratio (LR) tests.
            -  The first LR test looks at whether the frequency of violations is compatible with the confidence level $\alpha$. This part of the test does not test independence.
            - The second LR test checks if there is statistical evidence of dependence on the previous state. This second test checks independence.
            - If we reject the null hypothesis in the Christoffersen test, it means that the data is incompatible with the assumption that the violations are both independent and have the correct frequency.
            
        III. **Key Transformations**:
            - The first test checks if $\pi_{01}=\pi_{11}=1-\alpha$ jointly. If not, then either the frequency or the independence is rejected.
            - The second test checks the independence of the violations, by testing if $\pi_{01}=\pi_{11}$.
            - The combination of both tests gives the Christoffersen test statistic.
            
        IV. **Conclusion**:
            -  Because of the structure of the test, the Christoffersen test assesses both the frequency of violations and the independence of the violations simultaneously. Therefore, it assesses if both the frequency of violations is consistent with $\alpha$ and if the violations are independent of each other, simultaneously.  ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Continuando o exemplo anterior, o teste de Christoffersen n√£o apenas verifica se a frequ√™ncia de viola√ß√µes √© aproximadamente 5% (se $\alpha=0.95$), mas tamb√©m se a ocorr√™ncia de uma viola√ß√£o em um dia aumenta a probabilidade de uma viola√ß√£o no dia seguinte. Ele faz isso de forma simult√¢nea. Isso √© especialmente importante porque um modelo pode ter a frequ√™ncia de viola√ß√µes correta, mas as viola√ß√µes ocorrem em *clusters*, o que o teste de Christoffersen √© capaz de detectar.
    
**Proposi√ß√£o 5**
   *Al√©m do teste de Kupiec e do teste de Christoffersen, existem outros testes de *backtesting* como o teste de Lopez, o teste de correla√ß√£o serial, e testes baseados em fun√ß√µes de perda, que podem complementar a an√°lise do desempenho do modelo VAR.*
   *Proof:*
        I. **Initial Setup**:
            - The Kupiec and Christoffersen tests are not exhaustive.
            - There are other ways to evaluate a VAR model through backtesting.
        II. **Main Logical Steps**:
            - The Lopez test assesses the magnitude of losses that violate the VAR, not just the frequency. It uses a loss function that considers both the number and the size of the violations.
            - Tests of serial correlation can detect if violations cluster or are predictable, which is undesirable. For example, the Ljung-Box test.
            - Test based on loss functions (such as the tick loss) can be tailored to capture specific properties that are relevant for the user.
        III. **Key Transformations**:
             - The Lopez test, tests of serial correlation, and loss function-based tests provide additional tests that measure aspects of the VAR model not assessed by the Kupiec and Christoffersen test.
       IV. **Conclusion**:
            -  These other tests are useful to evaluate if the VAR model is adequate to a certain situation, and offer a more complete picture of the VAR model‚Äôs quality. ‚ñ†

> üí° **Exemplo Num√©rico:**
>  Suponha que o teste de Kupiec tenha aprovado um modelo VAR com um n√≠vel de confian√ßa de 95% mas o teste de Christoffersen tenha rejeitado o modelo por apresentar autocorrela√ß√£o. Nesse caso, podemos aplicar outros testes de *backtesting*. Por exemplo, o teste de Lopez poder√° apontar
que as viola√ß√µes do VAR s√£o muito maiores do que o esperado. Um teste de correla√ß√£o serial poder√° confirmar que as viola√ß√µes est√£o clusterizadas. Um teste baseado em fun√ß√µes de perda poder√° indicar que as perdas acima do