## 1. Visão Geral do Problema

Queremos calcular, para cada *carteira* (identificada por `GroupAccountNumber`) em uma *data de referência* $AsOfDate$, uma medida de *Value at Risk* (VaR) usando **simulações Monte Carlo baseadas em modelos GARCH**. O modelo GARCH é calibrado com dados históricos. Em linhas gerais, o modelo:

1.  **Identifica** as posições (exposições $\Delta$ e $\Gamma$) de cada carteira em diversos *instrumentos* (ex: boi, milho, dólar) e *tenores* (dias até expirar).
2.  **Obtém** variações históricas de preços (*returns*) para cada instrumento e tenor ao longo de um *período de lookback* ($L$).
3.  **Ajusta (Fit)** um modelo GARCH (especificamente, GJR-GARCH(1,1) no código) para a série histórica de retornos de *cada* par (instrumento, tenor), capturando a volatilidade condicional e agrupamento (clustering) da volatilidade.
4.  **Simula** múltiplos caminhos futuros (*paths*) de retornos para cada (instrumento, tenor) usando os parâmetros GARCH ajustados, ao longo de um *horizonte de simulação* ($H$, igual ao `lookforward_period`).
5.  **Calcula** o *lucro e prejuízo (PnL)* hipotético diário (para cada dia $h$ de 1 a $H$) de cada posição, aplicando os *retornos simulados* às exposições $\Delta$ e $\Gamma$, considerando o ajuste de tenor para simular rolagens.
6.  **Agrega** o PnL por carteira, data de referência e dia do horizonte ($h$).
7.  **Forma** uma distribuição de PnLs simulados para cada $(k, \omega, h)$ através dos múltiplos caminhos de simulação.
8.  **Extrai** o VaR (quantil $\alpha$ da perda, ex: 1% ou 5%) dessa distribuição de PnLs simulados.

O resultado final é um valor que indica quanto, segundo as simulações GARCH calibradas no histórico, a carteira pode *perder* em condições adversas com probabilidade $\alpha$, para cada dia $h$ no futuro até o horizonte $H$.

------

## 2. Notação e Conjuntos Básicos

-   $\Omega$: Conjunto de *carteiras* (`GroupAccountNumber`).
-   $\mathcal{D} = \{t_1, t_2, \dots, t_n\}$: Conjunto de *datas de referência* (`AsOfDate`).
-   $\mathcal{I}$: Conjunto de *instrumentos* ("CORN BMF", "USD/BRL", etc.).
-   $\mathcal{T}$: Conjunto de *tenores* originais (dias até expirar) nas exposições.
-   $L$: *Horizonte de lookback* (em dias úteis, `lookback_period`) para obter retornos históricos e ajustar GARCH.
-   $H$: *Horizonte de simulação* ou *lookforward period* (em dias úteis, `lookforward_period`), máximo `HoldingPeriod`.
-   $N$: Número de caminhos de simulação Monte Carlo (`n_returns_paths`).
-   $\alpha$: Nível(is) de quantil(is) para o VaR (`alpha`).

**DataFrames Principais (Conceituais):**

1.  `exposures_df`: Contém $\Delta_{k,\omega,i,\tau}, \Gamma_{k,\omega,i,\tau}$ (Seção 3).
2.  `returns_df`: Contém retornos históricos $R_{d,i,\tau}$ (Seção 4).
3.  `garch_params_df`: Contém parâmetros GARCH ajustados $\Theta_{i,\tau}$ (Seção 5).
4.  `simulated_returns`: Contém retornos simulados $\tilde{R}_{p,h,i,\tau'}$ (Seção 7).
5.  `pnl_results`: Contém PnLs simulados $PnL_{p,k,\omega}(h)$ (Seção 8).
6.  `var_results`: Contém o VaR final $VaR_{\alpha}(k,\omega,h)$ (Seção 9).

------

## 3. Exposições (Delta e Gama)

Para cada carteira $\omega \in \Omega$ e data $AsOfDate = t_k \in \mathcal{D}$, o DataFrame `exposures_df` (gerado por `MurexExposures` ou `_convert_portfolios_to_exposures`) contém:

$\Delta_{k,\omega,i,\tau}, \quad \Gamma_{k,\omega,i,\tau}$

onde $i \in \mathcal{I}$ é o instrumento e $\tau \in \mathcal{T}$ é o tenor original.

-   $\Delta$: Exposição linear à variação de preço.
-   $\Gamma$: Exposição de segunda ordem (convexidade).

O *tamanho do contrato* $CS_i$ (coluna `contract_size`) é obtido via join com `risk_factors_file` (usando `MER_DENOMINADOR`) ou defaultado para 1.

**Código:** `MurexExposures.get_data` ou `_convert_portfolios_to_exposures`. A coluna `contract_size` é adicionada posteriormente no `predict`.

------

## 4. Retornos Históricos

Para cada instrumento $i \in \mathcal{I}$ e tenor $\tau$ relevante (gerado internamente pelo `MitraReturns` até `lookforward_period`), a classe `MitraReturns` calcula retornos históricos sobre um período de $L$ dias úteis (`lookback_period`). Seja $\{d_1, d_2, \ldots, d_L\}$ o conjunto de datas históricas.

O DataFrame `returns_df` contém:

$R_{d,i,\tau} = \text{retorno no dia histórico } d \text{ do instrumento } i \text{ para o tenor } \tau$.

O cálculo depende do instrumento (controlado por `instruments` config e `usd_adjust`):

-   **Retorno Absoluto** (ex: Commodities BMF, CBT):
    $R_{d,i,\tau} = P_{d,i,\tau} - P_{d-\tau,i,\tau}$ (ou similar, considerando ajuste de preço $P$ e fator `factor`). Se `usd_adjust=True`, o preço $P$ é ajustado pelo PTAX antes da diferença.
-   **Retorno Percentual** (ex: "USD/BRL"):
    $R_{d,\text{USD/BRL},\tau} = \frac{P_{d,\text{USD/BRL},\tau} - P_{d-\tau,\text{USD/BRL},\tau}}{P_{d,\text{USD/BRL},\tau}}$ (ou similar, como implementado `(price - price.shift(tenor)) / price`).

**Código:** `MitraReturns.get_data`. Ele busca dados de tabelas (`view_mitra_*`), aplica fatores, ajusta por USD se necessário, calcula retornos (absolutos ou percentuais) para cada `tenor` de 1 até `lookforward_period` e retorna um DataFrame `(date, tenor, Instrument, RETURN, key)`.

------

## 5. Ajuste (Fit) de Modelos GARCH

Este é um passo crucial que difere da simulação histórica pura. Para *cada* par (instrumento $i$, tenor $\tau$) presente em `returns_df`, o modelo ajusta um GJR-GARCH(1,1):

-   Modelo:
    $R_{d,i,\tau} = \mu_{i,\tau} + \epsilon_{d,i,\tau}$
    $\epsilon_{d,i,\tau} = \sigma_{d,i,\tau} z_{d,i,\tau}, \quad z_{d,i,\tau} \sim N(0, 1)$
    $\sigma^2_{d,i,\tau} = \omega_{i,\tau} + \alpha_{i,\tau} \epsilon^2_{d-1,i,\tau} + \gamma_{i,\tau} \epsilon^2_{d-1,i,\tau} \mathbb{I}(\epsilon_{d-1,i,\tau} < 0) + \beta_{i,\tau} \sigma^2_{d-1,i,\tau}$

-   Processo: A função `fit_custom_garch_models` agrupa os retornos históricos $R_{d,i,\tau}$ por $(i, \tau)$ e usa `fit_garch_for_group` (que chama `fit_custom_garch_model`) para estimar os parâmetros $\Theta_{i,\tau} = (\mu_{i,\tau}, \omega_{i,\tau}, \alpha_{i,\tau}, \gamma_{i,\tau}, \beta_{i,\tau})$.
-   Algoritmo de Ajuste: Utiliza um algoritmo BHHH customizado (`bhhh_step`, `compute_individual_gradients`, etc.) para maximizar a log-verossimilhança (`log_likelihood`). Parâmetros são inicializados (`initialize_params`) e restringidos (`constrain_params`) para garantir positividade e estacionariedade ($\alpha + \beta < 1$).
-   Paralelização: O ajuste para diferentes pares $(i, \tau)$ é feito em paralelo usando `joblib` com backend `spark`.

-   Output: Um DataFrame (Pandas `garch_params_pdf`, depois convertido para Spark `garch_params_df`) contendo os parâmetros $\Theta_{i,\tau}$ para cada $(i, \tau)$.

**Código:** `fit_custom_garch_models`, `fit_garch_for_group`, `fit_custom_garch_model`, `bhhh_step`, `constrain_params`, etc.

------

## 6. Holding Period e Ajuste de Tenores

Para calcular o PnL simulado ao longo do horizonte $H$, o modelo precisa mapear a exposição original (com tenor $\tau$) para o fator de risco relevante no dia $h$ do horizonte ($1 \le h \le H$). Isso é feito pela função `_get_adjusted_tenor`, que calcula um *tenor ajustado* $\tau'$.

-   Input: Tenor original $\tau$ da exposição, Holding Period $h$.
-   Output: Tenor ajustado $\tau' = \tau'(h, \tau)$.
-   Lógica (como implementada em `_get_adjusted_tenor`):
    $\tau'(h, \tau) = \begin{cases} h, & \text{if } \tau > h \\ \tau, & \text{if } \tau \le h \text{ and } (h \bmod \tau) = 0 \\ h \bmod \tau, & \text{if } \tau \le h \text{ and } (h \bmod \tau) \ne 0 \end{cases}$
    *(Nota: Assume-se $\tau > 0$ e $h \ge 1$)*

-   Propósito: Simula a "rolagem" de contratos. Se um contrato com tenor $\tau$ vence antes do dia $h$, assume-se que a exposição continua, mas agora ligada a um fator de risco com um tenor efetivo $\tau'$. O modelo GARCH para $(i, \tau')$ será usado para simular o retorno nesse dia.

**Código:** `_get_adjusted_tenor`, usado dentro de `_calculate_pnl_for_path`.

------

## 7. Simulação Monte Carlo dos Retornos (GARCH Paths)

Usando os parâmetros GARCH ajustados $\Theta_{i,\tau'}$ (onde $\tau'$ são os tenores ajustados necessários), o modelo simula $N$ caminhos (`n_returns_paths`) de retornos futuros para cada $(i, \tau')$ ao longo do horizonte $H$ (`lookforward_period`).

-   Processo (para cada caminho $p = 1, \dots, N$):
    1.  Inicializar a variância $\sigma^2_{p,0,i,\tau'}$ (geralmente com a variância incondicional $\omega / (1 - \alpha - \beta)$, se estável, ou um valor piso).
    2.  Para cada dia $h = 1, \dots, H$:
        a.  Gerar uma inovação aleatória $z_{p,h,i,\tau'} \sim N(0, 1)$ (usando `np.random.RandomState` com semente única por path).
        b.  Calcular o resíduo simulado: $\epsilon_{p,h,i,\tau'} = \sigma_{p,h-1,i,\tau'} \cdot z_{p,h,i,\tau'}$.
        c.  Calcular o **retorno simulado**: $\tilde{R}_{p,h,i,\tau'} = \mu_{i,\tau'} + \epsilon_{p,h,i,\tau'}$.
        d.  Atualizar a variância para o próximo passo: $\sigma^2_{p,h,i,\tau'} = \omega_{i,\tau'} + \alpha_{i,\tau'} \epsilon^2_{p,h,i,\tau'} + \gamma_{i,\tau'} \epsilon^2_{p,h,i,\tau'} \mathbb{I}(\epsilon_{p,h,i,\tau'} < 0) + \beta_{i,\tau'} \sigma^2_{p,h-1,i,\tau'}$. (Com aplicação de pisos/tetos para estabilidade numérica).

-   Output: Um conjunto de séries de retornos simulados $\tilde{R}_{p,h,i,\tau'}$ para cada caminho $p$, dia $h$, instrumento $i$ e tenor ajustado $\tau'$.

**Código:** `_simulate_path_garch`. Esta função simula *um* caminho $p$ para *todos* os pares $(i, \tau')$ relevantes simultaneamente usando NumPy, retornando uma matriz `(horizon, M)`, onde M é o número de pares $(i, \tau')$. É chamada repetidamente (em paralelo) por `calculate_pnl_var_numpy` via `joblib`.

------

## 8. Cálculo de PnL Projetado (por Caminho Simulado)

Para cada caminho de simulação $p$, o modelo calcula o PnL agregado da carteira para cada dia $h$ do horizonte.

-   Processo (para um caminho $p$, data de referência $t_k$, carteira $\omega$, e dia $h \in \{1,\dots,H\}$):
    1.  Para cada exposição original $(\Delta_{k,\omega,i,\tau}, \Gamma_{k,\omega,i,\tau})$ na carteira:
        a.  Calcular o tenor ajustado $\tau' = \tau'(h, \tau)$.
        b.  Obter o retorno simulado correspondente $\tilde{R}_{p,h,i,\tau'}$ do passo 7.
        c.  Calcular a contribuição de PnL da exposição usando a aproximação Delta-Gama:
            $\text{pnl}_{p,k,\omega,i,\tau}(h) = \Delta_{k,\omega,i,\tau} \cdot \tilde{R}_{p,h,i,\tau'} \cdot CS_i + \frac{1}{2} \Gamma_{k,\omega,i,\tau} \cdot (\tilde{R}_{p,h,i,\tau'})^2 \cdot CS_i$.
    2.  Somar as contribuições de PnL sobre todos os instrumentos $i$ e tenores originais $\tau$ na carteira $\omega$:
        $PnL_{p,k,\omega}(h) = \sum_{i, \tau} \text{pnl}_{p,k,\omega,i,\tau}(h)$.

-   Output: Para cada caminho $p$, um conjunto de séries temporais $PnL_{p,k,\omega}(h)$ para $h=1,\dots,H$, uma para cada par $(k, \omega)$.

**Código:** `_calculate_pnl_for_path`. Esta função executa o cálculo acima para *um* caminho $p$ e retorna um dicionário onde as chaves são `(GroupAccountNumber, AsOfDate)` e os valores são arrays NumPy de PnL com tamanho $H$. Ela pré-calcula mapeamentos e usa operações NumPy/Pandas para eficiência.

------

## 9. Distribuição de PnL Simulado e Cálculo do VaR

Após executar as simulações para $N$ caminhos, para cada carteira $\omega$, data de referência $t_k$, e dia do horizonte $h$, temos uma **distribuição de PnLs simulados**:

$\mathcal{P}_{k,\omega}(h) = \{ PnL_{1,k,\omega}(h), PnL_{2,k,\omega}(h), \dots, PnL_{N,k,\omega}(h) \}$.

O VaR é então calculado como o quantil $\alpha$ desta distribuição empírica.

-   Cálculo do VaR:
    $VaR_{\alpha}(k,\omega,h) = \text{percentile}_{\alpha} ( \mathcal{P}_{k,\omega}(h) )$

    onde $\text{percentile}_{\alpha}$ denota o quantil empírico de ordem $\alpha$. Se $\alpha=0.01$, $VaR_{0.01}$ representa a perda esperada no pior 1% dos cenários simulados pelo GARCH para o dia $h$. O sinal dependerá da convenção (PnL positivo = lucro ou PnL positivo = perda). O código `np.percentile` retorna o valor do PnL naquele quantil (geralmente negativo para $\alpha$ baixo se PnL>0 é lucro).

-   Agregação e Output Final: A função `calculate_pnl_var_numpy` agrega os resultados de `_calculate_pnl_for_path` (que vêm de diferentes workers paralelos), constrói a matriz de PnLs `pnl_matrix` (shape `(N, H)`) para cada grupo `(k, \omega)`, calcula os percentis usando `np.percentile(..., axis=0)`, e formata o resultado final.

-   Output Final: Um DataFrame (`result_df`) com colunas:
    `GroupAccountNumber`, `AsOfDate`, `HoldingPeriod` (de 1 a $H$), `Quantile` ($\alpha$), `VaR`.

**Código:** `calculate_pnl_var_numpy` (agregação dos resultados dos paths e cálculo com `np.percentile`).

------

## 10. Pontos Essenciais e Considerações Adicionais

1.  **Modelo Base:** É um Monte Carlo VaR, mas os cenários são gerados por modelos **GARCH(1,1)-GJR** ajustados a dados históricos, não por reamostragem direta dos retornos históricos.
2.  **Ajuste GARCH:** Realizado para cada (Instrumento, Tenor) usando um algoritmo BHHH customizado e paralelizado com `joblib`/`spark`.
3.  **Simulação:** $N$ caminhos de retornos são simulados para frente por $H$ dias usando os parâmetros GARCH.
4.  **Rolagem de Contrato:** Simulada através do `AdjustedTenor` ($\tau'$) que mapeia a exposição no dia $h$ ao modelo GARCH apropriado.
5.  **Cálculo de PnL:** Usa aproximação Delta-Gama com os retornos *simulados*.
6.  **Eficiência:** O código usa NumPy extensivamente (`_simulate_path_garch`, `_calculate_pnl_for_path`) e paralelismo (`joblib` com backend `spark`) para lidar com o grande número de simulações e cálculos.
7.  **Exposições:** Podem vir de dados Murex (`MurexExposures`) ou de portfólios simulados (`_convert_portfolios_to_exposures`).
8.  **Flexibilidade:** Parâmetros como $\alpha, L, H, N$ são configuráveis.

------

## 11. Conclusão: Fluxo do Modelo

1.  **Input:** Exposições $(\Delta, \Gamma)$, Dados históricos de preços.
2.  **Pré-processamento:** Calcular Retornos Históricos $R_{d,i,\tau}$ (`MitraReturns`).
3.  **Calibração:** Ajustar GARCH $\Theta_{i,\tau}$ para cada $(i, \tau)$ usando $R_{d,i,\tau}$ (`fit_custom_garch_models`).
4.  **Simulação:** Gerar $N$ caminhos de retornos simulados $\tilde{R}_{p,h,i,\tau'}$ para $h=1..H$ usando $\Theta_{i,\tau'}$ (`_simulate_path_garch`).
5.  **Mapeamento:** Para cada $(k, \omega, i, \tau)$ e dia $h$, encontrar $\tau' = \tau'(h, \tau)$.
6.  **Cálculo de PnL:** Calcular $PnL_{p,k,\omega}(h)$ usando $\Delta, \Gamma, CS_i$ e $\tilde{R}_{p,h,i,\tau'}$ (`_calculate_pnl_for_path`).
7.  **Agregação & VaR:** Formar a distribuição $\{PnL_{p,k,\omega}(h)\}_{p=1}^N$ e calcular $VaR_{\alpha}(k,\omega,h) = \text{percentile}_{\alpha}$ (`calculate_pnl_var_numpy`).
8.  **Output:** Tabela de VaR.

Esta descrição detalha como o seu código implementa um cálculo de VaR sofisticado, combinando modelagem GARCH com simulação Monte Carlo e otimizações para execução em um ambiente Spark/NumPy/Joblib.
