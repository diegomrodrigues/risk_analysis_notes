## Model Verification Based on Failure Rates: Normal Approximation and Standardized Scores

### Introdu√ß√£o
Em continuidade √† discuss√£o sobre a verifica√ß√£o de modelos VAR baseada em taxas de falha, este cap√≠tulo aprofunda a an√°lise, explorando o uso da aproxima√ß√£o normal da distribui√ß√£o binomial para facilitar os c√°lculos estat√≠sticos. Conforme estabelecido anteriormente, a valida√ß√£o de modelos VAR exige uma compara√ß√£o rigorosa entre as perdas previstas e as perdas reais [^1]. O objetivo √© determinar se o n√∫mero de exce√ß√µes observadas √© consistente com o n√≠vel de confian√ßa do modelo. Esta se√ß√£o se concentra na aplica√ß√£o da aproxima√ß√£o normal e no uso do *z-score* para determinar se um modelo est√° mal calibrado. Conforme demonstrado no t√≥pico anterior, a taxa de falha, calculada como $N/T$, onde $N$ √© o n√∫mero de exce√ß√µes e $T$ √© o n√∫mero total de observa√ß√µes, √© um estimador consistente para a probabilidade de exce√ß√£o $p$. O teste de hip√≥tese usando a distribui√ß√£o binomial permite que avaliemos se o n√∫mero de exce√ß√µes $N$ √© estatisticamente compat√≠vel com o n√≠vel de confian√ßa do VAR.

### Conceitos Fundamentais

Conforme discutido anteriormente, o n√∫mero de exce√ß√µes $x$ em um per√≠odo de $T$ observa√ß√µes segue uma distribui√ß√£o binomial [^5]:

$$f(x) = \binom{T}{x} p^x (1-p)^{T-x}$$ [^5]

Onde $p$ representa a probabilidade de exce√ß√£o definida pelo modelo. Para valores grandes de $T$, essa distribui√ß√£o binomial pode ser aproximada por uma distribui√ß√£o normal. Esta aproxima√ß√£o √© uma consequ√™ncia do Teorema do Limite Central.

**Lema 2** A distribui√ß√£o binomial com par√¢metros $T$ e $p$ pode ser aproximada por uma distribui√ß√£o normal com m√©dia $E(x) = pT$ e vari√¢ncia $V(x) = p(1-p)T$ quando $T$ √© suficientemente grande.

*Proof:*
I. O Teorema do Limite Central afirma que a soma de um grande n√∫mero de vari√°veis aleat√≥rias independentes e identicamente distribu√≠das se aproxima de uma distribui√ß√£o normal.
II.  Em um processo de Bernoulli, cada observa√ß√£o √© independente e segue uma distribui√ß√£o Bernoulli com probabilidade de sucesso $p$.
III.  A distribui√ß√£o binomial √© a soma de $T$ vari√°veis aleat√≥rias Bernoulli independentes.
IV. Quando $T$ √© suficientemente grande (uma regra comum √© que $Tp \geq 5$ e $T(1-p) \geq 5$), a distribui√ß√£o binomial pode ser aproximada por uma distribui√ß√£o normal com m√©dia $E(x) = pT$ e vari√¢ncia $V(x) = p(1-p)T$.
V. Esta aproxima√ß√£o simplifica os c√°lculos e permite usar a distribui√ß√£o normal padr√£o para realizar testes de hip√≥tese. ‚ñ†

> üí° **Exemplo Num√©rico:** Vamos considerar um modelo VAR com um n√≠vel de confian√ßa de 99%, o que implica uma probabilidade de exce√ß√£o $p = 0.01$. Se analisarmos esse modelo em um per√≠odo de $T = 500$ dias, o n√∫mero esperado de exce√ß√µes seria $E(x) = pT = 0.01 \times 500 = 5$. A vari√¢ncia seria $V(x) = p(1-p)T = 0.01 \times 0.99 \times 500 = 4.95$. O desvio padr√£o seria $\sqrt{4.95} \approx 2.22$. Se observarmos um n√∫mero de exce√ß√µes $x$ pr√≥ximo de 5, a aproxima√ß√£o normal ser√° uma boa representa√ß√£o da distribui√ß√£o binomial. Se observarmos, por exemplo, 10 exce√ß√µes, podemos usar essa aproxima√ß√£o para avaliar a probabilidade desse evento.

**Lema 2.1** A aproxima√ß√£o normal da distribui√ß√£o binomial pode ser aprimorada pela corre√ß√£o de continuidade.

*Proof:*
I. A aproxima√ß√£o normal aproxima uma distribui√ß√£o discreta (binomial) por uma distribui√ß√£o cont√≠nua (normal).
II. Ao usar a distribui√ß√£o normal para aproximar a distribui√ß√£o binomial, o valor inteiro $x$ da distribui√ß√£o binomial √© mapeado para um intervalo na distribui√ß√£o normal.
III. Para melhorar a aproxima√ß√£o, uma corre√ß√£o de continuidade ajusta os limites de cada valor inteiro.
IV.  Ao calcular a probabilidade de $X \leq x$, usamos $X \leq x + 0.5$ na aproxima√ß√£o normal, e ao calcular a probabilidade de $X \geq x$, usamos $X \geq x - 0.5$.
V. Esta corre√ß√£o melhora a precis√£o da aproxima√ß√£o, especialmente quando o tamanho da amostra √© pequeno ou quando $p$ se distancia de 0.5.
VI. Portanto, a corre√ß√£o de continuidade adiciona precis√£o √† aproxima√ß√£o normal da distribui√ß√£o binomial. ‚ñ†

> üí° **Exemplo Num√©rico:** Se quisermos calcular a probabilidade de observar 7 ou menos exce√ß√µes em um teste com $T=100$ e $p=0.05$, usando a aproxima√ß√£o normal, sem a corre√ß√£o de continuidade, usar√≠amos o valor 7. Com a corre√ß√£o de continuidade, usar√≠amos 7.5. Isso significa que ao inv√©s de calcular $P(X \le 7)$, calculamos $P(X \le 7.5)$ usando a distribui√ß√£o normal, o que aumenta a precis√£o da estimativa.

**Lema 2.2** A corre√ß√£o de continuidade √© particularmente importante quando o tamanho da amostra *T* √© pequeno ou quando a probabilidade *p* √© pr√≥xima de 0 ou 1.

*Proof:*
I. A corre√ß√£o de continuidade √© mais relevante quando a distribui√ß√£o binomial √© menos sim√©trica e mais discreta.
II. Distribui√ß√µes binomiais com tamanho de amostra pequeno e probabilidades de sucesso ou fracasso pr√≥ximas de 0 ou 1 tendem a ser mais assim√©tricas e menos adequadas para aproxima√ß√£o normal.
III. A corre√ß√£o de continuidade ajusta as fronteiras discretas da binomial para melhorar a aproxima√ß√£o pela distribui√ß√£o normal cont√≠nua.
IV. A diferen√ßa entre a probabilidade discreta da binomial e a probabilidade cont√≠nua da normal √© maior nesses casos.
V. Portanto, a corre√ß√£o de continuidade √© mais importante nessas condi√ß√µes para garantir uma aproxima√ß√£o normal mais precisa. ‚ñ†

> üí° **Exemplo Num√©rico:** Vamos comparar duas situa√ß√µes. Primeiro, com $T=20$ e $p=0.5$, a distribui√ß√£o binomial √© relativamente sim√©trica, e a corre√ß√£o de continuidade ter√° um efeito menor. No segundo caso, com $T=20$ e $p=0.05$, a distribui√ß√£o binomial √© mais assim√©trica, e a corre√ß√£o de continuidade ter√° um impacto maior na precis√£o da aproxima√ß√£o normal. Em ambos os casos, a corre√ß√£o melhora a aproxima√ß√£o, mas ela √© mais importante no segundo caso, devido √† assimetria da distribui√ß√£o.

Essa aproxima√ß√£o √© crucial, pois nos permite calcular o *z-score* que segue uma distribui√ß√£o normal padr√£o. O *z-score*, tamb√©m apresentado no t√≥pico anterior [^6], √© dado por:

$$z = \frac{x - pT}{\sqrt{p(1-p)T}}$$ [^6]

Este *z-score* quantifica o desvio entre o n√∫mero de exce√ß√µes observadas $x$ e o n√∫mero de exce√ß√µes esperado $pT$, em unidades de desvio padr√£o. O uso do *z-score* simplifica o processo de teste de hip√≥tese, permitindo-nos verificar se o modelo est√° bem calibrado usando um valor de refer√™ncia da distribui√ß√£o normal padr√£o.

> üí° **Exemplo Num√©rico:** Considere um modelo VAR com um n√≠vel de confian√ßa de 99% ($p = 0.01$). Em um per√≠odo de 1000 dias ($T = 1000$), observamos 15 exce√ß√µes ($x = 15$). O n√∫mero esperado de exce√ß√µes √© $E(x) = pT = 0.01 \times 1000 = 10$. O desvio padr√£o do n√∫mero de exce√ß√µes √© $\sqrt{p(1-p)T} = \sqrt{0.01 \times 0.99 \times 1000} \approx 3.15$. Calculamos o z-score: $z = \frac{15 - 10}{3.15} \approx 1.59$. Em um teste bicaudal com um n√≠vel de confian√ßa de 95%, o valor cr√≠tico do z-score √© 1.96. Como $|1.59| < 1.96$, n√£o rejeitamos a hip√≥tese nula ao n√≠vel de confian√ßa de 95%, sugerindo que o modelo n√£o apresenta evid√™ncias estat√≠sticas de estar subestimando o risco neste exemplo.

O *z-score* nos permite quantificar a dist√¢ncia entre o n√∫mero observado de exce√ß√µes e o n√∫mero esperado de exce√ß√µes, expressando essa dist√¢ncia em unidades de desvio padr√£o.  O uso da aproxima√ß√£o normal para a distribui√ß√£o binomial simplifica o teste de hip√≥teses, permitindo utilizar um valor cr√≠tico tabelado da distribui√ß√£o normal padr√£o para verificar se um modelo VAR est√° corretamente calibrado. Em um n√≠vel de confian√ßa de 95% (teste bicaudal), rejeitamos a hip√≥tese nula se $|z| > 1.96$. Esta √© uma abordagem padr√£o na estat√≠stica e permite realizar testes de hip√≥tese com um n√≠vel de signific√¢ncia predefinido.

**Proposi√ß√£o 2** Um modelo VAR √© considerado mal calibrado quando o valor absoluto do *z-score* √© maior que o valor cr√≠tico correspondente ao n√≠vel de signific√¢ncia escolhido.

*Proof:*
I. O *z-score* quantifica o desvio entre o n√∫mero observado de exce√ß√µes e o n√∫mero esperado, em unidades de desvio padr√£o.
II.  Em um teste de hip√≥tese, estabelecemos um n√≠vel de signific√¢ncia ($\alpha$) que representa a probabilidade de rejeitar a hip√≥tese nula quando ela √© verdadeira (erro tipo I).
III. O n√≠vel de signific√¢ncia corresponde a √°reas nas caudas da distribui√ß√£o normal padr√£o.
IV. Em um teste bicaudal com n√≠vel de signific√¢ncia $\alpha$, rejeitamos a hip√≥tese nula se o valor absoluto do *z-score* for maior que o valor cr√≠tico $z_{\alpha/2}$, correspondente a $\alpha/2$.
V. Por exemplo, se $\alpha = 0.05$ (n√≠vel de confian√ßa de 95%), o valor cr√≠tico bicaudal √© $z_{0.025} = 1.96$.
VI. Se $|z| > z_{\alpha/2}$, conclu√≠mos que o desvio entre o n√∫mero observado de exce√ß√µes e o n√∫mero esperado √© estatisticamente significativo, indicando que o modelo VAR pode estar mal calibrado. ‚ñ†

> üí° **Exemplo Num√©rico:** Suponha um modelo VAR com um n√≠vel de confian√ßa de 97.5% ($p=0.025$). Em um per√≠odo de 500 dias ($T=500$), observamos 25 exce√ß√µes ($x=25$). O n√∫mero esperado de exce√ß√µes √© $E(x)=pT=0.025\times500=12.5$. O desvio padr√£o √© $\sqrt{p(1-p)T}=\sqrt{0.025\times0.975\times500}\approx3.5$. O *z-score* √© calculado como $z = \frac{25-12.5}{3.5} \approx 3.57$. Em um teste bicaudal com um n√≠vel de signific√¢ncia de 5% (confian√ßa de 95%), o valor cr√≠tico √© 1.96. Dado que $|3.57| > 1.96$, rejeitamos a hip√≥tese nula, indicando que o modelo VAR est√° mal calibrado e subestima o risco.

O uso do *z-score* com a aproxima√ß√£o normal para a distribui√ß√£o binomial permite que os testes de backtesting sejam realizados de forma eficiente e com resultados interpret√°veis. O valor do *z-score* fornece uma medida da probabilidade de observar uma taxa de falha t√£o extrema quanto a observada, caso o modelo estivesse corretamente calibrado, sob a hip√≥tese nula. No exemplo anterior, a probabilidade de observar um desvio de 3.57 desvios padr√£o da m√©dia √© muito pequena, sugerindo que o modelo VAR est√° mal calibrado, sob a hip√≥tese de que a probabilidade de exce√ß√£o √© 0.025.

**Corol√°rio 2** A precis√£o da aproxima√ß√£o normal da distribui√ß√£o binomial aumenta com o tamanho da amostra $T$ e com a proximidade de $p$ a 0.5.

*Proof:*
I. A aproxima√ß√£o normal da distribui√ß√£o binomial √© baseada no Teorema do Limite Central, que afirma que a distribui√ß√£o da soma de vari√°veis aleat√≥rias independentes e identicamente distribu√≠das se aproxima de uma distribui√ß√£o normal quando o n√∫mero de vari√°veis √© grande.
II.  Quanto maior o n√∫mero de observa√ß√µes $T$, mais pr√≥xima a distribui√ß√£o binomial se torna da distribui√ß√£o normal.
III.  Al√©m disso, quando a probabilidade de sucesso $p$ se aproxima de 0.5, a distribui√ß√£o binomial se torna mais sim√©trica, facilitando uma aproxima√ß√£o mais precisa pela distribui√ß√£o normal.
IV. Quando $p$ se aproxima de 0 ou 1, a distribui√ß√£o binomial torna-se mais assim√©trica e a aproxima√ß√£o normal pode ser menos precisa.
V.  Como regra geral, a aproxima√ß√£o normal √© considerada adequada quando $Tp \geq 5$ e $T(1-p) \geq 5$, o que garante que a distribui√ß√£o binomial n√£o seja muito assim√©trica.
VI. No entanto, para valores de $p$ muito pequenos ou muito grandes, pode ser necess√°rio um tamanho de amostra maior para que a aproxima√ß√£o normal seja v√°lida.
VII. A precis√£o da aproxima√ß√£o normal da distribui√ß√£o binomial aumenta com o tamanho da amostra $T$ e com a proximidade de $p$ a 0.5. ‚ñ†

> üí° **Exemplo Num√©rico:** Vamos comparar dois cen√°rios: um com $T = 100$ e $p = 0.5$ e outro com $T = 100$ e $p = 0.01$. No primeiro cen√°rio, a distribui√ß√£o binomial ser√° bem aproximada por uma normal, pois $Tp = 50$ e $T(1-p) = 50$. No segundo cen√°rio, a aproxima√ß√£o normal ser√° menos precisa, pois $Tp = 1$ e $T(1-p) = 99$. Para o segundo cen√°rio, um tamanho de amostra maior seria recomendado para que a aproxima√ß√£o normal seja mais confi√°vel.

**Corol√°rio 2.1** Para pequenos valores de *p*, √© recomend√°vel utilizar a corre√ß√£o de continuidade ao aplicar a aproxima√ß√£o normal da distribui√ß√£o binomial.

*Proof:*
I. Quando *p* √© pequeno, a distribui√ß√£o binomial √© assim√©trica, e a aproxima√ß√£o normal sem corre√ß√£o de continuidade pode n√£o ser precisa.
II. A corre√ß√£o de continuidade ajusta os limites da distribui√ß√£o discreta para a distribui√ß√£o cont√≠nua, melhorando a precis√£o da aproxima√ß√£o.
III. Para valores pequenos de *p*, a diferen√ßa entre a probabilidade discreta e a probabilidade cont√≠nua da aproxima√ß√£o normal √© mais significativa, tornando a corre√ß√£o de continuidade mais relevante.
IV. O uso da corre√ß√£o de continuidade √© especialmente √∫til quando *T* tamb√©m √© pequeno, e a distribui√ß√£o binomial √© mais longe de ser sim√©trica.
V. Portanto, para pequenos valores de *p*, a corre√ß√£o de continuidade melhora a qualidade da aproxima√ß√£o normal da distribui√ß√£o binomial. ‚ñ†

> üí° **Exemplo Num√©rico:** Considere um modelo VAR com $p = 0.01$ e $T = 100$. O n√∫mero esperado de exce√ß√µes √© $E(x) = 1$. Se observarmos 3 exce√ß√µes, o *z-score* sem a corre√ß√£o de continuidade seria: $z = \frac{3 - 1}{\sqrt{100 \times 0.01 \times 0.99}} \approx 2.01$. Com a corre√ß√£o de continuidade, usar√≠amos $x = 3 - 0.5 = 2.5$, resultando em: $z = \frac{2.5 - 1}{\sqrt{100 \times 0.01 \times 0.99}} \approx 1.51$. A diferen√ßa entre os *z-scores* mostra que a corre√ß√£o de continuidade tem um impacto significativo quando *p* √© pequeno, ajustando o teste para uma melhor aproxima√ß√£o.

A aproxima√ß√£o normal da distribui√ß√£o binomial, juntamente com o c√°lculo do *z-score*, oferece uma ferramenta poderosa para a avalia√ß√£o de modelos VAR em cen√°rios de *backtesting*. Essa abordagem permite realizar testes de hip√≥tese de forma eficiente e intuitiva, mesmo com grandes conjuntos de dados.

**Proposi√ß√£o 2.1** A an√°lise da distribui√ß√£o do *z-score* ao longo de diferentes subper√≠odos pode fornecer informa√ß√µes sobre a estabilidade da calibra√ß√£o do modelo VAR.

*Proof:*
I.  A an√°lise da distribui√ß√£o do *z-score* em diferentes subper√≠odos ajuda a identificar varia√ß√µes no desempenho do modelo VAR.
II. Se o modelo estiver corretamente calibrado, a distribui√ß√£o dos *z-scores* ao longo do tempo deve se manter aproximadamente constante, com a maioria dos valores pr√≥ximos de zero.
III. Varia√ß√µes significativas na distribui√ß√£o do *z-score* entre diferentes subper√≠odos podem indicar instabilidade ou uma mudan√ßa na calibra√ß√£o do modelo.
IV. Se a distribui√ß√£o se deslocar para a direita, com mais *z-scores* positivos, pode significar que o modelo est√° subestimando o risco. O oposto ocorre com a mudan√ßa para a esquerda, o que significa que o modelo est√° sobrestimando o risco.
V. A avalia√ß√£o da estabilidade da distribui√ß√£o do *z-score* permite identificar per√≠odos de tempo em que o modelo pode estar apresentando maior ou menor grau de erro.
VI. Esta an√°lise fornece informa√ß√µes √∫teis para a recalibra√ß√£o do modelo e para a melhoria da sua capacidade de previs√£o. Portanto, a distribui√ß√£o do *z-score* fornece informa√ß√µes relevantes sobre a estabilidade da calibra√ß√£o do modelo VAR. ‚ñ†

> üí° **Exemplo Num√©rico:**  Suponha que analisemos os *z-scores* de um modelo VAR ao longo de dois subper√≠odos de 250 dias cada. No primeiro subper√≠odo, a m√©dia dos *z-scores* seja 0.1 e o desvio padr√£o seja 0.9. No segundo subper√≠odo, a m√©dia passa para 1.5, e o desvio padr√£o sobe para 1.2. O deslocamento da m√©dia para um valor positivo sugere que o modelo est√°, em m√©dia, subestimando o risco no segundo subper√≠odo. O aumento do desvio padr√£o indica uma maior variabilidade nos resultados do modelo, sinalizando uma poss√≠vel instabilidade na sua calibra√ß√£o ao longo do tempo. Uma an√°lise mais detalhada poderia revelar as raz√µes por tr√°s dessas mudan√ßas.
```mermaid
graph LR
    A[Per√≠odo 1] -->|M√©dia z = 0.1, Desvio Padr√£o z = 0.9| B(Distribui√ß√£o z)
    C[Per√≠odo 2] -->|M√©dia z = 1.5, Desvio Padr√£o z = 1.2| D(Distribui√ß√£o z)
    B --> E{An√°lise Comparativa};
    D --> E;
    E --> F[Conclus√£o: Instabilidade]
```

Al√©m disso, como discutido no t√≥pico anterior, o teste de raz√£o de verossimilhan√ßa pode ser utilizado para testar a calibra√ß√£o do modelo VAR sem recorrer √† aproxima√ß√£o normal, sendo v√°lido tamb√©m para amostras pequenas. O teste de raz√£o de verossimilhan√ßa (LR) compara a verossimilhan√ßa dos dados sob a hip√≥tese nula com a verossimilhan√ßa sob a hip√≥tese alternativa. A estat√≠stica de teste LR √© dada por:

$$LR = -2 \ln\left(\frac{L(p;x)}{L(\hat{p};x)}\right)$$

Onde $L(p;x)$ √© a verossimilhan√ßa dos dados sob a hip√≥tese nula, usando a probabilidade de exce√ß√£o especificada pelo modelo $p$, e $L(\hat{p};x)$ √© a verossimilhan√ßa sob a hip√≥tese alternativa, usando a taxa de falha observada $\hat{p} = x/T$. Sob a hip√≥tese nula, o LR segue uma distribui√ß√£o qui-quadrado com 1 grau de liberdade, e rejeitamos a hip√≥tese nula se LR for maior que o valor cr√≠tico da distribui√ß√£o qui-quadrado para um n√≠vel de signific√¢ncia definido. Este m√©todo alternativo pode ser usado para verificar os resultados obtidos com a aproxima√ß√£o normal, especialmente quando o tamanho da amostra n√£o √© muito grande.

> üí° **Exemplo Num√©rico:** Vamos supor um modelo com $p=0.01$ e $T=100$. Observamos 3 exce√ß√µes ($x=3$). A taxa de falha observada √© $\hat{p} = 3/100 = 0.03$. A verossimilhan√ßa sob a hip√≥tese nula $L(p;x)$ √© calculada com $p=0.01$ e a verossimilhan√ßa sob a hip√≥tese alternativa $L(\hat{p};x)$ √© calculada com $\hat{p} = 0.03$. Utilizando softwares estat√≠sticos, podemos obter $L(0.01; 3) \approx 0.0061$ e $L(0.03;3) \approx 0.0213$. O LR √© ent√£o: $LR = -2 \ln(0.0061/0.0213) \approx -2 \ln(0.2864) \approx 2.50$. O valor cr√≠tico da distribui√ß√£o qui-quadrado com 1 grau de liberdade a 5% de signific√¢ncia √© 3.84. Como $2.50 < 3.84$, n√£o rejeitamos a hip√≥tese nula neste caso, indicando que o modelo n√£o est√° mal calibrado com base neste teste.

**Corol√°rio 3** O uso conjunto da aproxima√ß√£o normal e do teste de raz√£o de verossimilhan√ßa fornece uma abordagem robusta para o backtesting de modelos VAR, permitindo avaliar a calibra√ß√£o dos modelos sob diferentes condi√ß√µes.

*Proof:*
I. A aproxima√ß√£o normal da distribui√ß√£o binomial simplifica os c√°lculos e possibilita a aplica√ß√£o do *z-score*, o que facilita a compara√ß√£o com valores cr√≠ticos da distribui√ß√£o normal.
II.  No entanto, a aproxima√ß√£o normal pode ser menos precisa quando o tamanho da amostra √© pequeno ou quando a probabilidade de exce√ß√£o $p$ √© muito baixa ou alta.
III. O teste de raz√£o de verossimilhan√ßa √© v√°lido mesmo com amostras pequenas e n√£o depende da aproxima√ß√£o normal.
IV. O uso dos dois m√©todos conjuntamente permite verificar a consist√™ncia dos resultados e avaliar a robustez da conclus√£o sobre a calibra√ß√£o do modelo.
V. Se ambos os m√©todos conduzirem √† mesma conclus√£o, h√° maior confian√ßa na decis√£o tomada sobre o desempenho do modelo VAR.
VI.  A combina√ß√£o da aproxima√ß√£o normal e do teste de raz√£o de verossimilhan√ßa oferece uma abordagem robusta para o backtesting de modelos VAR, permitindo uma avalia√ß√£o mais completa da sua calibra√ß√£o. ‚ñ†

**Teorema 1** A escolha do n√≠vel de signific√¢ncia $\alpha$ no teste de hip√≥teses afeta diretamente o balan√ßo entre os erros do tipo I e do tipo II, que podem influenciar as decis√µes sobre a calibra√ß√£o do modelo VAR.

*Proof:*
I. O n√≠vel de signific√¢ncia $\alpha$ representa a probabilidade de rejeitar a hip√≥tese nula quando ela √© verdadeira (erro tipo I).
II. Reduzir $\alpha$ (por exemplo, de 5% para 1%) diminui a probabilidade de um erro do tipo I, tornando o teste mais rigoroso.
III. No entanto, a redu√ß√£o de $\alpha$ aumenta a probabilidade de n√£o rejeitar a hip√≥tese nula quando ela √© falsa (erro tipo II).
IV. Um erro do tipo II ocorre quando aceitamos um modelo VAR como corretamente calibrado quando, na verdade, ele est√° subestimando ou superestimando o risco.
V. A escolha de $\alpha$ envolve um compromisso entre os erros do tipo I e do tipo II, dependendo das consequ√™ncias de cada tipo de erro.
VI. Em situa√ß√µes onde a subestima√ß√£o do risco tem consequ√™ncias graves, √© prefer√≠vel escolher um valor de $\alpha$ maior para reduzir a probabilidade de aceitar um modelo mal calibrado.
VII. Portanto, a sele√ß√£o apropriada do n√≠vel de signific√¢ncia √© essencial para calibrar o teste de hip√≥tese e ajustar o balan√ßo entre os erros tipo I e II. ‚ñ†

> üí° **Exemplo Num√©rico:** Ao usar um n√≠vel de signific√¢ncia $\alpha = 0.05$ (5%), estamos aceitando uma probabilidade de 5% de rejeitar um modelo VAR que esteja bem calibrado. Se reduzirmos $\alpha$ para 0.01 (1%), o teste se tornar√° mais rigoroso, mas aumentaremos a chance de n√£o rejeitar um modelo VAR que esteja mal calibrado. A escolha depende do custo relativo de cada tipo de erro.

**Teorema 1.1** O poder estat√≠stico do teste de hip√≥teses aumenta com o tamanho da amostra T, permitindo identificar modelos mal calibrados com maior precis√£o.

*Proof:*
I. O poder estat√≠stico de um teste representa a probabilidade de rejeitar a hip√≥tese nula quando ela √© falsa, ou seja, de detectar um modelo VAR mal calibrado corretamente.
II. Com um tamanho de amostra maior T, a distribui√ß√£o amostral da taxa de falha se torna mais concentrada em torno do verdadeiro valor da probabilidade de exce√ß√£o p.
III. Como resultado, a diferen√ßa entre o n√∫mero de exce√ß√µes observado e o n√∫mero esperado de exce√ß√µes se torna mais f√°cil de detectar estatisticamente.
IV. Um tamanho de amostra maior reduz a variabilidade do estimador da taxa de falha e, consequentemente, aumenta o poder do teste.
V. Portanto, o poder do teste de hip√≥teses aumenta com o aumento do tamanho da amostra T, permitindo uma avalia√ß√£o mais precisa da calibra√ß√£o do modelo VAR. ‚ñ†

> üí° **Exemplo Num√©rico:** Em um cen√°rio onde $p = 0.01$, com $T=100$, observar√≠amos uma m√©dia de 1 exce√ß√£o. Se observarmos 3, o desvio padr√£o √© $\sqrt{100 \times 0.01 \times 0.99} \approx 0.99$. O z-score √© $z = (3-1)/0.99 = 2.02$. Agora, com $T = 1000$, a m√©dia seria 10 exce√ß√µes, o desvio padr√£o $\sqrt{1000 \times 0.01 \times 0.99} \approx 3.14$ e se observ√°ssemos 16 exce√ß√µes, o z-score seria $z = (16-10)/3.14 = 1.91$. Com o aumento da amostra, a estat√≠stica z fica mais precisa, aumentando o poder do teste de detectar um desvio.

**Teorema 1.2** A an√°lise conjunta dos z-scores e do teste de raz√£o de verossimilhan√ßa pode ser formalizada atrav√©s de um teste combinado, que agrega as informa√ß√µes de ambos os testes para aumentar o poder estat√≠stico.

*Proof:*
I. O z-score e o teste de raz√£o de verossimilhan√ßa fornecem informa√ß√µes complementares sobre a calibra√ß√£o do modelo VAR.
II. O z-score √© baseado na aproxima√ß√£o normal, enquanto o teste de raz√£o de verossimilhan√ßa √© baseado na distribui√ß√£o exata da binomial.
III. Ao combinar os dois testes, podemos obter uma medida mais robusta da calibra√ß√£o do modelo.
IV. Uma abordagem para combinar esses testes √© usar o m√©todo de Fisher para combinar os valores-p dos dois testes.
V. Sob a hip√≥tese nula, os valores-p s√£o distribu√≠dos uniformemente entre 0 e 1, e a estat√≠stica de teste combinada √© $-2 \sum_{i=1}^k \ln(p_i)$, onde $p_i$ s√£o os valores-p dos k testes individuais.
VI. Esta estat√≠stica segue uma distribui√ß√£o qui-quadrado com 2k graus de liberdade.
VII. Portanto, a combina√ß√£o dos testes do z-score e raz√£o de verossimilhan√ßa atrav√©s do m√©todo de Fisher pode melhorar o poder estat√≠stico na identifica√ß√£o de modelos mal calibrados, oferecendo uma avalia√ß√£o mais abrangente da calibra√ß√£o do VAR. ‚ñ†

> üí° **Exemplo Num√©rico:** Vamos supor que calculamos o valor-p para o z-score e para o teste de raz√£o de verossimilhan√ßa e obtivemos respectivamente $p_1=0.04$ e $p_2=0.06$. Usando o m√©todo de Fisher, a estat√≠stica combinada seria $-2(\ln(0.04) + \ln(0.06)) \approx 11.47$. Com 4 graus de liberdade (2 testes), o valor cr√≠tico a 5% √© 9.49. Rejeitamos a hip√≥tese nula combinada. Se analis√°ssemos cada teste isoladamente, os resultados poderiam n√£o ser significativos no n√≠vel de 5%, mas ao combin√°-los, aumenta-se o poder estat√≠stico.

**Lema 3**  Em situa√ß√µes em que a amostra √© muito pequena e a aproxima√ß√£o normal n√£o √© confi√°vel, o teste exato binomial pode ser empregado.

*Proof:*
I. O teste exato binomial calcula a probabilidade exata de observar um n√∫mero de exce√ß√µes t√£o extremo ou mais extremo do que o observado, dada a probabilidade de exce√ß√£o $p$ do modelo.
II. A probabilidade de observar $x$ ou mais exce√ß√µes √© dada pela soma das probabilidades binomiais:  $P(X \geq x) = \sum_{k=x}^{T} \binom{T}{k} p^k (1-p)^{T-k}$.
III. Da mesma forma, a probabilidade de observar $x$ ou menos exce√ß√µes √©: $P(X \leq x) = \sum_{k=0}^{x} \binom{T}{k} p^k (1-p)^{T-k}$.
IV.  O teste exato binomial n√£o requer a aproxima√ß√£o normal, e √© v√°lido mesmo para pequenos valores de $T$ e para valores de $p$ pr√≥ximos de 0 ou 1.
V. Este m√©todo √© mais computacionalmente intenso do que a aproxima√ß√£o normal, mas fornece resultados precisos quando as condi√ß√µes para a aproxima√ß√£o normal n√£o s√£o satisfeitas.
VI. Assim, o teste exato binomial √© uma alternativa valiosa ao z-score e ao teste de raz√£o de verossimilhan√ßa quando a aproxima√ß√£o normal n√£o √© adequada, especialmente em amostras pequenas. ‚ñ†

> üí° **Exemplo Num√©rico:** Considere um modelo VAR com $p=0.05$ e $T=20$. Se observamos 3 exce√ß√µes, calcular a probabilidade exata $P(X \geq 3)$ seria somar as probabilidades de 3, 4, 5, ... at√© 20 exce√ß√µes. Usando a f√≥rmula binomial, $P(X \geq 3) = \sum_{k=3}^{20} \binom{20}{k} 0.05^k 0.95^{20-k}$. O resultado exato √© aproximadamente 0.1887. O uso da aproxima√ß√£o normal, mesmo com a corre√ß√£o de continuidade, pode n√£o ser t√£o preciso com amostras pequenas.

### Conclus√£o

Esta se√ß√£o demonstrou como a aproxima√ß√£o normal da distribui√ß√£o binomial, juntamente com o c√°lculo do *z-score*, pode ser utilizada para simplificar e otimizar a an√°lise das taxas de falha em modelos VAR. O *z-score* fornece uma medida padronizada do desvio entre o n√∫mero de exce√ß√µes observadas e o n√∫mero de exce√ß√µes esperadas, facilitando a identifica√ß√£o de modelos mal calibrados atrav√©s da compara√ß√£o com os valores cr√≠ticos da distribui√ß√£o normal padr√£o.  A precis√£o da aproxima√ß√£o normal aumenta com o tamanho da amostra e com a proximidade de $p$ a 0.5, mas existem m√©todos alternativos, como o teste de raz√£o de verossimilhan√ßa, que permitem avaliar a calibra√ß√£o do modelo tamb√©m em amostras pequenas e sem recorrer √† aproxima√ß√£o normal. O uso conjunto de ambas as abordagens garante uma avalia√ß√£o mais completa e confi√°vel dos modelos VAR, contribuindo para uma gest√£o de risco mais eficaz. A introdu√ß√£o do teste exato binomial e de m√©todos de combina√ß√£o de testes enriquece ainda mais a an√°lise de backtesting de modelos VAR, garantindo uma avalia√ß√£o mais robusta e abrangente.

### Refer√™ncias
[^1]: *‚ÄúThis chapter turns to backtesting techniques for verifying the accuracy of VAR models.‚Äù*
[^5]: *‚ÄúThe simplest method to verify the accuracy of the model is to record the failure rate, which gives the proportion of times VAR is exceeded in a given sample...Ideally, the failure rate should give an unbiased measure of p, that is, should converge to p as the sample size increases...We want to know, at a given confidence level, whether N is too small or too large under the null hypothesis that p = 0.01 in a sample of size T.‚Äù*
[^6]: *‚Äúz= (x-pT)/sqrt(p(1-p)T) ~ N(0, 1)...If the decision rule is defined at the two-tailed 95 percent test confidence level, then the cutoff value of |z| is 1.96...Based on Equation (6.2), we have z = (x-pT)/‚àöp(1-p) T = (20 - 0.05 √ó 252)/‚àö0.05(0.95) 252 = 2.14...Therefore, we reject the hypothesis that the VAR model is unbiased.‚Äù*
<!-- END -->
