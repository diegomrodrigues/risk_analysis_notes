## Backtesting VAR: AnÃ¡lise Detalhada do Teste da RazÃ£o de VerossimilhanÃ§a para Cobertura Incondicional (LRuc)

### IntroduÃ§Ã£o
Em continuidade Ã  discussÃ£o anterior sobre a importÃ¢ncia do *backtesting* e do teste da razÃ£o de verossimilhanÃ§a para cobertura incondicional (LRuc) [^1], este capÃ­tulo tem como objetivo aprofundar o entendimento da estatÃ­stica de teste $LR_{uc}$ em si, explorando suas propriedades, derivaÃ§Ã£o e interpretaÃ§Ã£o. O teste $LR_{uc}$ Ã© uma ferramenta chave para avaliar se um modelo de Value-at-Risk (VAR) estÃ¡ bem calibrado, verificando se a frequÃªncia de exceÃ§Ãµes observadas Ã© consistente com o nÃ­vel de confianÃ§a estabelecido [^2]. Como vimos anteriormente, o modelo VAR Ã© Ãºtil apenas se prediz o risco de forma adequada, e a validaÃ§Ã£o do modelo, com o *backtesting*, Ã© essencial [^1]. A utilizaÃ§Ã£o de um framework estatÃ­stico como o teste $LR_{uc}$ Ã© um passo crucial para essa validaÃ§Ã£o [^3].

### Conceitos Fundamentais
Como mencionado anteriormente, o *backtesting* de modelos VAR envolve comparar sistematicamente as previsÃµes do modelo com os resultados reais [^3]. O teste $LR_{uc}$ surge como um mÃ©todo para verificar se o nÃºmero de exceÃ§Ãµes observadas (onde as perdas reais excedem o VAR previsto) estÃ¡ em linha com o nÃ­vel de confianÃ§a do VAR [^2]. Para isso, definimos a *taxa de falha* como a proporÃ§Ã£o de vezes que as perdas excedem o VAR [^5]. O teste $LR_{uc}$ usa essa taxa de falha observada para verificar se ela Ã© estatisticamente compatÃ­vel com a taxa de falha esperada, que Ã© definida pelo nÃ­vel de confianÃ§a do VAR [^5]. Este teste Ã© nÃ£o paramÃ©trico, o que significa que nÃ£o faz nenhuma suposiÃ§Ã£o sobre a distribuiÃ§Ã£o dos retornos, tornando-o aplicÃ¡vel a uma variedade de cenÃ¡rios [^5].

O teste $LR_{uc}$  Ã© baseado em uma estatÃ­stica que Ã© definida como [^9]:
$$
\text{LR}_{\text{uc}} = -2 \ln[(1 - p)^{T-N} p^N] + 2 \ln{[1 - (N/T)]^{T-N} (N/T)^N}
$$
onde:
*   $N$ Ã© o nÃºmero de exceÃ§Ãµes observadas durante o perÃ­odo de teste.
*   $T$ Ã© o nÃºmero total de observaÃ§Ãµes no perÃ­odo de teste.
*   $p$ Ã© a taxa de falha esperada, calculada como 1 menos o nÃ­vel de confianÃ§a do VAR (e.g., para um VAR de 99%, $p = 0.01$).

Como jÃ¡ derivado anteriormente (Teorema 1.1) [^5], uma formulaÃ§Ã£o equivalente e mais intuitiva pode ser:

$$
\text{LR}_{\text{uc}} = 2 \left[ N \ln\left(\frac{N/T}{p}\right) + (T-N) \ln\left(\frac{1-N/T}{1-p}\right) \right]
$$

Esta formulaÃ§Ã£o expressa o $LR_{uc}$ em termos da razÃ£o entre a taxa de falha observada e a taxa de falha esperada.

#### DerivaÃ§Ã£o e InterpretaÃ§Ã£o da EstatÃ­stica de Teste

**ProposiÃ§Ã£o 3.** *A estatÃ­stica $LR_{uc}$ Ã© derivada da razÃ£o de verossimilhanÃ§a, que compara a verossimilhanÃ§a dos dados sob a hipÃ³tese nula (o modelo estÃ¡ bem calibrado) com a verossimilhanÃ§a sob a hipÃ³tese alternativa (o modelo nÃ£o estÃ¡ bem calibrado). Sob a hipÃ³tese nula, a estatÃ­stica $LR_{uc}$ Ã© assintoticamente distribuÃ­da como uma qui-quadrado com um grau de liberdade.* [^9]

A intuiÃ§Ã£o por trÃ¡s da estatÃ­stica $LR_{uc}$ Ã© a seguinte:
*   O primeiro termo da equaÃ§Ã£o ($-2 \ln[(1 - p)^{T-N} p^N]$) representa a log-verossimilhanÃ§a dos dados (nÃºmero de exceÃ§Ãµes) sob a hipÃ³tese nula, ou seja, a hipÃ³tese de que o modelo VAR estÃ¡ corretamente calibrado e as exceÃ§Ãµes ocorrem com a frequÃªncia esperada $p$.
*   O segundo termo da equaÃ§Ã£o ($2 \ln{[1 - (N/T)]^{T-N} (N/T)^N}$) representa a log-verossimilhanÃ§a dos dados sob a hipÃ³tese alternativa, ou seja, a hipÃ³tese de que a taxa de falha observada $N/T$ Ã© a melhor estimativa da verdadeira taxa de falha.
*   A diferenÃ§a entre essas duas log-verossimilhanÃ§as (multiplicada por -2) nos dÃ¡ a estatÃ­stica $LR_{uc}$. Uma diferenÃ§a grande sugere que a taxa de falha observada Ã© estatisticamente diferente da taxa de falha esperada, levando Ã  rejeiÃ§Ã£o da hipÃ³tese nula.

**Lema 2.** *Quando a taxa de falha observada (N/T) se aproxima da taxa de falha esperada (p), a estatÃ­stica $LR_{uc}$ se aproxima de zero, indicando que o modelo VAR estÃ¡ bem calibrado.*

*Prova:*
I. Como jÃ¡ visto no corolÃ¡rio 1.1, quando $N/T = p$ [^5], cada termo dentro do logaritmo na formulaÃ§Ã£o do Teorema 1.1 Ã© igual a 1, e o logaritmo de 1 Ã© 0.
II. Consequentemente, $LR_{uc}$ torna-se zero, indicando perfeita concordÃ¢ncia entre a taxa de falha observada e esperada.  â– 

> ğŸ’¡ **Exemplo NumÃ©rico:**
> Suponha que temos um modelo VAR com nÃ­vel de confianÃ§a de 99% ($p = 0.01$) e observamos um perÃ­odo de backtesting com $T=1000$ dias. Se o nÃºmero de exceÃ§Ãµes observadas for exatamente o esperado, ou seja, $N = p \cdot T = 0.01 \cdot 1000 = 10$, entÃ£o $N/T = 10/1000 = 0.01$, que Ã© igual a $p$.
>
> Aplicando a fÃ³rmula:
> $$
> \text{LR}_{\text{uc}} = 2 \left[ 10 \ln\left(\frac{10/1000}{0.01}\right) + (1000-10) \ln\left(\frac{1-10/1000}{1-0.01}\right) \right]
> $$
> $$
> \text{LR}_{\text{uc}} = 2 \left[ 10 \ln\left(1\right) + 990 \ln\left(1\right) \right] = 2[10 \cdot 0 + 990 \cdot 0] = 0
> $$
>
> Neste caso, como esperado, $LR_{uc}$ Ã© igual a 0, o que indica que o modelo estÃ¡ perfeitamente calibrado.

**Lema 3.** *A estatÃ­stica $LR_{uc}$ Ã© sempre nÃ£o negativa, conforme demonstrado no corolÃ¡rio 1.2.* [^5]

*Prova:*
I. A funÃ§Ã£o de log-verossimilhanÃ§a atinge seu mÃ¡ximo quando a probabilidade de sucesso (taxa de falha) Ã© igual Ã  frequÃªncia observada (N/T).
II. Isso implica que a razÃ£o $\frac{L(p = N/T)}{L(p)}$ serÃ¡ sempre maior ou igual a 1.
III. O logaritmo de um nÃºmero maior ou igual a 1 Ã© sempre nÃ£o negativo.
IV. Como $LR_{uc}$ Ã© duas vezes o logaritmo dessa razÃ£o, $LR_{uc}$ Ã© sempre nÃ£o negativo [^5]. â– 

**Lema 3.1.** *A estatÃ­stica  $LR_{uc}$  pode ser interpretada como uma medida de divergÃªncia entre duas distribuiÃ§Ãµes de probabilidade: uma baseada na taxa de falha esperada  $p$ e outra baseada na taxa de falha observada  $N/T$*

*Prova:*

I. A estatÃ­stica $LR_{uc}$ Ã© construÃ­da a partir da razÃ£o de verossimilhanÃ§as, que compara a probabilidade dos dados observados sob duas hipÃ³teses distintas: uma onde a taxa de falha Ã© igual a $p$, e outra onde ela Ã© igual a $N/T$.
II. A log-verossimilhanÃ§a, que Ã© utilizada no cÃ¡lculo de  $LR_{uc}$, pode ser interpretada como uma medida da qualidade do ajuste de uma distribuiÃ§Ã£o de probabilidade aos dados. Assim, quanto maior o valor absoluto da diferenÃ§a entre as log-verossimilhanÃ§as, maior Ã© a divergÃªncia entre as distribuiÃ§Ãµes associadas a cada hipÃ³tese.
III. Especificamente, valores maiores de $LR_{uc}$ implicam que a distribuiÃ§Ã£o baseada em  $N/T$  estÃ¡ mais ajustada aos dados observados do que a distribuiÃ§Ã£o baseada em $p$. Ou seja, a taxa de falha observada Ã© estatisticamente diferente da esperada, e essa diferenÃ§a pode ser quantificada pela estatÃ­stica.  â– 

> ğŸ’¡ **Exemplo NumÃ©rico:**
> Imagine que, em vez de 10 exceÃ§Ãµes como no exemplo anterior, observamos 20 exceÃ§Ãµes em 1000 dias, com $p = 0.01$. Nesse caso, $N/T = 20/1000 = 0.02$.
>
> $$
> \text{LR}_{\text{uc}} = 2 \left[ 20 \ln\left(\frac{20/1000}{0.01}\right) + (1000-20) \ln\left(\frac{1-20/1000}{1-0.01}\right) \right]
> $$
> $$
> \text{LR}_{\text{uc}} = 2 \left[ 20 \ln\left(2\right) + 980 \ln\left(\frac{0.98}{0.99}\right) \right]
> $$
> $$
> \text{LR}_{\text{uc}} \approx 2 [20 \cdot 0.693 - 980 \cdot 0.010] \approx 2 [13.86 - 9.8] \approx 2 \cdot 4.06 \approx 8.12
> $$
>
> O valor de $LR_{uc}$ de aproximadamente 8.12 Ã© maior que 0 e reflete a divergÃªncia entre a taxa de falha observada (0.02) e a esperada (0.01).

**Lema 3.2.** *A estatÃ­stica $LR_{uc}$ pode ser expressa como uma diferenÃ§a entre duas entropias relativas (Kullback-Leibler Divergence), o que reforÃ§a a interpretaÃ§Ã£o de que ela mede a divergÃªncia entre duas distribuiÃ§Ãµes de probabilidade.*

*Prova:*
I. A entropia relativa (Kullback-Leibler Divergence) entre duas distribuiÃ§Ãµes de probabilidade, $P$ e $Q$, Ã© dada por $D_{KL}(P||Q) = \sum P(x) \ln(\frac{P(x)}{Q(x)})$.
II. No caso do teste $LR_{uc}$, podemos considerar que $P$ Ã© a distribuiÃ§Ã£o que descreve a frequÃªncia de exceÃ§Ãµes baseada na taxa de falha observada $N/T$, e $Q$ Ã© a distribuiÃ§Ã£o baseada na taxa de falha esperada $p$.
III. A estatÃ­stica $LR_{uc}$ pode ser reescrita como $LR_{uc} = 2T[D_{KL}(N/T||p) - D_{KL}(N/T||N/T)]$.
IV. Dado que $D_{KL}(N/T||N/T) = 0$, a estatÃ­stica  $LR_{uc}$  torna-se uma versÃ£o escalonada por 2T da divergÃªncia de Kullback-Leibler entre as distribuiÃ§Ãµes associadas Ã  taxa de falha observada e esperada.  â– 

**Lema 3.3** *A interpretaÃ§Ã£o da estatÃ­stica $LR_{uc}$ como uma medida de divergÃªncia entre distribuiÃ§Ãµes tambÃ©m pode ser vista atravÃ©s da distÃ¢ncia de Hellinger. A distÃ¢ncia de Hellinger Ã© uma outra forma de quantificar a diferenÃ§a entre duas distribuiÃ§Ãµes e sua relaÃ§Ã£o com a estatÃ­stica $LR_{uc}$ reforÃ§a essa interpretaÃ§Ã£o.*

*Prova:*

I. A distÃ¢ncia de Hellinger entre duas distribuiÃ§Ãµes de probabilidade, $P$ e $Q$, Ã© definida como $H(P,Q) = \sqrt{\frac{1}{2}\sum (\sqrt{P(x)} - \sqrt{Q(x)})^2}$.
II. No caso do teste $LR_{uc}$, as distribuiÃ§Ãµes $P$ e $Q$ podem ser consideradas como as distribuiÃ§Ãµes binomial com parÃ¢metros $(T, N/T)$ e $(T, p)$, respectivamente.
III. Sob condiÃ§Ãµes de regularidade e com aproximaÃ§Ãµes adequadas, pode-se demonstrar que a estatÃ­stica $LR_{uc}$ estÃ¡ relacionada com o quadrado da distÃ¢ncia de Hellinger, de tal forma que valores maiores de $LR_{uc}$ correspondem a uma maior distÃ¢ncia de Hellinger entre as duas distribuiÃ§Ãµes.
IV. Essa relaÃ§Ã£o reforÃ§a a interpretaÃ§Ã£o de que a estatÃ­stica $LR_{uc}$ mede a divergÃªncia entre as distribuiÃ§Ãµes de probabilidade baseadas nas taxas de falha observadas e esperadas, fornecendo uma interpretaÃ§Ã£o alternativa e complementar Ã  anÃ¡lise da divergÃªncia de Kullback-Leibler. â– 

#### DistribuiÃ§Ã£o AssintÃ³tica
Um aspecto crucial do teste $LR_{uc}$ Ã© que, sob a hipÃ³tese nula (o modelo VAR estÃ¡ corretamente calibrado), a estatÃ­stica do teste converge assintoticamente para uma distribuiÃ§Ã£o qui-quadrado com um grau de liberdade quando o nÃºmero de observaÃ§Ãµes (T) se torna grande [^9]. Isso significa que, para grandes amostras, podemos utilizar a distribuiÃ§Ã£o qui-quadrado para determinar se o valor observado de $LR_{uc}$ Ã© estatisticamente significativo.

**Teorema 2.** *Sob a hipÃ³tese nula, a estatÃ­stica $LR_{uc}$ segue assintoticamente uma distribuiÃ§Ã£o qui-quadrado com um grau de liberdade. Formalmente, dizemos que $LR_{uc} \overset{d}{\longrightarrow} \chi^2_1$, onde $\overset{d}{\longrightarrow}$ denota convergÃªncia em distribuiÃ§Ã£o.* [^9]

*Prova:*
I. A derivaÃ§Ã£o completa desse teorema envolve matemÃ¡tica estatÃ­stica avanÃ§ada, que estÃ¡ alÃ©m do escopo deste capÃ­tulo. No entanto, a ideia bÃ¡sica Ã© que, sob condiÃ§Ãµes de regularidade (que geralmente sÃ£o satisfeitas nos dados financeiros), a diferenÃ§a entre a log-verossimilhanÃ§a dos dados sob a hipÃ³tese nula e sob a hipÃ³tese alternativa, quando multiplicada por -2, converge para uma distribuiÃ§Ã£o qui-quadrado.
II. Especificamente, o nÃºmero de graus de liberdade corresponde Ã  diferenÃ§a entre o nÃºmero de parÃ¢metros estimados sob a hipÃ³tese alternativa e o nÃºmero de parÃ¢metros estimados sob a hipÃ³tese nula, sendo neste caso igual a 1, pois sob a hipÃ³tese alternativa, temos um parÃ¢metro (N/T) e sob a hipÃ³tese nula, temos o parÃ¢metro p, resultando em 1 grau de liberdade.  â– 

**Teorema 2.1.** *A convergÃªncia assintÃ³tica da estatÃ­stica $LR_{uc}$ para uma distribuiÃ§Ã£o qui-quadrado com um grau de liberdade pode ser entendida como uma consequÃªncia do Teorema Central do Limite (TCL) aplicado Ã  log-razÃ£o de verossimilhanÃ§as.*

*Prova:*

I. O TCL estabelece que a soma (ou mÃ©dia) de um grande nÃºmero de variÃ¡veis aleatÃ³rias independentes e identicamente distribuÃ­das converge para uma distribuiÃ§Ã£o normal, sob certas condiÃ§Ãµes.
II. A log-razÃ£o de verossimilhanÃ§as pode ser vista como uma soma de contribuiÃ§Ãµes individuais de cada observaÃ§Ã£o (exceÃ§Ã£o ou nÃ£o exceÃ§Ã£o)
III. Ao multiplicÃ¡-la por -2, e sob a hipÃ³tese nula, a distribuiÃ§Ã£o resultante aproxima-se de uma qui-quadrado com um grau de liberdade Ã  medida que o nÃºmero de observaÃ§Ãµes (T) aumenta.
IV. O grau de liberdade Ã© dado pela diferenÃ§a no nÃºmero de parÃ¢metros estimados entre a hipÃ³tese nula e a alternativa, que Ã© igual a 1 neste caso, visto que sob a hipÃ³tese nula temos o parÃ¢metro p, e na hipÃ³tese alternativa temos N/T.  â– 

Essa propriedade Ã© fundamental, pois permite estabelecer um valor crÃ­tico para o teste com base na distribuiÃ§Ã£o qui-quadrado. Por exemplo, com um nÃ­vel de confianÃ§a de 95%, o valor crÃ­tico para uma distribuiÃ§Ã£o qui-quadrado com um grau de liberdade Ã© 3.841 [^9]. Se o valor calculado de $LR_{uc}$ for maior do que esse valor crÃ­tico, rejeitamos a hipÃ³tese nula, indicando que o modelo VAR estÃ¡ mal calibrado.

> ğŸ’¡ **Exemplo NumÃ©rico:**
>
> Continuando com o exemplo anterior, onde $\text{LR}_{\text{uc}} \approx 8.12$, e considerando um nÃ­vel de significÃ¢ncia de 5% (ou um nÃ­vel de confianÃ§a de 95%), comparamos o valor da estatÃ­stica com o valor crÃ­tico da distribuiÃ§Ã£o qui-quadrado com 1 grau de liberdade. O valor crÃ­tico para $\chi^2_1$ a 5% de significÃ¢ncia Ã© 3.841.
>
> Como $8.12 > 3.841$, rejeitamos a hipÃ³tese nula, o que indica que o modelo VAR estÃ¡ mal calibrado. Isto Ã©, a taxa de falha observada (2%) Ã© estatisticamente diferente da taxa de falha esperada (1%).

**Teorema 2.2** *O Teorema de Wilks generaliza o resultado da distribuiÃ§Ã£o assintÃ³tica do teste $LR_{uc}$ e garante a convergÃªncia para uma distribuiÃ§Ã£o $\chi^2$ da estatÃ­stica de teste da razÃ£o de verossimilhanÃ§as, onde o nÃºmero de graus de liberdade Ã© dado pela diferenÃ§a entre o nÃºmero de parÃ¢metros estimados sob a hipÃ³tese alternativa e o nÃºmero de parÃ¢metros estimados sob a hipÃ³tese nula.*

*Prova:*
I. O Teorema de Wilks estabelece que sob certas condiÃ§Ãµes de regularidade, e com a hipÃ³tese nula sendo verdadeira, a estatÃ­stica do teste da razÃ£o de verossimilhanÃ§as converge assintoticamente para uma distribuiÃ§Ã£o qui-quadrado.
II. No caso do teste $LR_{uc}$, a hipÃ³tese nula assume que o modelo VAR estÃ¡ corretamente calibrado e que a taxa de falha observada Ã© compatÃ­vel com a taxa de falha esperada, resultando em um grau de liberdade.
III. Este teorema generaliza a ideia por trÃ¡s do Teorema 2, aplicando-se a uma classe mais ampla de modelos e hipÃ³teses.  â– 

**Teorema 2.3** *A convergÃªncia assintÃ³tica da estatÃ­stica $LR_{uc}$ para uma distribuiÃ§Ã£o qui-quadrado com um grau de liberdade tambÃ©m pode ser demonstrada utilizando a expansÃ£o de Taylor da funÃ§Ã£o log-verossimilhanÃ§a em torno do valor verdadeiro do parÃ¢metro. Essa abordagem oferece uma perspectiva alternativa para a compreensÃ£o da distribuiÃ§Ã£o assintÃ³tica.*

*Prova:*

I. A funÃ§Ã£o log-verossimilhanÃ§a, que Ã© a base para a construÃ§Ã£o da estatÃ­stica $LR_{uc}$, pode ser aproximada atravÃ©s de uma expansÃ£o de Taylor de segunda ordem em torno do valor verdadeiro da taxa de falha ($p$).
II. Ao realizar essa expansÃ£o e simplificar a expressÃ£o resultante, Ã© possÃ­vel mostrar que a estatÃ­stica $LR_{uc}$ converge para uma forma quadrÃ¡tica em relaÃ§Ã£o ao erro de estimaÃ§Ã£o da taxa de falha observada em relaÃ§Ã£o Ã  taxa de falha esperada.
III. A forma quadrÃ¡tica obtida Ã©, sob a hipÃ³tese nula, assintoticamente distribuÃ­da como uma qui-quadrado com um grau de liberdade, de acordo com resultados clÃ¡ssicos de estatÃ­stica assintÃ³tica.
IV. Esta abordagem, que utiliza a expansÃ£o de Taylor, complementa a anÃ¡lise anterior baseada no Teorema Central do Limite e no Teorema de Wilks, oferecendo uma outra perspectiva para a demonstraÃ§Ã£o da convergÃªncia assintÃ³tica da estatÃ­stica $LR_{uc}$.  â– 

#### ImplicaÃ§Ãµes PrÃ¡ticas e LimitaÃ§Ãµes
O teste $LR_{uc}$ fornece uma maneira formal de verificar a precisÃ£o de um modelo VAR. No entanto, como todos os testes estatÃ­sticos, ele tem algumas limitaÃ§Ãµes:

1.  **Poder do Teste:** O teste $LR_{uc}$ pode ter um poder baixo para amostras pequenas ou quando a taxa de falha esperada $p$ Ã© baixa. Isso significa que, em algumas situaÃ§Ãµes, o teste pode falhar em detectar um modelo mal calibrado, especialmente quando as exceÃ§Ãµes sÃ£o eventos raros [^16]. Aumentar o tamanho da amostra ajuda a aumentar o poder do teste [^10].
2.  **Erro do Tipo I e Tipo II:** Como mencionado anteriormente, Ã© necessÃ¡rio equilibrar os erros do Tipo I (rejeitar um modelo correto) e do Tipo II (nÃ£o rejeitar um modelo incorreto) [^8, ^11]. O nÃ­vel de confianÃ§a do teste controla o risco de erro do Tipo I, enquanto o poder do teste afeta o risco de erro do Tipo II [^8]. Ã‰ comum utilizar um nÃ­vel de confianÃ§a de 95%, o que implica que hÃ¡ uma chance de 5% de rejeitarmos um modelo que esteja corretamente calibrado.

**ObservaÃ§Ã£o 1.** *A escolha do nÃ­vel de confianÃ§a para o teste $LR_{uc}$ deve ser feita levando em consideraÃ§Ã£o a frequÃªncia de erros do Tipo I e Tipo II. NÃ­veis de confianÃ§a mais altos reduzem a probabilidade de rejeitar um modelo correto (erro Tipo I) mas aumentam a probabilidade de aceitar um modelo incorreto (erro Tipo II), e vice-versa.*

3.  **Cobertura Incondicional vs. Condicional:** O teste $LR_{uc}$ verifica apenas a cobertura *incondicional* do VAR, ou seja, se a taxa de falha mÃ©dia observada estÃ¡ de acordo com a taxa esperada. No entanto, ele nÃ£o avalia a *cobertura condicional*, ou seja, se as exceÃ§Ãµes se agrupam no tempo [^13]. O agrupamento de exceÃ§Ãµes, como observado em alguns perÃ­odos de maior volatilidade de mercado, sugere que o modelo VAR pode nÃ£o estar capturando adequadamente as mudanÃ§as no risco e, portanto, o teste $LR_{uc}$ pode nÃ£o ser suficiente por si sÃ³ para detectar esse tipo de problema [^13].
4.  **SuposiÃ§Ãµes:** Apesar de ser um teste nÃ£o paramÃ©trico em relaÃ§Ã£o Ã  distribuiÃ§Ã£o dos retornos, ele pressupÃµe que as exceÃ§Ãµes sÃ£o eventos independentes. A violaÃ§Ã£o dessa suposiÃ§Ã£o pode levar a resultados errÃ´neos, especialmente em perÃ­odos de alta volatilidade, onde as exceÃ§Ãµes tendem a se agrupar.

**CorolÃ¡rio 3.1.** *A limitaÃ§Ã£o do teste  $LR_{uc}$  em relaÃ§Ã£o Ã  cobertura condicional pode ser mitigada utilizando testes de cobertura condicional como o teste de Christoffersen, que complementa o $LR_{uc}$  ao verificar a independÃªncia temporal das exceÃ§Ãµes.* [^14, ^15]

**ObservaÃ§Ã£o 2.** *A independÃªncia das exceÃ§Ãµes Ã© uma suposiÃ§Ã£o importante do teste $LR_{uc}$. Em dados financeiros, Ã© comum que a volatilidade e, consequentemente, as exceÃ§Ãµes, se agrupem no tempo. Nesses casos, o teste $LR_{uc}$ pode subestimar o risco.*

**Exemplo:**
Revisando o exemplo do J.P. Morgan, citado anteriormente, onde foram observadas 20 exceÃ§Ãµes em 252 dias com um nÃ­vel de confianÃ§a do VAR de 95% [^6], e utilizando a fÃ³rmula do  $LR_{uc}$, temos:

$$
\text{LR}_{\text{uc}} = -2 \ln[(1 - 0.05)^{252-20} 0.05^{20}] + 2 \ln{[1 - (20/252)]^{252-20} (20/252)^{20}}
$$
$$
\text{LR}_{\text{uc}} = 2 \left[ 20 \ln\left(\frac{20/252}{0.05}\right) + (252-20) \ln\left(\frac{1-20/252}{1-0.05}\right) \right]
$$
$$
\text{LR}_{\text{uc}} \approx 3.91
$$
Como 3.91 > 3.841 (valor crÃ­tico para $\chi^2_1$ a 95% de confianÃ§a), rejeitamos a hipÃ³tese nula [^9]. Ou seja, os dados fornecem evidÃªncias suficientes para afirmar que o modelo de VAR usado pelo J.P. Morgan estava mal calibrado.

> ğŸ’¡ **Exemplo NumÃ©rico:**
> Para ilustrar a limitaÃ§Ã£o do poder do teste, considere uma situaÃ§Ã£o onde temos um modelo VAR com nÃ­vel de confianÃ§a de 99% (p=0.01) e observamos T=500 dias. EsperarÃ­amos, em mÃ©dia, 5 exceÃ§Ãµes. Suponha que observemos N=8 exceÃ§Ãµes, o que sugere uma taxa de falha observada de 8/500 = 0.016, um pouco maior que a esperada. Vamos calcular o $LR_{uc}$:
>
> $$
> \text{LR}_{\text{uc}} = 2 \left[ 8 \ln\left(\frac{8/500}{0.01}\right) + (500-8) \ln\left(\frac{1-8/500}{1-0.01}\right) \right]
> $$
> $$
> \text{LR}_{\text{uc}} = 2 \left[ 8 \ln\left(1.6\right) + 492 \ln\left(\frac{492/500}{0.99}\right) \right]
> $$
> $$
> \text{LR}_{\text{uc}} \approx 2 [8 \cdot 0.47 + 492 \cdot (-0.005)] \approx 2[3.76 - 2.46] \approx 2.6
> $$
>
> O valor de $LR_{uc} \approx 2.6$ Ã© menor que o valor crÃ­tico de 3.841, portanto, nÃ£o rejeitamos a hipÃ³tese nula a um nÃ­vel de significÃ¢ncia de 5%. Isso mostra que, mesmo que a taxa de falha observada seja maior que a esperada, o teste pode nÃ£o ter poder estatÃ­stico para detectar a falta de calibraÃ§Ã£o do modelo, especialmente com um nÃºmero de exceÃ§Ãµes pequeno e um nÃºmero total de observaÃ§Ãµes tambÃ©m nÃ£o muito grande. Aumentar o tamanho da amostra (T) aumentaria o poder do teste.

### ConclusÃ£o
A estatÃ­stica $LR_{uc}$ Ã© uma ferramenta fundamental no *backtesting* de modelos VAR. Ao comparar a frequÃªncia observada de exceÃ§Ãµes com a frequÃªncia esperada, ela fornece uma avaliaÃ§Ã£o estatÃ­stica da calibraÃ§Ã£o do modelo VAR. No entanto, Ã© crucial estar ciente das limitaÃ§Ãµes do teste, incluindo o seu poder limitado em algumas situaÃ§Ãµes, o risco de cometer erros de Tipo I e II, e a sua incapacidade de capturar o agrupamento temporal de exceÃ§Ãµes [^12, ^13]. O teste $LR_{uc}$ Ã© uma ferramenta muito Ãºtil e informativa, mas deve ser utilizada em conjunto com outros mÃ©todos de *backtesting*, como os testes de cobertura condicional, e outras tÃ©cnicas de anÃ¡lise de risco para garantir uma avaliaÃ§Ã£o abrangente e robusta da eficÃ¡cia do modelo VAR [^13, ^16]. Ã‰ importante reconhecer que o $LR_{uc}$ nÃ£o Ã© um fim em si mesmo, mas parte de um processo maior e contÃ­nuo de validaÃ§Ã£o do modelo [^4].

### ReferÃªncias
[^1]: *â€œValue-at-risk (VAR) models are only useful insofar as they predict risk reasonably well. This is why the application of these models always should be accompanied by validation.â€*
[^2]: *â€œWhen the model is perfectly calibrated, the number of observations falling outside VAR should be in line with the confidence level. The number of exceedences is also known as the number of exceptions.â€*
[^3]: *â€œBacktesting is a formal statistical framework that consists of verifying that actual losses are in line with projected losses. This involves systematically comparing the history of VAR forecasts with their associated portfolio returns.â€*
[^4]: *â€œThese procedures, sometimes called reality checks, are essential for VAR users and risk managers, who need to check that their VAR forecasts are well calibrated.â€*
[^5]: *â€œThe simplest method to verify the accuracy of the model is to record the failure rate, which gives the proportion of times VAR is exceeded in a given sample... We want to know, at a given confidence level, whether N is too small or too large under the null hypothesis that p = 0.01 in a sample of size T. Note that this test makes no assumption about the return distribution. As a result, this approach is fully nonparametric.â€*
[^6]: *â€œIn its 1998 annual report, the U.S. commercial bank J.P. Morgan (JPM) explained that In 1998, daily revenue fell short of the downside (95 percent VAR) band on 20 days, or more than 5 percent of the time. Nine of these 20 occurrences fell within the August to October period.â€*
[^7]: *â€œWe can test whether this was bad luck or a faulty model, assuming 252 days in the year. Based on Equation (6.2), we have z = (x-pT)/âˆšp(1-p) T = (20 - 0.05 Ã— 252)/âˆš0.05(0.95) 252 = 2.14. This is larger than the cutoff value of 1.96. Therefore, we reject the hypothesis that the VAR model is unbiased.â€*
[^8]: *â€œWhen designing a verification test, the user faces a tradeoff between these two types of error... For backtesting purposes, users of VAR models need to balance type 1 errors against type 2 errors.â€*
[^9]: *â€œLRuc = -2 In[(1 â€“ p)T-N pN] + 2 ln{[1 â€“ (N/T)]T-N (N/T)N} which is asymptotically (i.e., when T is large) distributed chi-square with one degree of freedom under the null hypothesis that p is the true probability. Thus we would reject the null hypothesis if LR > 3.841... In the JPM example, we had N = 20 exceptions over T = 252 days, using p = 95 percent VAR confidence level. Setting these numbers into Equation (6.3) gives LRuc = 3.91. Therefore, we reject unconditional coverage, as expected.â€*
[^10]: *â€œThe table also shows that this interval, expressed as a proportion N/T, shrinks as the sample size increases. ... With more data, we should be able to reject the model more easily if it is false.â€*
[^11]: *â€œThe heart of the conflict is that, inevitably, the supervisor also will commit type 2 errors for a bank that willfully cheats on its VAR reporting.â€*
[^12]: *â€œThe crux of the backtesting problem is separating bad luck from a faulty model, or balancing type 1 errors against type 2 errors.â€*
[^13]: *â€œSo far the framework focuses on unconditional coverage because it ignores conditioning, or time variation in the data. The observed exceptions, however, could cluster or "bunch" closely in time, which also should invalidate the model.â€*
[^14]: *â€œSuch a test has been developed by Christoffersen (1998), who extends the LRuc statistic to specify that the deviations must be serially independent.â€*
[^15]: *â€œThe combined test statistic for conditional coverage then is LRcc = LRuc + LRindâ€*
[^16]: *â€œWe have seen that the standard exception tests often lack power, especially when the VAR confidence level is high and when the number of observations is low. This has led to a search for improved tests.â€*
<!-- END -->
