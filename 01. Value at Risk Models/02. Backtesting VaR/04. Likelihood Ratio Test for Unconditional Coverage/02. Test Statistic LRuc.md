## Backtesting VAR: An√°lise Detalhada do Teste da Raz√£o de Verossimilhan√ßa para Cobertura Incondicional (LRuc)

### Introdu√ß√£o
Em continuidade √† discuss√£o anterior sobre a import√¢ncia do *backtesting* e do teste da raz√£o de verossimilhan√ßa para cobertura incondicional (LRuc) [^1], este cap√≠tulo tem como objetivo aprofundar o entendimento da estat√≠stica de teste $LR_{uc}$ em si, explorando suas propriedades, deriva√ß√£o e interpreta√ß√£o. O teste $LR_{uc}$ √© uma ferramenta chave para avaliar se um modelo de Value-at-Risk (VAR) est√° bem calibrado, verificando se a frequ√™ncia de exce√ß√µes observadas √© consistente com o n√≠vel de confian√ßa estabelecido [^2]. Como vimos anteriormente, o modelo VAR √© √∫til apenas se prediz o risco de forma adequada, e a valida√ß√£o do modelo, com o *backtesting*, √© essencial [^1]. A utiliza√ß√£o de um framework estat√≠stico como o teste $LR_{uc}$ √© um passo crucial para essa valida√ß√£o [^3].

### Conceitos Fundamentais
Como mencionado anteriormente, o *backtesting* de modelos VAR envolve comparar sistematicamente as previs√µes do modelo com os resultados reais [^3]. O teste $LR_{uc}$ surge como um m√©todo para verificar se o n√∫mero de exce√ß√µes observadas (onde as perdas reais excedem o VAR previsto) est√° em linha com o n√≠vel de confian√ßa do VAR [^2]. Para isso, definimos a *taxa de falha* como a propor√ß√£o de vezes que as perdas excedem o VAR [^5]. O teste $LR_{uc}$ usa essa taxa de falha observada para verificar se ela √© estatisticamente compat√≠vel com a taxa de falha esperada, que √© definida pelo n√≠vel de confian√ßa do VAR [^5]. Este teste √© n√£o param√©trico, o que significa que n√£o faz nenhuma suposi√ß√£o sobre a distribui√ß√£o dos retornos, tornando-o aplic√°vel a uma variedade de cen√°rios [^5].

O teste $LR_{uc}$  √© baseado em uma estat√≠stica que √© definida como [^9]:
$$
\text{LR}_{\text{uc}} = -2 \ln[(1 - p)^{T-N} p^N] + 2 \ln{[1 - (N/T)]^{T-N} (N/T)^N}
$$
onde:
*   $N$ √© o n√∫mero de exce√ß√µes observadas durante o per√≠odo de teste.
*   $T$ √© o n√∫mero total de observa√ß√µes no per√≠odo de teste.
*   $p$ √© a taxa de falha esperada, calculada como 1 menos o n√≠vel de confian√ßa do VAR (e.g., para um VAR de 99%, $p = 0.01$).

Como j√° derivado anteriormente (Teorema 1.1) [^5], uma formula√ß√£o equivalente e mais intuitiva pode ser:

$$
\text{LR}_{\text{uc}} = 2 \left[ N \ln\left(\frac{N/T}{p}\right) + (T-N) \ln\left(\frac{1-N/T}{1-p}\right) \right]
$$

Esta formula√ß√£o expressa o $LR_{uc}$ em termos da raz√£o entre a taxa de falha observada e a taxa de falha esperada.

#### Deriva√ß√£o e Interpreta√ß√£o da Estat√≠stica de Teste

**Proposi√ß√£o 3.** *A estat√≠stica $LR_{uc}$ √© derivada da raz√£o de verossimilhan√ßa, que compara a verossimilhan√ßa dos dados sob a hip√≥tese nula (o modelo est√° bem calibrado) com a verossimilhan√ßa sob a hip√≥tese alternativa (o modelo n√£o est√° bem calibrado). Sob a hip√≥tese nula, a estat√≠stica $LR_{uc}$ √© assintoticamente distribu√≠da como uma qui-quadrado com um grau de liberdade.* [^9]

A intui√ß√£o por tr√°s da estat√≠stica $LR_{uc}$ √© a seguinte:
*   O primeiro termo da equa√ß√£o ($-2 \ln[(1 - p)^{T-N} p^N]$) representa a log-verossimilhan√ßa dos dados (n√∫mero de exce√ß√µes) sob a hip√≥tese nula, ou seja, a hip√≥tese de que o modelo VAR est√° corretamente calibrado e as exce√ß√µes ocorrem com a frequ√™ncia esperada $p$.
*   O segundo termo da equa√ß√£o ($2 \ln{[1 - (N/T)]^{T-N} (N/T)^N}$) representa a log-verossimilhan√ßa dos dados sob a hip√≥tese alternativa, ou seja, a hip√≥tese de que a taxa de falha observada $N/T$ √© a melhor estimativa da verdadeira taxa de falha.
*   A diferen√ßa entre essas duas log-verossimilhan√ßas (multiplicada por -2) nos d√° a estat√≠stica $LR_{uc}$. Uma diferen√ßa grande sugere que a taxa de falha observada √© estatisticamente diferente da taxa de falha esperada, levando √† rejei√ß√£o da hip√≥tese nula.

**Lema 2.** *Quando a taxa de falha observada (N/T) se aproxima da taxa de falha esperada (p), a estat√≠stica $LR_{uc}$ se aproxima de zero, indicando que o modelo VAR est√° bem calibrado.*

*Prova:*
I. Como j√° visto no corol√°rio 1.1, quando $N/T = p$ [^5], cada termo dentro do logaritmo na formula√ß√£o do Teorema 1.1 √© igual a 1, e o logaritmo de 1 √© 0.
II. Consequentemente, $LR_{uc}$ torna-se zero, indicando perfeita concord√¢ncia entre a taxa de falha observada e esperada.  ‚ñ†

> üí° **Exemplo Num√©rico:**
> Suponha que temos um modelo VAR com n√≠vel de confian√ßa de 99% ($p = 0.01$) e observamos um per√≠odo de backtesting com $T=1000$ dias. Se o n√∫mero de exce√ß√µes observadas for exatamente o esperado, ou seja, $N = p \cdot T = 0.01 \cdot 1000 = 10$, ent√£o $N/T = 10/1000 = 0.01$, que √© igual a $p$.
>
> Aplicando a f√≥rmula:
> $$
> \text{LR}_{\text{uc}} = 2 \left[ 10 \ln\left(\frac{10/1000}{0.01}\right) + (1000-10) \ln\left(\frac{1-10/1000}{1-0.01}\right) \right]
> $$
> $$
> \text{LR}_{\text{uc}} = 2 \left[ 10 \ln\left(1\right) + 990 \ln\left(1\right) \right] = 2[10 \cdot 0 + 990 \cdot 0] = 0
> $$
>
> Neste caso, como esperado, $LR_{uc}$ √© igual a 0, o que indica que o modelo est√° perfeitamente calibrado.

**Lema 3.** *A estat√≠stica $LR_{uc}$ √© sempre n√£o negativa, conforme demonstrado no corol√°rio 1.2.* [^5]

*Prova:*
I. A fun√ß√£o de log-verossimilhan√ßa atinge seu m√°ximo quando a probabilidade de sucesso (taxa de falha) √© igual √† frequ√™ncia observada (N/T).
II. Isso implica que a raz√£o $\frac{L(p = N/T)}{L(p)}$ ser√° sempre maior ou igual a 1.
III. O logaritmo de um n√∫mero maior ou igual a 1 √© sempre n√£o negativo.
IV. Como $LR_{uc}$ √© duas vezes o logaritmo dessa raz√£o, $LR_{uc}$ √© sempre n√£o negativo [^5]. ‚ñ†

**Lema 3.1.** *A estat√≠stica  $LR_{uc}$  pode ser interpretada como uma medida de diverg√™ncia entre duas distribui√ß√µes de probabilidade: uma baseada na taxa de falha esperada  $p$ e outra baseada na taxa de falha observada  $N/T$*

*Prova:*

I. A estat√≠stica $LR_{uc}$ √© constru√≠da a partir da raz√£o de verossimilhan√ßas, que compara a probabilidade dos dados observados sob duas hip√≥teses distintas: uma onde a taxa de falha √© igual a $p$, e outra onde ela √© igual a $N/T$.
II. A log-verossimilhan√ßa, que √© utilizada no c√°lculo de  $LR_{uc}$, pode ser interpretada como uma medida da qualidade do ajuste de uma distribui√ß√£o de probabilidade aos dados. Assim, quanto maior o valor absoluto da diferen√ßa entre as log-verossimilhan√ßas, maior √© a diverg√™ncia entre as distribui√ß√µes associadas a cada hip√≥tese.
III. Especificamente, valores maiores de $LR_{uc}$ implicam que a distribui√ß√£o baseada em  $N/T$  est√° mais ajustada aos dados observados do que a distribui√ß√£o baseada em $p$. Ou seja, a taxa de falha observada √© estatisticamente diferente da esperada, e essa diferen√ßa pode ser quantificada pela estat√≠stica.  ‚ñ†

> üí° **Exemplo Num√©rico:**
> Imagine que, em vez de 10 exce√ß√µes como no exemplo anterior, observamos 20 exce√ß√µes em 1000 dias, com $p = 0.01$. Nesse caso, $N/T = 20/1000 = 0.02$.
>
> $$
> \text{LR}_{\text{uc}} = 2 \left[ 20 \ln\left(\frac{20/1000}{0.01}\right) + (1000-20) \ln\left(\frac{1-20/1000}{1-0.01}\right) \right]
> $$
> $$
> \text{LR}_{\text{uc}} = 2 \left[ 20 \ln\left(2\right) + 980 \ln\left(\frac{0.98}{0.99}\right) \right]
> $$
> $$
> \text{LR}_{\text{uc}} \approx 2 [20 \cdot 0.693 - 980 \cdot 0.010] \approx 2 [13.86 - 9.8] \approx 2 \cdot 4.06 \approx 8.12
> $$
>
> O valor de $LR_{uc}$ de aproximadamente 8.12 √© maior que 0 e reflete a diverg√™ncia entre a taxa de falha observada (0.02) e a esperada (0.01).

**Lema 3.2.** *A estat√≠stica $LR_{uc}$ pode ser expressa como uma diferen√ßa entre duas entropias relativas (Kullback-Leibler Divergence), o que refor√ßa a interpreta√ß√£o de que ela mede a diverg√™ncia entre duas distribui√ß√µes de probabilidade.*

*Prova:*
I. A entropia relativa (Kullback-Leibler Divergence) entre duas distribui√ß√µes de probabilidade, $P$ e $Q$, √© dada por $D_{KL}(P||Q) = \sum P(x) \ln(\frac{P(x)}{Q(x)})$.
II. No caso do teste $LR_{uc}$, podemos considerar que $P$ √© a distribui√ß√£o que descreve a frequ√™ncia de exce√ß√µes baseada na taxa de falha observada $N/T$, e $Q$ √© a distribui√ß√£o baseada na taxa de falha esperada $p$.
III. A estat√≠stica $LR_{uc}$ pode ser reescrita como $LR_{uc} = 2T[D_{KL}(N/T||p) - D_{KL}(N/T||N/T)]$.
IV. Dado que $D_{KL}(N/T||N/T) = 0$, a estat√≠stica  $LR_{uc}$  torna-se uma vers√£o escalonada por 2T da diverg√™ncia de Kullback-Leibler entre as distribui√ß√µes associadas √† taxa de falha observada e esperada.  ‚ñ†

**Lema 3.3** *A interpreta√ß√£o da estat√≠stica $LR_{uc}$ como uma medida de diverg√™ncia entre distribui√ß√µes tamb√©m pode ser vista atrav√©s da dist√¢ncia de Hellinger. A dist√¢ncia de Hellinger √© uma outra forma de quantificar a diferen√ßa entre duas distribui√ß√µes e sua rela√ß√£o com a estat√≠stica $LR_{uc}$ refor√ßa essa interpreta√ß√£o.*

*Prova:*

I. A dist√¢ncia de Hellinger entre duas distribui√ß√µes de probabilidade, $P$ e $Q$, √© definida como $H(P,Q) = \sqrt{\frac{1}{2}\sum (\sqrt{P(x)} - \sqrt{Q(x)})^2}$.
II. No caso do teste $LR_{uc}$, as distribui√ß√µes $P$ e $Q$ podem ser consideradas como as distribui√ß√µes binomial com par√¢metros $(T, N/T)$ e $(T, p)$, respectivamente.
III. Sob condi√ß√µes de regularidade e com aproxima√ß√µes adequadas, pode-se demonstrar que a estat√≠stica $LR_{uc}$ est√° relacionada com o quadrado da dist√¢ncia de Hellinger, de tal forma que valores maiores de $LR_{uc}$ correspondem a uma maior dist√¢ncia de Hellinger entre as duas distribui√ß√µes.
IV. Essa rela√ß√£o refor√ßa a interpreta√ß√£o de que a estat√≠stica $LR_{uc}$ mede a diverg√™ncia entre as distribui√ß√µes de probabilidade baseadas nas taxas de falha observadas e esperadas, fornecendo uma interpreta√ß√£o alternativa e complementar √† an√°lise da diverg√™ncia de Kullback-Leibler. ‚ñ†

#### Distribui√ß√£o Assint√≥tica
Um aspecto crucial do teste $LR_{uc}$ √© que, sob a hip√≥tese nula (o modelo VAR est√° corretamente calibrado), a estat√≠stica do teste converge assintoticamente para uma distribui√ß√£o qui-quadrado com um grau de liberdade quando o n√∫mero de observa√ß√µes (T) se torna grande [^9]. Isso significa que, para grandes amostras, podemos utilizar a distribui√ß√£o qui-quadrado para determinar se o valor observado de $LR_{uc}$ √© estatisticamente significativo.

**Teorema 2.** *Sob a hip√≥tese nula, a estat√≠stica $LR_{uc}$ segue assintoticamente uma distribui√ß√£o qui-quadrado com um grau de liberdade. Formalmente, dizemos que $LR_{uc} \overset{d}{\longrightarrow} \chi^2_1$, onde $\overset{d}{\longrightarrow}$ denota converg√™ncia em distribui√ß√£o.* [^9]

*Prova:*
I. A deriva√ß√£o completa desse teorema envolve matem√°tica estat√≠stica avan√ßada, que est√° al√©m do escopo deste cap√≠tulo. No entanto, a ideia b√°sica √© que, sob condi√ß√µes de regularidade (que geralmente s√£o satisfeitas nos dados financeiros), a diferen√ßa entre a log-verossimilhan√ßa dos dados sob a hip√≥tese nula e sob a hip√≥tese alternativa, quando multiplicada por -2, converge para uma distribui√ß√£o qui-quadrado.
II. Especificamente, o n√∫mero de graus de liberdade corresponde √† diferen√ßa entre o n√∫mero de par√¢metros estimados sob a hip√≥tese alternativa e o n√∫mero de par√¢metros estimados sob a hip√≥tese nula, sendo neste caso igual a 1, pois sob a hip√≥tese alternativa, temos um par√¢metro (N/T) e sob a hip√≥tese nula, temos o par√¢metro p, resultando em 1 grau de liberdade.  ‚ñ†

**Teorema 2.1.** *A converg√™ncia assint√≥tica da estat√≠stica $LR_{uc}$ para uma distribui√ß√£o qui-quadrado com um grau de liberdade pode ser entendida como uma consequ√™ncia do Teorema Central do Limite (TCL) aplicado √† log-raz√£o de verossimilhan√ßas.*

*Prova:*

I. O TCL estabelece que a soma (ou m√©dia) de um grande n√∫mero de vari√°veis aleat√≥rias independentes e identicamente distribu√≠das converge para uma distribui√ß√£o normal, sob certas condi√ß√µes.
II. A log-raz√£o de verossimilhan√ßas pode ser vista como uma soma de contribui√ß√µes individuais de cada observa√ß√£o (exce√ß√£o ou n√£o exce√ß√£o)
III. Ao multiplic√°-la por -2, e sob a hip√≥tese nula, a distribui√ß√£o resultante aproxima-se de uma qui-quadrado com um grau de liberdade √† medida que o n√∫mero de observa√ß√µes (T) aumenta.
IV. O grau de liberdade √© dado pela diferen√ßa no n√∫mero de par√¢metros estimados entre a hip√≥tese nula e a alternativa, que √© igual a 1 neste caso, visto que sob a hip√≥tese nula temos o par√¢metro p, e na hip√≥tese alternativa temos N/T.  ‚ñ†

Essa propriedade √© fundamental, pois permite estabelecer um valor cr√≠tico para o teste com base na distribui√ß√£o qui-quadrado. Por exemplo, com um n√≠vel de confian√ßa de 95%, o valor cr√≠tico para uma distribui√ß√£o qui-quadrado com um grau de liberdade √© 3.841 [^9]. Se o valor calculado de $LR_{uc}$ for maior do que esse valor cr√≠tico, rejeitamos a hip√≥tese nula, indicando que o modelo VAR est√° mal calibrado.

> üí° **Exemplo Num√©rico:**
>
> Continuando com o exemplo anterior, onde $\text{LR}_{\text{uc}} \approx 8.12$, e considerando um n√≠vel de signific√¢ncia de 5% (ou um n√≠vel de confian√ßa de 95%), comparamos o valor da estat√≠stica com o valor cr√≠tico da distribui√ß√£o qui-quadrado com 1 grau de liberdade. O valor cr√≠tico para $\chi^2_1$ a 5% de signific√¢ncia √© 3.841.
>
> Como $8.12 > 3.841$, rejeitamos a hip√≥tese nula, o que indica que o modelo VAR est√° mal calibrado. Isto √©, a taxa de falha observada (2%) √© estatisticamente diferente da taxa de falha esperada (1%).

**Teorema 2.2** *O Teorema de Wilks generaliza o resultado da distribui√ß√£o assint√≥tica do teste $LR_{uc}$ e garante a converg√™ncia para uma distribui√ß√£o $\chi^2$ da estat√≠stica de teste da raz√£o de verossimilhan√ßas, onde o n√∫mero de graus de liberdade √© dado pela diferen√ßa entre o n√∫mero de par√¢metros estimados sob a hip√≥tese alternativa e o n√∫mero de par√¢metros estimados sob a hip√≥tese nula.*

*Prova:*
I. O Teorema de Wilks estabelece que sob certas condi√ß√µes de regularidade, e com a hip√≥tese nula sendo verdadeira, a estat√≠stica do teste da raz√£o de verossimilhan√ßas converge assintoticamente para uma distribui√ß√£o qui-quadrado.
II. No caso do teste $LR_{uc}$, a hip√≥tese nula assume que o modelo VAR est√° corretamente calibrado e que a taxa de falha observada √© compat√≠vel com a taxa de falha esperada, resultando em um grau de liberdade.
III. Este teorema generaliza a ideia por tr√°s do Teorema 2, aplicando-se a uma classe mais ampla de modelos e hip√≥teses.  ‚ñ†

**Teorema 2.3** *A converg√™ncia assint√≥tica da estat√≠stica $LR_{uc}$ para uma distribui√ß√£o qui-quadrado com um grau de liberdade tamb√©m pode ser demonstrada utilizando a expans√£o de Taylor da fun√ß√£o log-verossimilhan√ßa em torno do valor verdadeiro do par√¢metro. Essa abordagem oferece uma perspectiva alternativa para a compreens√£o da distribui√ß√£o assint√≥tica.*

*Prova:*

I. A fun√ß√£o log-verossimilhan√ßa, que √© a base para a constru√ß√£o da estat√≠stica $LR_{uc}$, pode ser aproximada atrav√©s de uma expans√£o de Taylor de segunda ordem em torno do valor verdadeiro da taxa de falha ($p$).
II. Ao realizar essa expans√£o e simplificar a express√£o resultante, √© poss√≠vel mostrar que a estat√≠stica $LR_{uc}$ converge para uma forma quadr√°tica em rela√ß√£o ao erro de estima√ß√£o da taxa de falha observada em rela√ß√£o √† taxa de falha esperada.
III. A forma quadr√°tica obtida √©, sob a hip√≥tese nula, assintoticamente distribu√≠da como uma qui-quadrado com um grau de liberdade, de acordo com resultados cl√°ssicos de estat√≠stica assint√≥tica.
IV. Esta abordagem, que utiliza a expans√£o de Taylor, complementa a an√°lise anterior baseada no Teorema Central do Limite e no Teorema de Wilks, oferecendo uma outra perspectiva para a demonstra√ß√£o da converg√™ncia assint√≥tica da estat√≠stica $LR_{uc}$.  ‚ñ†

#### Implica√ß√µes Pr√°ticas e Limita√ß√µes
O teste $LR_{uc}$ fornece uma maneira formal de verificar a precis√£o de um modelo VAR. No entanto, como todos os testes estat√≠sticos, ele tem algumas limita√ß√µes:

1.  **Poder do Teste:** O teste $LR_{uc}$ pode ter um poder baixo para amostras pequenas ou quando a taxa de falha esperada $p$ √© baixa. Isso significa que, em algumas situa√ß√µes, o teste pode falhar em detectar um modelo mal calibrado, especialmente quando as exce√ß√µes s√£o eventos raros [^16]. Aumentar o tamanho da amostra ajuda a aumentar o poder do teste [^10].
2.  **Erro do Tipo I e Tipo II:** Como mencionado anteriormente, √© necess√°rio equilibrar os erros do Tipo I (rejeitar um modelo correto) e do Tipo II (n√£o rejeitar um modelo incorreto) [^8, ^11]. O n√≠vel de confian√ßa do teste controla o risco de erro do Tipo I, enquanto o poder do teste afeta o risco de erro do Tipo II [^8]. √â comum utilizar um n√≠vel de confian√ßa de 95%, o que implica que h√° uma chance de 5% de rejeitarmos um modelo que esteja corretamente calibrado.

**Observa√ß√£o 1.** *A escolha do n√≠vel de confian√ßa para o teste $LR_{uc}$ deve ser feita levando em considera√ß√£o a frequ√™ncia de erros do Tipo I e Tipo II. N√≠veis de confian√ßa mais altos reduzem a probabilidade de rejeitar um modelo correto (erro Tipo I) mas aumentam a probabilidade de aceitar um modelo incorreto (erro Tipo II), e vice-versa.*

3.  **Cobertura Incondicional vs. Condicional:** O teste $LR_{uc}$ verifica apenas a cobertura *incondicional* do VAR, ou seja, se a taxa de falha m√©dia observada est√° de acordo com a taxa esperada. No entanto, ele n√£o avalia a *cobertura condicional*, ou seja, se as exce√ß√µes se agrupam no tempo [^13]. O agrupamento de exce√ß√µes, como observado em alguns per√≠odos de maior volatilidade de mercado, sugere que o modelo VAR pode n√£o estar capturando adequadamente as mudan√ßas no risco e, portanto, o teste $LR_{uc}$ pode n√£o ser suficiente por si s√≥ para detectar esse tipo de problema [^13].
4.  **Suposi√ß√µes:** Apesar de ser um teste n√£o param√©trico em rela√ß√£o √† distribui√ß√£o dos retornos, ele pressup√µe que as exce√ß√µes s√£o eventos independentes. A viola√ß√£o dessa suposi√ß√£o pode levar a resultados err√¥neos, especialmente em per√≠odos de alta volatilidade, onde as exce√ß√µes tendem a se agrupar.

**Corol√°rio 3.1.** *A limita√ß√£o do teste  $LR_{uc}$  em rela√ß√£o √† cobertura condicional pode ser mitigada utilizando testes de cobertura condicional como o teste de Christoffersen, que complementa o $LR_{uc}$  ao verificar a independ√™ncia temporal das exce√ß√µes.* [^14, ^15]

**Observa√ß√£o 2.** *A independ√™ncia das exce√ß√µes √© uma suposi√ß√£o importante do teste $LR_{uc}$. Em dados financeiros, √© comum que a volatilidade e, consequentemente, as exce√ß√µes, se agrupem no tempo. Nesses casos, o teste $LR_{uc}$ pode subestimar o risco.*

**Exemplo:**
Revisando o exemplo do J.P. Morgan, citado anteriormente, onde foram observadas 20 exce√ß√µes em 252 dias com um n√≠vel de confian√ßa do VAR de 95% [^6], e utilizando a f√≥rmula do  $LR_{uc}$, temos:

$$
\text{LR}_{\text{uc}} = -2 \ln[(1 - 0.05)^{252-20} 0.05^{20}] + 2 \ln{[1 - (20/252)]^{252-20} (20/252)^{20}}
$$
$$
\text{LR}_{\text{uc}} = 2 \left[ 20 \ln\left(\frac{20/252}{0.05}\right) + (252-20) \ln\left(\frac{1-20/252}{1-0.05}\right) \right]
$$
$$
\text{LR}_{\text{uc}} \approx 3.91
$$
Como 3.91 > 3.841 (valor cr√≠tico para $\chi^2_1$ a 95% de confian√ßa), rejeitamos a hip√≥tese nula [^9]. Ou seja, os dados fornecem evid√™ncias suficientes para afirmar que o modelo de VAR usado pelo J.P. Morgan estava mal calibrado.

> üí° **Exemplo Num√©rico:**
> Para ilustrar a limita√ß√£o do poder do teste, considere uma situa√ß√£o onde temos um modelo VAR com n√≠vel de confian√ßa de 99% (p=0.01) e observamos T=500 dias. Esperar√≠amos, em m√©dia, 5 exce√ß√µes. Suponha que observemos N=8 exce√ß√µes, o que sugere uma taxa de falha observada de 8/500 = 0.016, um pouco maior que a esperada. Vamos calcular o $LR_{uc}$:
>
> $$
> \text{LR}_{\text{uc}} = 2 \left[ 8 \ln\left(\frac{8/500}{0.01}\right) + (500-8) \ln\left(\frac{1-8/500}{1-0.01}\right) \right]
> $$
> $$
> \text{LR}_{\text{uc}} = 2 \left[ 8 \ln\left(1.6\right) + 492 \ln\left(\frac{492/500}{0.99}\right) \right]
> $$
> $$
> \text{LR}_{\text{uc}} \approx 2 [8 \cdot 0.47 + 492 \cdot (-0.005)] \approx 2[3.76 - 2.46] \approx 2.6
> $$
>
> O valor de $LR_{uc} \approx 2.6$ √© menor que o valor cr√≠tico de 3.841, portanto, n√£o rejeitamos a hip√≥tese nula a um n√≠vel de signific√¢ncia de 5%. Isso mostra que, mesmo que a taxa de falha observada seja maior que a esperada, o teste pode n√£o ter poder estat√≠stico para detectar a falta de calibra√ß√£o do modelo, especialmente com um n√∫mero de exce√ß√µes pequeno e um n√∫mero total de observa√ß√µes tamb√©m n√£o muito grande. Aumentar o tamanho da amostra (T) aumentaria o poder do teste.

### Conclus√£o
A estat√≠stica $LR_{uc}$ √© uma ferramenta fundamental no *backtesting* de modelos VAR. Ao comparar a frequ√™ncia observada de exce√ß√µes com a frequ√™ncia esperada, ela fornece uma avalia√ß√£o estat√≠stica da calibra√ß√£o do modelo VAR. No entanto, √© crucial estar ciente das limita√ß√µes do teste, incluindo o seu poder limitado em algumas situa√ß√µes, o risco de cometer erros de Tipo I e II, e a sua incapacidade de capturar o agrupamento temporal de exce√ß√µes [^12, ^13]. O teste $LR_{uc}$ √© uma ferramenta muito √∫til e informativa, mas deve ser utilizada em conjunto com outros m√©todos de *backtesting*, como os testes de cobertura condicional, e outras t√©cnicas de an√°lise de risco para garantir uma avalia√ß√£o abrangente e robusta da efic√°cia do modelo VAR [^13, ^16]. √â importante reconhecer que o $LR_{uc}$ n√£o √© um fim em si mesmo, mas parte de um processo maior e cont√≠nuo de valida√ß√£o do modelo [^4].

### Refer√™ncias
[^1]: *‚ÄúValue-at-risk (VAR) models are only useful insofar as they predict risk reasonably well. This is why the application of these models always should be accompanied by validation.‚Äù*
[^2]: *‚ÄúWhen the model is perfectly calibrated, the number of observations falling outside VAR should be in line with the confidence level. The number of exceedences is also known as the number of exceptions.‚Äù*
[^3]: *‚ÄúBacktesting is a formal statistical framework that consists of verifying that actual losses are in line with projected losses. This involves systematically comparing the history of VAR forecasts with their associated portfolio returns.‚Äù*
[^4]: *‚ÄúThese procedures, sometimes called reality checks, are essential for VAR users and risk managers, who need to check that their VAR forecasts are well calibrated.‚Äù*
[^5]: *‚ÄúThe simplest method to verify the accuracy of the model is to record the failure rate, which gives the proportion of times VAR is exceeded in a given sample... We want to know, at a given confidence level, whether N is too small or too large under the null hypothesis that p = 0.01 in a sample of size T. Note that this test makes no assumption about the return distribution. As a result, this approach is fully nonparametric.‚Äù*
[^6]: *‚ÄúIn its 1998 annual report, the U.S. commercial bank J.P. Morgan (JPM) explained that In 1998, daily revenue fell short of the downside (95 percent VAR) band on 20 days, or more than 5 percent of the time. Nine of these 20 occurrences fell within the August to October period.‚Äù*
[^7]: *‚ÄúWe can test whether this was bad luck or a faulty model, assuming 252 days in the year. Based on Equation (6.2), we have z = (x-pT)/‚àöp(1-p) T = (20 - 0.05 √ó 252)/‚àö0.05(0.95) 252 = 2.14. This is larger than the cutoff value of 1.96. Therefore, we reject the hypothesis that the VAR model is unbiased.‚Äù*
[^8]: *‚ÄúWhen designing a verification test, the user faces a tradeoff between these two types of error... For backtesting purposes, users of VAR models need to balance type 1 errors against type 2 errors.‚Äù*
[^9]: *‚ÄúLRuc = -2 In[(1 ‚Äì p)T-N pN] + 2 ln{[1 ‚Äì (N/T)]T-N (N/T)N} which is asymptotically (i.e., when T is large) distributed chi-square with one degree of freedom under the null hypothesis that p is the true probability. Thus we would reject the null hypothesis if LR > 3.841... In the JPM example, we had N = 20 exceptions over T = 252 days, using p = 95 percent VAR confidence level. Setting these numbers into Equation (6.3) gives LRuc = 3.91. Therefore, we reject unconditional coverage, as expected.‚Äù*
[^10]: *‚ÄúThe table also shows that this interval, expressed as a proportion N/T, shrinks as the sample size increases. ... With more data, we should be able to reject the model more easily if it is false.‚Äù*
[^11]: *‚ÄúThe heart of the conflict is that, inevitably, the supervisor also will commit type 2 errors for a bank that willfully cheats on its VAR reporting.‚Äù*
[^12]: *‚ÄúThe crux of the backtesting problem is separating bad luck from a faulty model, or balancing type 1 errors against type 2 errors.‚Äù*
[^13]: *‚ÄúSo far the framework focuses on unconditional coverage because it ignores conditioning, or time variation in the data. The observed exceptions, however, could cluster or "bunch" closely in time, which also should invalidate the model.‚Äù*
[^14]: *‚ÄúSuch a test has been developed by Christoffersen (1998), who extends the LRuc statistic to specify that the deviations must be serially independent.‚Äù*
[^15]: *‚ÄúThe combined test statistic for conditional coverage then is LRcc = LRuc + LRind‚Äù*
[^16]: *‚ÄúWe have seen that the standard exception tests often lack power, especially when the VAR confidence level is high and when the number of observations is low. This has led to a search for improved tests.‚Äù*
<!-- END -->
