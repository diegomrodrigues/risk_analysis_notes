## Backtesting VAR: DistribuiÃ§Ã£o AssintÃ³tica da EstatÃ­stica LRuc e RejeiÃ§Ã£o da HipÃ³tese Nula

### IntroduÃ§Ã£o
Dando continuidade Ã  anÃ¡lise detalhada do teste da razÃ£o de verossimilhanÃ§a para cobertura incondicional (LRuc) [^1, ^2], este capÃ­tulo foca na distribuiÃ§Ã£o assintÃ³tica da estatÃ­stica LRuc e como essa propriedade Ã© utilizada para estabelecer critÃ©rios de rejeiÃ§Ã£o da hipÃ³tese nula. Como discutido anteriormente, o teste LRuc avalia se a taxa de falha observada em um modelo VAR Ã© consistente com a taxa de falha esperada [^3, ^5]. A capacidade de determinar se uma divergÃªncia entre essas taxas Ã© estatisticamente significativa Ã© fundamental para a validaÃ§Ã£o do modelo. A distribuiÃ§Ã£o assintÃ³tica da estatÃ­stica LRuc permite essa avaliaÃ§Ã£o, oferecendo uma base para decisÃµes sobre a adequaÃ§Ã£o do modelo [^9].

### Conceitos Fundamentais
Conforme explorado anteriormente, o teste LRuc compara a log-verossimilhanÃ§a dos dados sob a hipÃ³tese nula (modelo VAR bem calibrado) com a log-verossimilhanÃ§a sob a hipÃ³tese alternativa (modelo mal calibrado) [^2]. A estatÃ­stica do teste LRuc Ã© definida como [^9]:

$$
\text{LR}_{\text{uc}} = -2 \ln[(1 - p)^{T-N} p^N] + 2 \ln{[1 - (N/T)]^{T-N} (N/T)^N}
$$

ou, de forma equivalente [^5]:

$$
\text{LR}_{\text{uc}} = 2 \left[ N \ln\left(\frac{N/T}{p}\right) + (T-N) \ln\left(\frac{1-N/T}{1-p}\right) \right]
$$

Onde:
*   $N$ Ã© o nÃºmero de exceÃ§Ãµes observadas.
*   $T$ Ã© o nÃºmero total de observaÃ§Ãµes.
*   $p$ Ã© a taxa de falha esperada (1 - nÃ­vel de confianÃ§a do VAR).

A interpretaÃ§Ã£o e aplicaÃ§Ã£o do teste LRuc dependem crucialmente da sua distribuiÃ§Ã£o assintÃ³tica. Como demonstrado no capÃ­tulo anterior, sob a hipÃ³tese nula (o modelo VAR estÃ¡ corretamente calibrado), esta estatÃ­stica segue assintoticamente uma distribuiÃ§Ã£o qui-quadrado com um grau de liberdade [^2, ^9]. Esta propriedade permite que o teste seja implementado de forma prÃ¡tica, estabelecendo um valor crÃ­tico com o qual comparar o resultado do teste.

#### DistribuiÃ§Ã£o AssintÃ³tica da EstatÃ­stica LRuc
A propriedade da distribuiÃ§Ã£o assintÃ³tica da estatÃ­stica LRuc Ã© fundamental para a sua utilizaÃ§Ã£o. Assintoticamente, ou seja, quando o nÃºmero de observaÃ§Ãµes ($T$) Ã© grande, a distribuiÃ§Ã£o da estatÃ­stica LRuc sob a hipÃ³tese nula, se aproxima de uma distribuiÃ§Ã£o qui-quadrado com um grau de liberdade [^2, ^9].

**ProposiÃ§Ã£o 4.** *Sob a hipÃ³tese nula, quando o tamanho da amostra ($T$) tende ao infinito, a estatÃ­stica LRuc converge em distribuiÃ§Ã£o para uma qui-quadrado com um grau de liberdade. Formalmente, $LR_{uc} \overset{d}{\longrightarrow} \chi^2_1$, onde $\overset{d}{\longrightarrow}$ denota convergÃªncia em distribuiÃ§Ã£o.* [^9]

Essa convergÃªncia Ã© uma consequÃªncia do Teorema Central do Limite (TCL) e da teoria assintÃ³tica para testes de razÃ£o de verossimilhanÃ§a, como vimos anteriormente [^2]. Em termos prÃ¡ticos, essa propriedade significa que, para amostras grandes, podemos usar a distribuiÃ§Ã£o qui-quadrado para determinar se o valor observado de LRuc Ã© estatisticamente significativo [^2].

**Teorema 3.** *A estatÃ­stica LRuc Ã© assintoticamente distribuÃ­da como uma qui-quadrado com um grau de liberdade sob a hipÃ³tese nula. Formalmente, $LR_{uc} \overset{d}{\longrightarrow} \chi^2_1$, onde $\overset{d}{\longrightarrow}$ denota convergÃªncia em distribuiÃ§Ã£o e $\chi^2_1$ denota uma distribuiÃ§Ã£o qui-quadrado com um grau de liberdade.* [^9]
*Prova:*
I. A demonstraÃ§Ã£o formal deste teorema envolve a utilizaÃ§Ã£o do Teorema de Wilks, que estabelece que a estatÃ­stica da razÃ£o de verossimilhanÃ§a converge para uma distribuiÃ§Ã£o qui-quadrado com graus de liberdade iguais Ã  diferenÃ§a entre o nÃºmero de parÃ¢metros estimados sob a hipÃ³tese alternativa e a hipÃ³tese nula.
II.  No contexto do teste LRuc, sob a hipÃ³tese nula, a taxa de falha Ã© p, que Ã© um valor conhecido. Sob a hipÃ³tese alternativa, a taxa de falha Ã© estimada pela frequÃªncia observada N/T. Portanto, a diferenÃ§a no nÃºmero de parÃ¢metros Ã© 1, e por isso, a estatÃ­stica converge para $\chi^2_1$
III. A intuiÃ§Ã£o por trÃ¡s do teorema Ã© que, quando o nÃºmero de observaÃ§Ãµes Ã© grande, a distribuiÃ§Ã£o das taxas de falha observadas se aproxima de uma distribuiÃ§Ã£o normal centrada na taxa de falha esperada.
IV. Uma consequÃªncia importante desse teorema Ã© que, para amostras grandes, podemos usar a distribuiÃ§Ã£o qui-quadrado para estabelecer um valor crÃ­tico para o teste de hipÃ³teses, rejeitando a hipÃ³tese nula caso o valor observado de LRuc seja maior do que esse valor crÃ­tico. â– 

**Teorema 3.1.** *A convergÃªncia da estatÃ­stica $LR_{uc}$ para uma distribuiÃ§Ã£o qui-quadrado pode ser vista como um caso especial da teoria assintÃ³tica de testes da razÃ£o de verossimilhanÃ§a. Em particular, a estatÃ­stica do teste da razÃ£o de verossimilhanÃ§a Ã© assintoticamente distribuÃ­da como uma qui-quadrado com um nÃºmero de graus de liberdade igual Ã  diferenÃ§a entre a dimensionalidade dos espaÃ§os de parÃ¢metros sob a hipÃ³tese alternativa e sob a hipÃ³tese nula.*

*Prova:*

I. A demonstraÃ§Ã£o detalhada do Teorema de Wilks e suas implicaÃ§Ãµes para a convergÃªncia da estatÃ­stica $LR_{uc}$ requer conhecimentos de estatÃ­stica assintÃ³tica e teoria da estimaÃ§Ã£o.
II. Em termos gerais, o teorema estabelece que, sob condiÃ§Ãµes de regularidade (que geralmente sÃ£o satisfeitas nos dados financeiros) e sob a hipÃ³tese nula, a estatÃ­stica da razÃ£o de verossimilhanÃ§a, que compara a verossimilhanÃ§a dos dados sob a hipÃ³tese alternativa e a hipÃ³tese nula, converge para uma distribuiÃ§Ã£o qui-quadrado.
III. O nÃºmero de graus de liberdade dessa qui-quadrado Ã© determinado pela diferenÃ§a entre os parÃ¢metros estimados sob as hipÃ³teses alternativa e nula.
IV. No caso do teste $LR_{uc}$, sob a hipÃ³tese nula temos a taxa de falha esperada $p$, e sob a hipÃ³tese alternativa temos a taxa de falha observada $N/T$, de modo que a diferenÃ§a de nÃºmero de parÃ¢metros Ã© 1.  â– 

> ğŸ’¡ **Exemplo NumÃ©rico:**
>
> Vamos simular um cenÃ¡rio onde um modelo VAR tem um nÃ­vel de confianÃ§a de 99% (taxa de falha esperada p=0.01). Simularemos 1000 amostras de tamanho T=250 (aproximadamente um ano de dados diÃ¡rios) e calcularemos a estatÃ­stica LRuc para cada amostra. Sob a hipÃ³tese nula (o modelo estÃ¡ bem calibrado), a estatÃ­stica LRuc deve convergir para uma distribuiÃ§Ã£o qui-quadrado com 1 grau de liberdade.
>
> ```python
> import numpy as np
> from scipy.stats import chi2
>
> def calculate_lruc(N, T, p):
>     if N == 0 or N == T:
>         return 0  # Avoid log of zero
>     lruc = 2 * (N * np.log(N/T / p) + (T - N) * np.log((1 - N/T) / (1 - p)))
>     return lruc
>
> def simulate_lruc_distribution(T, p, num_simulations):
>   lruc_values = []
>   for _ in range(num_simulations):
>     N = np.random.binomial(T, p) #simulate number of exceptions
>     lruc = calculate_lruc(N, T, p)
>     lruc_values.append(lruc)
>   return np.array(lruc_values)
>
> T = 250
> p = 0.01
> num_simulations = 1000
> lruc_values = simulate_lruc_distribution(T, p, num_simulations)
>
> # Compare simulated distribution with chi2
> df = 1
> critical_value = chi2.ppf(0.95, df)
> rejection_count = np.sum(lruc_values > critical_value)
> rejection_rate = rejection_count/num_simulations
> print(f"Rejection rate: {rejection_rate:.3f}")
> ```
>
> A taxa de rejeiÃ§Ã£o simulada deve ser prÃ³xima ao nÃ­vel de significÃ¢ncia (5% para um nÃ­vel de confianÃ§a de 95%), confirmando que a distribuiÃ§Ã£o da estatÃ­stica LRuc se aproxima da distribuiÃ§Ã£o qui-quadrado com um grau de liberdade.

**Lema 4.** *A convergÃªncia da estatÃ­stica LRuc para uma distribuiÃ§Ã£o qui-quadrado ocorre Ã  medida que o tamanho da amostra (T) aumenta, e a aproximaÃ§Ã£o Ã© mais precisa para tamanhos de amostra maiores. Para tamanhos de amostra pequenos, a distribuiÃ§Ã£o da estatÃ­stica LRuc pode ser diferente da distribuiÃ§Ã£o qui-quadrado, o que pode levar a conclusÃµes errÃ´neas sobre a calibraÃ§Ã£o do modelo.*

*Prova:*
I. A convergÃªncia assintÃ³tica Ã© uma propriedade que se manifesta Ã  medida que o tamanho da amostra se aproxima do infinito. Para amostras finitas, a aproximaÃ§Ã£o pode nÃ£o ser perfeita.
II. Em geral, quanto maior a amostra, mais prÃ³xima a distribuiÃ§Ã£o da estatÃ­stica LRuc estarÃ¡ da distribuiÃ§Ã£o qui-quadrado, o que aumenta a confianÃ§a nos resultados do teste.
III.  A falta de convergÃªncia para tamanhos de amostras pequenos pode levar a erros do tipo I (rejeitar uma hipÃ³tese verdadeira) ou do tipo II (nÃ£o rejeitar uma hipÃ³tese falsa) com maior frequÃªncia do que o esperado para um nÃ­vel de significÃ¢ncia dado.  â– 

**Lema 4.1.** *Embora a estatÃ­stica LRuc convirja para uma distribuiÃ§Ã£o qui-quadrado, a velocidade dessa convergÃªncia pode depender da taxa de falha esperada $p$. Para valores de $p$ prÃ³ximos de 0 ou 1, o tamanho da amostra necessÃ¡rio para obter uma boa aproximaÃ§Ã£o pela qui-quadrado pode ser maior.*

*Prova:*
I. A demonstraÃ§Ã£o formal desta afirmaÃ§Ã£o envolve a anÃ¡lise da expansÃ£o de Taylor da funÃ§Ã£o de verossimilhanÃ§a e do comportamento assintÃ³tico da variÃ¢ncia da estatÃ­stica.
II. Intuitivamente, quando $p$ Ã© muito pequeno (ou muito grande), os eventos de exceÃ§Ã£o sÃ£o raros, e amostras menores podem nÃ£o capturar a variabilidade desses eventos de forma adequada.
III. Isso significa que, em modelos com taxas de falha muito pequenas ou muito grandes, Ã© preciso um nÃºmero maior de observaÃ§Ãµes para que a distribuiÃ§Ã£o da estatÃ­stica LRuc seja bem aproximada pela distribuiÃ§Ã£o qui-quadrado, e portanto, o teste pode ter menos poder estatÃ­stico para amostras menores. â– 

**Lema 4.2.** *A estatÃ­stica LRuc pode ser expressa em termos da funÃ§Ã£o de entropia binÃ¡ria, que fornece uma interpretaÃ§Ã£o informacional da estatÃ­stica.*

*Prova:*
I. A funÃ§Ã£o de entropia binÃ¡ria Ã© definida como $H(x) = -x \ln(x) - (1-x)\ln(1-x)$.
II. Reorganizando a expressÃ£o da estatÃ­stica LRuc, podemos observar que ela pode ser reescrita como:
$$ \text{LR}_{\text{uc}} = 2T \left[  \frac{N}{T} \ln\left(\frac{N/T}{p}\right) + (1-\frac{N}{T}) \ln\left(\frac{1-N/T}{1-p}\right) \right] $$
III. Multiplicando e dividindo por $\ln(2)$, e utilizando a definiÃ§Ã£o de entropia binÃ¡ria, podemos expressar a estatÃ­stica como:
$$ \text{LR}_{\text{uc}} = 2T \ln(2) \left[ \frac{N}{T} \log_2\left(\frac{N/T}{p}\right) + (1-\frac{N}{T}) \log_2\left(\frac{1-N/T}{1-p}\right) \right]  $$
$$  \text{LR}_{\text{uc}} = 2T \ln(2) \left[  -H(N/T) + \frac{N}{T}\log_2(p) + (1-\frac{N}{T}) \log_2(1-p) \right]  $$
IV. A expressÃ£o acima relaciona a estatÃ­stica LRuc com a diferenÃ§a entre a entropia binÃ¡ria observada com a taxa de falha amostral $N/T$ e a entropia binÃ¡ria esperada, baseada na taxa de falha teÃ³rica $p$.  A estatÃ­stica LRuc, portanto, mede a discrepÃ¢ncia entre essas duas entropias. â– 

**Lema 4.3** *A estatÃ­stica LRuc tambÃ©m pode ser interpretada como uma medida de distÃ¢ncia entre a distribuiÃ§Ã£o binomial observada dos dados de exceÃ§Ã£o e a distribuiÃ§Ã£o binomial esperada sob a hipÃ³tese nula. Essa interpretaÃ§Ã£o oferece uma perspectiva complementar Ã  interpretaÃ§Ã£o baseada na entropia.*

*Prova:*
I. Sob a hipÃ³tese nula, o nÃºmero de exceÃ§Ãµes $N$ segue uma distribuiÃ§Ã£o binomial com parÃ¢metros $T$ (nÃºmero de tentativas) e $p$ (probabilidade de sucesso), $N \sim Bin(T, p)$.
II. A verossimilhanÃ§a dos dados sob a hipÃ³tese nula Ã© dada por $L_0 = (1-p)^{T-N}p^N$, e a verossimilhanÃ§a sob a hipÃ³tese alternativa (onde a taxa de falha Ã© estimada por $N/T$) Ã© $L_1 = (1-N/T)^{T-N}(N/T)^N$.
III. A estatÃ­stica LRuc Ã© definida como $-2\ln(L_0/L_1)$, que pode ser vista como uma medida da distÃ¢ncia entre as duas verossimilhanÃ§as.
IV. A distribuiÃ§Ã£o binomial dos dados observados, com parÃ¢metros $T$ e $N/T$, contrasta com a distribuiÃ§Ã£o binomial esperada sob a hipÃ³tese nula, com parÃ¢metros $T$ e $p$.  A estatÃ­stica LRuc quantifica a discrepÃ¢ncia entre essas distribuiÃ§Ãµes. â– 

#### CritÃ©rio de RejeiÃ§Ã£o da HipÃ³tese Nula
A propriedade da distribuiÃ§Ã£o assintÃ³tica da estatÃ­stica LRuc permite estabelecer um critÃ©rio para rejeitar a hipÃ³tese nula, que, como jÃ¡ vimos, afirma que o modelo VAR estÃ¡ bem calibrado. Dada a convergÃªncia para uma distribuiÃ§Ã£o qui-quadrado com um grau de liberdade, podemos usar o quantil da distribuiÃ§Ã£o qui-quadrado para estabelecer um valor crÃ­tico para o teste.

**ProposiÃ§Ã£o 5.** *A hipÃ³tese nula Ã© rejeitada se o valor calculado de LRuc for maior do que o valor crÃ­tico correspondente a um dado nÃ­vel de significÃ¢ncia (ou nÃ­vel de confianÃ§a).*

Para um nÃ­vel de confianÃ§a de 95% (ou nÃ­vel de significÃ¢ncia de 5%), o valor crÃ­tico da distribuiÃ§Ã£o qui-quadrado com um grau de liberdade Ã© aproximadamente 3.841 [^9]. Isso significa que, se o valor calculado de LRuc for maior que 3.841, rejeitamos a hipÃ³tese nula de que o modelo VAR estÃ¡ bem calibrado. Essa rejeiÃ§Ã£o indica que a taxa de falha observada Ã© estatisticamente diferente da taxa de falha esperada, o que sugere que o modelo VAR estÃ¡ mal calibrado.

**Teorema 4.** *Dado um nÃ­vel de significÃ¢ncia $\alpha$, a hipÃ³tese nula Ã© rejeitada se o valor observado da estatÃ­stica  $LR_{uc}$  for maior do que o quantil  $(1-\alpha)$  da distribuiÃ§Ã£o qui-quadrado com um grau de liberdade, ou seja,  $LR_{uc} > \chi^2_{1, 1-\alpha}$.*

*Prova:*
I. O nÃ­vel de significÃ¢ncia $\alpha$ representa a probabilidade de rejeitar a hipÃ³tese nula quando ela Ã© verdadeira (erro do tipo I).
II.  Para um nÃ­vel de significÃ¢ncia $\alpha$, o valor crÃ­tico $\chi^2_{1, 1-\alpha}$  Ã© o valor da distribuiÃ§Ã£o qui-quadrado com um grau de liberdade tal que a probabilidade de observar um valor maior que este, sob a hipÃ³tese nula, seja igual a $\alpha$.
III. Se o valor observado de LRuc for maior que este valor crÃ­tico, rejeitamos a hipÃ³tese nula, pois Ã© improvÃ¡vel que um valor tÃ£o extremo ocorra se a hipÃ³tese nula fosse verdadeira.  â– 

> ğŸ’¡ **Exemplo NumÃ©rico:**
>
> Vamos supor que estamos realizando um backtesting de um modelo VAR com um nÃ­vel de confianÃ§a de 99% (p=0.01). Temos uma amostra de 500 dias (T=500) e observamos 10 exceÃ§Ãµes (N=10). Primeiro, calculamos a estatÃ­stica LRuc:
>
> $$
> \text{LR}_{\text{uc}} = 2 \left[ 10 \ln\left(\frac{10/500}{0.01}\right) + (500-10) \ln\left(\frac{1-10/500}{1-0.01}\right) \right] \approx 2.057
> $$
>
>  Agora, comparamos esse valor com o valor crÃ­tico para um nÃ­vel de significÃ¢ncia de 5% (3.841). Como 2.057 < 3.841, nÃ£o rejeitamos a hipÃ³tese nula a 5% de significÃ¢ncia. Isso significa que nÃ£o temos evidÃªncias estatÃ­sticas suficientes para concluir que o modelo VAR estÃ¡ mal calibrado com este nÃ­vel de significÃ¢ncia. No entanto, com um nÃ­vel de significÃ¢ncia de 10% (valor crÃ­tico de 2.706) tambÃ©m nÃ£o rejeitarÃ­amos a hipÃ³tese nula.

#### InterpretaÃ§Ã£o do Resultado do Teste
A interpretaÃ§Ã£o do resultado do teste LRuc deve considerar o possÃ­vel erro do Tipo I e do Tipo II. O nÃ­vel de significÃ¢ncia (Î±) controla a probabilidade de cometer um erro do tipo I, ou seja, de rejeitar um modelo bem calibrado [^2]. O poder do teste (1-Î²), que Ã© a probabilidade de rejeitar um modelo mal calibrado, Ã© afetado pelo tamanho da amostra e pelo nÃ­vel de significÃ¢ncia [^2].

**Lema 5.** *Aumentar o nÃ­vel de significÃ¢ncia (Î±) aumenta a probabilidade de rejeitar um modelo bem calibrado (erro do Tipo I), enquanto diminuir Î± aumenta a probabilidade de nÃ£o rejeitar um modelo mal calibrado (erro do Tipo II).*

*Prova:*
I. O nÃ­vel de significÃ¢ncia Ã© a probabilidade de rejeitar a hipÃ³tese nula quando ela Ã© verdadeira, ou seja, a probabilidade de cometer um erro do tipo I.
II. Ao aumentar $\alpha$, aumentamos tambÃ©m o valor crÃ­tico que permite rejeitar a hipÃ³tese nula, portanto, tambÃ©m aumentamos a probabilidade de rejeitar um modelo bem calibrado.
III. Consequentemente, diminuir $\alpha$ implica que serÃ¡ mais difÃ­cil rejeitar a hipÃ³tese nula, o que aumenta a probabilidade de nÃ£o rejeitar um modelo mal calibrado, ou seja, de cometer um erro do tipo II. â– 

**Lema 5.1.** *Aumentar o tamanho da amostra (T) aumenta o poder do teste, reduzindo a probabilidade de erro do tipo II. Isso ocorre porque amostras maiores permitem detectar desvios da hipÃ³tese nula com maior precisÃ£o.*

*Prova:*
I.  Com um tamanho de amostra maior, a variÃ¢ncia da distribuiÃ§Ã£o da taxa de falha observada diminui, o que torna a distribuiÃ§Ã£o mais centrada ao redor do seu valor mÃ©dio, que Ã© a taxa de falha real.
II. Isso implica que os valores de LRuc associados a um modelo mal calibrado tendem a se afastar mais do valor zero, o que aumenta a probabilidade de rejeitar corretamente a hipÃ³tese nula quando ela Ã© falsa.
III. Portanto, o aumento de T reduz a probabilidade de cometer um erro do tipo II.  â– 

> ğŸ’¡ **Exemplo NumÃ©rico:**
>
> Suponha que temos dois cenÃ¡rios para backtesting de um modelo VAR com um nÃ­vel de confianÃ§a de 95% (p=0.05). No primeiro cenÃ¡rio, temos uma amostra de T=100 dias e observamos 8 exceÃ§Ãµes (N=8). No segundo cenÃ¡rio, temos uma amostra de T=1000 dias e observamos 80 exceÃ§Ãµes (N=80), mantendo a mesma taxa de falha amostral N/T=0.08. Vamos calcular os valores de LRuc para cada cenÃ¡rio:
>
> **CenÃ¡rio 1 (T=100, N=8):**
> $$
> \text{LR}_{\text{uc}} = 2 \left[ 8 \ln\left(\frac{8/100}{0.05}\right) + (100-8) \ln\left(\frac{1-8/100}{1-0.05}\right) \right] \approx 2.88
> $$
>
> **CenÃ¡rio 2 (T=1000, N=80):**
> $$
> \text{LR}_{\text{uc}} = 2 \left[ 80 \ln\left(\frac{80/1000}{0.05}\right) + (1000-80) \ln\left(\frac{1-80/1000}{1-0.05}\right) \right] \approx 28.83
> $$
>
> No cenÃ¡rio 1, com T=100, o valor de LRuc Ã© 2.88, que nÃ£o Ã© suficiente para rejeitar a hipÃ³tese nula a 5% de significÃ¢ncia (valor crÃ­tico de 3.841). No entanto, no cenÃ¡rio 2, com T=1000, o valor de LRuc Ã© 28.83, que Ã© muito maior que o valor crÃ­tico, levando Ã  rejeiÃ§Ã£o da hipÃ³tese nula a 5% de significÃ¢ncia. Este exemplo ilustra como o poder do teste aumenta com o tamanho da amostra.

**Lema 5.2.** *O poder do teste LRuc nÃ£o depende apenas do tamanho da amostra, mas tambÃ©m da magnitude da diferenÃ§a entre a taxa de falha esperada e a verdadeira taxa de falha do modelo. Quanto maior a discrepÃ¢ncia, maior o poder do teste.*
*Prova:*
I. A estatÃ­stica LRuc Ã© construÃ­da para detectar desvios entre a taxa de falha esperada $p$ e a taxa de falha observada $N/T$. Quanto maior a diferenÃ§a entre $p$ e a verdadeira taxa de falha, mais a estatÃ­stica LRuc tende a se afastar de zero.
II. Como o poder do teste Ã© a probabilidade de rejeitar corretamente a hipÃ³tese nula quando ela Ã© falsa, e essa probabilidade aumenta com valores de LRuc mais extremos, temos que o poder do teste tambÃ©m aumenta com a discrepÃ¢ncia entre $p$ e a verdadeira taxa de falha.
III. Assim, mesmo com um tamanho de amostra moderado, o teste pode ter um poder significativo se a discrepÃ¢ncia entre as taxas for grande, enquanto um grande tamanho de amostra pode ser necessÃ¡rio para detectar pequenas discrepÃ¢ncias. â– 

**Lema 5.3** *A precisÃ£o do teste LRuc tambÃ©m estÃ¡ relacionada com a frequÃªncia de ocorrÃªncia de exceÃ§Ãµes sob a hipÃ³tese nula, ou seja, com o valor de p. Para valores de p muito prÃ³ximos de 0 ou 1, a variÃ¢ncia da taxa de falha observada $N/T$ Ã© menor, o que pode levar a uma menor sensibilidade do teste.*

*Prova:*
I. A variÃ¢ncia da taxa de falha observada $N/T$ Ã© dada por $\frac{p(1-p)}{T}$, que atinge seu valor mÃ¡ximo quando $p=0.5$ e diminui quando $p$ se aproxima de 0 ou 1.
II.  Uma menor variÃ¢ncia da taxa de falha observada implica que a distribuiÃ§Ã£o da estatÃ­stica LRuc sob a hipÃ³tese nula serÃ¡ mais concentrada ao redor de seu valor mÃ©dio, o que pode tornar mais difÃ­cil detectar pequenas discrepÃ¢ncias entre a taxa de falha esperada e a verdadeira taxa de falha.
III. Portanto, para valores de $p$ muito prÃ³ximos de 0 ou 1, o teste LRuc pode ser menos sensÃ­vel a pequenas variaÃ§Ãµes na taxa de falha. â– 

> ğŸ’¡ **Exemplo NumÃ©rico:**
> Vamos comparar dois cenÃ¡rios de backtesting. Em ambos temos T=500 observaÃ§Ãµes, mas em um caso p=0.05 e no outro p=0.005.
>
> **CenÃ¡rio 1 (p=0.05, N=40):**
>  $$
> \text{LR}_{\text{uc}} = 2 \left[ 40 \ln\left(\frac{40/500}{0.05}\right) + (500-40) \ln\left(\frac{1-40/500}{1-0.05}\right) \right] \approx 20.62
> $$
>
> **CenÃ¡rio 2 (p=0.005, N=10):**
>  $$
> \text{LR}_{\text{uc}} = 2 \left[ 10 \ln\left(\frac{10/500}{0.005}\right) + (500-10) \ln\left(\frac{1-10/500}{1-0.005}\right) \right] \approx 14.47
> $$
> No cenÃ¡rio 1, com p=0.05 e N=40, o valor da estatÃ­stica Ã© LRuc â‰ˆ 20.62. No cenÃ¡rio 2, com p=0.005 e N=10, o valor da estatÃ­stica Ã© LRuc â‰ˆ 14.47. Em ambos os casos rejeitarÃ­amos a hipÃ³tese nula a um nÃ­vel de significÃ¢ncia de 5%, mas notamos que para uma taxa de falha menor a estatÃ­stica tambÃ©m Ã© menor, o que pode levar o teste a ter menos poder estatÃ­stico para detectar desvios da hipÃ³tese nula, se o nÃºmero de exceÃ§Ãµes observadas nÃ£o for muito diferente do esperado.

**Lema 5.4.** *A estatÃ­stica LRuc Ã© um teste de hipÃ³tese assintÃ³tico, e portanto, a validade da aproximaÃ§Ã£o pela distribuiÃ§Ã£o qui-quadrado depende do tamanho da amostra. Para tamanhos de amostra pequenos, o uso do valor crÃ­tico da distribuiÃ§Ã£o qui-quadrado pode levar a conclusÃµes errÃ´neas. MÃ©todos alternativos, como simulaÃ§Ãµes de Monte Carlo, podem ser mais apropriados nesses casos.*

*Prova:*
I. A convergÃªncia da estatÃ­stica LRuc para a distribuiÃ§Ã£o qui-quadrado Ã© uma propriedade que se manifesta quando o tamanho da amostra tende ao infinito. Para amostras finitas, a aproximaÃ§Ã£o pode ser inadequada.
II.  Para amostras pequenas, a verdadeira distribuiÃ§Ã£o da estatÃ­stica LRuc pode diferir significativamente da distribuiÃ§Ã£o qui-quadrado, o que invalida a utilizaÃ§Ã£o do valor crÃ­tico padrÃ£o.
III. SimulaÃ§Ãµes de Monte Carlo podem ser utilizadas para gerar a distribuiÃ§Ã£o empÃ­rica da estatÃ­stica LRuc sob a hipÃ³tese nula, permitindo a determinaÃ§Ã£o de valores crÃ­ticos mais apropriados para o tamanho da amostra considerado. â– 

####  Exemplo PrÃ¡tico
Retomando o exemplo da J.P. Morgan, onde foram observadas 20 exceÃ§Ãµes em 252 dias, com um nÃ­vel de confianÃ§a do VAR de 95% [^6], calculamos anteriormente um valor de LRuc de aproximadamente 3.91 [^9].

$$
\text{LR}_{\text{uc}} = 2 \left[ 20 \ln\left(\frac{20/252}{0.05}\right) + (252-20) \ln\left(\frac{1-20/252}{1-0.05}\right) \right] \approx 3.91
$$

Como 3.91 > 3.841 (valor crÃ­tico para $\chi^2_1$ a 95% de confianÃ§a), rejeitamos a hipÃ³tese nula [^9]. Isso indica que hÃ¡ evidÃªncias estatÃ­sticas suficientes para concluir que o modelo VAR utilizado pela J.P. Morgan estava mal calibrado.

### ConclusÃ£o
A propriedade assintÃ³tica da distribuiÃ§Ã£o qui-quadrado da estatÃ­stica LRuc Ã© fundamental para o teste de *backtesting* de modelos VAR, possibilitando estabelecer um critÃ©rio objetivo para a rejeiÃ§Ã£o da hipÃ³tese nula e a avaliaÃ§Ã£o da calibraÃ§Ã£o do modelo. Ao comparar o valor calculado da estatÃ­stica com um valor crÃ­tico proveniente da distribuiÃ§Ã£o qui-quadrado, Ã© possÃ­vel tomar decisÃµes informadas sobre a adequaÃ§Ã£o do modelo, considerando os riscos de erros do tipo I e tipo II [^12]. A anÃ¡lise apresentada neste capÃ­tulo reforÃ§a o carÃ¡ter prÃ¡tico e a importÃ¢ncia do teste LRuc como ferramenta essencial na gestÃ£o de riscos financeiros, em conjunto com outras tÃ©cnicas de avaliaÃ§Ã£o, como os testes de cobertura condicional e anÃ¡lises grÃ¡ficas [^13, ^16].

### ReferÃªncias
[^1]: *â€œValue-at-risk (VAR) models are only useful insofar as they predict risk reasonably well. This is why the application of these models always should be accompanied by validation.â€*
[^2]: *â€œWhen the model is perfectly calibrated, the number of observations falling outside VAR should be in line with the confidence level. The number of exceedences is also known as the number of exceptions.â€*
[^3]: *â€œBacktesting is a formal statistical framework that consists of verifying that actual losses are in line with projected losses. This involves systematically comparing the history of VAR forecasts with their associated portfolio returns.â€*
[^4]: *â€œThese procedures, sometimes called reality checks, are essential for VAR users and risk managers, who need to check that their VAR forecasts are well calibrated.â€*
[^5]: *â€œThe simplest method to verify the accuracy of the model is to record the failure rate, which gives the proportion of times VAR is exceeded in a given sample... We want to know, at a given confidence level, whether N is too small or too large under the null hypothesis that p = 0.01 in a sample of size T. Note that this test makes no assumption about the return distribution. As a result, this approach is fully nonparametric.â€*
[^6]: *â€œIn its 1998 annual report, the U.S. commercial bank J.P. Morgan (JPM) explained that In 1998, daily revenue fell short of the downside (95 percent VAR) band on 20 days, or more than 5 percent of the time. Nine of these 20 occurrences fell within the August to October period.â€*
[^7]: *â€œWe can test whether this was bad luck or a faulty model, assuming 252 days in the year. Based on Equation (6.2), we have z = (x-pT)/âˆšp(1-p) T = (20 - 0.05 Ã— 252)/âˆš0.05(0.95) 252 = 2.14. This is larger than the cutoff value of 1.96. Therefore, we reject the hypothesis that the VAR model is unbiased.â€*
[^8]: *â€œWhen designing a verification test, the user faces a tradeoff between these two types of error... For backtesting purposes, users of VAR models need to balance type 1 errors against type 2 errors.â€*
[^9]: *â€œLRuc = -2 In[(1 â€“ p)T-N pN] + 2 ln{[1 â€“ (N/T)]T-N (N/T)N} which is asymptotically (i.e., when T is large) distributed chi-square with one degree of freedom under the null hypothesis that p is the true probability. Thus we would reject the null hypothesis if LR > 3.841... In the JPM example, we had N = 20 exceptions over T = 252 days, using p = 95 percent VAR confidence level. Setting these numbers into Equation (6.3) gives LRuc = 3.91. Therefore, we reject unconditional coverage, as expected.â€*
[^10]: *â€œThe table also shows that this interval, expressed as a proportion N/T, shrinks as the sample size increases. ... With more data, we should be able to reject the model more easily if it is false.â€*
[^11]: *â€œThe heart of the conflict is that, inevitably, the supervisor also will commit type 2 errors for a bank that willfully cheats on its VAR reporting.â€*
[^12]: *â€œThe crux of the backtesting problem is separating bad luck from a faulty model, or balancing type 1 errors against type 2 errors.â€*
[^13]: *â€œSo far the framework focuses on unconditional coverage because it ignores conditioning, or time variation in the data. The observed exceptions, however, could cluster or "bunch" closely in time, which also should invalidate the model.â€*
[^14]: *â€œSuch a test has been developed by Christoffersen (1998), who extends the LRuc statistic to specify that the deviations must be serially independent.â€*
[^15]: *â€œThe combined test statistic for conditional coverage then is LRcc = LRuc + LRindâ€*
[^16]: *â€œWe have seen that the standard exception tests often lack power, especially when the VAR confidence level is high and when the number of observations is low. This has led to a search for improved tests.â€*
<!-- END -->
