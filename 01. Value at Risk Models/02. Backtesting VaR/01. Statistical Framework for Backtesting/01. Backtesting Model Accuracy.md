## Backtesting VAR: Uma Abordagem de Teste de Hip√≥tese Estat√≠stica Usando Taxas de Falha
### Introdu√ß√£o
Como vimos anteriormente, a valida√ß√£o de modelos √© crucial para garantir a precis√£o das previs√µes de risco, sendo o **backtesting** uma ferramenta essencial nesse processo [^1]. O backtesting, como apresentado, √© um framework estat√≠stico formal para verificar se as perdas reais est√£o alinhadas com as perdas projetadas [^1]. Este cap√≠tulo aprofunda-se na natureza estat√≠stica do backtesting, focando em como as taxas de falha, ou seja, a propor√ß√£o de vezes que o VAR √© excedido, s√£o usadas para avaliar a precis√£o do modelo. Especificamente, exploraremos como o n√∫mero de exce√ß√µes segue uma distribui√ß√£o binomial, o que nos permite aplicar testes estat√≠sticos rigorosos para validar modelos de Value-at-Risk (VAR).

### Conceitos Fundamentais
O backtesting de modelos VAR √© essencial para garantir que os modelos de risco sejam precisos e confi√°veis [^1]. A premissa b√°sica √© que um modelo bem calibrado deve produzir um n√∫mero de exce√ß√µes que seja consistente com o n√≠vel de confian√ßa especificado. Por exemplo, um modelo VAR de 99% deve ser excedido, em m√©dia, 1% do tempo [^2]. O objetivo √© verificar se o modelo est√° gerando um n√∫mero adequado de exce√ß√µes ou se est√° subestimando (muitas exce√ß√µes) ou superestimando (poucas exce√ß√µes) o risco [^2].

==O ponto de partida para a an√°lise estat√≠stica do backtesting √© o conceito de **taxa de falha** (failure rate), que √© a propor√ß√£o de vezes que as perdas reais excedem o VAR previsto. Seja $N$ o n√∫mero de exce√ß√µes observadas em um per√≠odo de $T$ dias. A taxa de falha √© dada por $N/T$. Idealmente, a taxa de falha deve convergir para o valor $p$ esperado, onde $p$ representa a probabilidade de uma exce√ß√£o (por exemplo, $p = 0.01$ para um VAR de 99%) [^3].==

Formalmente, sob a hip√≥tese nula de que o modelo VAR est√° corretamente calibrado, o n√∫mero de exce√ß√µes $x$ segue uma distribui√ß√£o binomial [^3]:
$$f(x) = \binom{T}{x} p^x (1-p)^{T-x}$$
Onde:
- $T$ √© o n√∫mero de dias observados.
- $x$ √© o n√∫mero de exce√ß√µes observadas.
- $p$ √© a probabilidade de uma exce√ß√£o (n√≠vel de cauda √† esquerda).

> üí° **Exemplo Num√©rico:** Suponha que temos um modelo VAR com n√≠vel de confian√ßa de 99% ($p=0.01$) e observamos $T=250$ dias. Se o modelo estivesse perfeitamente calibrado, o n√∫mero esperado de exce√ß√µes seria $E(x) = pT = 0.01 \times 250 = 2.5$.  A probabilidade de observar exatamente 3 exce√ß√µes, usando a distribui√ß√£o binomial, seria:
>
> $f(3) = \binom{250}{3} (0.01)^3 (0.99)^{247} \approx 0.215$.
>
> Isso mostra a probabilidade de se observar um n√∫mero espec√≠fico de exce√ß√µes, assumindo que o modelo est√° calibrado corretamente.

A distribui√ß√£o binomial possui uma m√©dia $E(x) = pT$ e vari√¢ncia $V(x) = p(1-p)T$ [^3]. Para amostras grandes (grande $T$), podemos usar o teorema do limite central para aproximar a distribui√ß√£o binomial por uma distribui√ß√£o normal [^3]. Essa aproxima√ß√£o nos permite usar um teste z padr√£o para verificar se o n√∫mero de exce√ß√µes observadas √© significativamente diferente do esperado. O teste z √© dado por [^4]:

$$z = \frac{x - pT}{\sqrt{p(1-p)T}} \sim N(0,1)$$

Para um n√≠vel de confian√ßa de 95%, o valor cr√≠tico para um teste bicaudal √© $|z| = 1.96$. Se o valor absoluto do z-score calculado exceder esse valor cr√≠tico, rejeitamos a hip√≥tese nula de que o modelo VAR est√° corretamente calibrado [^4]. Esse processo √© um exemplo de **teste de hip√≥teses estat√≠sticas**.

> üí° **Exemplo Num√©rico:**  Considerando novamente o exemplo anterior com $p=0.01$ e $T=250$, se observarmos $x=6$ exce√ß√µes, podemos calcular o z-score:
>
> $z = \frac{6 - (0.01)(250)}{\sqrt{(0.01)(0.99)(250)}} = \frac{6 - 2.5}{\sqrt{2.475}} \approx \frac{3.5}{1.573} \approx 2.22$
>
>  Como $|2.22| > 1.96$, rejeitamos a hip√≥tese nula ao n√≠vel de signific√¢ncia de 5%, concluindo que o modelo VAR est√° mal calibrado (subestima o risco).

**Proposi√ß√£o 1.** *Uma formula√ß√£o alternativa para o teste z pode ser obtida utilizando a taxa de falha observada, $\hat{p} = x/T$. Substituindo $x = \hat{p}T$ na f√≥rmula do teste z, obtemos:*
$$z = \frac{\hat{p}T - pT}{\sqrt{p(1-p)T}} = \frac{\hat{p} - p}{\sqrt{p(1-p)/T}} $$
*Esta formula√ß√£o √© √∫til pois expressa o teste em termos da diferen√ßa entre a taxa de falha observada e a probabilidade de exce√ß√£o esperada.*

**Prova da Proposi√ß√£o 1:**
I. Come√ßamos com a f√≥rmula padr√£o do teste z:
$$z = \frac{x - pT}{\sqrt{p(1-p)T}}$$

II.  Substitu√≠mos $x$ pela taxa de falha observada $\hat{p}$ multiplicada pelo n√∫mero total de observa√ß√µes $T$, ou seja, $x = \hat{p}T$:
$$z = \frac{\hat{p}T - pT}{\sqrt{p(1-p)T}}$$

III. Fatoramos $T$ no numerador:
$$z = \frac{(\hat{p} - p)T}{\sqrt{p(1-p)T}}$$

IV. Levamos $T$ para dentro da raiz no denominador, o que implica tirar a raiz quadrada:
$$z = \frac{(\hat{p} - p)T}{\sqrt{p(1-p)}\sqrt{T}} = \frac{(\hat{p} - p)T}{\sqrt{p(1-p)T}}$$

V. Simplificamos dividindo o numerador e o denominador por $\sqrt{T}$:
$$z = \frac{(\hat{p} - p)\sqrt{T}}{\sqrt{p(1-p)}} = \frac{\hat{p} - p}{\sqrt{p(1-p)/T}}$$
Portanto, provamos a equival√™ncia da formula√ß√£o do teste z em termos da taxa de falha observada. ‚ñ†

**Observa√ß√£o 1.** *A Proposi√ß√£o 1 demonstra que o teste z pode ser interpretado como uma medida da diferen√ßa entre a taxa de falha observada e a taxa de falha esperada, normalizada pelo desvio padr√£o da taxa de falha. Isto real√ßa a import√¢ncia da precis√£o da taxa de falha observada, que √© influenciada pelo tamanho da amostra $T$. Um valor de $T$ maior reduz a vari√¢ncia do estimador $\hat{p}$, tornando o teste mais sens√≠vel a desvios do valor esperado $p$.*

> üí° **Exemplo Num√©rico:** Se observarmos 5 exce√ß√µes em 500 dias com um VAR de 99% ($p=0.01$), ent√£o $\hat{p} = \frac{5}{500}=0.01$. O z-score ser√°:
>
> $z = \frac{0.01 - 0.01}{\sqrt{0.01(0.99)/500}} = 0$.
>
> Nesse caso, n√£o rejeitamos a hip√≥tese nula de calibra√ß√£o correta do VAR. Se, em vez disso, observarmos 10 exce√ß√µes, ent√£o $\hat{p} = \frac{10}{500} = 0.02$. O z-score ser√°:
>
> $z = \frac{0.02 - 0.01}{\sqrt{0.01(0.99)/500}} \approx \frac{0.01}{0.00445} \approx 2.24$.
>
> Aqui, como $|2.24| > 1.96$, rejeitar√≠amos a hip√≥tese nula. Este exemplo mostra como o tamanho da amostra e a taxa de falha observada afetam o resultado do teste.

Uma preocupa√ß√£o central no backtesting √© o equil√≠brio entre erros do tipo I e do tipo II [^8]. Um **erro do tipo I** (falso positivo) ocorre quando rejeitamos um modelo correto, enquanto um **erro do tipo II** (falso negativo) ocorre quando n√£o rejeitamos um modelo incorreto [^8]. No contexto do backtesting, um erro do tipo I significa que penalizamos um banco por um modelo VAR que, na verdade, √© preciso; e um erro do tipo II significa que deixamos de identificar um modelo VAR defeituoso, expondo o banco a riscos maiores [^8].

Um teste com alta **pot√™ncia** (power) tem uma baixa probabilidade de cometer um erro do tipo II. Idealmente, gostar√≠amos de um teste que minimize ambos os tipos de erro [^8]. No entanto, esses erros s√£o inversamente relacionados: diminuir a probabilidade de cometer um erro do tipo I geralmente aumenta a probabilidade de cometer um erro do tipo II e vice-versa [^8].

**Lema 1.** *A pot√™ncia de um teste estat√≠stico, que √© a probabilidade de rejeitar a hip√≥tese nula quando ela √© falsa, √© influenciada pelo tamanho da amostra ($T$). Para um n√≠vel de signific√¢ncia fixo, aumentar o tamanho da amostra tende a aumentar a pot√™ncia do teste, diminuindo a probabilidade de cometer um erro do tipo II.*
*Demonstra√ß√£o: Com um $T$ maior, a vari√¢ncia do estimador $\hat{p}$ diminui, tornando o teste mais sens√≠vel √† diferen√ßas entre a taxa de falha observada e a esperada.*

**Prova do Lema 1:**
I. A vari√¢ncia da taxa de falha observada $\hat{p}$ √© dada por $V(\hat{p}) = \frac{p(1-p)}{T}$.
II. √Ä medida que $T$ aumenta, a vari√¢ncia $V(\hat{p})$ diminui. Isso significa que a distribui√ß√£o de $\hat{p}$ torna-se mais concentrada em torno de seu valor esperado $p$.
III. Com uma distribui√ß√£o de $\hat{p}$ mais concentrada, a probabilidade de observar um valor $\hat{p}$ que seja muito diferente de $p$ aumenta, caso a hip√≥tese nula seja falsa. 
IV. Consequentemente, um $T$ maior aumenta a pot√™ncia do teste, ou seja, a probabilidade de rejeitar a hip√≥tese nula quando ela √© de fato falsa, reduzindo a probabilidade de um erro do tipo II. ‚ñ†

> üí° **Exemplo Num√©rico:** Suponha que a verdadeira taxa de falha seja 2% ($p'=0.02$) e estamos testando um modelo VAR com $p=0.01$. Se usarmos $T=250$, a variabilidade de $\hat{p}$ ser√° maior, dificultando a distin√ß√£o entre as duas taxas. No entanto, com $T=2500$, a variabilidade de $\hat{p}$ ser√° muito menor, aumentando a probabilidade de detectar que o modelo est√° mal calibrado, ou seja, aumentando o poder do teste e reduzindo a chance de um erro do tipo II.

**Lema 1.1** *A rela√ß√£o entre o tamanho da amostra e a pot√™ncia do teste pode ser explorada em mais detalhes. Especificamente, se a verdadeira taxa de falha for diferente de $p$, aumentar o tamanho da amostra $T$ ir√° aumentar a probabilidade de rejeitar corretamente a hip√≥tese nula.*
*Demonstra√ß√£o:  Se a verdadeira taxa de falha √© $p' \neq p$, ent√£o a distribui√ß√£o amostral de $\hat{p}$ se concentra em torno de $p'$, e o desvio padr√£o de $\hat{p}$ diminui com $\sqrt{T}$. Para $T$ suficientemente grande, a diferen√ßa entre $\hat{p}$ e $p$ se tornar√° estatisticamente significativa com alta probabilidade, levando √† rejei√ß√£o da hip√≥tese nula.*

**Prova do Lema 1.1:**
I. Seja $p'$ a verdadeira taxa de falha, e $p$ a taxa de falha sob a hip√≥tese nula.
II. Quando a hip√≥tese nula √© falsa, $\hat{p}$ tende a se agrupar em torno de $p'$.
III. O desvio padr√£o de $\hat{p}$ √© $\sqrt{\frac{p'(1-p')}{T}}$. Como podemos ver, o desvio padr√£o diminui com o aumento de $T$.
IV. √Ä medida que $T$ cresce, a distribui√ß√£o de $\hat{p}$ torna-se mais estreita em torno de $p'$.
V. Consequentemente, a probabilidade de $\hat{p}$ cair longe de $p$ e entrar na regi√£o de rejei√ß√£o da hip√≥tese nula aumenta com $T$, aumentando a probabilidade de rejeitar corretamente a hip√≥tese nula. ‚ñ†

> üí° **Exemplo Num√©rico:** Continuando o exemplo anterior, se a verdadeira taxa de falha for $p'=0.02$, um tamanho de amostra maior como $T=5000$ far√° com que a distribui√ß√£o de $\hat{p}$ se concentre mais perto de 0.02. Isso aumentar√° a chance de detectarmos uma taxa de falha observada $\hat{p}$ significativamente diferente de $p=0.01$ (a taxa esperada sob a hip√≥tese nula), levando √† rejei√ß√£o correta da hip√≥tese nula.

**Lema 1.2** *O poder do teste tamb√©m depende da magnitude da diferen√ßa entre a taxa de falha verdadeira $p'$ e a taxa de falha sob a hip√≥tese nula $p$. Se a diferen√ßa $|p' - p|$ for grande, o poder do teste ser√° maior, indicando que um n√∫mero menor de observa√ß√µes $T$ ser√° necess√°rio para detectar uma discrep√¢ncia. Por outro lado, se a diferen√ßa for pequena, um tamanho de amostra $T$ maior ser√° necess√°rio para obter um poder de teste adequado.*

**Prova do Lema 1.2:**
I. O poder do teste depende de qu√£o longe o verdadeiro valor $p'$ est√° do valor hipot√©tico $p$.
II. Se $|p'-p|$ for grande, a distribui√ß√£o de $\hat{p}$ sob a hip√≥tese nula e a distribui√ß√£o de $\hat{p}$ sob a hip√≥tese alternativa (ou seja, quando a hip√≥tese nula √© falsa) estar√£o bem separadas.
III. Com distribui√ß√µes bem separadas, mesmo um tamanho de amostra $T$ relativamente pequeno pode fornecer evid√™ncias suficientes para rejeitar a hip√≥tese nula.
IV. Por outro lado, se $|p' - p|$ for pequeno, as distribui√ß√µes de $\hat{p}$ sob as hip√≥teses nula e alternativa estar√£o pr√≥ximas, e ser√° necess√°rio um $T$ muito maior para detectar que o modelo est√° incorretamente calibrado. Isso √© porque um $T$ maior reduz a vari√¢ncia de $\hat{p}$, fazendo com que a sua distribui√ß√£o se torne mais estreita e a separa√ß√£o entre as duas distribui√ß√µes (nula e alternativa) seja mais aparente. ‚ñ†

> üí° **Exemplo Num√©rico:** Se tivermos um modelo VAR com $p=0.01$, e a verdadeira taxa de falha for $p'=0.05$ (uma grande diferen√ßa), um tamanho de amostra $T=500$ pode ser suficiente para detectar a falha com alta probabilidade. No entanto, se a verdadeira taxa de falha fosse $p'=0.015$ (uma diferen√ßa pequena), precisar√≠amos de um $T$ muito maior, como $T=5000$, para ter uma pot√™ncia razo√°vel no teste.

Um exemplo pr√°tico foi apresentado com a an√°lise das exce√ß√µes do J.P. Morgan, em que um z-score de 2.14 levou √† rejei√ß√£o da hip√≥tese de que o modelo VAR estava n√£o enviesado, evidenciando a utilidade do teste estat√≠stico para identificar problemas em modelos de risco [^4].

A escolha do n√≠vel de confian√ßa para o teste de backtesting √© distinta do n√≠vel de confian√ßa usado para calcular o VAR. Por exemplo, podemos usar um n√≠vel de confian√ßa de 95% para o teste de backtesting de modelos VAR que foram constru√≠dos com um n√≠vel de confian√ßa de 99% [^3].

**Teorema 1.** *O teste z, como apresentado, assume que as exce√ß√µes s√£o independentes. No entanto, em algumas situa√ß√µes, pode haver depend√™ncia temporal entre as exce√ß√µes. Nestes casos, o teste z cl√°ssico pode n√£o ser apropriado, e uma abordagem baseada em modelos de s√©ries temporais ou testes de cobertura condicional podem ser mais adequados.*
*Demonstra√ß√£o: A presen√ßa de autocorrela√ß√£o nas exce√ß√µes invalida a suposi√ß√£o de independ√™ncia, e como consequ√™ncia, a distribui√ß√£o da estat√≠stica de teste pode se desviar da distribui√ß√£o normal.*

**Prova do Teorema 1:**
I. A deriva√ß√£o da estat√≠stica de teste $z$ assume que as exce√ß√µes s√£o independentes e identicamente distribu√≠das (iid) seguindo uma distribui√ß√£o binomial, que pode ser aproximada por uma distribui√ß√£o normal para grandes valores de $T$.
II. Se as exce√ß√µes apresentarem depend√™ncia temporal (por exemplo, autocorrela√ß√£o), a distribui√ß√£o binomial n√£o √© mais v√°lida, pois as exce√ß√µes n√£o ser√£o eventos independentes.
III. Consequentemente, a estat√≠stica de teste $z$ n√£o seguir√° mais uma distribui√ß√£o normal padr√£o sob a hip√≥tese nula, e sua distribui√ß√£o sob a hip√≥tese alternativa pode se desviar ainda mais da distribui√ß√£o normal padr√£o.
IV. Portanto, o uso da estat√≠stica de teste $z$ cl√°ssica quando as exce√ß√µes s√£o dependentes pode levar a infer√™ncias estat√≠sticas incorretas, como rejeitar incorretamente um modelo correto ou deixar de rejeitar um modelo incorreto. ‚ñ†

> üí° **Exemplo Num√©rico:** Suponha que as exce√ß√µes de um modelo VAR ocorram em clusters. Por exemplo, se houver uma exce√ß√£o no dia *t*, h√° uma alta probabilidade de que haja outra exce√ß√£o nos dias *t+1* ou *t+2*. Nesse cen√°rio, a premissa de independ√™ncia do teste z √© violada, e ele pode n√£o detectar corretamente um modelo mal calibrado.

**Teorema 1.1** *Uma alternativa ao teste z cl√°ssico, quando a hip√≥tese de independ√™ncia das exce√ß√µes n√£o se sustenta, pode ser desenvolvida atrav√©s da modelagem da sequ√™ncia de exce√ß√µes como uma s√©rie temporal. Por exemplo, um modelo autorregressivo (AR) pode capturar a depend√™ncia temporal nas exce√ß√µes. O teste de hip√≥teses, neste caso, envolve avaliar os par√¢metros do modelo AR e verificar se eles s√£o significativamente diferentes de zero, o que indicaria a presen√ßa de depend√™ncia.*
*Demonstra√ß√£o: Ao modelar a sequ√™ncia de exce√ß√µes como uma s√©rie temporal, podemos levar em conta a poss√≠vel autocorrela√ß√£o e obter resultados mais confi√°veis em contextos onde as exce√ß√µes n√£o s√£o independentes.*

**Prova do Teorema 1.1:**
I. Se as exce√ß√µes apresentam depend√™ncia temporal, ent√£o modelar a sequ√™ncia de exce√ß√µes como uma s√©rie temporal permite explicitamente capturar essa depend√™ncia.
II. O modelo AR(p) assume que a exce√ß√£o atual depende linearmente das $p$ exce√ß√µes anteriores, onde $p$ √© a ordem do modelo.
III. O modelo pode ser estimado por m√©todos de m√°xima verossimilhan√ßa ou outros m√©todos apropriados, e os par√¢metros do modelo podem ser testados para determinar se eles s√£o significativamente diferentes de zero.
IV. Se os coeficientes da s√©rie temporal forem significativamente diferentes de zero, ent√£o a depend√™ncia temporal das exce√ß√µes foi detectada. A presen√ßa de depend√™ncia temporal torna o teste $z$ inadequado para backtesting, levando √† necessidade de m√©todos mais avan√ßados. ‚ñ†

> üí° **Exemplo Num√©rico:** Se modelarmos a sequ√™ncia de exce√ß√µes como um AR(1), a equa√ß√£o seria $x_t = \phi x_{t-1} + \epsilon_t$. Onde $x_t$ representa se houve exce√ß√£o no dia *t* ($1$ se sim, $0$ se n√£o), $\phi$ √© o par√¢metro autoregressivo, e $\epsilon_t$ √© o erro aleat√≥rio. Se o coeficiente $\phi$ for estatisticamente diferente de zero, isto indica que h√° depend√™ncia temporal entre as exce√ß√µes, invalidando o uso do teste z cl√°ssico.

**Teorema 1.2** *Outra forma de abordar a depend√™ncia temporal das exce√ß√µes √© atrav√©s de testes de cobertura condicional. Esses testes verificam n√£o apenas a frequ√™ncia de exce√ß√µes, mas tamb√©m se elas ocorrem em clusters, indicando que a probabilidade de uma exce√ß√£o pode depender de exce√ß√µes anteriores. O teste de Christoffersen √© um exemplo de teste de cobertura condicional, que leva em considera√ß√£o a depend√™ncia temporal entre as exce√ß√µes.*
*Demonstra√ß√£o: Ao analisar a sequ√™ncia de exce√ß√µes com testes de cobertura condicional, podemos detectar a presen√ßa de depend√™ncia temporal que n√£o seria identificada pelos testes baseados na distribui√ß√£o binomial.*

**Prova do Teorema 1.2:**
I. Os testes de cobertura condicional, como o teste de Christoffersen, analisam a sequ√™ncia de exce√ß√µes, e n√£o apenas o n√∫mero total de exce√ß√µes.
II. Eles verificam se as exce√ß√µes ocorrem aleatoriamente ou em clusters, o que indicaria que a ocorr√™ncia de uma exce√ß√£o aumenta a probabilidade de uma exce√ß√£o subsequente.
III. O teste de Christoffersen testa conjuntamente a cobertura incondicional e a independ√™ncia das exce√ß√µes por meio de uma raz√£o de verossimilhan√ßa.
IV. Se as exce√ß√µes apresentarem depend√™ncia temporal, o teste de Christoffersen indicar√° que o modelo VAR est√° mal calibrado, pois sua cobertura n√£o √© condicionalmente correta. O teste de cobertura condicional √© mais adequado para detectar depend√™ncias temporais entre exce√ß√µes do que testes que consideram apenas a cobertura incondicional, como o teste z cl√°ssico. ‚ñ†

> üí° **Exemplo Num√©rico:** O teste de Christoffersen analisaria a sequ√™ncia de exce√ß√µes e verificaria, por exemplo, se a probabilidade de uma exce√ß√£o ap√≥s outra exce√ß√£o √© maior do que a probabilidade de uma exce√ß√£o ap√≥s um dia sem exce√ß√£o. Se essa depend√™ncia for estatisticamente significativa, indicar√° que o modelo VAR n√£o est√° lidando adequadamente com clusters de exce√ß√µes.

### Conclus√£o

O backtesting √© um processo cr√≠tico para a valida√ß√£o de modelos de risco, e a an√°lise estat√≠stica das taxas de falha fornece uma base s√≥lida para essa avalia√ß√£o. A distribui√ß√£o binomial e a aproxima√ß√£o normal permitem que testes estat√≠sticos sejam usados para decidir se o n√∫mero de exce√ß√µes observadas √© consistente com a precis√£o do modelo. A considera√ß√£o dos erros do tipo I e do tipo II √© crucial para construir testes de backtesting com a pot√™ncia necess√°ria para detectar modelos defeituosos enquanto minimizam penalidades desnecess√°rias. Como discutido, a escolha do n√≠vel de confian√ßa e a decis√£o de usar retornos hipot√©ticos ou limpos s√£o fatores cr√≠ticos para garantir que o backtesting seja uma ferramenta eficaz na gest√£o de riscos [^2]. Este cap√≠tulo estabelece as bases para an√°lises mais avan√ßadas, tais como testes de cobertura condicional, que exploraremos em seguida.

### Refer√™ncias
[^1]: *This chapter turns to backtesting techniques for verifying the accuracy of VAR models. Backtesting is a formal statistical framework that consists of verifying that actual losses are in line with projected losses.*
[^2]: *When the model is perfectly calibrated, the number of observations falling outside VAR should be in line with the confidence level. The number of exceedences is also known as the number of exceptions.*
[^3]: *The simplest method to verify the accuracy of the model is to record the failure rate, which gives the proportion of times VAR is exceeded in a given sample... Under the null hypothesis that the model is correctly calibrated, the number of exceptions x follows a binomial probability distribution.*
[^4]: *Based on Equation (6.2), we have z = (x-pT)/‚àöp(1-p) T = (20 - 0.05 √ó 252)/‚àö0.05(0.95) 252 = 2.14. This is larger than the cut-off value of 1.96. Therefore, we reject the hypothesis that the VAR model is unbiased.*
[^8]: *When designing a verification test, the user faces a tradeoff between these two types of error... For backtesting purposes, users of VAR models need to balance type 1 errors against type 2 errors.*
<!-- END -->
