## Backtesting VAR: Aproxima√ß√£o Normal e Teste Z para Grandes Amostras
### Introdu√ß√£o
Como vimos nos cap√≠tulos anteriores, o backtesting √© uma metodologia crucial para avaliar a precis√£o dos modelos VAR, e a taxa de falha √© uma m√©trica chave nesse processo [^1, ^2]. A distribui√ß√£o binomial descreve o n√∫mero de exce√ß√µes em um dado per√≠odo, e o teste z nos permite avaliar se a taxa de falha observada se desvia significativamente da esperada. Neste cap√≠tulo, vamos nos concentrar na aplica√ß√£o da aproxima√ß√£o normal para a distribui√ß√£o binomial e o uso do teste z para simplificar o backtesting quando lidamos com amostras grandes, complementando o conhecimento pr√©vio de testes de hip√≥tese estat√≠stica com taxas de falha [^3, ^4].

### Conceitos Fundamentais
A distribui√ß√£o binomial, como vimos, √© o modelo te√≥rico para o n√∫mero de exce√ß√µes em um backtesting [^3]:
$$f(x) = \binom{T}{x} p^x (1-p)^{T-x}$$
Entretanto, lidar diretamente com a distribui√ß√£o binomial para grandes valores de $T$ pode ser computacionalmente intensivo. Felizmente, quando $T$ √© grande, o **Teorema do Limite Central** nos permite aproximar a distribui√ß√£o binomial por uma distribui√ß√£o normal com m√©dia $E(x) = pT$ e vari√¢ncia $V(x) = p(1-p)T$ [^3]. Essa aproxima√ß√£o simplifica muito os c√°lculos e permite a aplica√ß√£o do **teste z**.

A aproxima√ß√£o normal √© adequada quando $T$ √© grande e $p$ n√£o est√° muito pr√≥ximo de 0 ou 1 [Proposi√ß√£o 3]. A regra geral sugere que a aproxima√ß√£o normal √© razo√°vel quando $Tp \geq 5$ e $T(1-p) \geq 5$ [Proposi√ß√£o 3].  Caso contr√°rio, a distribui√ß√£o binomial deve ser utilizada diretamente [Proposi√ß√£o 3.1].
**Proposi√ß√£o 3.1.** *Se as condi√ß√µes  $Tp \geq 5$ e $T(1-p) \geq 5$ n√£o s√£o satisfeitas, a aproxima√ß√£o normal para a distribui√ß√£o binomial pode n√£o ser precisa, e o uso da distribui√ß√£o binomial direta para o c√°lculo de probabilidades torna-se mais apropriado. Isso ocorre especialmente quando $p$ √© muito pequeno ou muito grande, e o n√∫mero de amostras $T$ n√£o √© suficientemente grande para que o teorema do limite central produza uma aproxima√ß√£o precisa.*

> üí° **Exemplo Num√©rico:** Considere um cen√°rio com um modelo VAR com um n√≠vel de confian√ßa de 99% ($p=0.01$) e um tamanho de amostra de $T=400$. Aqui, $Tp = 400 \times 0.01 = 4$ e $T(1-p) = 400 \times 0.99 = 396$.  Como $Tp = 4 < 5$, a aproxima√ß√£o normal pode n√£o ser ideal, e usar a distribui√ß√£o binomial diretamente seria mais apropriado para c√°lculos de probabilidade mais precisos. Se, por outro lado, tiv√©ssemos $T=600$, ter√≠amos $Tp=6$ e $T(1-p)=594$, satisfazendo as condi√ß√µes para a aproxima√ß√£o normal.

**Proposi√ß√£o 3.2.** *A aproxima√ß√£o normal para a distribui√ß√£o binomial tamb√©m pode ser avaliada usando a regra de Sturges para o n√∫mero de intervalos em um histograma. Para um tamanho de amostra $T$, o n√∫mero de intervalos $k$ pode ser estimado por $k \approx 1 + 3.322 \log_{10}(T)$. Uma visualiza√ß√£o da distribui√ß√£o binomial, utilizando um histograma com $k$ intervalos, pode dar uma intui√ß√£o de qu√£o pr√≥xima a distribui√ß√£o binomial est√° da normal.*
*Demonstra√ß√£o: A regra de Sturges √© uma diretriz para escolher o n√∫mero de intervalos para um histograma. O n√∫mero de intervalos impacta a visualiza√ß√£o de uma distribui√ß√£o, e um n√∫mero excessivo ou insuficiente de intervalos pode distorcer a sua apar√™ncia. Aplicar essa regra para o histograma de uma distribui√ß√£o binomial permite uma an√°lise visual de sua simetria e formato, ajudando a determinar se a aproxima√ß√£o normal √© razo√°vel. Uma distribui√ß√£o binomial com um n√∫mero grande de amostras se assemelha cada vez mais √† forma sim√©trica da distribui√ß√£o normal, o que justifica a aplica√ß√£o da aproxima√ß√£o.*

> üí° **Exemplo Num√©rico:** Se temos um tamanho de amostra $T = 1000$, o n√∫mero de intervalos usando a regra de Sturges seria $k \approx 1 + 3.322 \log_{10}(1000) = 1 + 3.322 * 3 \approx 10.966$.  Portanto, um histograma com cerca de 11 intervalos ajudaria a visualizar a distribui√ß√£o binomial e sua similaridade com a normal. Para $T=100$, $k \approx 1 + 3.322 \log_{10}(100) = 1 + 3.322 * 2 \approx 7.644$, ent√£o cerca de 8 intervalos s√£o apropriados.

**Proposi√ß√£o 3.3.** *Uma forma alternativa de verificar a adequa√ß√£o da aproxima√ß√£o normal √© calcular a assimetria (skewness) e a curtose da distribui√ß√£o binomial. Para uma distribui√ß√£o normal, a assimetria √© 0 e a curtose √© 3. Desvios significativos desses valores indicam que a distribui√ß√£o binomial pode n√£o ser bem aproximada pela normal.*

*Demonstra√ß√£o: A assimetria e a curtose s√£o medidas descritivas da forma de uma distribui√ß√£o. A assimetria quantifica o grau de falta de simetria, enquanto a curtose mede a "achatamento" da distribui√ß√£o.  Para a distribui√ß√£o binomial, a assimetria √© dada por $\frac{1-2p}{\sqrt{T p (1-p)}}$ e a curtose por $3 + \frac{1 - 6p(1-p)}{Tp(1-p)}$.  Quando $T$ √© grande e $p$ n√£o est√° pr√≥ximo de 0 ou 1, ambos os valores se aproximam de 0 e 3, respectivamente, indicando que a distribui√ß√£o binomial se assemelha √† normal.*
    Prova:
    I. Dada a distribui√ß√£o binomial com par√¢metros $T$ e $p$, a m√©dia √© $\mu = Tp$ e a vari√¢ncia √© $\sigma^2 = Tp(1-p)$.
    II. A assimetria de uma distribui√ß√£o √© dada por $\frac{E[(X-\mu)^3]}{\sigma^3}$. Para a distribui√ß√£o binomial, $E[(X-\mu)^3] = Tp(1-p)(1-2p)$.
    III. Substituindo os valores na f√≥rmula da assimetria, obtemos:
        $$\text{Assimetria} = \frac{Tp(1-p)(1-2p)}{(Tp(1-p))^{3/2}} = \frac{1-2p}{\sqrt{Tp(1-p)}}$$
    IV. A curtose de uma distribui√ß√£o √© dada por $\frac{E[(X-\mu)^4]}{\sigma^4} - 3$. Para a distribui√ß√£o binomial, $E[(X-\mu)^4] = 3(Tp(1-p))^2 + Tp(1-p)(1-6p(1-p))$.
    V. Substituindo os valores na f√≥rmula da curtose, obtemos:
        $$\text{Curtose} = \frac{3(Tp(1-p))^2 + Tp(1-p)(1-6p(1-p))}{(Tp(1-p))^2} - 3 = 3 + \frac{1-6p(1-p)}{Tp(1-p)} - 3 = 3 + \frac{1-6p(1-p)}{Tp(1-p)}$$
    VI. Portanto, demonstramos que a assimetria da distribui√ß√£o binomial √© $\frac{1-2p}{\sqrt{T p (1-p)}}$ e a curtose √© $3 + \frac{1 - 6p(1-p)}{Tp(1-p)}$. Quando $T$ √© grande e $p$ n√£o est√° muito pr√≥ximo de 0 ou 1, ambas se aproximam de 0 e 3, respectivamente, que s√£o os valores correspondentes a uma distribui√ß√£o normal. ‚ñ†

> üí° **Exemplo Num√©rico:** Se temos $T = 100$ e $p=0.05$, a assimetria √© $\frac{1 - 2(0.05)}{\sqrt{100 \times 0.05 \times 0.95}} = \frac{0.9}{\sqrt{4.75}} \approx 0.41$. A curtose √© $3 + \frac{1 - 6(0.05)(0.95)}{100 \times 0.05 \times 0.95} = 3 + \frac{1 - 0.285}{4.75} \approx 3.15$.  Estes valores indicam um desvio em rela√ß√£o √† distribui√ß√£o normal (assimetria de 0 e curtose de 3) e justificam ter cuidado ao utilizar a aproxima√ß√£o normal.  Por outro lado, se $T = 1000$ e $p=0.05$, a assimetria √© $\frac{1 - 2(0.05)}{\sqrt{1000 \times 0.05 \times 0.95}} \approx 0.129$, e a curtose √© $3 + \frac{1 - 6(0.05)(0.95)}{1000 \times 0.05 \times 0.95} \approx 3.015$, que s√£o muito mais pr√≥ximos dos valores de uma distribui√ß√£o normal.
O teste z, baseado na aproxima√ß√£o normal, √© dado por [^4]:
$$z = \frac{x - pT}{\sqrt{p(1-p)T}} \sim N(0,1)$$
Onde:
-   $x$ √© o n√∫mero de exce√ß√µes observadas.
-   $p$ √© a probabilidade de uma exce√ß√£o (n√≠vel de cauda √† esquerda).
-   $T$ √© o n√∫mero total de observa√ß√µes.

Esta estat√≠stica de teste quantifica o desvio do n√∫mero de exce√ß√µes observadas em rela√ß√£o ao n√∫mero esperado, medido em termos de desvios padr√£o. Rejeitamos a hip√≥tese nula de que o modelo VAR est√° corretamente calibrado se o valor absoluto do z-score for maior do que um valor cr√≠tico predeterminado (por exemplo, 1.96 para um n√≠vel de signific√¢ncia de 5% em um teste bicaudal).

Uma formula√ß√£o alternativa, expressa em termos da taxa de falha observada $\hat{p} = x/T$, tamb√©m pode ser usada [Proposi√ß√£o 1]:
$$z = \frac{\hat{p} - p}{\sqrt{p(1-p)/T}}$$
Prova:
    I. Partindo da formula√ß√£o do teste z:
        $$z = \frac{x - pT}{\sqrt{p(1-p)T}}$$
    II. Dividindo o numerador e denominador por $T$:
    $$z = \frac{\frac{x}{T} - \frac{pT}{T}}{\frac{\sqrt{p(1-p)T}}{T}}$$
    III. Como $\hat{p} = x/T$:
         $$z = \frac{\hat{p} - p}{\frac{\sqrt{p(1-p)T}}{T}}$$
    IV. Usando a propriedade $\frac{\sqrt{a}}{\sqrt{b}} = \sqrt{\frac{a}{b}}$ e $\frac{1}{T} = \frac{1}{\sqrt{T^2}}$:
          $$z = \frac{\hat{p} - p}{\sqrt{\frac{p(1-p)T}{T^2}}}$$
    V. Simplificando:
    $$z = \frac{\hat{p} - p}{\sqrt{p(1-p)/T}}$$
    VI. Portanto, demonstramos que a formula√ß√£o do teste z em termos da taxa de falha observada √©:
        $$z = \frac{\hat{p} - p}{\sqrt{p(1-p)/T}}$$‚ñ†

Essa formula√ß√£o ressalta a import√¢ncia da precis√£o da taxa de falha observada $\hat{p}$ na avalia√ß√£o da calibra√ß√£o do modelo e facilita a interpreta√ß√£o do teste, pois o valor $z$ torna-se uma medida da dist√¢ncia entre a taxa de falha observada e a esperada, normalizada pelo seu desvio padr√£o. O **Corol√°rio 1** demonstrou que $\hat{p}$ √© um estimador n√£o viesado da taxa de falha $p$ e que a sua vari√¢ncia diminui quando $T$ aumenta, tornando o estimador mais preciso.

**Corol√°rio 3.** *O teste z √© uma estat√≠stica de teste aproximada, que se torna mais precisa √† medida que o tamanho da amostra $T$ aumenta e a distribui√ß√£o binomial se aproxima da normal. No entanto, para tamanhos de amostra finitos, a aproxima√ß√£o pode n√£o ser perfeita e a distribui√ß√£o real da estat√≠stica de teste pode se desviar da normal.*

*Demonstra√ß√£o: A aproxima√ß√£o da distribui√ß√£o binomial pela normal baseia-se no teorema do limite central, que √© uma afirma√ß√£o assint√≥tica. Para tamanhos de amostra finitos, a distribui√ß√£o da estat√≠stica do teste pode n√£o ser exatamente normal. A diferen√ßa entre a distribui√ß√£o real e a normal depende do tamanho da amostra T e da probabilidade $p$. Para garantir que a aproxima√ß√£o seja precisa, a regra geral √© que $Tp$ e $T(1-p)$ sejam pelo menos 5.*
**Lema 3.2.** *Em situa√ß√µes onde $T$ √© pequeno ou $p$ est√° pr√≥ximo de 0 ou 1, a estat√≠stica de teste z pode ser imprecisa. Para melhorar a aproxima√ß√£o e aumentar a precis√£o do teste, √© poss√≠vel usar uma corre√ß√£o de continuidade ao calcular o z-score. Essa corre√ß√£o ajusta o n√∫mero de exce√ß√µes observadas por 0.5, sendo adicionado ou subtra√≠do dependendo se estamos olhando para a cauda direita ou esquerda da distribui√ß√£o.*
  *Demonstra√ß√£o: A corre√ß√£o de continuidade busca melhorar a aproxima√ß√£o da distribui√ß√£o binomial discreta pela normal cont√≠nua. Especificamente, o z-score com corre√ß√£o de continuidade √© dado por $z_c = \frac{x \pm 0.5 - pT}{\sqrt{p(1-p)T}}$, onde usamos $x-0.5$ se estamos olhando para a cauda esquerda da distribui√ß√£o e $x+0.5$ para a cauda direita. Esta corre√ß√£o ajuda a melhorar a aproxima√ß√£o quando o n√∫mero de amostras √© pequeno, aproximando a probabilidade exata da distribui√ß√£o discreta.*

> üí° **Exemplo Num√©rico:** Considere um modelo VAR com n√≠vel de confian√ßa de 99% ($p=0.01$) e um tamanho de amostra de $T=100$. Aqui, $Tp = 1$ e $T(1-p)=99$. A regra geral ($Tp \geq 5$) n√£o √© satisfeita. Se observarmos 3 exce√ß√µes, a estat√≠stica do teste z seria:
> $z = \frac{3 - 100*0.01}{\sqrt{0.01(1-0.01)100}} = \frac{2}{\sqrt{0.99}} = \frac{2}{0.995} \approx 2.01$.
> No entanto, este teste z pode n√£o ser preciso, devido a amostra pequena.
> üí° **Exemplo Num√©rico:** Aplicando a corre√ß√£o de continuidade ao exemplo anterior, e como queremos analisar se a taxa de falha observada √© maior que a esperada, usar√≠amos: $z_c = \frac{3 - 0.5 - 100*0.01}{\sqrt{0.01(1-0.01)100}} = \frac{1.5}{\sqrt{0.99}} \approx 1.51$. O valor $z_c$ √© menor do que o valor $z$, demonstrando que a corre√ß√£o de continuidade tende a gerar resultados mais conservadores, e corrige para o fato de estarmos aproximando uma distribui√ß√£o discreta com uma cont√≠nua.

> üí° **Exemplo Num√©rico:** Considere agora um modelo VAR com n√≠vel de confian√ßa de 99% ($p=0.01$) e um tamanho de amostra de $T=1000$. Aqui, $Tp=10$ e $T(1-p)=990$. A regra geral √© satisfeita. Se observarmos 15 exce√ß√µes, o teste z seria:
> $z = \frac{15 - 1000*0.01}{\sqrt{0.01(1-0.01)1000}} = \frac{5}{\sqrt{9.9}} = \frac{5}{3.146} \approx 1.59$.
> Neste caso, o teste z provavelmente √© mais preciso.

O **Lema 2** e o **Lema 2.1** demonstraram como o tamanho da amostra $T$ influencia a pot√™ncia do teste. O **Lema 2** forneceu uma formula√ß√£o aproximada para calcular o tamanho m√≠nimo de amostra $T$ necess√°rio para alcan√ßar um poder espec√≠fico $1-\beta$ para detectar um desvio $\delta$ na taxa de falha esperada. O **Lema 2.1** enfatizou que a quantidade de dados necess√°ria para um determinado poder aumenta quadraticamente com a diminui√ß√£o do desvio a ser detectado.
**Lema 2.2.** *O poder de um teste estat√≠stico, em particular o teste z, √© afetado por fatores como o tamanho da amostra, o n√≠vel de signific√¢ncia, e a magnitude do desvio da hip√≥tese nula. Para aumentar o poder de um teste, pode-se aumentar o tamanho da amostra, aumentar o n√≠vel de signific√¢ncia (tornando mais f√°cil rejeitar a hip√≥tese nula), ou ter um desvio maior da hip√≥tese nula. No entanto, aumentar o n√≠vel de signific√¢ncia pode aumentar a probabilidade de cometer um erro do tipo I.*

**Proposi√ß√£o 4.** *Para o teste z bicaudal, rejeitamos a hip√≥tese nula quando o valor absoluto do z-score √© maior que o valor cr√≠tico correspondente ao n√≠vel de signific√¢ncia $\alpha$. O valor cr√≠tico √© geralmente denotado como $z_{\alpha/2}$. Especificamente, se $|z| > z_{\alpha/2}$, rejeitamos a hip√≥tese nula, concluindo que a taxa de falha observada √© estatisticamente diferente da esperada.*
*Demonstra√ß√£o: A regra de rejei√ß√£o para um teste z bicaudal √© baseada na distribui√ß√£o normal. O valor cr√≠tico $z_{\alpha/2}$ √© o valor na distribui√ß√£o normal padr√£o tal que a √°rea nas caudas (esquerda e direita) totaliza $\alpha$. Se o valor absoluto da estat√≠stica de teste z for maior que o valor cr√≠tico, ent√£o o valor z calculado est√° na regi√£o de rejei√ß√£o. No caso de um n√≠vel de signific√¢ncia de 5%, $\alpha = 0.05$ e  $z_{\alpha/2} = z_{0.025} \approx 1.96$, que deixa 2.5% de probabilidade em cada cauda da distribui√ß√£o normal.*

> üí° **Exemplo Num√©rico:** Consideremos novamente o modelo VAR de 99% com $p=0.01$ e $T=1000$. Se observarmos 20 exce√ß√µes, a taxa de falha observada √© $\hat{p} = 20/1000 = 0.02$. O z-score √©:
>
> $z = \frac{20 - 0.01*1000}{\sqrt{0.01*(1-0.01)*1000}} = \frac{10}{3.146} \approx 3.18$.
>
> Dado que $|3.18| > 1.96$, rejeitamos a hip√≥tese nula ao n√≠vel de 5%, concluindo que o modelo VAR est√° mal calibrado (subestima o risco).

> üí° **Exemplo Num√©rico:** Consideremos o mesmo modelo VAR de 99% com $p=0.01$ e $T=1000$, mas com 5 exce√ß√µes. A taxa de falha observada √© $\hat{p} = 5/1000 = 0.005$. O z-score √©:
>
> $z = \frac{5 - 0.01*1000}{\sqrt{0.01*(1-0.01)*1000}} = \frac{-5}{3.146} \approx -1.59$.
>
> Dado que $|-1.59| < 1.96$, n√£o rejeitamos a hip√≥tese nula ao n√≠vel de 5%, concluindo que o modelo VAR est√° bem calibrado (a amostra de 5 exce√ß√µes em 1000 dias n√£o √© estatisticamente diferente de uma amostra onde o modelo VAR est√° calibrado corretamente).

**Proposi√ß√£o 5.** *Para um teste z unilateral (e.g., testar se a taxa de falha observada √© significativamente maior do que a esperada), rejeitamos a hip√≥tese nula quando o valor z for maior do que o valor cr√≠tico correspondente ao n√≠vel de signific√¢ncia $\alpha$. O valor cr√≠tico √© denotado como $z_{\alpha}$ neste caso. Especificamente, se $z > z_{\alpha}$, rejeitamos a hip√≥tese nula de que a taxa de falha √© maior do que o esperado, enquanto se $z < -z_{\alpha}$ rejeitamos a hip√≥tese de que a taxa de falha √© menor do que o esperado.*

*Demonstra√ß√£o: Em um teste unilateral, estamos interessados apenas em desvios em uma dire√ß√£o espec√≠fica. Se queremos testar se a taxa de falha observada √© significativamente maior que a esperada, usamos um teste unilateral, onde a regra de rejei√ß√£o baseia-se na √°rea na cauda direita da distribui√ß√£o normal. O valor cr√≠tico $z_{\alpha}$ √© o valor na distribui√ß√£o normal padr√£o tal que a √°rea √† direita totaliza $\alpha$. Se o valor da estat√≠stica de teste z for maior que o valor cr√≠tico, ent√£o o valor z calculado est√° na regi√£o de rejei√ß√£o. No caso de um n√≠vel de signific√¢ncia de 5% para testar se a taxa de falha observada √© maior que a esperada, $\alpha = 0.05$ e $z_{\alpha} = z_{0.05} \approx 1.645$. Da mesma forma, se quisermos testar se a taxa de falha √© menor do que a esperada, usamos um teste unilateral √† esquerda e $z$ tem que ser menor que $-z_{\alpha}$.*
    Prova:
    I. Para um teste unilateral √† direita, procuramos o valor $z_{\alpha}$ tal que $P(Z > z_{\alpha}) = \alpha$, onde $Z$ segue uma distribui√ß√£o normal padr√£o.
    II. Se $z > z_{\alpha}$, isso significa que o valor observado est√° na regi√£o de rejei√ß√£o, a √°rea na cauda direita da distribui√ß√£o normal, com uma probabilidade de $\alpha$ de ocorrer sob a hip√≥tese nula. Portanto, rejeitamos a hip√≥tese nula.
    III. Para um teste unilateral √† esquerda, procuramos o valor $-z_{\alpha}$ tal que $P(Z < -z_{\alpha}) = \alpha$, onde $Z$ segue uma distribui√ß√£o normal padr√£o.
    IV. Se $z < -z_{\alpha}$, isso significa que o valor observado est√° na regi√£o de rejei√ß√£o, a √°rea na cauda esquerda da distribui√ß√£o normal, com uma probabilidade de $\alpha$ de ocorrer sob a hip√≥tese nula. Portanto, rejeitamos a hip√≥tese nula.
    V. Portanto, demonstramos que para um teste z unilateral √† direita, rejeitamos a hip√≥tese nula se $z > z_{\alpha}$, e para um teste z unilateral √† esquerda, rejeitamos a hip√≥tese nula se $z < -z_{\alpha}$. ‚ñ†

> üí° **Exemplo Num√©rico:** Consideremos um modelo VAR de 99% com $p=0.01$ e $T=500$. Queremos testar se a taxa de falha observada √© significativamente maior do que o esperado. Se observarmos 12 exce√ß√µes, a taxa de falha observada √© $\hat{p} = 12/500 = 0.024$. O z-score √©:
>
> $z = \frac{12 - 0.01*500}{\sqrt{0.01*(1-0.01)*500}} = \frac{7}{2.22} \approx 3.15$
>
> Dado que $3.15 > 1.645$, rejeitamos a hip√≥tese nula ao n√≠vel de 5%, concluindo que o modelo VAR est√° mal calibrado e subestima o risco.

> üí° **Exemplo Num√©rico:** Considere o mesmo modelo VAR de 99% com $p=0.01$ e $T=500$. Queremos testar se a taxa de falha observada √© significativamente menor do que o esperado. Se observarmos 1 exce√ß√£o, a taxa de falha observada √© $\hat{p} = 1/500 = 0.002$. O z-score √©:
>
> $z = \frac{1 - 0.01*500}{\sqrt{0.01*(1-0.01)*500}} = \frac{-4}{2.22} \approx -1.80$
>
> Dado que $-1.80 < -1.645$, rejeitamos a hip√≥tese nula ao n√≠vel de 5%, concluindo que o modelo VAR est√° bem calibrado, mas com uma superestima√ß√£o do risco.
**Proposi√ß√£o 5.1** *Em um teste unilateral, a escolha da cauda (direita ou esquerda) depende da hip√≥tese alternativa que se deseja testar. Se a hip√≥tese alternativa sugere que a taxa de falha observada √© maior que a esperada, usamos um teste unilateral √† direita. Se a hip√≥tese alternativa sugere que a taxa de falha observada √© menor que a esperada, usamos um teste unilateral √† esquerda. A escolha correta do teste √© crucial para a validade das conclus√µes.*

**Proposi√ß√£o 5.2** *O poder de um teste unilateral √© geralmente maior do que o poder de um teste bicaudal para um mesmo tamanho de amostra e n√≠vel de signific√¢ncia, quando a verdadeira dire√ß√£o do desvio √© conhecida. Isso ocorre porque, em um teste unilateral, concentramos toda a √°rea de rejei√ß√£o em uma √∫nica cauda, tornando o teste mais sens√≠vel a desvios nessa dire√ß√£o.*

**Proposi√ß√£o 5.3** *A escolha entre um teste unilateral e um teste bicaudal depende da hip√≥tese espec√≠fica que se deseja testar. Se houver um motivo a priori para acreditar que a taxa de falha s√≥ pode ser maior ou menor que o esperado, um teste unilateral pode ser mais apropriado. No entanto, se n√£o houver nenhuma raz√£o para suspeitar que o desvio s√≥ pode ocorrer em uma dire√ß√£o, um teste bicaudal √© mais conservador e, em geral, mais recomendado.*

O **Lema 3** mostrou como calcular o p-valor para o teste z. O **Lema 3.1** estendeu o c√°lculo do p-valor para testes unilaterais. O **Corol√°rio 2** sumarizou a regra de decis√£o usando o p-valor: rejeitar a hip√≥tese nula quando o p-valor √© menor que o n√≠vel de signific√¢ncia.

A escolha do n√≠vel de confian√ßa para o backtesting, como demonstrado na **Proposi√ß√£o 2**, √© independente do n√≠vel de confian√ßa usado na constru√ß√£o do modelo VAR. Este ponto √© crucial porque permite que o backtesting avalie a robustez do modelo em diferentes condi√ß√µes operacionais.

√â importante considerar tamb√©m as limita√ß√µes da aproxima√ß√£o normal e a necessidade de m√©todos mais avan√ßados, como testes de cobertura condicional, quando as exce√ß√µes n√£o s√£o independentes [Teoremas 1, 1.1 e 1.2].
**Teorema 1.3** *O teste z baseado na aproxima√ß√£o normal assume que as exce√ß√µes s√£o independentes. No entanto, em muitos casos reais, as exce√ß√µes podem n√£o ser independentes e podem ocorrer em grupos, especialmente quando h√° volatilidade agrupada. Nestes casos, o teste z pode levar a conclus√µes err√¥neas, e os testes de cobertura condicional, que consideram a autocorrela√ß√£o das exce√ß√µes, s√£o mais apropriados. Estes testes de cobertura condicional avaliam a distribui√ß√£o condicional do n√∫mero de exce√ß√µes, dado o hist√≥rico de exce√ß√µes anteriores, garantindo uma avalia√ß√£o mais robusta da precis√£o do modelo VAR.*

**Teorema 1.4** *Quando o teste z √© usado para avaliar v√°rios modelos VAR simultaneamente, surge o problema de compara√ß√µes m√∫ltiplas. Usar o mesmo n√≠vel de signific√¢ncia $\alpha$ para cada teste individual aumenta a probabilidade de rejeitar erroneamente a hip√≥tese nula para pelo menos um dos modelos. Para corrigir isso, √© necess√°rio usar m√©todos de ajuste de n√≠vel de signific√¢ncia, como a corre√ß√£o de Bonferroni, que reduz o n√≠vel de signific√¢ncia individual de cada teste.*
*Demonstra√ß√£o: O problema das compara√ß√µes m√∫ltiplas surge porque a probabilidade de cometer um erro do tipo I (rejeitar a hip√≥tese nula quando ela √© verdadeira) aumenta com o n√∫mero de testes realizados. A corre√ß√£o de Bonferroni ajusta o n√≠vel de signific√¢ncia $\alpha$ dividindo-o pelo n√∫mero de testes realizados. Por exemplo, se estivermos realizando $n$ testes simult√¢neos com um n√≠vel de signific√¢ncia desejado $\alpha$, o novo n√≠vel de signific√¢ncia para cada teste individual ser√° $\alpha/n$.*
    Prova:
    I. Suponha que estamos realizando $n$ testes de hip√≥tese simultaneamente.
    II. Se a hip√≥tese nula for verdadeira para todos os testes, ent√£o a probabilidade de n√£o cometer um erro do tipo I para cada teste individual √© $1-\alpha$, onde $\alpha$ √© o n√≠vel de signific√¢ncia.
    III. A probabilidade de n√£o cometer um erro do tipo I em todos os testes √© $(1-\alpha)^n$, supondo que os testes sejam independentes.
    IV. Portanto, a probabilidade de cometer pelo menos um erro do tipo I em $n$ testes √© $1 - (1-\alpha)^n$.
    V. Quando $n$ √© grande, esta probabilidade se aproxima de 1, indicando uma alta chance de rejeitar erroneamente pelo menos uma hip√≥tese nula.
    VI. A corre√ß√£o de Bonferroni ajusta o n√≠vel de signific√¢ncia dividindo-o pelo n√∫mero de testes, definindo $\alpha' = \alpha/n$ como o novo n√≠vel de signific√¢ncia para cada teste.
    VII. Ao fazer isso, a probabilidade de n√£o cometer um erro do tipo I em todos os testes √© $(1-\alpha')^n \approx (1-\alpha/n)^n$.
    VIII. Para grandes valores de n, $(1-\alpha/n)^n \approx e^{-\alpha}$, onde e √© a base do logaritmo natural,
    IX. Para valores pequenos de $\alpha$, $e^{-\alpha}$ √© aproximadamente $1 - \alpha$.
    X. Assim, corrigindo o n√≠vel de signific√¢ncia, garantimos que a probabilidade de cometer pelo menos um erro do tipo I em $n$ testes seja aproximadamente $\alpha$. ‚ñ†

> üí° **Exemplo Num√©rico:** Suponha que estamos testando simultaneamente 5 modelos VAR, usando um n√≠vel de signific√¢ncia de 5% ($\alpha=0.05$). Se usarmos o mesmo n√≠vel de signific√¢ncia para todos os testes, a probabilidade de cometer pelo menos um erro do tipo I √©  $1-(1-0.05)^5 \approx 0.226$, ou seja, 22.6%. Aplicando a corre√ß√£o de Bonferroni, o novo n√≠vel de signific√¢ncia para cada teste seria $\alpha' = 0.05/5 = 0.01$. Este ajuste reduz a probabilidade de erros do tipo I ao realizar m√∫ltiplos testes.

**Teorema 1.5** *Outro m√©todo de corre√ß√£o para compara√ß√µes m√∫ltiplas √© o m√©todo de Benjamini-Hochberg, que controla a False Discovery Rate (FDR). A FDR √© a propor√ß√£o esperada de hip√≥teses nulas rejeitadas que s√£o, na verdade, verdadeiras. O m√©todo de Benjamini-Hochberg √© menos conservador que a corre√ß√£o de Bonferroni e pode levar a uma maior pot√™ncia do teste em algumas situa√ß√µes.*

*Demonstra√ß√£o: O m√©todo de Benjamini-Hochberg ajusta os p-valores individuais para controlar a FDR. Os p-valores s√£o classificados em ordem crescente e cada p-valor √© comparado com um valor cr√≠tico ajustado baseado em sua posi√ß√£o na lista ordenada. Este m√©todo permite um controle menos rigoroso sobre os erros do tipo I do que a corre√ß√£o de Bonferroni, mas com uma maior probabilidade de identificar resultados verdadeiramente significativos.*

### Conclus√£o
Este cap√≠tulo detalhou a aproxima√ß√£o normal para a distribui√ß√£o binomial e a aplica√ß√£o do teste z no backtesting,  demonstrando como o uso do teorema central do limite simplifica o teste de hip√≥teses estat√≠sticas. Os testes z e a sua formula√ß√£o usando a taxa de falha observada nos fornecem uma forma eficiente e precisa de avaliar a precis√£o do modelo VAR em cen√°rios com grandes amostras. Exploramos como o tamanho da amostra influencia o poder do teste e como a escolha do n√≠vel de confian√ßa afeta a probabilidade de cometer erros do tipo I e tipo II. Ao entender as bases estat√≠sticas do backtesting, estamos melhor equipados para avaliar criticamente a adequa√ß√£o dos modelos VAR e tomar decis√µes informadas sobre a gest√£o de riscos.

### Refer√™ncias
[^1]: *This chapter turns to backtesting techniques for verifying the accuracy of VAR models. Backtesting is a formal statistical framework that consists of verifying that actual losses are in line with projected losses.*
[^2]: *When the model is perfectly calibrated, the number of observations falling outside VAR should be in line with the confidence level. The number of exceedences is also known as the number of exceptions.*
[^3]: *The simplest method to verify the accuracy of the model is to record the failure rate, which gives the proportion of times VAR is exceeded in a given sample... Under the null hypothesis that the model is correctly calibrated, the number of exceptions x follows a binomial probability distribution.*
[^4]: *Based on Equation (6.2), we have z = (x-pT)/‚àöp(1-p) T = (20 - 0.05 √ó 252)/‚àö0.05(0.95) 252 = 2.14. This is larger than the cut-off value of 1.96. Therefore, we reject the hypothesis that the VAR model is unbiased.*
<!-- END -->
