## Simula√ß√µes com M√∫ltiplas Vari√°veis
### Introdu√ß√£o

Este cap√≠tulo aprofunda a aplica√ß√£o dos m√©todos de Monte Carlo em cen√°rios multivariados. Em continuidade com a discuss√£o sobre a necessidade de modelar corretamente as correla√ß√µes entre as vari√°veis de risco e a import√¢ncia de garantir que a matriz de correla√ß√£o seja positiva definida, esta se√ß√£o aborda a simula√ß√£o determin√≠stica como uma alternativa √†s simula√ß√µes de Monte Carlo tradicionais.

### Conceitos Fundamentais

#### Simula√ß√µes de Monte Carlo vs. Simula√ß√£o Determin√≠stica

As simula√ß√µes de Monte Carlo geram pontos pseudoaleat√≥rios para "preencher" um espa√ßo N-dimensional, onde N √© o n√∫mero de fatores de risco [^325]. Em contraste, a simula√ß√£o determin√≠stica emprega esquemas que s√£o constru√≠dos para prover um preenchimento mais consistente do espa√ßo N-dimensional [^325].

#### Simula√ß√£o Determin√≠stica (Quasi-Monte Carlo - QMC)

Na simula√ß√£o determin√≠stica, tamb√©m conhecida como *Quasi-Monte Carlo* (QMC), embora o termo seja um equ√≠voco, os n√∫meros n√£o s√£o independentes, mas sim constru√≠dos como uma sequ√™ncia ordenada de pontos [^325]. A escolha do esquema determin√≠stico deve levar em considera√ß√£o o tamanho da amostra, a dimensionalidade do problema e, possivelmente, a forma da fun√ß√£o que est√° sendo integrada [^325]. Al√©m da sequ√™ncia de Sobol, outras sequ√™ncias de baixa discrep√¢ncia incluem a sequ√™ncia de Halton e a sequ√™ncia de Faure.

**Teorema 1** [Sequ√™ncias de Baixa Discrep√¢ncia]: Uma sequ√™ncia $(x_n)_{n \geq 1}$ em $[0,1]^d$ tem baixa discrep√¢ncia se sua discrep√¢ncia $D_N$ satisfaz $D_N = O(N^{-1} (\log N)^d)$ para todo $N$.

*Prova do Teorema 1:*

I. Seja $(x_n)_{n \geq 1}$ uma sequ√™ncia de pontos em $[0,1]^d$. A discrep√¢ncia $D_N$ √© uma medida de qu√£o uniformemente os pontos est√£o distribu√≠dos no hipercubo unit√°rio.

II. Formalmente, a discrep√¢ncia $D_N$ √© definida como:

$$D_N = \sup_{B \in \mathcal{B}} \left| \frac{\text{n√∫mero de pontos em } B}{N} - \text{volume de } B \right|$$

onde $\mathcal{B}$ √© o conjunto de todos os ret√¢ngulos alinhados com os eixos em $[0,1]^d$.

III. Uma sequ√™ncia de baixa discrep√¢ncia √© aquela para a qual $D_N$ converge para 0 o mais r√°pido poss√≠vel quando $N$ aumenta. O limite superior da discrep√¢ncia √© dado por:

$$D_N = O(N^{-1} (\log N)^d)$$

Isso significa que existe uma constante $C$ tal que:

$$D_N \leq C \cdot \frac{(\log N)^d}{N}$$

IV. Essa taxa de converg√™ncia √© significativamente melhor do que a obtida com pontos aleat√≥rios, que geralmente t√™m uma discrep√¢ncia da ordem de $O(N^{-1/2})$. Portanto, sequ√™ncias com baixa discrep√¢ncia proporcionam uma cobertura mais uniforme do espa√ßo, reduzindo o erro de integra√ß√£o num√©rica. ‚ñ†

> üí° **Exemplo Num√©rico:**
>
> Suponha que voc√™ esteja calculando uma integral em um espa√ßo 2D. Com 100 pontos aleat√≥rios, o erro pode ser em torno de 10%. Usando uma sequ√™ncia de baixa discrep√¢ncia com os mesmos 100 pontos, o erro pode ser reduzido para 2%, demonstrando a melhor cobertura do espa√ßo.
>
> ```python
> import numpy as np
> from scipy.stats import qmc
>
> # Fun√ß√£o a ser integrada (exemplo: x^2 + y^2)
> def f(x):
>     return x[:, 0]**2 + x[:, 1]**2
>
> # Limites de integra√ß√£o
> lower_bound = [0, 0]
> upper_bound = [1, 1]
>
> # N√∫mero de amostras
> n_samples = 100
>
> # Monte Carlo tradicional
> random_samples = np.random.uniform(lower_bound, upper_bound, size=(n_samples, 2))
> mc_estimate = np.mean(f(random_samples))
>
> # Quasi-Monte Carlo com sequ√™ncia de Sobol
> sobol_engine = qmc.Sobol(d=2, scramble=False)
> sobol_samples = sobol_engine.random(n=n_samples)
> # Ajusta os valores para os limites de integra√ß√£o
> sobol_samples = qmc.scale(sobol_samples, lower_bound, upper_bound)
> qmc_estimate = np.mean(f(sobol_samples))
>
> # Valor anal√≠tico da integral (para compara√ß√£o)
> analytical_value = 2/3
>
> # Calcula os erros
> mc_error = abs(mc_estimate - analytical_value)
> qmc_error = abs(qmc_estimate - analytical_value)
>
> print(f"Monte Carlo Estimate: {mc_estimate}, Error: {mc_error}")
> print(f"Quasi-Monte Carlo Estimate: {qmc_estimate}, Error: {qmc_error}")
> ```
> Nesse exemplo, ao executar o c√≥digo, voc√™ ver√° que o erro associado ao m√©todo Quasi-Monte Carlo √© significativamente menor do que o erro associado ao m√©todo de Monte Carlo tradicional, evidenciando a melhor converg√™ncia da sequ√™ncia de Sobol.

#### Distribui√ß√£o dos Pontos

A Figura 12-4 do texto [^325] compara uma distribui√ß√£o para duas vari√°veis, mostrando pontos pseudoaleat√≥rios √† esquerda e uma sequ√™ncia determin√≠stica de baixa discrep√¢ncia √† direita, obtida de um procedimento conhecido como *Sobol sequence*.

A sequ√™ncia pseudoaleat√≥ria frequentemente apresenta "aglomerados" em algumas regi√µes, deixando outras √°reas com pouca cobertura. Esses aglomerados s√£o ineficientes porque n√£o contribuem com mais informa√ß√µes. Em contraste, o painel direito da figura [^325] exibe uma cobertura mais uniforme, onde o esquema determin√≠stico preenche sistematicamente o espa√ßo deixado pelos n√∫meros anteriores na s√©rie.

#### Taxa de Converg√™ncia

Os m√©todos quase aleat√≥rios t√™m a propriedade desej√°vel de que o erro padr√£o diminui a uma taxa mais r√°pida, proporcional a algo pr√≥ximo de 1/K, em vez de $1/\sqrt{K}$ para simula√ß√µes padr√£o [^325]. V√°rios autores demonstraram que os m√©todos determin√≠sticos proporcionam uma melhora not√°vel na velocidade [^325].

*Prova da Taxa de Converg√™ncia:*

I.  **Erro em Monte Carlo padr√£o:** Na simula√ß√£o de Monte Carlo, a estimativa de uma integral √© obtida pela m√©dia dos valores da fun√ß√£o em pontos amostrados aleatoriamente. O erro desta estimativa √© tipicamente da ordem de $O(1/\sqrt{K})$, onde $K$ √© o n√∫mero de amostras.

II. **Erro em Quasi-Monte Carlo (QMC):** Os m√©todos QMC, que utilizam sequ√™ncias de baixa discrep√¢ncia, exploram a propriedade de que a integral de uma fun√ß√£o suave pode ser aproximada com maior precis√£o se os pontos de amostragem forem mais uniformemente distribu√≠dos.

III. **Teorema de Koksma-Hlawka:** O teorema de Koksma-Hlawka fornece um limite superior para o erro na integra√ß√£o num√©rica usando sequ√™ncias de baixa discrep√¢ncia:

$$ \left| \int_{[0,1]^d} f(x) \, dx - \frac{1}{K} \sum_{i=1}^K f(x_i) \right| \leq V(f) \cdot D_K(x_1, \dots, x_K) $$

onde:
   - $f(x)$ √© a fun√ß√£o a ser integrada.
   - $V(f)$ √© a varia√ß√£o de Hardy-Krause da fun√ß√£o $f$.
   - $D_K(x_1, \dots, x_K)$ √© a discrep√¢ncia da sequ√™ncia de pontos $x_1, \dots, x_K$.

IV. **Discrep√¢ncia e Taxa de Converg√™ncia:** Como a discrep√¢ncia $D_K$ para sequ√™ncias de baixa discrep√¢ncia √© da ordem de $O((\log K)^d / K)$, o erro na integra√ß√£o QMC √© limitado por:

$$ \text{Erro} \leq V(f) \cdot O\left( \frac{(\log K)^d}{K} \right) $$

V. **Compara√ß√£o das Taxas de Converg√™ncia:**
   - Para Monte Carlo padr√£o, o erro √© da ordem de $O(1/\sqrt{K})$.
   - Para QMC, o erro √© da ordem de $O((\log K)^d / K)$.

Para $K$ suficientemente grande, $(\log K)^d / K$ converge para 0 mais rapidamente do que $1/\sqrt{K}$. Portanto, os m√©todos QMC t√™m uma taxa de converg√™ncia mais r√°pida do que os m√©todos de Monte Carlo padr√£o. ‚ñ†

> üí° **Exemplo Num√©rico:**
>
> Suponha que voc√™ esteja calculando o pre√ßo de uma op√ß√£o usando simula√ß√£o de Monte Carlo. Ap√≥s 10.000 simula√ß√µes (K = 10.000), o erro padr√£o √© de 0,01 (1%). Com simula√ß√£o QMC, o mesmo erro padr√£o poderia ser alcan√ßado com um n√∫mero significativamente menor de simula√ß√µes, digamos, 1.000, devido √† taxa de converg√™ncia superior.

#### Implementa√ß√£o da Sequ√™ncia de Sobol

Uma *sequ√™ncia de Sobol* √© um tipo de sequ√™ncia de baixa discrep√¢ncia usada em m√©todos QMC. A implementa√ß√£o da sequ√™ncia de Sobol envolve gerar n√∫meros em base 2 e realizar opera√ß√µes de XOR com base em dire√ß√µes espec√≠ficas. A implementa√ß√£o detalhada pode ser encontrada em Press et al. (1992) [^325].

> üí° **Exemplo Num√©rico:**
>
> Para ilustrar a gera√ß√£o de uma sequ√™ncia de Sobol, considere a gera√ß√£o dos primeiros tr√™s n√∫meros em uma dimens√£o. A sequ√™ncia de Sobol para a primeira dimens√£o √© gerada por:
>
> 1.  **Dire√ß√µes Iniciais:** Definir dire√ß√µes iniciais para cada bit (por exemplo, 1/2, 1/4, 1/8).
> 2.  **Primeiro N√∫mero:** O primeiro n√∫mero √© sempre 0.
> 3.  **Gera√ß√£o dos Pr√≥ximos N√∫meros:** Para gerar os pr√≥ximos n√∫meros, invertemos o bit menos significativo n√£o utilizado e aplicamos a dire√ß√£o correspondente. Por exemplo:
>     *   **Segundo N√∫mero:** O bit menos significativo n√£o utilizado √© o primeiro bit (1/2). Ent√£o, o segundo n√∫mero √© 1/2 = 0,5.
>     *   **Terceiro N√∫mero:** O pr√≥ximo bit menos significativo n√£o utilizado √© o segundo bit (1/4). Ent√£o, o terceiro n√∫mero √© 1/4 = 0,25.
>
> Para obter mais n√∫meros, continuamos o processo, invertendo o bit apropriado e somando as dire√ß√µes correspondentes.

Para fins ilustrativos, o c√≥digo abaixo, demonstra como seria gerar uma sequ√™ncia de Sobol unidimensional em Python. Embora simplificado, ele destaca os passos chave na constru√ß√£o de uma sequ√™ncia de Sobol:

```python
import numpy as np

def sobol_sequence(n_points, dimensions):
    """Gera uma sequ√™ncia de Sobol para n_points em 'dimensions' dimens√µes."""

    # Vetor de dire√ß√µes (este exemplo √© simplificado e assume dire√ß√£o fixa)
    directions = np.array([1/2, 1/4, 1/8, 1/16, 1/32, 1/64, 1/128, 1/256])

    # Garante que temos dire√ß√µes suficientes
    n_bits = int(np.ceil(np.log2(max(1, n_points))))
    if len(directions) < n_bits:
        raise ValueError("Precisamos de mais dire√ß√µes na sequ√™ncia.")

    sobol_numbers = np.zeros(n_points)
    binary_counter = 0

    for i in range(n_points):
        value = 0
        temp_counter = binary_counter
        k = 0 # Index das dire√ß√µes

        # Realiza XOR nas dire√ß√µes apropriadas
        while temp_counter > 0:
            if temp_counter % 2 != 0:
                value += directions[k]
            k += 1
            temp_counter //= 2

        sobol_numbers[i] = value
        binary_counter += 1

    return sobol_numbers

# Exemplo de uso
n_points = 10
dimensions = 1
sequencia_sobol = sobol_sequence(n_points, dimensions)
print(sequencia_sobol)
```

O c√≥digo acima demonstra o processo iterativo de gera√ß√£o de n√∫meros de Sobol. Para cada ponto, ele determina quais bits no contador bin√°rio est√£o definidos e usa esses bits para selecionar dire√ß√µes correspondentes de um conjunto pr√©-definido. Os valores das dire√ß√µes s√£o ent√£o somados para criar o n√∫mero de Sobol. Este exemplo utiliza uma abordagem simplificada, assumindo dire√ß√µes fixas e uma √∫nica dimens√£o para fins de clareza. Em implementa√ß√µes pr√°ticas de alta dimens√£o, as dire√ß√µes seriam geradas usando polin√¥mios primitivos, garantindo melhores propriedades de preenchimento de espa√ßo e corre√ß√£o de sequ√™ncia.

**Teorema 1.1** [Gera√ß√£o da Sequ√™ncia de Sobol com Polin√¥mios Primitivos]: A sequ√™ncia de Sobol em alta dimens√£o √© constru√≠da usando polin√¥mios primitivos sobre o corpo finito $F_2$. Cada dimens√£o √© associada a um polin√¥mio primitivo diferente.

*Prova do Teorema 1.1:*

I. A sequ√™ncia de Sobol √© constru√≠da usando uma abordagem bin√°ria, onde cada n√∫mero √© representado como uma soma de fra√ß√µes bin√°rias. Para garantir propriedades de baixa discrep√¢ncia em dimens√µes mais altas, a gera√ß√£o dessas fra√ß√µes bin√°rias √© baseada em polin√¥mios primitivos sobre o corpo finito $F_2$ (o corpo com dois elementos, 0 e 1).

II. Um polin√¥mio primitivo de grau $r$ sobre $F_2$ √© um polin√¥mio que √© irredut√≠vel (n√£o pode ser fatorado em polin√¥mios n√£o constantes de grau inferior) e para o qual a menor pot√™ncia de $x$ que resulta em 1 (m√≥dulo o polin√¥mio) √© $2^r - 1$.

III. Cada dimens√£o $i$ da sequ√™ncia de Sobol √© associada a um polin√¥mio primitivo diferente $P_i(x)$ de grau $r_i$. Este polin√¥mio √© usado para gerar uma sequ√™ncia de n√∫meros de dire√ß√£o $v_{i,k}$, onde $k = 1, 2, \dots$.

IV. Os n√∫meros de dire√ß√£o s√£o calculados recursivamente usando a seguinte rela√ß√£o:

$$v_{i,k} = c_{i,1}v_{i,k-1} \oplus c_{i,2}v_{i,k-2} \oplus \dots \oplus c_{i,r_i}v_{i,k-r_i} \oplus v_{i,k-r_i}$$

onde:
    - $\oplus$ denota a opera√ß√£o XOR (adi√ß√£o m√≥dulo 2).
    - $c_{i,j}$ s√£o os coeficientes do polin√¥mio primitivo $P_i(x) = x^{r_i} + c_{i,1}x^{r_i-1} + \dots + c_{i,r_i}$.

V. O $j$-√©simo n√∫mero na $i$-√©sima dimens√£o da sequ√™ncia de Sobol, $x_{i,j}$, √© ent√£o calculado como:

$$x_{i,j} = \bigoplus_{k=1}^{\infty} b_k v_{i,k}$$

onde $b_k$ √© o $k$-√©simo bit na representa√ß√£o bin√°ria de $j$ (ou seja, $j = \sum_{k=1}^{\infty} b_k 2^{k-1}$).

VI. Ao usar polin√¥mios primitivos para gerar os n√∫meros de dire√ß√£o, garantimos que os bits na sequ√™ncia de Sobol sejam bem distribu√≠dos e que a sequ√™ncia resultante tenha baixa discrep√¢ncia, proporcionando uma cobertura uniforme do espa√ßo amostral. ‚ñ†

#### Vantagens da Sequ√™ncia de Sobol

A propriedade essencial da sequ√™ncia de Sobol √© que cada dimens√£o √© dividida em $2^k$ intervalos iguais, e cada intervalo cont√©m exatamente um ponto. Portanto, as sequ√™ncias de Sobol conseguem preencher um espa√ßo de forma muito mais uniforme do que os n√∫meros aleat√≥rios, o que √© crucial para simula√ß√µes precisas.

#### Exemplo de Aplica√ß√£o Pr√°tica

Em um estudo comparando a computa√ß√£o de VAR para um portf√≥lio exposto a 34 fatores de risco utilizando 1.000 pontos, Papageorgiou e Paskov (1999) [^325] descobriram que a sequ√™ncia determin√≠stica pode ser 10 vezes mais precisa que o m√©todo de Monte Carlo tradicional [^325].

> üí° **Exemplo Num√©rico:**
>
> Considere uma carteira com op√ß√µes sobre v√°rios ativos. Cada ativo tem uma volatilidade que afeta o pre√ßo da op√ß√£o. Na simula√ß√£o de Monte Carlo tradicional, pontos aleat√≥rios seriam usados para amostrar a volatilidade de cada ativo. Com QMC, uma sequ√™ncia de Sobol garantiria que o espa√ßo de poss√≠veis volatilidades seja amostrado de forma mais uniforme, levando a uma estimativa mais precisa do valor da carteira.

**Corol√°rio 1** [Redu√ß√£o da Vari√¢ncia]: O uso de sequ√™ncias de Sobol em QMC reduz a vari√¢ncia do estimador em compara√ß√£o com o m√©todo de Monte Carlo padr√£o, dada a cobertura mais uniforme do espa√ßo amostral.

*Prova do Corol√°rio 1:*

I. Seja $\hat{\theta}_{MC}$ o estimador obtido pelo m√©todo de Monte Carlo padr√£o e $\hat{\theta}_{QMC}$ o estimador obtido pelo m√©todo Quasi-Monte Carlo usando sequ√™ncias de Sobol.

II. A vari√¢ncia de um estimador √© uma medida de qu√£o dispersas est√£o as estimativas em torno do valor verdadeiro $\theta$. Uma vari√¢ncia menor indica que as estimativas s√£o mais precisas e consistentes.

III. A vari√¢ncia do estimador de Monte Carlo padr√£o √© dada por:

$$Var(\hat{\theta}_{MC}) = \frac{\sigma^2}{K}$$

onde $\sigma^2$ √© a vari√¢ncia da fun√ß√£o que est√° sendo integrada e $K$ √© o n√∫mero de amostras.

IV. O erro na integra√ß√£o QMC √© limitado pelo teorema de Koksma-Hlawka:

$$ \left| \int_{[0,1]^d} f(x) \, dx - \frac{1}{K} \sum_{i=1}^K f(x_i) \right| \leq V(f) \cdot D_K(x_1, \dots, x_K) $$

Como as sequ√™ncias de Sobol t√™m baixa discrep√¢ncia, a discrep√¢ncia $D_K$ √© significativamente menor do que a discrep√¢ncia obtida com amostras aleat√≥rias.

V. Devido √† cobertura mais uniforme do espa√ßo amostral proporcionada pelas sequ√™ncias de Sobol, o estimador QMC tem uma vari√¢ncia menor em compara√ß√£o com o estimador de Monte Carlo padr√£o. Isso se traduz em estimativas mais precisas e uma converg√™ncia mais r√°pida para o valor verdadeiro.

VI. Portanto, o uso de sequ√™ncias de Sobol em QMC reduz a vari√¢ncia do estimador em compara√ß√£o com o m√©todo de Monte Carlo padr√£o. ‚ñ†

> üí° **Exemplo Num√©rico:**
>
> Vamos supor que estamos calculando o Value at Risk (VaR) de uma carteira. Usando Monte Carlo, ap√≥s 5.000 simula√ß√µes, obtemos um VaR de \$ 1 milh√£o com um erro padr√£o de \$ 50.000. Com QMC e sequ√™ncia de Sobol, o mesmo VaR de \$ 1 milh√£o pode ser estimado com apenas 1.000 simula√ß√µes e um erro padr√£o de \$ 20.000, demonstrando uma redu√ß√£o significativa na vari√¢ncia e, portanto, maior precis√£o com menos amostras.

#### Desvantagens

Uma desvantagem desses m√©todos √© que, como os draws n√£o s√£o independentes, a precis√£o n√£o pode ser facilmente avaliada [^326]. Em contraste com o m√©todo de Monte Carlo, n√£o podemos construir bandas de confian√ßa em torno das estimativas [^326]. Outro problema √© que, para problemas de alta dimensionalidade, algumas sequ√™ncias QMC tendem a entrar em ciclo, o que leva a diminui√ß√µes no desempenho [^326]. No entanto, sequ√™ncias QMC selecionadas adequadamente podem proporcionar acelera√ß√µes substanciais nos c√°lculos [^326]. Para mitigar o problema de ciclagem, t√©cnicas como *scrambling* podem ser empregadas para randomizar a sequ√™ncia QMC sem perder suas propriedades de baixa discrep√¢ncia.

![Monte Carlo vs Quasi-Monte Carlo](./../images/figure1.png)

### Conclus√£o

A simula√ß√£o determin√≠stica, utilizando sequ√™ncias QMC, oferece uma alternativa eficiente e precisa √†s simula√ß√µes de Monte Carlo tradicionais para problemas de alta dimensionalidade [^325]. Embora apresente desafios na avalia√ß√£o da precis√£o e potencial para ciclagem em dimens√µes elevadas, a sua capacidade de proporcionar uma cobertura mais uniforme do espa√ßo de amostragem resulta numa converg√™ncia mais r√°pida e estimativas mais precisas em muitas aplica√ß√µes financeiras [^325].

### Refer√™ncias

[^1]: Cap√≠tulo 12 do livro texto.
[^321]: P√°gina 321 do livro texto.
[^322]: P√°gina 322 do livro texto.
[^323]: P√°gina 323 do livro texto.
[^324]: P√°gina 324 do livro texto.
[^325]: P√°gina 325 do livro texto.
[^326]: P√°gina 326 do livro texto.
<!-- END -->