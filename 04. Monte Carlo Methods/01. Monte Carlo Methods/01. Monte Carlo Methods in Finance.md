### IntroduÃ§Ã£o

Os mÃ©todos de Monte Carlo oferecem uma abordagem flexÃ­vel e poderosa para a anÃ¡lise de risco financeiro, especialmente para a avaliaÃ§Ã£o de derivativos complexos e para o cÃ¡lculo do Value at Risk (VAR) [^1]. Ao simular repetidamente um processo aleatÃ³rio para a variÃ¡vel financeira de interesse, abrangendo uma ampla gama de situaÃ§Ãµes possÃ­veis, essas tÃ©cnicas permitem recriar toda a distribuiÃ§Ã£o dos valores do portfÃ³lio, a partir da qual o VAR pode ser derivado [^2]. Este capÃ­tulo explora em profundidade esses mÃ©todos, abordando desde os fundamentos da simulaÃ§Ã£o de trajetÃ³rias de preÃ§os atÃ© tÃ©cnicas avanÃ§adas para melhorar a eficiÃªncia computacional e lidar com mÃºltiplas variÃ¡veis de risco.

### Conceitos Fundamentais

**SimulaÃ§Ã£o de TrajetÃ³rias de PreÃ§os**

A essÃªncia dos mÃ©todos de Monte Carlo reside na simulaÃ§Ã£o de trajetÃ³rias de preÃ§os. O primeiro passo, e o mais crucial, Ã© a escolha de um modelo estocÃ¡stico particular para o comportamento dos preÃ§os [^3]. Um modelo comumente usado Ã© o **movimento browniano geomÃ©trico (GBM)**, que fundamenta grande parte da teoria de precificaÃ§Ã£o de opÃ§Ãµes [^3]. O modelo assume que as inovaÃ§Ãµes no preÃ§o do ativo sÃ£o nÃ£o correlacionadas ao longo do tempo e que pequenos movimentos nos preÃ§os podem ser descritos por:

$$ dS_t = \mu S_t dt + \sigma S_t dz \quad (12.1) $$

onde $dz$ Ã© uma variÃ¡vel aleatÃ³ria distribuÃ­da normalmente com mÃ©dia zero e variÃ¢ncia $dt$ [^3]. Essa variÃ¡vel impulsiona os *shocks* aleatÃ³rios no preÃ§o e nÃ£o depende de informaÃ§Ãµes passadas. Ã‰ *browniano* no sentido de que sua variÃ¢ncia diminui continuamente com o intervalo de tempo, $V(dz) = dt$ [^3]. Isso exclui processos com saltos repentinos, por exemplo. O processo tambÃ©m Ã© geomÃ©trico porque todos os parÃ¢metros sÃ£o escalados pelo preÃ§o atual $S_t$ [^3].

Os parÃ¢metros $\mu$ e $\sigma$ representam o *drift* instantÃ¢neo e a volatilidade no tempo $t$, que podem evoluir ao longo do tempo [^3]. Para simplificar, assume-se que esses parÃ¢metros sÃ£o constantes ao longo do tempo. No entanto, como $\mu$ e $\sigma$ podem ser funÃ§Ãµes de variÃ¡veis passadas, seria fÃ¡cil simular a variaÃ§Ã£o do tempo nas variÃ¢ncias como em um processo GARCH, por exemplo [^4].

Na prÃ¡tica, o processo com incrementos infinitesimalmente pequenos $dt$ pode ser aproximado por movimentos discretos de tamanho $\Delta t$ [^4]. Define-se $t$ como o tempo presente, $T$ como o tempo alvo e $\tau = T - t$ como o horizonte (VAR). Para gerar uma sÃ©rie de variÃ¡veis aleatÃ³rias $S_{t+i}$ ao longo do intervalo $\tau$, primeiro divide-se $\tau$ em $n$ incrementos, com $\Delta t = \tau/n$ [^4].

Integrando $dS/S$ ao longo de um intervalo finito, tem-se aproximadamente:

$$ \Delta S_t = S_{t-1} (\mu \Delta t + \sigma \epsilon \sqrt{\Delta t}) \quad (12.2) $$

onde $\epsilon$ Ã© agora uma variÃ¡vel aleatÃ³ria normal padrÃ£o, ou seja, com mÃ©dia zero e variÃ¢ncia unitÃ¡ria [^4]. Pode-se verificar que esse processo gera uma mÃ©dia $E(\Delta S/S) = \mu \Delta t$, que cresce com o tempo, assim como a variÃ¢ncia $V(\Delta S/S) = \sigma^2 \Delta t$ [^4].

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Suponha que o preÃ§o atual de uma aÃ§Ã£o seja $S_t = 100$, o *drift* anualizado seja $\mu = 0.1$ (10%) e a volatilidade anualizada seja $\sigma = 0.2$ (20%). Queremos simular o preÃ§o da aÃ§Ã£o daqui a um dia ($\Delta t = 1/252$, assumindo 252 dias Ãºteis em um ano). Gere um nÃºmero aleatÃ³rio de uma distribuiÃ§Ã£o normal padrÃ£o, por exemplo, $\epsilon = 0.5$.
>
> Usando a equaÃ§Ã£o (12.2):
>
> $$ \Delta S_t = 100 \times (0.1 \times \frac{1}{252} + 0.2 \times 0.5 \times \sqrt{\frac{1}{252}}) $$
> $$ \Delta S_t = 100 \times (0.0003968 + 0.2 \times 0.5 \times 0.063) $$
> $$ \Delta S_t = 100 \times (0.0003968 + 0.0063) $$
> $$ \Delta S_t = 100 \times 0.0066968 = 0.66968 $$
>
> Portanto, a variaÃ§Ã£o no preÃ§o da aÃ§Ã£o Ã© aproximadamente $0.67$. O preÃ§o da aÃ§Ã£o no prÃ³ximo dia simulado seria:
>
> $$ S_{t+1} = S_t + \Delta S_t = 100 + 0.66968 = 100.66968 $$
>
> Podemos repetir este processo muitas vezes com diferentes valores de $\epsilon$ para simular vÃ¡rias trajetÃ³rias de preÃ§os.
>
> ```python
> import numpy as np
>
> # ParÃ¢metros
> S_t = 100       # PreÃ§o atual da aÃ§Ã£o
> mu = 0.1        # Drift anualizado
> sigma = 0.2     # Volatilidade anualizada
> delta_t = 1/252 # Intervalo de tempo (1 dia)
>
> # Gerar um nÃºmero aleatÃ³rio de uma distribuiÃ§Ã£o normal padrÃ£o
> epsilon = np.random.normal(0, 1)
>
> # Calcular a variaÃ§Ã£o no preÃ§o da aÃ§Ã£o
> delta_S_t = S_t * (mu * delta_t + sigma * epsilon * np.sqrt(delta_t))
>
> # Calcular o preÃ§o da aÃ§Ã£o no prÃ³ximo dia
> S_t_plus_1 = S_t + delta_S_t
>
> print(f"VariaÃ§Ã£o no preÃ§o da aÃ§Ã£o: {delta_S_t:.4f}")
> print(f"PreÃ§o da aÃ§Ã£o no prÃ³ximo dia: {S_t_plus_1:.4f}")
> ```

*Proof:* Demonstraremos que $E[\Delta S_t / S_{t-1}] = \mu \Delta t$ e $Var[\Delta S_t / S_{t-1}] = \sigma^2 \Delta t$.

I. Tomando a esperanÃ§a da EquaÃ§Ã£o (12.2):
$$E[\Delta S_t / S_{t-1}] = E[\mu \Delta t + \sigma \epsilon \sqrt{\Delta t}]$$

II. Como $\mu$, $\Delta t$ e $\sigma$ sÃ£o constantes e $E[\epsilon] = 0$, temos:
$$E[\Delta S_t / S_{t-1}] = \mu \Delta t + \sigma \sqrt{\Delta t} E[\epsilon] = \mu \Delta t + \sigma \sqrt{\Delta t} \cdot 0 = \mu \Delta t$$

III. Tomando a variÃ¢ncia da EquaÃ§Ã£o (12.2):
$$Var[\Delta S_t / S_{t-1}] = Var[\mu \Delta t + \sigma \epsilon \sqrt{\Delta t}]$$

IV. Como $\mu \Delta t$ Ã© constante, sua variÃ¢ncia Ã© zero:
$$Var[\Delta S_t / S_{t-1}] = Var[\sigma \epsilon \sqrt{\Delta t}] = \sigma^2 \Delta t Var[\epsilon]$$

V. Como $\epsilon$ Ã© uma variÃ¡vel normal padrÃ£o, $Var[\epsilon] = 1$:
$$Var[\Delta S_t / S_{t-1}] = \sigma^2 \Delta t \cdot 1 = \sigma^2 \Delta t$$

Portanto, demonstramos que $E[\Delta S_t / S_{t-1}] = \mu \Delta t$ e $Var[\Delta S_t / S_{t-1}] = \sigma^2 \Delta t$ â– 

Para simular a trajetÃ³ria de preÃ§os para $S$, comeÃ§a-se de $S_t$ e gera-se uma sequÃªncia de *epsilons* ($\epsilon$'s) para $i = 1, 2, ..., n$ [^4]. EntÃ£o, $S_{t+1}$ Ã© definido como $S_{t+1} = S_t + S_t (\mu \Delta t + \sigma \epsilon_1 \sqrt{\Delta t})$, $S_{t+2}$ Ã© calculado de forma semelhante a partir de $S_{t+1} + S_{t+1} (\mu \Delta t + \sigma \epsilon_2 \sqrt{\Delta t})$, e assim por diante para valores futuros, atÃ© que o horizonte alvo seja atingido, ponto no qual o preÃ§o Ã© $S_{t+n} = S_T$ [^4].

![SimulaÃ§Ã£o de caminho de preÃ§o](../images/figure7.jpg)

**Teorema 1** (ConvergÃªncia da SimulaÃ§Ã£o de Monte Carlo).
A precisÃ£o da simulaÃ§Ã£o de Monte Carlo aumenta com o nÃºmero de simulaÃ§Ãµes. Formalmente, se $\hat{\theta}_N$ Ã© a estimativa de um parÃ¢metro $\theta$ obtida a partir de $N$ simulaÃ§Ãµes independentes, entÃ£o, sob certas condiÃ§Ãµes de regularidade (como a existÃªncia de momentos de segunda ordem), $\hat{\theta}_N$ converge para $\theta$ quando $N$ tende ao infinito. AlÃ©m disso, o erro da estimativa diminui tipicamente na ordem de $1/\sqrt{N}$.

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Suponha que estejamos estimando o preÃ§o de uma opÃ§Ã£o de compra europeia usando simulaÃ§Ã£o de Monte Carlo. O preÃ§o verdadeiro da opÃ§Ã£o (calculado analiticamente usando o modelo de Black-Scholes) Ã© $\theta = 5.50$. ApÃ³s $N = 1000$ simulaÃ§Ãµes, obtemos uma estimativa de $\hat{\theta}_{1000} = 5.65$ com um desvio padrÃ£o amostral de $\sigma = 1.5$.
>
> O erro padrÃ£o da estimativa Ã© $\frac{\sigma}{\sqrt{N}} = \frac{1.5}{\sqrt{1000}} \approx 0.0474$.
>
> Um intervalo de confianÃ§a de 95% para o preÃ§o da opÃ§Ã£o Ã© dado por:
>
> $$ \hat{\theta}_{1000} \pm 1.96 \times \frac{\sigma}{\sqrt{N}} = 5.65 \pm 1.96 \times 0.0474 = [5.557, 5.743] $$
>
> Observe que o preÃ§o verdadeiro da opÃ§Ã£o, $\theta = 5.50$, estÃ¡ ligeiramente fora deste intervalo. Para melhorar a precisÃ£o, aumentamos o nÃºmero de simulaÃ§Ãµes para $N = 10000$. Suponha que agora obtemos uma estimativa de $\hat{\theta}_{10000} = 5.52$ com um desvio padrÃ£o amostral de $\sigma = 1.4$.
>
> O novo erro padrÃ£o Ã© $\frac{\sigma}{\sqrt{N}} = \frac{1.4}{\sqrt{10000}} = 0.014$.
>
> O novo intervalo de confianÃ§a de 95% Ã©:
>
> $$ \hat{\theta}_{10000} \pm 1.96 \times \frac{\sigma}{\sqrt{N}} = 5.52 \pm 1.96 \times 0.014 = [5.492, 5.548] $$
>
> Desta vez, o preÃ§o verdadeiro da opÃ§Ã£o, $\theta = 5.50$, estÃ¡ dentro do intervalo de confianÃ§a. Este exemplo ilustra como aumentar o nÃºmero de simulaÃ§Ãµes pode melhorar a precisÃ£o da estimativa e reduzir o erro.
>
> ```python
> import numpy as np
> from scipy.stats import norm
>
> # ParÃ¢metros
> true_price = 5.50
>
> # SimulaÃ§Ã£o 1: N = 1000
> num_simulations_1 = 1000
> estimated_price_1 = 5.65
> std_dev_1 = 1.5
>
> # Erro padrÃ£o
> standard_error_1 = std_dev_1 / np.sqrt(num_simulations_1)
>
> # Intervalo de confianÃ§a de 95%
> confidence_interval_1 = norm.interval(0.95, loc=estimated_price_1, scale=standard_error_1)
>
> print(f"SimulaÃ§Ã£o 1 (N=1000):")
> print(f"  PreÃ§o estimado: {estimated_price_1:.3f}")
> print(f"  Erro padrÃ£o: {standard_error_1:.3f}")
> print(f"  Intervalo de confianÃ§a de 95%: {confidence_interval_1}")
> print(f"  PreÃ§o verdadeiro estÃ¡ dentro do intervalo? {true_price >= confidence_interval_1[0] and true_price <= confidence_interval_1[1]}")
>
> # SimulaÃ§Ã£o 2: N = 10000
> num_simulations_2 = 10000
> estimated_price_2 = 5.52
> std_dev_2 = 1.4
>
> # Erro padrÃ£o
> standard_error_2 = std_dev_2 / np.sqrt(num_simulations_2)
>
> # Intervalo de confianÃ§a de 95%
> confidence_interval_2 = norm.interval(0.95, loc=estimated_price_2, scale=standard_error_2)
>
> print(f"\nSimulaÃ§Ã£o 2 (N=10000):")
> print(f"  PreÃ§o estimado: {estimated_price_2:.3f}")
> print(f"  Erro padrÃ£o: {standard_error_2:.3f}")
> print(f"  Intervalo de confianÃ§a de 95%: {confidence_interval_2}")
> print(f"  PreÃ§o verdadeiro estÃ¡ dentro do intervalo? {true_price >= confidence_interval_2[0] and true_price <= confidence_interval_2[1]}")
> ```

*Proof:*
I. Seja $\hat{\theta}_N = \frac{1}{N} \sum_{i=1}^{N} X_i$ uma estimativa de $\theta$, onde $X_i$ sÃ£o variÃ¡veis aleatÃ³rias independentes e identicamente distribuÃ­das (i.i.d.) com $E[X_i] = \theta$ e $Var[X_i] = \sigma^2 < \infty$.

II. Pela Lei Forte dos Grandes NÃºmeros (LSGL), temos que:
$$P\left(\lim_{N \to \infty} \hat{\theta}_N = \theta\right) = 1$$
Isso significa que $\hat{\theta}_N$ converge quase certamente para $\theta$ quando $N \to \infty$.

III. O Teorema do Limite Central (TLC) nos diz que a distribuiÃ§Ã£o de $\hat{\theta}_N$ se aproxima de uma distribuiÃ§Ã£o normal quando $N$ Ã© grande:
$$\sqrt{N}(\hat{\theta}_N - \theta) \xrightarrow{d} N(0, \sigma^2)$$
onde $\xrightarrow{d}$ denota convergÃªncia em distribuiÃ§Ã£o.

IV. Isso implica que o erro da estimativa, $|\hat{\theta}_N - \theta|$, Ã© tipicamente da ordem de $\frac{\sigma}{\sqrt{N}}$. Portanto, o erro diminui na ordem de $1/\sqrt{N}$.

Assim, demonstramos a convergÃªncia de $\hat{\theta}_N$ para $\theta$ e a taxa de convergÃªncia do erro â– 

**ProposiÃ§Ã£o 1** (DiscretizaÃ§Ã£o de Euler-Maruyama).
A equaÃ§Ã£o (12.2) representa uma discretizaÃ§Ã£o de Euler-Maruyama do processo de Ito definido em (12.1).

*Proof:* A discretizaÃ§Ã£o de Euler-Maruyama Ã© um mÃ©todo para aproximar soluÃ§Ãµes de equaÃ§Ãµes diferenciais estocÃ¡sticas. A equaÃ§Ã£o (12.1) Ã© uma equaÃ§Ã£o diferencial estocÃ¡stica. A equaÃ§Ã£o (12.2) aproxima a soluÃ§Ã£o dessa equaÃ§Ã£o.

Para melhorar a precisÃ£o da simulaÃ§Ã£o de trajetÃ³rias, pode-se refinar a discretizaÃ§Ã£o temporal, ou seja, aumentar o nÃºmero de passos $n$ para um dado horizonte $\tau$. No entanto, isso aumenta o custo computacional. MÃ©todos de variÃ¢ncia reduzida, como variÃ¡veis de controle e amostragem estratificada, podem ser empregados para aumentar a eficiÃªncia da simulaÃ§Ã£o.

**CriaÃ§Ã£o de NÃºmeros AleatÃ³rios**

As simulaÃ§Ãµes de Monte Carlo sÃ£o baseadas em sorteios aleatÃ³rios $\epsilon$ de uma variÃ¡vel com a distribuiÃ§Ã£o de probabilidade desejada [^6]. A anÃ¡lise numÃ©rica geralmente prossegue em duas etapas:

1. O primeiro bloco de construÃ§Ã£o para um gerador de nÃºmeros aleatÃ³rios Ã© uma distribuiÃ§Ã£o uniforme sobre o intervalo [0,1] que produz uma variÃ¡vel aleatÃ³ria $x$ [^6]. Mais propriamente falando, esses nÃºmeros sÃ£o "pseudo" aleatÃ³rios porque sÃ£o gerados a partir de um algoritmo usando uma regra predefinida. ComeÃ§ando a partir do mesmo nÃºmero "semente", a sequÃªncia pode ser repetida Ã  vontade [^6].
2. A prÃ³xima etapa Ã© transformar o nÃºmero aleatÃ³rio uniforme $x$ na distribuiÃ§Ã£o desejada atravÃ©s da funÃ§Ã£o de distribuiÃ§Ã£o cumulativa inversa (pdf) [^6]. Tome a distribuiÃ§Ã£o normal. Por definiÃ§Ã£o, a pdf cumulativa $N(y)$ estÃ¡ sempre entre 0 e 1. Portanto, para gerar uma variÃ¡vel aleatÃ³ria normalmente distribuÃ­da, calcula-se $y$ tal que $x = N(y)$ ou $y = N^{-1}(x)$ [^6]. De forma mais geral, qualquer funÃ§Ã£o de distribuiÃ§Ã£o pode ser gerada, desde que a funÃ§Ã£o $N(y)$ possa ser invertida [^6]. Este procedimento Ã© chamado de *mÃ©todo de transformaÃ§Ã£o inversa* [^6].

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Suponha que geramos um nÃºmero aleatÃ³rio uniforme $x = 0.75$ no intervalo [0, 1]. Queremos transformar este nÃºmero em uma variÃ¡vel aleatÃ³ria normalmente distribuÃ­da usando o mÃ©todo de transformaÃ§Ã£o inversa. Precisamos encontrar o valor $y$ tal que $N(y) = 0.75$, onde $N(y)$ Ã© a funÃ§Ã£o de distribuiÃ§Ã£o cumulativa normal padrÃ£o.
>
> Usando uma tabela de distribuiÃ§Ã£o normal padrÃ£o ou uma funÃ§Ã£o estatÃ­stica em um software, encontramos que o valor de $y$ correspondente a $N(y) = 0.75$ Ã© aproximadamente $y = 0.674$.
>
> Portanto, o nÃºmero aleatÃ³rio normalmente distribuÃ­do gerado a partir do nÃºmero uniforme $x = 0.75$ Ã© $y = 0.674$.
>
> ```python
> from scipy.stats import norm
>
> # NÃºmero aleatÃ³rio uniforme
> x = 0.75
>
> # Encontrar o valor correspondente na distribuiÃ§Ã£o normal padrÃ£o
> y = norm.ppf(x)
>
> print(f"NÃºmero aleatÃ³rio uniforme: {x}")
> print(f"NÃºmero aleatÃ³rio normalmente distribuÃ­do: {y:.3f}")
> ```

**Teorema 2** (Box-Muller).
O mÃ©todo de Box-Muller Ã© um algoritmo para gerar pares de nÃºmeros aleatÃ³rios independentes e normalmente distribuÃ­dos, dados um ou mais nÃºmeros aleatÃ³rios uniformemente distribuÃ­dos. Se $U_1$ e $U_2$ sÃ£o variÃ¡veis aleatÃ³rias independentes uniformemente distribuÃ­das no intervalo (0, 1), entÃ£o as variÃ¡veis:

$$Z_1 = \sqrt{-2 \ln(U_1)} \cos(2 \pi U_2)$$
$$Z_2 = \sqrt{-2 \ln(U_1)} \sin(2 \pi U_2)$$

sÃ£o variÃ¡veis aleatÃ³rias independentes com distribuiÃ§Ã£o normal padrÃ£o.

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Suponha que geramos dois nÃºmeros aleatÃ³rios uniformemente distribuÃ­dos: $U_1 = 0.25$ e $U_2 = 0.75$. Usando o mÃ©todo de Box-Muller, podemos gerar dois nÃºmeros aleatÃ³rios normalmente distribuÃ­dos $Z_1$ e $Z_2$.
>
> $$ Z_1 = \sqrt{-2 \ln(0.25)} \cos(2 \pi \times 0.75) = \sqrt{-2 \times (-1.386)} \cos(4.712) = \sqrt{2.772} \times (-0.000796) \approx 1.665 \times (-0.000796) \approx -0.001325 $$
> $$ Z_2 = \sqrt{-2 \ln(0.25)} \sin(2 \pi \times 0.75) = \sqrt{-2 \times (-1.386)} \sin(4.712) = \sqrt{2.772} \times (-1.000) \approx 1.665 \times (-1.000) \approx -1.665 $$
>
> Portanto, $Z_1 \approx -0.001325$ e $Z_2 \approx -1.665$ sÃ£o dois nÃºmeros aleatÃ³rios independentes com distribuiÃ§Ã£o normal padrÃ£o.
>
> ```python
> import numpy as np
>
> # NÃºmeros aleatÃ³rios uniformemente distribuÃ­dos
> U1 = 0.25
> U2 = 0.75
>
> # MÃ©todo de Box-Muller
> Z1 = np.sqrt(-2 * np.log(U1)) * np.cos(2 * np.pi * U2)
> Z2 = np.sqrt(-2 * np.log(U1)) * np.sin(2 * np.pi * U2)
>
> print(f"U1: {U1}")
> print(f"U2: {U2}")
> print(f"Z1: {Z1:.3f}")
> print(f"Z2: {Z2:.3f}")
> ```

*Proof:*
Para provar que $Z_1$ e $Z_2$ sÃ£o variÃ¡veis aleatÃ³rias normais padrÃ£o independentes, precisamos mostrar que sua funÃ§Ã£o densidade de probabilidade conjunta Ã© o produto de duas funÃ§Ãµes densidade de probabilidade normais padrÃ£o.

I. Encontre a funÃ§Ã£o de densidade de probabilidade conjunta de $Z_1$ e $Z_2$ usando a transformaÃ§Ã£o de variÃ¡veis. A transformaÃ§Ã£o Ã© dada por:
$Z_1 = \sqrt{-2 \ln(U_1)} \cos(2 \pi U_2)$
$Z_2 = \sqrt{-2 \ln(U_1)} \sin(2 \pi U_2)$

II. Calcule o Jacobiano da transformaÃ§Ã£o:
Primeiro, expresse $U_1$ e $U_2$ em termos de $Z_1$ e $Z_2$:
$U_1 = e^{-\frac{Z_1^2 + Z_2^2}{2}}$
$U_2 = \frac{1}{2\pi} \arctan(\frac{Z_2}{Z_1})$
O Jacobiano $J$ Ã© dado por:
$$J = \begin{vmatrix} \frac{\partial U_1}{\partial Z_1} & \frac{\partial U_1}{\partial Z_2} \\ \frac{\partial U_2}{\partial Z_1} & \frac{\partial U_2}{\partial Z_2} \end{vmatrix} = \begin{vmatrix} -Z_1 e^{-\frac{Z_1^2 + Z_2^2}{2}} & -Z_2 e^{-\frac{Z_1^2 + Z_2^2}{2}} \\ \frac{-Z_2}{2\pi (Z_1^2 + Z_2^2)} & \frac{Z_1}{2\pi (Z_1^2 + Z_2^2)} \end{vmatrix}$$
$$J = -Z_1 e^{-\frac{Z_1^2 + Z_2^2}{2}} \frac{Z_1}{2\pi (Z_1^2 + Z_2^2)} - \left(-Z_2 e^{-\frac{Z_1^2 + Z_2^2}{2}} \frac{-Z_2}{2\pi (Z_1^2 + Z_2^2)}\right)$$
$$J = -\frac{e^{-\frac{Z_1^2 + Z_2^2}{2}}}{2\pi} \frac{Z_1^2 + Z_2^2}{Z_1^2 + Z_2^2} = -\frac{e^{-\frac{Z_1^2 + Z_2^2}{2}}}{2\pi}$$
Tome o valor absoluto do Jacobiano: $|J| = \frac{e^{-\frac{Z_1^2 + Z_2^2}{2}}}{2\pi}$

III. A funÃ§Ã£o densidade de probabilidade conjunta de $U_1$ e $U_2$ Ã© $f_{U_1, U_2}(u_1, u_2) = 1$ para $0 < u_1 < 1$ e $0 < u_2 < 1$, pois sÃ£o uniformemente distribuÃ­das e independentes.

IV. A funÃ§Ã£o densidade de probabilidade conjunta de $Z_1$ e $Z_2$ Ã©:
$$f_{Z_1, Z_2}(z_1, z_2) = f_{U_1, U_2}(u_1, u_2) |J| = 1 \cdot \frac{e^{-\frac{z_1^2 + z_2^2}{2}}}{2\pi} = \frac{1}{2\pi} e^{-\frac{z_1^2 + z_2^2}{2}}$$

V. Observe que a funÃ§Ã£o densidade de probabilidade conjunta pode ser fatorada como:
$$f_{Z_1, Z_2}(z_1, z_2) = \frac{1}{\sqrt{2\pi}} e^{-\frac{z_1^2}{2}} \cdot \frac{1}{\sqrt{2\pi}} e^{-\frac{z_2^2}{2}}$$

Isto mostra que $Z_1$ e $Z_2$ sÃ£o variÃ¡veis aleatÃ³rias normais padrÃ£o independentes. â– 

**Lema 2.1** (Propriedades da DistribuiÃ§Ã£o Normal PadrÃ£o).
Seja $Z$ uma variÃ¡vel aleatÃ³ria com distribuiÃ§Ã£o normal padrÃ£o. EntÃ£o, $E[Z] = 0$ e $Var[Z] = 1$.

**Bootstrap**

Uma alternativa Ã  geraÃ§Ã£o de nÃºmeros aleatÃ³rios a partir de uma distribuiÃ§Ã£o hipotÃ©tica Ã© amostrar a partir de dados histÃ³ricos [^7]. Assim, Ã© possÃ­vel ser agnÃ³stico sobre a distribuiÃ§Ã£o. Por exemplo, suponha que observamos uma sÃ©rie de $M$ retornos $R = \Delta S/S, \{R\} = (R_1,...,R_M)$, que podem ser considerados como variÃ¡veis aleatÃ³rias i.i.d. retiradas de uma distribuiÃ§Ã£o desconhecida [^7]. O mÃ©todo de simulaÃ§Ã£o histÃ³rica consiste em usar esta sÃ©rie uma vez para gerar pseudoretornos [^7]. Mas isso pode ser estendido muito mais.

O bootstrap estima esta distribuiÃ§Ã£o pela distribuiÃ§Ã£o empÃ­rica de $R$, atribuindo igual probabilidade a cada realizaÃ§Ã£o [^7]. O mÃ©todo foi proposto inicialmente por Efron (1979) como uma tÃ©cnica de randomizaÃ§Ã£o nÃ£o paramÃ©trica que extrai da distribuiÃ§Ã£o observada dos dados para modelar a distribuiÃ§Ã£o de uma estatÃ­stica de interesse [^7].

O procedimento Ã© realizado amostrando de $\{R\}$, com reposiÃ§Ã£o, tantas observaÃ§Ãµes quantas forem necessÃ¡rias [^7]. Por exemplo, suponha que se queira gerar 100 retornos para o futuro, mas nÃ£o se queira impor qualquer suposiÃ§Ã£o sobre a distribuiÃ§Ã£o dos retornos diÃ¡rios. Poder-se-ia projetar retornos escolhendo aleatoriamente um retorno de cada vez da amostra ao longo dos Ãºltimos $M = 500$ dias, com reposiÃ§Ã£o [^8]. Define-se a escolha do Ã­ndice como $m(1)$, um nÃºmero entre 1 e 500. O retorno selecionado entÃ£o Ã© $R_{m(1)}$, e o retorno simulado do dia seguinte Ã© $S_{t+1} = S_t(1 + R_{m(1)})$ [^8]. Repetindo a operaÃ§Ã£o para um total de 100 sorteios resulta em um total de 100 pseudovalores $S_{t+1}, ..., S_{t+n}$ [^8].

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Suponha que temos uma sÃ©rie histÃ³rica de retornos diÃ¡rios de uma aÃ§Ã£o nos Ãºltimos $M = 10$ dias: $\{R\} = (0.01, -0.005, 0.02, 0.015, -0.01, 0.008, -0.002, 0.012, 0.005, -0.003)$. O preÃ§o atual da aÃ§Ã£o Ã© $S_t = 100$. Queremos simular o preÃ§o da aÃ§Ã£o para os prÃ³ximos 3 dias usando o mÃ©todo de bootstrap.
>
> 1. **Dia 1:** Geramos um nÃºmero aleatÃ³rio entre 1 e 10 (com reposiÃ§Ã£o). Suponha que o nÃºmero gerado seja 3. O retorno correspondente Ã© $R_3 = 0.02$. Portanto, o preÃ§o da aÃ§Ã£o no dia 1 Ã© $S_{t+1} = 100 \times (1 + 0.02) = 102$.
> 2. **Dia 2:** Geramos outro nÃºmero aleatÃ³rio entre 1 e 10. Suponha que o nÃºmero gerado seja 7. O retorno correspondente Ã© $R_7 = -0.002$. Portanto, o preÃ§o da aÃ§Ã£o no dia 2 Ã© $S_{t+2} = 102 \times (1 - 0.002) = 101.796$.
> 3. **Dia 3:** Geramos outro nÃºmero aleatÃ³rio entre 1 e 10. Suponha que o nÃºmero gerado seja 1. O retorno correspondente Ã© $R_1 = 0.01$. Portanto, o preÃ§o da aÃ§Ã£o no dia 3 Ã© $S_{t+3} = 101.796 \times (1 + 0.01) = 102.814$.
>
> Assim, simulamos uma possÃ­vel trajetÃ³ria de preÃ§os para os prÃ³ximos 3 dias usando o mÃ©todo de bootstrap.
>
> ```python
> import numpy as np
>
> # Retornos histÃ³ricos
> R = np.array([0.01, -0.005, 0.02, 0.015, -0.01, 0.008, -0.002, 0.012, 0.005, -0.003])
>
> # PreÃ§o atual da aÃ§Ã£o
> S_t = 100
>
> # NÃºmero de dias para simular
> num_days = 3
>
> # SimulaÃ§Ã£o de bootstrap
> S = [S_t]
> for i in range(num_days):
>     # Gerar um Ã­ndice aleatÃ³rio
>     m = np.random.randint(0, len(R))
>     # Calcular o preÃ§o da aÃ§Ã£o no prÃ³ximo dia
>     S_next = S[-1] * (1 + R[m])
>     S.append(S_next)
>
> print(f"PreÃ§o atual da aÃ§Ã£o: {S_t}")
> for i in range(1, len(S)):
>     print(f"PreÃ§o da aÃ§Ã£o no dia {i}: {S[i]:.3f}")
> ```

Uma vantagem essencial do bootstrap Ã© que ele pode incluir caudas gordas, saltos ou qualquer desvio da distribuiÃ§Ã£o normal [^8]. Por exemplo, pode-se incluir o retorno da quebra de 19 de outubro de 1987, que nunca (ou quase nunca) ocorreria sob uma distribuiÃ§Ã£o normal [^8]. O mÃ©todo tambÃ©m contabiliza as correlaÃ§Ãµes entre as sÃ©ries porque um sorteio consiste nos retornos simultÃ¢neos para $N$ sÃ©ries, tais como aÃ§Ãµes, tÃ­tulos e preÃ§os de moedas [^8].

**Teorema 3** (AproximaÃ§Ã£o de Monte Carlo para Integrais).
Seja $g(x)$ uma funÃ§Ã£o integrÃ¡vel e $x_1, x_2, ..., x_N$ amostras independentes de uma distribuiÃ§Ã£o de probabilidade $f(x)$. EntÃ£o, a integral de $g(x)$ em relaÃ§Ã£o a $f(x)$ pode ser aproximada por:

$$\int g(x) f(x) dx \approx \frac{1}{N} \sum_{i=1}^{N} g(x_i)$$

AlÃ©m disso, essa aproximaÃ§Ã£o converge para o valor verdadeiro da integral quando $N$ tende ao infinito, de acordo com a lei dos grandes nÃºmeros.

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Queremos calcular a integral $\int_{0}^{1} x^2 dx$ usando a aproximaÃ§Ã£o de Monte Carlo. A soluÃ§Ã£o analÃ­tica Ã© $\frac{1}{3}$.
>
> Seja $g(x) = x^2$ e $f(x) = 1$ (distribuiÃ§Ã£o uniforme no intervalo [0, 1]). Geramos $N = 1000$ nÃºmeros aleatÃ³rios uniformemente distribuÃ­dos no intervalo [0, 1].
>
> $$x_i \sim U(0, 1), \quad i = 1, 2, ..., 1000$$
>
> Calculamos a mÃ©dia dos valores de $g(x_i)$:
>
> $$\frac{1}{N} \sum_{i=1}^{N} g(x_i) = \frac{1}{1000} \sum_{i=1}^{1000} x_i^2$$
>
> Suponha que apÃ³s calcular a soma, obtemos:
>
> $$\sum_{i=1}^{1000} x_i^2 = 328.5$$
>
> EntÃ£o, a aproximaÃ§Ã£o de Monte Carlo Ã©:
>
> $$\int_{0}^{1} x^2 dx \approx \frac{1}{1000} \times 328.5 = 0.3285$$
>
> Este valor Ã© prÃ³ximo da soluÃ§Ã£o analÃ­tica de $\frac{1}{3} \approx 0.333$. Aumentando o nÃºmero de amostras $N$ melhoraria a precisÃ£o da aproximaÃ§Ã£o.
>
> ```python
> import numpy as np
>
> # NÃºmero de amostras
> num_samples = 1000
>
> # Gerar nÃºmeros aleatÃ³rios uniformemente distribuÃ­dos
> x = np.random.uniform(0, 1, num_samples)
>
> # Calcular g(x_i) = x_i^2
> g_x = x**2
>
> # AproximaÃ§Ã£o de Monte Carlo
> integral_approximation = np.mean(g_x)
>
> print(f"AproximaÃ§Ã£o de Monte Carlo da integral: {integral_approximation:.4f}")
> print(f"SoluÃ§Ã£o analÃ­tica: {1/3:.4f}")
> ```

*Proof:*
I. Considere a integral $\int g(x) f(x) dx = E[g(X)]$, onde$f(x)$ Ã© a funÃ§Ã£o de densidade de probabilidade de $X$.

II. Podemos aproximar essa esperanÃ§a usando a mÃ©dia amostral de $g(X_i)$ para $N$ amostras $X_i$ retiradas de $f(x)$:

$$
E[g(X)] \approx \frac{1}{N} \sum_{i=1}^{N} g(X_i)
$$

III. No nosso caso, $g(x) = x^2$ e $f(x) = 1$ para $x \in [0, 1]$ (distribuiÃ§Ã£o uniforme).

IV. Portanto, a aproximaÃ§Ã£o de Monte Carlo da integral Ã© a mÃ©dia dos valores de $x_i^2$ para $x_i$ amostrados de uma distribuiÃ§Ã£o uniforme em $[0, 1]$.

V. A soluÃ§Ã£o analÃ­tica Ã© $\int_0^1 x^2 dx = \frac{1}{3}$.

VI. A convergÃªncia do mÃ©todo de Monte Carlo para o valor real da integral Ã© garantida pela Lei Forte dos Grandes NÃºmeros, que afirma que, Ã  medida que $N \rightarrow \infty$, a mÃ©dia amostral converge para a esperanÃ§a verdadeira. $\blacksquare$

### Integrais Multidimensionais

O mÃ©todo de Monte Carlo Ã© particularmente Ãºtil para calcular integrais multidimensionais, onde outros mÃ©todos numÃ©ricos podem se tornar computacionalmente proibitivos.

**Exemplo:** Calcular o volume de uma hiperesfera unitÃ¡ria em $n$ dimensÃµes.

```python
import numpy as np

def monte_carlo_hyperesphere_volume(n, N):
    """
    Calcula o volume de uma hiperesfera unitÃ¡ria em n dimensÃµes
    usando o mÃ©todo de Monte Carlo.
    """
    points = np.random.uniform(-1, 1, size=(N, n))
    inside = np.linalg.norm(points, axis=1) <= 1
    volume_approximation = (2**n) * np.sum(inside) / N
    return volume_approximation

# ParÃ¢metros
n_dimensions = 10  # NÃºmero de dimensÃµes
n_samples = 100000   # NÃºmero de amostras

# Calcula o volume
volume_approximation = monte_carlo_hyperesphere_volume(n_dimensions, n_samples)

print(f"AproximaÃ§Ã£o de Monte Carlo do volume da hiperesfera em {n_dimensions} dimensÃµes: {volume_approximation:.4f}")
```

### ReduÃ§Ã£o de VariÃ¢ncia

A precisÃ£o dos mÃ©todos de Monte Carlo depende do nÃºmero de amostras utilizadas. TÃ©cnicas de reduÃ§Ã£o de variÃ¢ncia podem ser empregadas para obter estimativas mais precisas com o mesmo nÃºmero de amostras. Algumas tÃ©cnicas comuns incluem:

*   **Amostragem Estratificada:** Dividir o espaÃ§o amostral em subregiÃµes (estratos) e amostrar cada estrato de forma independente.

*   **VariÃ¡veis de Controle:** Usar uma funÃ§Ã£o conhecida com uma integral conhecida para reduzir a variÃ¢ncia da estimativa.

*   **Amostragem por ImportÃ¢ncia:** Amostrar a partir de uma distribuiÃ§Ã£o que se assemelha Ã  funÃ§Ã£o integranda para reduzir a variÃ¢ncia nas regiÃµes importantes.

### Amostragem por ImportÃ¢ncia

A amostragem por importÃ¢ncia Ã© uma tÃ©cnica de reduÃ§Ã£o de variÃ¢ncia que envolve amostrar a partir de uma distribuiÃ§Ã£o de probabilidade diferente da distribuiÃ§Ã£o original.  O objetivo Ã© concentrar as amostras em regiÃµes do espaÃ§o amostral que contribuem mais para a integral.

Seja $I = \int_a^b f(x) dx$ a integral que queremos calcular. Introduzimos uma funÃ§Ã£o de densidade de probabilidade $g(x)$ tal que $g(x) > 0$ sempre que $f(x) \neq 0$. EntÃ£o podemos reescrever a integral como:

$$
I = \int_a^b \frac{f(x)}{g(x)} g(x) dx = E_g \left[ \frac{f(X)}{g(X)} \right]
$$

Onde $E_g$ denota a esperanÃ§a em relaÃ§Ã£o Ã  distribuiÃ§Ã£o $g(x)$.  Aproximamos essa esperanÃ§a por:

$$
I \approx \frac{1}{N} \sum_{i=1}^N \frac{f(X_i)}{g(X_i)}
$$

Onde $X_i$ sÃ£o amostras retiradas da distribuiÃ§Ã£o $g(x)$. A escolha de $g(x)$ Ã© crucial. Idealmente, $g(x)$ deve se assemelhar a $f(x)$ para que a variÃ¢ncia da estimativa seja reduzida.

**Exemplo:**

Calcular $\int_0^1 e^{-x^2} dx$ usando amostragem por importÃ¢ncia.

```python
import numpy as np
import math

def f(x):
    return math.exp(-x**2)

def g(x):
    return 2 * (1 - x) # Densidade de probabilidade triangular

def sample_g():
    return 1 - np.sqrt(np.random.uniform(0, 1))

N = 10000
samples = [sample_g() for _ in range(N)]
weights = [f(x) / g(x) for x in samples]
integral_approximation = np.mean(weights)

print(f"AproximaÃ§Ã£o de Monte Carlo com amostragem por importÃ¢ncia: {integral_approximation:.4f}")

# ComparaÃ§Ã£o com Monte Carlo simples e soluÃ§Ã£o numÃ©rica (quadratura de Gauss)
def monte_carlo_simple(N):
    samples = np.random.uniform(0, 1, N)
    return np.mean([f(x) for x in samples])

from scipy.integrate import quad
result, _ = quad(f, 0, 1)

print(f"AproximaÃ§Ã£o de Monte Carlo simples: {monte_carlo_simple(N):.4f}")
print(f"SoluÃ§Ã£o numÃ©rica (quadratura de Gauss): {result:.4f}")
```

*Proof:*

I.  A integral pode ser reescrita como a esperanÃ§a de uma funÃ§Ã£o em relaÃ§Ã£o a uma distribuiÃ§Ã£o $g(x)$ diferente da distribuiÃ§Ã£o uniforme original.

II.  A escolha de $g(x)$ influencia a variÃ¢ncia da estimativa. Uma boa escolha minimiza a variÃ¢ncia.

III. Amostrar diretamente de $g(x)$ permite concentrar as amostras em regiÃµes onde a funÃ§Ã£o $f(x)$ tem maior impacto na integral.

IV.  A ponderaÃ§Ã£o de cada amostra por $f(x)/g(x)$ corrige o viÃ©s introduzido pela amostragem a partir de $g(x)$.

V.  A convergÃªncia para o valor real da integral Ã© garantida se $g(x) > 0$ sempre que $f(x) \neq 0$ e pela Lei Forte dos Grandes NÃºmeros. $\blacksquare$
<!-- END -->