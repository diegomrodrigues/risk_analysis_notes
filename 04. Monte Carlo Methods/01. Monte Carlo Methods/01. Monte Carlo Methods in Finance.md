### Introdu√ß√£o

Os m√©todos de Monte Carlo oferecem uma abordagem flex√≠vel e poderosa para a an√°lise de risco financeiro, especialmente para a avalia√ß√£o de derivativos complexos e para o c√°lculo do Value at Risk (VAR) [^1]. Ao simular repetidamente um processo aleat√≥rio para a vari√°vel financeira de interesse, abrangendo uma ampla gama de situa√ß√µes poss√≠veis, essas t√©cnicas permitem recriar toda a distribui√ß√£o dos valores do portf√≥lio, a partir da qual o VAR pode ser derivado [^2]. Este cap√≠tulo explora em profundidade esses m√©todos, abordando desde os fundamentos da simula√ß√£o de trajet√≥rias de pre√ßos at√© t√©cnicas avan√ßadas para melhorar a efici√™ncia computacional e lidar com m√∫ltiplas vari√°veis de risco.

### Conceitos Fundamentais

**Simula√ß√£o de Trajet√≥rias de Pre√ßos**

A ess√™ncia dos m√©todos de Monte Carlo reside na simula√ß√£o de trajet√≥rias de pre√ßos. O primeiro passo, e o mais crucial, √© a escolha de um modelo estoc√°stico particular para o comportamento dos pre√ßos [^3]. Um modelo comumente usado √© o **movimento browniano geom√©trico (GBM)**, que fundamenta grande parte da teoria de precifica√ß√£o de op√ß√µes [^3]. O modelo assume que as inova√ß√µes no pre√ßo do ativo s√£o n√£o correlacionadas ao longo do tempo e que pequenos movimentos nos pre√ßos podem ser descritos por:

$$ dS_t = \mu S_t dt + \sigma S_t dz \quad (12.1) $$

onde $dz$ √© uma vari√°vel aleat√≥ria distribu√≠da normalmente com m√©dia zero e vari√¢ncia $dt$ [^3]. Essa vari√°vel impulsiona os *shocks* aleat√≥rios no pre√ßo e n√£o depende de informa√ß√µes passadas. √â *browniano* no sentido de que sua vari√¢ncia diminui continuamente com o intervalo de tempo, $V(dz) = dt$ [^3]. Isso exclui processos com saltos repentinos, por exemplo. O processo tamb√©m √© geom√©trico porque todos os par√¢metros s√£o escalados pelo pre√ßo atual $S_t$ [^3].

Os par√¢metros $\mu$ e $\sigma$ representam o *drift* instant√¢neo e a volatilidade no tempo $t$, que podem evoluir ao longo do tempo [^3]. Para simplificar, assume-se que esses par√¢metros s√£o constantes ao longo do tempo. No entanto, como $\mu$ e $\sigma$ podem ser fun√ß√µes de vari√°veis passadas, seria f√°cil simular a varia√ß√£o do tempo nas vari√¢ncias como em um processo GARCH, por exemplo [^4].

Na pr√°tica, o processo com incrementos infinitesimalmente pequenos $dt$ pode ser aproximado por movimentos discretos de tamanho $\Delta t$ [^4]. Define-se $t$ como o tempo presente, $T$ como o tempo alvo e $\tau = T - t$ como o horizonte (VAR). Para gerar uma s√©rie de vari√°veis aleat√≥rias $S_{t+i}$ ao longo do intervalo $\tau$, primeiro divide-se $\tau$ em $n$ incrementos, com $\Delta t = \tau/n$ [^4].

Integrando $dS/S$ ao longo de um intervalo finito, tem-se aproximadamente:

$$ \Delta S_t = S_{t-1} (\mu \Delta t + \sigma \epsilon \sqrt{\Delta t}) \quad (12.2) $$

onde $\epsilon$ √© agora uma vari√°vel aleat√≥ria normal padr√£o, ou seja, com m√©dia zero e vari√¢ncia unit√°ria [^4]. Pode-se verificar que esse processo gera uma m√©dia $E(\Delta S/S) = \mu \Delta t$, que cresce com o tempo, assim como a vari√¢ncia $V(\Delta S/S) = \sigma^2 \Delta t$ [^4].

> üí° **Exemplo Num√©rico:**
>
> Suponha que o pre√ßo atual de uma a√ß√£o seja $S_t = 100$, o *drift* anualizado seja $\mu = 0.1$ (10%) e a volatilidade anualizada seja $\sigma = 0.2$ (20%). Queremos simular o pre√ßo da a√ß√£o daqui a um dia ($\Delta t = 1/252$, assumindo 252 dias √∫teis em um ano). Gere um n√∫mero aleat√≥rio de uma distribui√ß√£o normal padr√£o, por exemplo, $\epsilon = 0.5$.
>
> Usando a equa√ß√£o (12.2):
>
> $$ \Delta S_t = 100 \times (0.1 \times \frac{1}{252} + 0.2 \times 0.5 \times \sqrt{\frac{1}{252}}) $$
> $$ \Delta S_t = 100 \times (0.0003968 + 0.2 \times 0.5 \times 0.063) $$
> $$ \Delta S_t = 100 \times (0.0003968 + 0.0063) $$
> $$ \Delta S_t = 100 \times 0.0066968 = 0.66968 $$
>
> Portanto, a varia√ß√£o no pre√ßo da a√ß√£o √© aproximadamente $0.67$. O pre√ßo da a√ß√£o no pr√≥ximo dia simulado seria:
>
> $$ S_{t+1} = S_t + \Delta S_t = 100 + 0.66968 = 100.66968 $$
>
> Podemos repetir este processo muitas vezes com diferentes valores de $\epsilon$ para simular v√°rias trajet√≥rias de pre√ßos.
>
> ```python
> import numpy as np
>
> # Par√¢metros
> S_t = 100       # Pre√ßo atual da a√ß√£o
> mu = 0.1        # Drift anualizado
> sigma = 0.2     # Volatilidade anualizada
> delta_t = 1/252 # Intervalo de tempo (1 dia)
>
> # Gerar um n√∫mero aleat√≥rio de uma distribui√ß√£o normal padr√£o
> epsilon = np.random.normal(0, 1)
>
> # Calcular a varia√ß√£o no pre√ßo da a√ß√£o
> delta_S_t = S_t * (mu * delta_t + sigma * epsilon * np.sqrt(delta_t))
>
> # Calcular o pre√ßo da a√ß√£o no pr√≥ximo dia
> S_t_plus_1 = S_t + delta_S_t
>
> print(f"Varia√ß√£o no pre√ßo da a√ß√£o: {delta_S_t:.4f}")
> print(f"Pre√ßo da a√ß√£o no pr√≥ximo dia: {S_t_plus_1:.4f}")
> ```

*Proof:* Demonstraremos que $E[\Delta S_t / S_{t-1}] = \mu \Delta t$ e $Var[\Delta S_t / S_{t-1}] = \sigma^2 \Delta t$.

I. Tomando a esperan√ßa da Equa√ß√£o (12.2):
$$E[\Delta S_t / S_{t-1}] = E[\mu \Delta t + \sigma \epsilon \sqrt{\Delta t}]$$

II. Como $\mu$, $\Delta t$ e $\sigma$ s√£o constantes e $E[\epsilon] = 0$, temos:
$$E[\Delta S_t / S_{t-1}] = \mu \Delta t + \sigma \sqrt{\Delta t} E[\epsilon] = \mu \Delta t + \sigma \sqrt{\Delta t} \cdot 0 = \mu \Delta t$$

III. Tomando a vari√¢ncia da Equa√ß√£o (12.2):
$$Var[\Delta S_t / S_{t-1}] = Var[\mu \Delta t + \sigma \epsilon \sqrt{\Delta t}]$$

IV. Como $\mu \Delta t$ √© constante, sua vari√¢ncia √© zero:
$$Var[\Delta S_t / S_{t-1}] = Var[\sigma \epsilon \sqrt{\Delta t}] = \sigma^2 \Delta t Var[\epsilon]$$

V. Como $\epsilon$ √© uma vari√°vel normal padr√£o, $Var[\epsilon] = 1$:
$$Var[\Delta S_t / S_{t-1}] = \sigma^2 \Delta t \cdot 1 = \sigma^2 \Delta t$$

Portanto, demonstramos que $E[\Delta S_t / S_{t-1}] = \mu \Delta t$ e $Var[\Delta S_t / S_{t-1}] = \sigma^2 \Delta t$ ‚ñ†

Para simular a trajet√≥ria de pre√ßos para $S$, come√ßa-se de $S_t$ e gera-se uma sequ√™ncia de *epsilons* ($\epsilon$'s) para $i = 1, 2, ..., n$ [^4]. Ent√£o, $S_{t+1}$ √© definido como $S_{t+1} = S_t + S_t (\mu \Delta t + \sigma \epsilon_1 \sqrt{\Delta t})$, $S_{t+2}$ √© calculado de forma semelhante a partir de $S_{t+1} + S_{t+1} (\mu \Delta t + \sigma \epsilon_2 \sqrt{\Delta t})$, e assim por diante para valores futuros, at√© que o horizonte alvo seja atingido, ponto no qual o pre√ßo √© $S_{t+n} = S_T$ [^4].

![Simula√ß√£o de caminho de pre√ßo](../images/figure7.jpg)

**Teorema 1** (Converg√™ncia da Simula√ß√£o de Monte Carlo).
A precis√£o da simula√ß√£o de Monte Carlo aumenta com o n√∫mero de simula√ß√µes. Formalmente, se $\hat{\theta}_N$ √© a estimativa de um par√¢metro $\theta$ obtida a partir de $N$ simula√ß√µes independentes, ent√£o, sob certas condi√ß√µes de regularidade (como a exist√™ncia de momentos de segunda ordem), $\hat{\theta}_N$ converge para $\theta$ quando $N$ tende ao infinito. Al√©m disso, o erro da estimativa diminui tipicamente na ordem de $1/\sqrt{N}$.

> üí° **Exemplo Num√©rico:**
>
> Suponha que estejamos estimando o pre√ßo de uma op√ß√£o de compra europeia usando simula√ß√£o de Monte Carlo. O pre√ßo verdadeiro da op√ß√£o (calculado analiticamente usando o modelo de Black-Scholes) √© $\theta = 5.50$. Ap√≥s $N = 1000$ simula√ß√µes, obtemos uma estimativa de $\hat{\theta}_{1000} = 5.65$ com um desvio padr√£o amostral de $\sigma = 1.5$.
>
> O erro padr√£o da estimativa √© $\frac{\sigma}{\sqrt{N}} = \frac{1.5}{\sqrt{1000}} \approx 0.0474$.
>
> Um intervalo de confian√ßa de 95% para o pre√ßo da op√ß√£o √© dado por:
>
> $$ \hat{\theta}_{1000} \pm 1.96 \times \frac{\sigma}{\sqrt{N}} = 5.65 \pm 1.96 \times 0.0474 = [5.557, 5.743] $$
>
> Observe que o pre√ßo verdadeiro da op√ß√£o, $\theta = 5.50$, est√° ligeiramente fora deste intervalo. Para melhorar a precis√£o, aumentamos o n√∫mero de simula√ß√µes para $N = 10000$. Suponha que agora obtemos uma estimativa de $\hat{\theta}_{10000} = 5.52$ com um desvio padr√£o amostral de $\sigma = 1.4$.
>
> O novo erro padr√£o √© $\frac{\sigma}{\sqrt{N}} = \frac{1.4}{\sqrt{10000}} = 0.014$.
>
> O novo intervalo de confian√ßa de 95% √©:
>
> $$ \hat{\theta}_{10000} \pm 1.96 \times \frac{\sigma}{\sqrt{N}} = 5.52 \pm 1.96 \times 0.014 = [5.492, 5.548] $$
>
> Desta vez, o pre√ßo verdadeiro da op√ß√£o, $\theta = 5.50$, est√° dentro do intervalo de confian√ßa. Este exemplo ilustra como aumentar o n√∫mero de simula√ß√µes pode melhorar a precis√£o da estimativa e reduzir o erro.
>
> ```python
> import numpy as np
> from scipy.stats import norm
>
> # Par√¢metros
> true_price = 5.50
>
> # Simula√ß√£o 1: N = 1000
> num_simulations_1 = 1000
> estimated_price_1 = 5.65
> std_dev_1 = 1.5
>
> # Erro padr√£o
> standard_error_1 = std_dev_1 / np.sqrt(num_simulations_1)
>
> # Intervalo de confian√ßa de 95%
> confidence_interval_1 = norm.interval(0.95, loc=estimated_price_1, scale=standard_error_1)
>
> print(f"Simula√ß√£o 1 (N=1000):")
> print(f"  Pre√ßo estimado: {estimated_price_1:.3f}")
> print(f"  Erro padr√£o: {standard_error_1:.3f}")
> print(f"  Intervalo de confian√ßa de 95%: {confidence_interval_1}")
> print(f"  Pre√ßo verdadeiro est√° dentro do intervalo? {true_price >= confidence_interval_1[0] and true_price <= confidence_interval_1[1]}")
>
> # Simula√ß√£o 2: N = 10000
> num_simulations_2 = 10000
> estimated_price_2 = 5.52
> std_dev_2 = 1.4
>
> # Erro padr√£o
> standard_error_2 = std_dev_2 / np.sqrt(num_simulations_2)
>
> # Intervalo de confian√ßa de 95%
> confidence_interval_2 = norm.interval(0.95, loc=estimated_price_2, scale=standard_error_2)
>
> print(f"\nSimula√ß√£o 2 (N=10000):")
> print(f"  Pre√ßo estimado: {estimated_price_2:.3f}")
> print(f"  Erro padr√£o: {standard_error_2:.3f}")
> print(f"  Intervalo de confian√ßa de 95%: {confidence_interval_2}")
> print(f"  Pre√ßo verdadeiro est√° dentro do intervalo? {true_price >= confidence_interval_2[0] and true_price <= confidence_interval_2[1]}")
> ```

*Proof:*
I. Seja $\hat{\theta}_N = \frac{1}{N} \sum_{i=1}^{N} X_i$ uma estimativa de $\theta$, onde $X_i$ s√£o vari√°veis aleat√≥rias independentes e identicamente distribu√≠das (i.i.d.) com $E[X_i] = \theta$ e $Var[X_i] = \sigma^2 < \infty$.

II. Pela Lei Forte dos Grandes N√∫meros (LSGL), temos que:
$$P\left(\lim_{N \to \infty} \hat{\theta}_N = \theta\right) = 1$$
Isso significa que $\hat{\theta}_N$ converge quase certamente para $\theta$ quando $N \to \infty$.

III. O Teorema do Limite Central (TLC) nos diz que a distribui√ß√£o de $\hat{\theta}_N$ se aproxima de uma distribui√ß√£o normal quando $N$ √© grande:
$$\sqrt{N}(\hat{\theta}_N - \theta) \xrightarrow{d} N(0, \sigma^2)$$
onde $\xrightarrow{d}$ denota converg√™ncia em distribui√ß√£o.

IV. Isso implica que o erro da estimativa, $|\hat{\theta}_N - \theta|$, √© tipicamente da ordem de $\frac{\sigma}{\sqrt{N}}$. Portanto, o erro diminui na ordem de $1/\sqrt{N}$.

Assim, demonstramos a converg√™ncia de $\hat{\theta}_N$ para $\theta$ e a taxa de converg√™ncia do erro ‚ñ†

**Proposi√ß√£o 1** (Discretiza√ß√£o de Euler-Maruyama).
A equa√ß√£o (12.2) representa uma discretiza√ß√£o de Euler-Maruyama do processo de Ito definido em (12.1).

*Proof:* A discretiza√ß√£o de Euler-Maruyama √© um m√©todo para aproximar solu√ß√µes de equa√ß√µes diferenciais estoc√°sticas. A equa√ß√£o (12.1) √© uma equa√ß√£o diferencial estoc√°stica. A equa√ß√£o (12.2) aproxima a solu√ß√£o dessa equa√ß√£o.

Para melhorar a precis√£o da simula√ß√£o de trajet√≥rias, pode-se refinar a discretiza√ß√£o temporal, ou seja, aumentar o n√∫mero de passos $n$ para um dado horizonte $\tau$. No entanto, isso aumenta o custo computacional. M√©todos de vari√¢ncia reduzida, como vari√°veis de controle e amostragem estratificada, podem ser empregados para aumentar a efici√™ncia da simula√ß√£o.

**Cria√ß√£o de N√∫meros Aleat√≥rios**

As simula√ß√µes de Monte Carlo s√£o baseadas em sorteios aleat√≥rios $\epsilon$ de uma vari√°vel com a distribui√ß√£o de probabilidade desejada [^6]. A an√°lise num√©rica geralmente prossegue em duas etapas:

1. O primeiro bloco de constru√ß√£o para um gerador de n√∫meros aleat√≥rios √© uma distribui√ß√£o uniforme sobre o intervalo [0,1] que produz uma vari√°vel aleat√≥ria $x$ [^6]. Mais propriamente falando, esses n√∫meros s√£o "pseudo" aleat√≥rios porque s√£o gerados a partir de um algoritmo usando uma regra predefinida. Come√ßando a partir do mesmo n√∫mero "semente", a sequ√™ncia pode ser repetida √† vontade [^6].
2. A pr√≥xima etapa √© transformar o n√∫mero aleat√≥rio uniforme $x$ na distribui√ß√£o desejada atrav√©s da fun√ß√£o de distribui√ß√£o cumulativa inversa (pdf) [^6]. Tome a distribui√ß√£o normal. Por defini√ß√£o, a pdf cumulativa $N(y)$ est√° sempre entre 0 e 1. Portanto, para gerar uma vari√°vel aleat√≥ria normalmente distribu√≠da, calcula-se $y$ tal que $x = N(y)$ ou $y = N^{-1}(x)$ [^6]. De forma mais geral, qualquer fun√ß√£o de distribui√ß√£o pode ser gerada, desde que a fun√ß√£o $N(y)$ possa ser invertida [^6]. Este procedimento √© chamado de *m√©todo de transforma√ß√£o inversa* [^6].

> üí° **Exemplo Num√©rico:**
>
> Suponha que geramos um n√∫mero aleat√≥rio uniforme $x = 0.75$ no intervalo [0, 1]. Queremos transformar este n√∫mero em uma vari√°vel aleat√≥ria normalmente distribu√≠da usando o m√©todo de transforma√ß√£o inversa. Precisamos encontrar o valor $y$ tal que $N(y) = 0.75$, onde $N(y)$ √© a fun√ß√£o de distribui√ß√£o cumulativa normal padr√£o.
>
> Usando uma tabela de distribui√ß√£o normal padr√£o ou uma fun√ß√£o estat√≠stica em um software, encontramos que o valor de $y$ correspondente a $N(y) = 0.75$ √© aproximadamente $y = 0.674$.
>
> Portanto, o n√∫mero aleat√≥rio normalmente distribu√≠do gerado a partir do n√∫mero uniforme $x = 0.75$ √© $y = 0.674$.
>
> ```python
> from scipy.stats import norm
>
> # N√∫mero aleat√≥rio uniforme
> x = 0.75
>
> # Encontrar o valor correspondente na distribui√ß√£o normal padr√£o
> y = norm.ppf(x)
>
> print(f"N√∫mero aleat√≥rio uniforme: {x}")
> print(f"N√∫mero aleat√≥rio normalmente distribu√≠do: {y:.3f}")
> ```

**Teorema 2** (Box-Muller).
O m√©todo de Box-Muller √© um algoritmo para gerar pares de n√∫meros aleat√≥rios independentes e normalmente distribu√≠dos, dados um ou mais n√∫meros aleat√≥rios uniformemente distribu√≠dos. Se $U_1$ e $U_2$ s√£o vari√°veis aleat√≥rias independentes uniformemente distribu√≠das no intervalo (0, 1), ent√£o as vari√°veis:

$$Z_1 = \sqrt{-2 \ln(U_1)} \cos(2 \pi U_2)$$
$$Z_2 = \sqrt{-2 \ln(U_1)} \sin(2 \pi U_2)$$

s√£o vari√°veis aleat√≥rias independentes com distribui√ß√£o normal padr√£o.

> üí° **Exemplo Num√©rico:**
>
> Suponha que geramos dois n√∫meros aleat√≥rios uniformemente distribu√≠dos: $U_1 = 0.25$ e $U_2 = 0.75$. Usando o m√©todo de Box-Muller, podemos gerar dois n√∫meros aleat√≥rios normalmente distribu√≠dos $Z_1$ e $Z_2$.
>
> $$ Z_1 = \sqrt{-2 \ln(0.25)} \cos(2 \pi \times 0.75) = \sqrt{-2 \times (-1.386)} \cos(4.712) = \sqrt{2.772} \times (-0.000796) \approx 1.665 \times (-0.000796) \approx -0.001325 $$
> $$ Z_2 = \sqrt{-2 \ln(0.25)} \sin(2 \pi \times 0.75) = \sqrt{-2 \times (-1.386)} \sin(4.712) = \sqrt{2.772} \times (-1.000) \approx 1.665 \times (-1.000) \approx -1.665 $$
>
> Portanto, $Z_1 \approx -0.001325$ e $Z_2 \approx -1.665$ s√£o dois n√∫meros aleat√≥rios independentes com distribui√ß√£o normal padr√£o.
>
> ```python
> import numpy as np
>
> # N√∫meros aleat√≥rios uniformemente distribu√≠dos
> U1 = 0.25
> U2 = 0.75
>
> # M√©todo de Box-Muller
> Z1 = np.sqrt(-2 * np.log(U1)) * np.cos(2 * np.pi * U2)
> Z2 = np.sqrt(-2 * np.log(U1)) * np.sin(2 * np.pi * U2)
>
> print(f"U1: {U1}")
> print(f"U2: {U2}")
> print(f"Z1: {Z1:.3f}")
> print(f"Z2: {Z2:.3f}")
> ```

*Proof:*
Para provar que $Z_1$ e $Z_2$ s√£o vari√°veis aleat√≥rias normais padr√£o independentes, precisamos mostrar que sua fun√ß√£o densidade de probabilidade conjunta √© o produto de duas fun√ß√µes densidade de probabilidade normais padr√£o.

I. Encontre a fun√ß√£o de densidade de probabilidade conjunta de $Z_1$ e $Z_2$ usando a transforma√ß√£o de vari√°veis. A transforma√ß√£o √© dada por:
$Z_1 = \sqrt{-2 \ln(U_1)} \cos(2 \pi U_2)$
$Z_2 = \sqrt{-2 \ln(U_1)} \sin(2 \pi U_2)$

II. Calcule o Jacobiano da transforma√ß√£o:
Primeiro, expresse $U_1$ e $U_2$ em termos de $Z_1$ e $Z_2$:
$U_1 = e^{-\frac{Z_1^2 + Z_2^2}{2}}$
$U_2 = \frac{1}{2\pi} \arctan(\frac{Z_2}{Z_1})$
O Jacobiano $J$ √© dado por:
$$J = \begin{vmatrix} \frac{\partial U_1}{\partial Z_1} & \frac{\partial U_1}{\partial Z_2} \\ \frac{\partial U_2}{\partial Z_1} & \frac{\partial U_2}{\partial Z_2} \end{vmatrix} = \begin{vmatrix} -Z_1 e^{-\frac{Z_1^2 + Z_2^2}{2}} & -Z_2 e^{-\frac{Z_1^2 + Z_2^2}{2}} \\ \frac{-Z_2}{2\pi (Z_1^2 + Z_2^2)} & \frac{Z_1}{2\pi (Z_1^2 + Z_2^2)} \end{vmatrix}$$
$$J = -Z_1 e^{-\frac{Z_1^2 + Z_2^2}{2}} \frac{Z_1}{2\pi (Z_1^2 + Z_2^2)} - \left(-Z_2 e^{-\frac{Z_1^2 + Z_2^2}{2}} \frac{-Z_2}{2\pi (Z_1^2 + Z_2^2)}\right)$$
$$J = -\frac{e^{-\frac{Z_1^2 + Z_2^2}{2}}}{2\pi} \frac{Z_1^2 + Z_2^2}{Z_1^2 + Z_2^2} = -\frac{e^{-\frac{Z_1^2 + Z_2^2}{2}}}{2\pi}$$
Tome o valor absoluto do Jacobiano: $|J| = \frac{e^{-\frac{Z_1^2 + Z_2^2}{2}}}{2\pi}$

III. A fun√ß√£o densidade de probabilidade conjunta de $U_1$ e $U_2$ √© $f_{U_1, U_2}(u_1, u_2) = 1$ para $0 < u_1 < 1$ e $0 < u_2 < 1$, pois s√£o uniformemente distribu√≠das e independentes.

IV. A fun√ß√£o densidade de probabilidade conjunta de $Z_1$ e $Z_2$ √©:
$$f_{Z_1, Z_2}(z_1, z_2) = f_{U_1, U_2}(u_1, u_2) |J| = 1 \cdot \frac{e^{-\frac{z_1^2 + z_2^2}{2}}}{2\pi} = \frac{1}{2\pi} e^{-\frac{z_1^2 + z_2^2}{2}}$$

V. Observe que a fun√ß√£o densidade de probabilidade conjunta pode ser fatorada como:
$$f_{Z_1, Z_2}(z_1, z_2) = \frac{1}{\sqrt{2\pi}} e^{-\frac{z_1^2}{2}} \cdot \frac{1}{\sqrt{2\pi}} e^{-\frac{z_2^2}{2}}$$

Isto mostra que $Z_1$ e $Z_2$ s√£o vari√°veis aleat√≥rias normais padr√£o independentes. ‚ñ†

**Lema 2.1** (Propriedades da Distribui√ß√£o Normal Padr√£o).
Seja $Z$ uma vari√°vel aleat√≥ria com distribui√ß√£o normal padr√£o. Ent√£o, $E[Z] = 0$ e $Var[Z] = 1$.

**Bootstrap**

Uma alternativa √† gera√ß√£o de n√∫meros aleat√≥rios a partir de uma distribui√ß√£o hipot√©tica √© amostrar a partir de dados hist√≥ricos [^7]. Assim, √© poss√≠vel ser agn√≥stico sobre a distribui√ß√£o. Por exemplo, suponha que observamos uma s√©rie de $M$ retornos $R = \Delta S/S, \{R\} = (R_1,...,R_M)$, que podem ser considerados como vari√°veis aleat√≥rias i.i.d. retiradas de uma distribui√ß√£o desconhecida [^7]. O m√©todo de simula√ß√£o hist√≥rica consiste em usar esta s√©rie uma vez para gerar pseudoretornos [^7]. Mas isso pode ser estendido muito mais.

O bootstrap estima esta distribui√ß√£o pela distribui√ß√£o emp√≠rica de $R$, atribuindo igual probabilidade a cada realiza√ß√£o [^7]. O m√©todo foi proposto inicialmente por Efron (1979) como uma t√©cnica de randomiza√ß√£o n√£o param√©trica que extrai da distribui√ß√£o observada dos dados para modelar a distribui√ß√£o de uma estat√≠stica de interesse [^7].

O procedimento √© realizado amostrando de $\{R\}$, com reposi√ß√£o, tantas observa√ß√µes quantas forem necess√°rias [^7]. Por exemplo, suponha que se queira gerar 100 retornos para o futuro, mas n√£o se queira impor qualquer suposi√ß√£o sobre a distribui√ß√£o dos retornos di√°rios. Poder-se-ia projetar retornos escolhendo aleatoriamente um retorno de cada vez da amostra ao longo dos √∫ltimos $M = 500$ dias, com reposi√ß√£o [^8]. Define-se a escolha do √≠ndice como $m(1)$, um n√∫mero entre 1 e 500. O retorno selecionado ent√£o √© $R_{m(1)}$, e o retorno simulado do dia seguinte √© $S_{t+1} = S_t(1 + R_{m(1)})$ [^8]. Repetindo a opera√ß√£o para um total de 100 sorteios resulta em um total de 100 pseudovalores $S_{t+1}, ..., S_{t+n}$ [^8].

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos uma s√©rie hist√≥rica de retornos di√°rios de uma a√ß√£o nos √∫ltimos $M = 10$ dias: $\{R\} = (0.01, -0.005, 0.02, 0.015, -0.01, 0.008, -0.002, 0.012, 0.005, -0.003)$. O pre√ßo atual da a√ß√£o √© $S_t = 100$. Queremos simular o pre√ßo da a√ß√£o para os pr√≥ximos 3 dias usando o m√©todo de bootstrap.
>
> 1. **Dia 1:** Geramos um n√∫mero aleat√≥rio entre 1 e 10 (com reposi√ß√£o). Suponha que o n√∫mero gerado seja 3. O retorno correspondente √© $R_3 = 0.02$. Portanto, o pre√ßo da a√ß√£o no dia 1 √© $S_{t+1} = 100 \times (1 + 0.02) = 102$.
> 2. **Dia 2:** Geramos outro n√∫mero aleat√≥rio entre 1 e 10. Suponha que o n√∫mero gerado seja 7. O retorno correspondente √© $R_7 = -0.002$. Portanto, o pre√ßo da a√ß√£o no dia 2 √© $S_{t+2} = 102 \times (1 - 0.002) = 101.796$.
> 3. **Dia 3:** Geramos outro n√∫mero aleat√≥rio entre 1 e 10. Suponha que o n√∫mero gerado seja 1. O retorno correspondente √© $R_1 = 0.01$. Portanto, o pre√ßo da a√ß√£o no dia 3 √© $S_{t+3} = 101.796 \times (1 + 0.01) = 102.814$.
>
> Assim, simulamos uma poss√≠vel trajet√≥ria de pre√ßos para os pr√≥ximos 3 dias usando o m√©todo de bootstrap.
>
> ```python
> import numpy as np
>
> # Retornos hist√≥ricos
> R = np.array([0.01, -0.005, 0.02, 0.015, -0.01, 0.008, -0.002, 0.012, 0.005, -0.003])
>
> # Pre√ßo atual da a√ß√£o
> S_t = 100
>
> # N√∫mero de dias para simular
> num_days = 3
>
> # Simula√ß√£o de bootstrap
> S = [S_t]
> for i in range(num_days):
>     # Gerar um √≠ndice aleat√≥rio
>     m = np.random.randint(0, len(R))
>     # Calcular o pre√ßo da a√ß√£o no pr√≥ximo dia
>     S_next = S[-1] * (1 + R[m])
>     S.append(S_next)
>
> print(f"Pre√ßo atual da a√ß√£o: {S_t}")
> for i in range(1, len(S)):
>     print(f"Pre√ßo da a√ß√£o no dia {i}: {S[i]:.3f}")
> ```

Uma vantagem essencial do bootstrap √© que ele pode incluir caudas gordas, saltos ou qualquer desvio da distribui√ß√£o normal [^8]. Por exemplo, pode-se incluir o retorno da quebra de 19 de outubro de 1987, que nunca (ou quase nunca) ocorreria sob uma distribui√ß√£o normal [^8]. O m√©todo tamb√©m contabiliza as correla√ß√µes entre as s√©ries porque um sorteio consiste nos retornos simult√¢neos para $N$ s√©ries, tais como a√ß√µes, t√≠tulos e pre√ßos de moedas [^8].

**Teorema 3** (Aproxima√ß√£o de Monte Carlo para Integrais).
Seja $g(x)$ uma fun√ß√£o integr√°vel e $x_1, x_2, ..., x_N$ amostras independentes de uma distribui√ß√£o de probabilidade $f(x)$. Ent√£o, a integral de $g(x)$ em rela√ß√£o a $f(x)$ pode ser aproximada por:

$$\int g(x) f(x) dx \approx \frac{1}{N} \sum_{i=1}^{N} g(x_i)$$

Al√©m disso, essa aproxima√ß√£o converge para o valor verdadeiro da integral quando $N$ tende ao infinito, de acordo com a lei dos grandes n√∫meros.

> üí° **Exemplo Num√©rico:**
>
> Queremos calcular a integral $\int_{0}^{1} x^2 dx$ usando a aproxima√ß√£o de Monte Carlo. A solu√ß√£o anal√≠tica √© $\frac{1}{3}$.
>
> Seja $g(x) = x^2$ e $f(x) = 1$ (distribui√ß√£o uniforme no intervalo [0, 1]). Geramos $N = 1000$ n√∫meros aleat√≥rios uniformemente distribu√≠dos no intervalo [0, 1].
>
> $$x_i \sim U(0, 1), \quad i = 1, 2, ..., 1000$$
>
> Calculamos a m√©dia dos valores de $g(x_i)$:
>
> $$\frac{1}{N} \sum_{i=1}^{N} g(x_i) = \frac{1}{1000} \sum_{i=1}^{1000} x_i^2$$
>
> Suponha que ap√≥s calcular a soma, obtemos:
>
> $$\sum_{i=1}^{1000} x_i^2 = 328.5$$
>
> Ent√£o, a aproxima√ß√£o de Monte Carlo √©:
>
> $$\int_{0}^{1} x^2 dx \approx \frac{1}{1000} \times 328.5 = 0.3285$$
>
> Este valor √© pr√≥ximo da solu√ß√£o anal√≠tica de $\frac{1}{3} \approx 0.333$. Aumentando o n√∫mero de amostras $N$ melhoraria a precis√£o da aproxima√ß√£o.
>
> ```python
> import numpy as np
>
> # N√∫mero de amostras
> num_samples = 1000
>
> # Gerar n√∫meros aleat√≥rios uniformemente distribu√≠dos
> x = np.random.uniform(0, 1, num_samples)
>
> # Calcular g(x_i) = x_i^2
> g_x = x**2
>
> # Aproxima√ß√£o de Monte Carlo
> integral_approximation = np.mean(g_x)
>
> print(f"Aproxima√ß√£o de Monte Carlo da integral: {integral_approximation:.4f}")
> print(f"Solu√ß√£o anal√≠tica: {1/3:.4f}")
> ```

*Proof:*
I. Considere a integral $\int g(x) f(x) dx = E[g(X)]$, onde$f(x)$ √© a fun√ß√£o de densidade de probabilidade de $X$.

II. Podemos aproximar essa esperan√ßa usando a m√©dia amostral de $g(X_i)$ para $N$ amostras $X_i$ retiradas de $f(x)$:

$$
E[g(X)] \approx \frac{1}{N} \sum_{i=1}^{N} g(X_i)
$$

III. No nosso caso, $g(x) = x^2$ e $f(x) = 1$ para $x \in [0, 1]$ (distribui√ß√£o uniforme).

IV. Portanto, a aproxima√ß√£o de Monte Carlo da integral √© a m√©dia dos valores de $x_i^2$ para $x_i$ amostrados de uma distribui√ß√£o uniforme em $[0, 1]$.

V. A solu√ß√£o anal√≠tica √© $\int_0^1 x^2 dx = \frac{1}{3}$.

VI. A converg√™ncia do m√©todo de Monte Carlo para o valor real da integral √© garantida pela Lei Forte dos Grandes N√∫meros, que afirma que, √† medida que $N \rightarrow \infty$, a m√©dia amostral converge para a esperan√ßa verdadeira. $\blacksquare$

### Integrais Multidimensionais

O m√©todo de Monte Carlo √© particularmente √∫til para calcular integrais multidimensionais, onde outros m√©todos num√©ricos podem se tornar computacionalmente proibitivos.

**Exemplo:** Calcular o volume de uma hiperesfera unit√°ria em $n$ dimens√µes.

```python
import numpy as np

def monte_carlo_hyperesphere_volume(n, N):
    """
    Calcula o volume de uma hiperesfera unit√°ria em n dimens√µes
    usando o m√©todo de Monte Carlo.
    """
    points = np.random.uniform(-1, 1, size=(N, n))
    inside = np.linalg.norm(points, axis=1) <= 1
    volume_approximation = (2**n) * np.sum(inside) / N
    return volume_approximation

# Par√¢metros
n_dimensions = 10  # N√∫mero de dimens√µes
n_samples = 100000   # N√∫mero de amostras

# Calcula o volume
volume_approximation = monte_carlo_hyperesphere_volume(n_dimensions, n_samples)

print(f"Aproxima√ß√£o de Monte Carlo do volume da hiperesfera em {n_dimensions} dimens√µes: {volume_approximation:.4f}")
```

### Redu√ß√£o de Vari√¢ncia

A precis√£o dos m√©todos de Monte Carlo depende do n√∫mero de amostras utilizadas. T√©cnicas de redu√ß√£o de vari√¢ncia podem ser empregadas para obter estimativas mais precisas com o mesmo n√∫mero de amostras. Algumas t√©cnicas comuns incluem:

*   **Amostragem Estratificada:** Dividir o espa√ßo amostral em subregi√µes (estratos) e amostrar cada estrato de forma independente.

*   **Vari√°veis de Controle:** Usar uma fun√ß√£o conhecida com uma integral conhecida para reduzir a vari√¢ncia da estimativa.

*   **Amostragem por Import√¢ncia:** Amostrar a partir de uma distribui√ß√£o que se assemelha √† fun√ß√£o integranda para reduzir a vari√¢ncia nas regi√µes importantes.

### Amostragem por Import√¢ncia

A amostragem por import√¢ncia √© uma t√©cnica de redu√ß√£o de vari√¢ncia que envolve amostrar a partir de uma distribui√ß√£o de probabilidade diferente da distribui√ß√£o original.  O objetivo √© concentrar as amostras em regi√µes do espa√ßo amostral que contribuem mais para a integral.

Seja $I = \int_a^b f(x) dx$ a integral que queremos calcular. Introduzimos uma fun√ß√£o de densidade de probabilidade $g(x)$ tal que $g(x) > 0$ sempre que $f(x) \neq 0$. Ent√£o podemos reescrever a integral como:

$$
I = \int_a^b \frac{f(x)}{g(x)} g(x) dx = E_g \left[ \frac{f(X)}{g(X)} \right]
$$

Onde $E_g$ denota a esperan√ßa em rela√ß√£o √† distribui√ß√£o $g(x)$.  Aproximamos essa esperan√ßa por:

$$
I \approx \frac{1}{N} \sum_{i=1}^N \frac{f(X_i)}{g(X_i)}
$$

Onde $X_i$ s√£o amostras retiradas da distribui√ß√£o $g(x)$. A escolha de $g(x)$ √© crucial. Idealmente, $g(x)$ deve se assemelhar a $f(x)$ para que a vari√¢ncia da estimativa seja reduzida.

**Exemplo:**

Calcular $\int_0^1 e^{-x^2} dx$ usando amostragem por import√¢ncia.

```python
import numpy as np
import math

def f(x):
    return math.exp(-x**2)

def g(x):
    return 2 * (1 - x) # Densidade de probabilidade triangular

def sample_g():
    return 1 - np.sqrt(np.random.uniform(0, 1))

N = 10000
samples = [sample_g() for _ in range(N)]
weights = [f(x) / g(x) for x in samples]
integral_approximation = np.mean(weights)

print(f"Aproxima√ß√£o de Monte Carlo com amostragem por import√¢ncia: {integral_approximation:.4f}")

# Compara√ß√£o com Monte Carlo simples e solu√ß√£o num√©rica (quadratura de Gauss)
def monte_carlo_simple(N):
    samples = np.random.uniform(0, 1, N)
    return np.mean([f(x) for x in samples])

from scipy.integrate import quad
result, _ = quad(f, 0, 1)

print(f"Aproxima√ß√£o de Monte Carlo simples: {monte_carlo_simple(N):.4f}")
print(f"Solu√ß√£o num√©rica (quadratura de Gauss): {result:.4f}")
```

*Proof:*

I.  A integral pode ser reescrita como a esperan√ßa de uma fun√ß√£o em rela√ß√£o a uma distribui√ß√£o $g(x)$ diferente da distribui√ß√£o uniforme original.

II.  A escolha de $g(x)$ influencia a vari√¢ncia da estimativa. Uma boa escolha minimiza a vari√¢ncia.

III. Amostrar diretamente de $g(x)$ permite concentrar as amostras em regi√µes onde a fun√ß√£o $f(x)$ tem maior impacto na integral.

IV.  A pondera√ß√£o de cada amostra por $f(x)/g(x)$ corrige o vi√©s introduzido pela amostragem a partir de $g(x)$.

V.  A converg√™ncia para o valor real da integral √© garantida se $g(x) > 0$ sempre que $f(x) \neq 0$ e pela Lei Forte dos Grandes N√∫meros. $\blacksquare$
<!-- END -->