## Custos Computacionais e Melhorias Cont√≠nuas nos M√©todos de Monte Carlo para VAR

### Introdu√ß√£o

Este cap√≠tulo visa explorar detalhadamente os desafios computacionais associados aos m√©todos de Monte Carlo, particularmente no contexto da avalia√ß√£o do Value at Risk (VAR), e discutir os avan√ßos que est√£o sendo feitos para tornar essas t√©cnicas mais pr√°ticas e eficientes. Como destacado em cap√≠tulos anteriores [^1], os m√©todos de Monte Carlo s√£o ferramentas poderosas para a an√°lise de risco financeiro, permitindo simular a evolu√ß√£o de pre√ßos de ativos e calcular m√©tricas como o VAR. No entanto, a necessidade de um grande n√∫mero de replica√ß√µes para obter estimativas precisas pode levar a custos computacionais significativos, especialmente para portf√≥lios grandes ou instrumentos financeiros complexos [^1, 10]. Discutiremos como a complexidade de modelos de avalia√ß√£o, como simula√ß√µes aninhadas para instrumentos complexos, pode agravar ainda mais esses custos [^10]. Al√©m disso, abordaremos como os avan√ßos cont√≠nuos em poder de computa√ß√£o e m√©todos de avalia√ß√£o est√£o ajudando a superar essas limita√ß√µes [^10].

### Custos Computacionais em M√©todos de Monte Carlo para VAR

Os m√©todos de Monte Carlo, embora poderosos, podem ser computacionalmente intensivos [^10]. Para um portf√≥lio exposto a apenas um fator de risco, podemos precisar de $10.000$ replica√ß√µes desse fator de risco para precis√£o aceit√°vel [^10]. Se o portf√≥lio contiver $1.000$ ativos a serem precificados usando avalia√ß√µes completas, ser√£o necess√°rias $10$ milh√µes de avalia√ß√µes [^10]. Se, al√©m disso, o portf√≥lio contiver instrumentos complexos, como hipotecas ou op√ß√µes ex√≥ticas, cuja avalia√ß√£o em si requer uma simula√ß√£o, medir o risco em uma data-alvo exigir√° uma "simula√ß√£o dentro de uma simula√ß√£o":

*   Para avalia√ß√£o (ou seja, do horizonte VAR at√© o vencimento do instrumento).
*   Para gerenciamento de risco (ou seja, do tempo presente at√© o horizonte VAR).

Sem atalhos, o n√∫mero de simula√ß√µes necess√°rias pode atingir valores astron√¥micos [^10]. Isso ocorre porque o c√°lculo do VAR geralmente envolve os seguintes passos:

1.  **Simula√ß√£o de Cen√°rios:** Gera√ß√£o de um grande n√∫mero de cen√°rios de mercado poss√≠veis, simulando a evolu√ß√£o de fatores de risco relevantes (pre√ßos de ativos, taxas de juros, etc.) ao longo do horizonte de tempo do VAR.
2.  **Avalia√ß√£o do Portf√≥lio:** Para cada cen√°rio simulado, avaliar o valor do portf√≥lio na data alvo. Isso pode envolver a precifica√ß√£o de um grande n√∫mero de instrumentos financeiros, incluindo derivativos complexos.
3.  **C√°lculo do VAR:** Com base na distribui√ß√£o dos valores do portf√≥lio simulados, calcular o VAR como o percentil apropriado da distribui√ß√£o (por exemplo, o 5¬∫ percentil para um VAR de 95\%).

Para op√ß√µes complexas e instrumentos, cuja avalia√ß√£o em si requer uma simula√ß√£o, medir o risco em uma data-alvo exige "uma simula√ß√£o dentro de uma simula√ß√£o" [^10]. Em virtude de suas caracter√≠sticas e din√¢mica intr√≠nsecas, as op√ß√µes e os ativos complexos requerem uma simula√ß√£o para seu c√°lculo de valor intr√≠nseco [^10]. Uma das maneiras de contornar este problema √© atrav√©s da an√°lise de cen√°rios que ajudam a determinar par√¢metros importantes para avalia√ß√£o, tais como volatilidade, que ajuda em uma avalia√ß√£o adequada dos derivativos.

Essa complexidade pode aumentar substancialmente o tempo de execu√ß√£o de uma simula√ß√£o de Monte Carlo, tornando-a impratic√°vel para aplica√ß√µes em tempo real ou para portf√≥lios muito grandes.

> üí° **Exemplo Num√©rico:**
>
> Considere um portf√≥lio com 1000 ativos, onde cada ativo necessita de 500 simula√ß√µes de Monte Carlo para a sua avalia√ß√£o. Isso resulta em $1000 \times 500 = 500,000$ avalia√ß√µes. Se cada avalia√ß√£o demorar 0.01 segundos, o tempo total de computa√ß√£o ser√° de $500,000 \times 0.01 = 5000$ segundos, ou aproximadamente 1.39 horas. Se quisermos calcular o VAR com 10,000 cen√°rios, o tempo total necess√°rio seria de $10,000 \times 1.39 = 13,900$ horas, o que demonstra a necessidade de otimiza√ß√µes para reduzir o tempo de computa√ß√£o.
>
> Se, adicionalmente, 10% desses ativos forem op√ß√µes que requerem uma simula√ß√£o aninhada com 100 simula√ß√µes cada, o tempo de computa√ß√£o aumentaria significativamente. Para estas op√ß√µes, seriam necess√°rias $100 \times 100 \times 500 = 5,000,000$ simula√ß√µes adicionais, elevando ainda mais os custos computacionais.
>
> ```python
> import numpy as np
>
> # Par√¢metros
> num_ativos = 1000
> simulacoes_por_ativo = 500
> tempo_por_simulacao = 0.01  # segundos
> num_cenarios_var = 10000
>
> # C√°lculo do tempo total sem simula√ß√£o aninhada
> tempo_total_segundos = num_ativos * simulacoes_por_ativo * tempo_por_simulacao
> tempo_total_horas = tempo_total_segundos / 3600
>
> print(f"Tempo total sem simula√ß√£o aninhada: {tempo_total_horas:.2f} horas")
>
> # Simula√ß√£o aninhada para 10% dos ativos
> num_opcoes = int(0.1 * num_ativos)
> simulacoes_aninhadas = 100
>
> tempo_adicional_segundos = num_opcoes * simulacoes_aninhadas * simulacoes_por_ativo * tempo_por_simulacao
> tempo_adicional_horas = tempo_adicional_segundos / 3600
>
> print(f"Tempo adicional devido √† simula√ß√£o aninhada: {tempo_adicional_horas:.2f} horas")
>
> # Tempo total com simula√ß√£o aninhada
> tempo_total_com_aninhada_segundos = tempo_total_segundos + tempo_adicional_segundos
> tempo_total_com_aninhada_horas = tempo_total_com_aninhada_segundos / 3600
>
> print(f"Tempo total com simula√ß√£o aninhada: {tempo_total_com_aninhada_horas:.2f} horas")
>
> # C√°lculo do tempo para o VAR
> tempo_var_horas = num_cenarios_var * tempo_total_com_aninhada_horas
> print(f"Tempo total para calcular o VAR: {tempo_var_horas:.2f} horas")
> ```

### M√©todos de Acelera√ß√£o e Redu√ß√£o de Vari√¢ncia

Como demonstrado anteriormente, a precis√£o das simula√ß√µes de Monte Carlo pode ser melhorada aumentando o n√∫mero de simula√ß√µes e replicando o n√∫mero de simula√ß√µes com m√©dia nas replica√ß√µes [^10]. Mas, isso tamb√©m aumenta o custo computacional. A seguir alguns m√©todos de acelera√ß√£o ou redu√ß√£o de vari√¢ncia.
Para acelerar os c√°lculos, h√° uma busca por m√©todos para acelerar os c√°lculos. Um dos primeiros e mais f√°ceis √© a t√©cnica de *vari√°vel antit√©tica*, que consiste em mudar o sinal de todas as amostras aleat√≥rias $\epsilon$. Quando apropriado, a t√©cnica da vari√°vel antit√©tica (usar o oposto de cada n√∫mero aleat√≥rio gerado como outra simula√ß√£o) cria duas vezes o n√∫mero de replica√ß√µes para os fatores de risco com pouco custo adicional [^10, 13]. Ainda precisamos, no entanto, duas vezes o n√∫mero original de avalia√ß√µes completas na data de destino [^13].

**Proposi√ß√£o 1**.
A t√©cnica de vari√°vel antit√©tica √© mais eficaz quando a fun√ß√£o de pagamento √© mon√≥tona em rela√ß√£o aos fatores de risco.

*Prova*.
A t√©cnica da vari√°vel antit√©tica funciona melhor quando a fun√ß√£o de pagamento √© aproximadamente linear ou mon√≥tona em rela√ß√£o aos fatores de risco. Isso ocorre porque a t√©cnica antit√©tica introduz uma correla√ß√£o negativa entre as simula√ß√µes originais e suas contrapartes antit√©ticas. Se a fun√ß√£o de pagamento for mon√≥tona, essa correla√ß√£o negativa reduzir√° a vari√¢ncia da estimativa de Monte Carlo. Se a fun√ß√£o de pagamento n√£o for mon√≥tona, a correla√ß√£o negativa pode n√£o ser t√£o eficaz na redu√ß√£o da vari√¢ncia. $\blacksquare$

> üí° **Exemplo Num√©rico:**
>
> Suponha que estamos avaliando uma op√ß√£o de compra europeia usando simula√ß√£o de Monte Carlo. O pre√ßo do ativo subjacente segue um movimento browniano geom√©trico. Para cada caminho simulado do pre√ßo do ativo, calculamos o payoff da op√ß√£o no vencimento. Na t√©cnica da vari√°vel antit√©tica, para cada n√∫mero aleat√≥rio $z$ usado para gerar um caminho do pre√ßo do ativo, tamb√©m usamos $-z$ para gerar um caminho antit√©tico. Os payoffs correspondentes s√£o ent√£o usados para calcular o pre√ßo da op√ß√£o.
>
> Se o pre√ßo simulado do ativo no vencimento for $S_T$, e o pre√ßo de exerc√≠cio for $K$, o payoff da op√ß√£o de compra ser√° $\max(S_T - K, 0)$. Se usarmos $N$ caminhos simulados, teremos $N$ payoffs. Com a t√©cnica da vari√°vel antit√©tica, teremos $2N$ payoffs. A estimativa do pre√ßo da op√ß√£o √© a m√©dia dos $2N$ payoffs descontados para o presente.
>
> ```python
> import numpy as np
> from scipy.stats import norm
>
> # Par√¢metros da op√ß√£o
> S0 = 100      # Pre√ßo inicial do ativo
> K = 110       # Pre√ßo de exerc√≠cio
> T = 1         # Tempo at√© o vencimento (anos)
> r = 0.05      # Taxa de juros livre de risco
> sigma = 0.2   # Volatilidade
> N = 1000      # N√∫mero de simula√ß√µes
>
> # Simula√ß√£o de Monte Carlo com vari√°vel antit√©tica
> def monte_carlo_antithetic(S0, K, T, r, sigma, N):
>     z = np.random.normal(0, 1, N)  # N√∫meros aleat√≥rios normais
>     z_antithetic = -z             # Vari√°veis antit√©ticas
>
>     # Caminhos simulados com vari√°veis antit√©ticas
>     ST = S0 * np.exp((r - 0.5 * sigma**2) * T + sigma * np.sqrt(T) * z)
>     ST_antithetic = S0 * np.exp((r - 0.5 * sigma**2) * T + sigma * np.sqrt(T) * z_antithetic)
>
>     # Payoffs das op√ß√µes
>     payoff = np.maximum(ST - K, 0)
>     payoff_antithetic = np.maximum(ST_antithetic - K, 0)
>
>     # Pre√ßo da op√ß√£o (m√©dia dos payoffs descontados)
>     option_price = np.exp(-r * T) * np.mean(np.concatenate([payoff, payoff_antithetic]))
>
>     return option_price
>
> # C√°lculo do pre√ßo da op√ß√£o
> option_price = monte_carlo_antithetic(S0, K, T, r, sigma, N)
> print(f"Pre√ßo da op√ß√£o com vari√°vel antit√©tica: {option_price:.2f}")
>
> # Compara√ß√£o com o pre√ßo de Black-Scholes
> def black_scholes(S0, K, T, r, sigma):
>     d1 = (np.log(S0 / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))
>     d2 = d1 - sigma * np.sqrt(T)
>     option_price = S0 * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)
>     return option_price
>
> bs_price = black_scholes(S0, K, T, r, sigma)
> print(f"Pre√ßo da op√ß√£o com Black-Scholes: {bs_price:.2f}")
> ```

Outra ferramenta √∫til √© a t√©cnica de *vari√°veis de controle* [^13]. Aqui, tentamos estimar o VAR, uma fun√ß√£o da amostra de dados. Denominamos essa fun√ß√£o $V(X)$. Assumimos agora que a fun√ß√£o pode ser aproximada por outra fun√ß√£o, como uma aproxima√ß√£o quadr√°tica $V^0(X)$, para a qual temos uma solu√ß√£o de forma fechada $v^0$. Para qualquer amostra, o erro ent√£o √© conhecido por ser $V^0(X) - v^0$ para a aproxima√ß√£o quadr√°tica [^14]. Se esse erro for altamente correlacionado com o erro de amostragem em $V(X)$, o estimador da vari√°vel de controle pode ser tomado como:

$$ V_{cv} = V(X) - [V^0(X) - v^0] \quad (12.5) $$

Este estimador tem uma vari√¢ncia muito menor do que o original quando a fun√ß√£o quadr√°tica fornece uma boa aproxima√ß√£o da fun√ß√£o verdadeira [^14].

**Lema 2**.
A efici√™ncia da t√©cnica de vari√°veis de controle depende da correla√ß√£o entre a vari√°vel de controle e a fun√ß√£o de pagamento.

*Prova*.
Seja $\rho$ a correla√ß√£o entre $V(X)$ e $V^0(X)$. A redu√ß√£o na vari√¢ncia ao usar vari√°veis de controle √© proporcional a $\rho^2$. Portanto, quanto maior a correla√ß√£o, maior a redu√ß√£o na vari√¢ncia.

I. Considere a vari√¢ncia do estimador da vari√°vel de controle $V_{cv}$:
   $$Var(V_{cv}) = Var(V(X) - [V^0(X) - v^0]) = Var(V(X) - V^0(X))$$

II. Expanda a vari√¢ncia:
    $$Var(V_{cv}) = Var(V(X)) + Var(V^0(X)) - 2Cov(V(X), V^0(X))$$

III. Usando a defini√ß√£o do coeficiente de correla√ß√£o $\rho$:
     $$Cov(V(X), V^0(X)) = \rho \cdot \sigma_{V(X)} \cdot \sigma_{V^0(X)}$$
     Onde $\sigma_{V(X)}$ e $\sigma_{V^0(X)}$ s√£o os desvios padr√£o de $V(X)$ e $V^0(X)$, respectivamente.

IV. Substitua a covari√¢ncia na equa√ß√£o da vari√¢ncia:
    $$Var(V_{cv}) = Var(V(X)) + Var(V^0(X)) - 2\rho \cdot \sigma_{V(X)} \cdot \sigma_{V^0(X)}$$

V. Para que a t√©cnica de vari√°veis de controle seja eficaz, queremos que $Var(V_{cv}) < Var(V(X))$. Isso acontece quando a correla√ß√£o $\rho$ √© alta, implicando que $V^0(X)$ √© um bom preditor de $V(X)$.

VI. Consequentemente, a redu√ß√£o na vari√¢ncia √© maior quando $\rho$ √© maior. Na verdade, a redu√ß√£o na vari√¢ncia pode ser expressa como:
    $$Reduction = Var(V(X)) - Var(V_{cv}) = 2\rho \cdot \sigma_{V(X)} \cdot \sigma_{V^0(X)} - Var(V^0(X))$$

VII. Se $V^0(X)$ √© uma boa aproxima√ß√£o de $V(X)$, ent√£o $\sigma_{V^0(X)} \approx \sigma_{V(X)}$, e a redu√ß√£o pode ser aproximada por:
     $$Reduction \approx 2\rho \cdot \sigma_{V(X)}^2 - \sigma_{V(X)}^2 = (2\rho - 1) \sigma_{V(X)}^2$$

VIII. Portanto, para que haja uma redu√ß√£o significativa na vari√¢ncia, $\rho$ deve ser maior que $0.5$. Em geral, quanto mais pr√≥ximo $\rho$ estiver de 1, mais eficaz ser√° a t√©cnica de vari√°veis de controle. $\blacksquare$

> üí° **Exemplo Num√©rico:**
>
> Suponha que estamos precificando uma op√ß√£o asi√°tica (que √© computacionalmente intensiva) usando simula√ß√£o de Monte Carlo. Podemos usar uma op√ß√£o europeia padr√£o com os mesmos par√¢metros como vari√°vel de controle, pois ela tem uma f√≥rmula anal√≠tica de Black-Scholes e est√° correlacionada com a op√ß√£o asi√°tica.
>
> Seja $V(X)$ o pre√ßo da op√ß√£o asi√°tica calculado por Monte Carlo e $V^0(X)$ o pre√ßo da op√ß√£o europeia calculado pela f√≥rmula de Black-Scholes (que √© $v^0$). Durante cada simula√ß√£o, calculamos ambos $V(X)$ e $V^0(X)$.
>
> 1.  Calculamos a covari√¢ncia entre $V(X)$ e $V^0(X)$.
> 2.  Estimamos o coeficiente $\beta$ que minimiza a vari√¢ncia de $V(X) - \beta(V^0(X) - v^0)$.
> 3.  Usamos a t√©cnica da vari√°vel de controle para estimar o pre√ßo da op√ß√£o asi√°tica.
>
> ```python
> import numpy as np
> from scipy.stats import norm
>
> # Par√¢metros da op√ß√£o
> S0 = 100      # Pre√ßo inicial do ativo
> K = 100       # Pre√ßo de exerc√≠cio
> T = 1         # Tempo at√© o vencimento (anos)
> r = 0.05      # Taxa de juros livre de risco
> sigma = 0.2   # Volatilidade
> N = 1000      # N√∫mero de simula√ß√µes
>
> # Fun√ß√£o para calcular o pre√ßo da op√ß√£o europeia usando Black-Scholes
> def black_scholes(S0, K, T, r, sigma):
>     d1 = (np.log(S0 / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))
>     d2 = d1 - sigma * np.sqrt(T)
>     option_price = S0 * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)
>     return option_price
>
> # Simula√ß√£o de Monte Carlo para a op√ß√£o asi√°tica
> def monte_carlo_asian(S0, K, T, r, sigma, N):
>     dt = T / N
>     sum_prices = np.zeros(N)
>
>     for i in range(N):
>         z = np.random.normal(0, 1, N)
>         prices = S0 * np.exp(np.cumsum((r - 0.5 * sigma**2) * dt + sigma * np.sqrt(dt) * z))
>         sum_prices[i] = np.mean(prices)
>
>     payoff = np.maximum(sum_prices - K, 0)
>     option_price = np.exp(-r * T) * np.mean(payoff)
>
>     return option_price
>
> # Pre√ßo da op√ß√£o europeia (vari√°vel de controle)
> european_price = black_scholes(S0, K, T, r, sigma)
>
> # Simula√ß√£o de Monte Carlo com vari√°vel de controle
> def monte_carlo_control_variate(S0, K, T, r, sigma, N, european_price):
>     asian_prices = np.zeros(N)
>     european_prices = np.zeros(N)
>
>     for i in range(N):
>         # Simula√ß√£o da op√ß√£o asi√°tica
>         dt = T / N
>         z = np.random.normal(0, 1, N)
>         prices = S0 * np.exp(np.cumsum((r - 0.5 * sigma**2) * dt + sigma * np.sqrt(dt) * z))
>         asian_prices[i] = np.exp(-r * T) * np.mean(np.maximum(np.mean(prices) - K, 0))
>
>         # Simula√ß√£o da op√ß√£o europeia (para cada caminho simulado)
>         european_prices[i] = black_scholes(S0, K, T, r, sigma)
>
>     # C√°lculo da covari√¢ncia
>     covariance = np.cov(asian_prices, european_prices)[0, 1]
>     variance_european = np.var(european_prices)
>
>     # C√°lculo do coeficiente beta
>     beta = covariance / variance_european
>
>     # Estimador da vari√°vel de controle
>     control_variate_estimator = asian_prices - beta * (european_prices - european_price)
>     option_price = np.mean(control_variate_estimator)
>
>     return option_price
>
> # C√°lculo do pre√ßo da op√ß√£o asi√°tica com vari√°vel de controle
> control_variate_price = monte_carlo_control_variate(S0, K, T, r, sigma, N, european_price)
>
> # C√°lculo do pre√ßo da op√ß√£o asi√°tica sem vari√°vel de controle
> asian_price = monte_carlo_asian(S0, K, T, r, sigma, N)
>
> print(f"Pre√ßo da op√ß√£o asi√°tica (sem vari√°vel de controle): {asian_price:.2f}")
> print(f"Pre√ßo da op√ß√£o asi√°tica (com vari√°vel de controle): {control_variate_price:.2f}")
> print(f"Pre√ßo da op√ß√£o europeia (Black-Scholes): {european_price:.2f}")
> ```

> üí° **Caixa de Destaque:**
>
> Os m√©todos quasi-Monte Carlo (QMC) usam sequ√™ncias determin√≠sticas de baixa discrep√¢ncia em vez de n√∫meros aleat√≥rios, com isso s√£o preenchidos o $N$-espa√ßo de forma mais uniforme [^22]. A qualidade da escolha deve levar em considera√ß√£o o tamanho da amostra e a dimensionalidade do problema [^22]. Por exemplo, Papageorgiou e Paskov (1999) comparam a computa√ß√£o do VAR para um portf√≥lio exposto a 34 fatores de risco usando 1000 pontos e descobriram que a sequ√™ncia determin√≠stica pode ser 10 vezes mais precisa do que o m√©todo de Monte Carlo [^11].
>
![VAR computation using Quasi-Monte Carlo](./../images/figure1.png)

**Lema 1** (Estimativa de erro).
Estimativas de erro com uma simula√ß√£o padr√£o diminuem √† taxa de $1/\sqrt{K}$, enquanto que com m√©todos quasi-Monte Carlo diminuem a uma taxa pr√≥xima de $1/K$.

**Teorema 1** (Amostragem Estratificada).
A amostragem estratificada garante uma melhor cobertura do espa√ßo amostral, reduzindo a vari√¢ncia das estimativas.

*Prova*.
A t√©cnica da amostragem estratificada √© outro m√©todo para reduzir a vari√¢ncia [^14]. Dividimos a regi√£o de simula√ß√£o em duas zonas e tentamos manter o n√∫mero de replica√ß√µes em $K=1000$ [^14]. Para aumentar a precis√£o do estimador VAR, dividimos os espa√ßos em zonas, que agora se transformam em uma distribui√ß√£o normal para o pre√ßo do ativo subjacente usando o m√©todo de transforma√ß√£o inversa [^14]. Agora mudamos essas probabilidades para $50\%$ para ambas as regi√µes [^14]. O n√∫mero de observa√ß√µes √© agora $K_1=500$ para a primeira regi√£o, e $K_2=500$ para a segunda. Os estimadores precisam ser ajustados para a estratifica√ß√£o.

I. Seja $\hat{\theta}$ o estimador de Monte Carlo padr√£o baseado em $K$ amostras, e seja $\hat{\theta}_{strat}$ o estimador estratificado. O objetivo √© mostrar que $Var(\hat{\theta}_{strat}) \leq Var(\hat{\theta})$.

II. Seja $\Omega$ o espa√ßo amostral, dividido em $n$ estratos $S_1, S_2, \dots, S_n$. Seja $K_i$ o n√∫mero de amostras no estrato $S_i$, tal que $\sum_{i=1}^{n} K_i = K$.

III. O estimador estratificado √© dado por:
     $$\hat{\theta}_{strat} = \sum_{i=1}^{n} P(S_i) \hat{\theta}_i$$
     Onde $P(S_i)$ √© a probabilidade do estrato $S_i$, e $\hat{\theta}_i$ √© o estimador de Monte Carlo dentro do estrato $S_i$.

IV. A vari√¢ncia do estimador estratificado √©:
    $$Var(\hat{\theta}_{strat}) = Var\left(\sum_{i=1}^{n} P(S_i) \hat{\theta}_i\right)$$

V. Assumindo que as amostras em diferentes estratos s√£o independentes, temos:
   $$Var(\hat{\theta}_{strat}) = \sum_{i=1}^{n} P(S_i)^2 Var(\hat{\theta}_i)$$

VI. Seja $\sigma_i^2$ a vari√¢ncia dentro do estrato $S_i$. Ent√£o, $Var(\hat{\theta}_i) = \frac{\sigma_i^2}{K_i}$. Assim:
    $$Var(\hat{\theta}_{strat}) = \sum_{i=1}^{n} P(S_i)^2 \frac{\sigma_i^2}{K_i}$$

VII. Usando a aloca√ß√£o proporcional, onde $K_i = K P(S_i)$, temos:
     $$Var(\hat{\theta}_{strat}) = \sum_{i=1}^{n} P(S_i)^2 \frac{\sigma_i^2}{K P(S_i)} = \frac{1}{K} \sum_{i=1}^{n} P(S_i) \sigma_i^2$$

VIII. Agora, considere a vari√¢ncia do estimador de Monte Carlo padr√£o:
      $$Var(\hat{\theta}) = \frac{\sigma^2}{K}$$
      Onde $\sigma^2$ √© a vari√¢ncia total sobre todo o espa√ßo amostral $\Omega$.

IX. Pela lei da vari√¢ncia total:
    $$\sigma^2 = E[Var(X|S)] + Var(E[X|S])$$
    Onde $S$ representa os estratos.

X. Expressando isso em termos de nossos estimadores:
   $$\sigma^2 = \sum_{i=1}^{n} P(S_i) \sigma_i^2 + \sum_{i=1}^{n} P(S_i) (\mu_i - \mu)^2$$
   Onde $\mu_i$ √© a m√©dia dentro do estrato $S_i$, e $\mu$ √© a m√©dia global.

XI. Substituindo na express√£o para $Var(\hat{\theta})$:
    $$Var(\hat{\theta}) = \frac{1}{K} \left( \sum_{i=1}^{n} P(S_i) \sigma_i^2 + \sum_{i=1}^{n} P(S_i) (\mu_i - \mu)^2 \right)$$

XII. Comparando $Var(\hat{\theta}_{strat})$ e $Var(\hat{\theta})$:
     $$Var(\hat{\theta}) - Var(\hat{\theta}_{strat}) = \frac{1}{K} \sum_{i=1}^{n} P(S_i) (\mu_i - \mu)^2 \geq 0$$

XIII. Portanto, $Var(\hat{\theta}_{strat}) \leq Var(\hat{\theta})$. Isso demonstra que a amostragem estratificada reduz a vari√¢ncia em compara√ß√£o com a amostragem de Monte Carlo padr√£o. $\blacksquare$

> üí° **Exemplo Num√©rico:**
>
> Suponha que queremos estimar o pre√ßo de uma op√ß√£o de compra europeia usando amostragem estratificada com dois estratos: um para cen√°rios onde o pre√ßo do ativo no vencimento √© menor que o pre√ßo de exerc√≠cio, e outro para cen√°rios onde √© maior.
>
> 1.  Dividimos o espa√ßo amostral em dois estratos com igual probabilidade ($P(S_1) = P(S_2) = 0.5$).
> 2.  Geramos 500 amostras em cada estrato ($K_1 = K_2 = 500$).
> 3.  Calculamos o payoff m√©dio em cada estrato.
> 4.  Estimamos o pre√ßo da op√ß√£o como a m√©dia ponderada dos payoffs m√©dios nos estratos.
>
> ```python
> import numpy as np
> from scipy.stats import norm
>
> # Par√¢metros da op√ß√£o
> S0 = 100      # Pre√ßo inicial do ativo
> K = 110       # Pre√ßo de exerc√≠cio
> T = 1         # Tempo at√© o vencimento (anos)
> r = 0.05      # Taxa de juros livre de risco
> sigma = 0.2   # Volatilidade
> K1 = 500      # N√∫mero de amostras no estrato 1
> K2 = 500      # N√∫mero de amostras no estrato 2
>
> # Simula√ß√£o de Monte Carlo com amostragem estratificada
> def monte_carlo_stratified(S0, K, T, r, sigma, K1, K2):
>     # Estrato 1: Pre√ßo do ativo menor que o pre√ßo de exerc√≠cio
>     z1 = np.random.normal(0, 1, K1)
>     ST1 = S0 * np.exp((r - 0.5 * sigma**2) * T + sigma * np.sqrt(T) * z1)
>     payoff1 = np.maximum(ST1 - K, 0)
>     mean_payoff1 = np.mean(payoff1)
>
>     # Estrato 2: Pre√ßo do ativo maior que o pre√ßo de exerc√≠cio
>     z2 = np.random.normal(0, 1, K2)
>     ST2 = S0 * np.exp((r - 0.5 * sigma**2) * T + sigma * np.sqrt(T) * z2)
>     payoff2 = np.maximum(ST2 - K, 0)
>     mean_payoff2 = np.mean(payoff2)
>
>     # Pre√ßo da op√ß√£o com amostragem estratificada
>     option_price = np.exp(-r * T) * (0.5 * mean_payoff1 + 0.5 * mean_payoff2)
>
>     return option_price
>
> # C√°lculo do pre√ßo da op√ß√£o
> option_price = monte_carlo_stratified(S0, K, T, r, sigma, K1, K2)
> print(f"Pre√ßo da op√ß√£o com amostragem estratificada: {option_price:.2f}")
>
> # Compara√ß√£o com o pre√ßo de Black-Scholes
> def black_scholes(S0, K, T, r, sigma):
>     d1 = (np.log(S0 / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))
>     d2 = d1 - sigma * np.sqrt(T)
>     option_price = S0 * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)
>     return option_price
>
> bs_price = black_scholes(S0, K, T, r, sigma)
> print(f"Pre√ßo da op√ß√£o com Black-Scholes: {bs_price:.2f}")
> ```
>
> O c√°lculo do erro padr√£o da estimativa total √©:
> $SE = \frac{\sigma}{\sqrt{n}}$
>
> O objetivo √© que o erro seja menor do que na amostragem aleat√≥ria simples, e que a estimativa seja mais precisa.

### Avan√ßos em Poder de Computa√ß√£o e M√©todos de Avalia√ß√£o

Felizmente, os custos de tempo est√£o diminuindo devido aos avan√ßos em computadores e m√©todos de avalia√ß√£o mais r√°pidos [^10]. A disponibilidade crescente de poder de computa√ß√£o e o desenvolvimento de algoritmos de avalia√ß√£o mais eficientes est√£o tornando as simula√ß√µes de Monte Carlo mais pr√°ticas para uma gama maior de aplica√ß√µes [^10]. Algumas das principais tend√™ncias nessa √°rea incluem:

*   **Processamento Paralelo:** O uso de arquiteturas de computa√ß√£o paralela (CPUs multi-core, GPUs) permite realizar simula√ß√µes em larga escala de forma mais r√°pida, dividindo o trabalho entre m√∫ltiplos processadores.
*   **Computa√ß√£o em Nuvem:** A computa√ß√£o em nuvem oferece acesso a recursos computacionais escal√°veis sob demanda, permitindo executar simula√ß√µes complexas sem a necessidade de investir em infraestrutura de hardware local.
*   **T√©cnicas de Aproxima√ß√£o:** O desenvolvimento de t√©cnicas de aproxima√ß√£o para precificar derivativos complexos (por exemplo, modelos de ordem reduzida, m√©todos de elementos finitos) pode reduzir significativamente o tempo de avalia√ß√£o do portf√≥lio em cada cen√°rio simulado.
*   **Algoritmos Otimizados:** A otimiza√ß√£o de algoritmos de simula√ß√£o (por exemplo, uso de n√∫meros aleat√≥rios de baixa discrep√¢ncia, t√©cnicas de redu√ß√£o de vari√¢ncia) pode melhorar a efici√™ncia da simula√ß√£o sem comprometer a precis√£o.

> üí° **Exemplo Num√©rico:**
>
> Suponha que uma simula√ß√£o de Monte Carlo para um portf√≥lio de derivativos demore 24 horas para ser executada em um √∫nico servidor. Ao utilizar processamento paralelo com 24 n√∫cleos de CPU, o tempo de execu√ß√£o pode ser reduzido para aproximadamente 1 hora, assumindo uma paraleliza√ß√£o perfeita. A computa√ß√£o em nuvem permite escalar o n√∫mero de servidores sob demanda, reduzindo ainda mais o tempo de execu√ß√£o.
>
> Al√©m disso, a utiliza√ß√£o de modelos de ordem reduzida pode simplificar os c√°lculos, acelerando a avalia√ß√£o de cada cen√°rio individualmente. Por exemplo, um modelo completo que demore 1 segundo por cen√°rio pode ser substitu√≠do por um modelo de ordem reduzida que demore 0.1 segundo, reduzindo o tempo total de simula√ß√£o em 90\%.

### Estratifica√ß√£o adaptativa
Uma alternativa interessante √© a estratifica√ß√£o adaptativa, de acordo com o seguinte teorema:

**Teorema 2** (Amostragem Estratificada Adaptativa).
Seja um espa√ßo amostral $\Omega$ particionado em estratos $S_1, S_2, \dots, S_n$. A melhor aloca√ß√£o de amostras para minimizar a vari√¢ncia total do estimador estratificado √© proporcional ao produto do tamanho do estrato e o desvio padr√£o dentro do estrato.

*Prova*.
Seja $N$ o n√∫mero total de amostras, e $N_i$ o n√∫mero de amostras alocadas ao estrato $S_i$. Seja $\sigma_i$ o desvio padr√£o da vari√°vel de interesse dentro do estrato $S_i$. Queremos minimizar a vari√¢ncia do estimador estratificado:

$$Var(\hat{\theta}_{strat}) = \sum_{i=1}^n \left( \frac{P(S_i)}{N_i} \right)^2 \sigma_i^2$$
Onde $P(S_i)$ √© a probabilidade do estrato $S_i$.

Usando os multiplicadores de Lagrange para minimizar $Var(\hat{\theta}_{strat})$ sujeito √† restri√ß√£o $\sum_{i=1}^n N_i = N$, formamos a fun√ß√£o Lagrangiana:

$$L(n_1, n_2, ..., n_H, \lambda) = \sum_{i=1}^H \frac{N_i^2 \sigma_i^2}{n_i} + \lambda \left( \sum_{i=1}^H n_i - n \right)$$

Para encontrar o m√≠nimo, derivamos $L$ em rela√ß√£o a $n_i$ e $\lambda$ e igualamos a zero:

$$\frac{\partial L}{\partial n_i} = -\frac{N_i^2 \sigma_i^2}{n_i^2} + \lambda = 0 \quad \text{para } i = 1, 2, ..., H$$
$$\frac{\partial L}{\partial \lambda} = \sum_{i=1}^H n_i - n = 0$$

Da primeira equa√ß√£o, temos:

$$n_i^2 = \frac{N_i^2 \sigma_i^2}{\lambda} \Rightarrow n_i = \frac{N_i \sigma_i}{\sqrt{\lambda}}$$

Substituindo na segunda equa√ß√£o:

$$\sum_{i=1}^H \frac{N_i \sigma_i}{\sqrt{\lambda}} = n \Rightarrow \sqrt{\lambda} = \frac{1}{n} \sum_{i=1}^H N_i \sigma_i$$

Portanto:

$$n_i = \frac{N_i \sigma_i}{\frac{1}{n} \sum_{i=1}^H N_i \sigma_i} = n \frac{N_i \sigma_i}{\sum_{i=1}^H N_i \sigma_i}$$

Assim, o tamanho √≥timo da amostra para cada estrato √©:

$$n_i = n \cdot \frac{N_i \sigma_i}{\sum_{j=1}^H N_j \sigma_j}$$

Esta f√≥rmula mostra que o tamanho da amostra em cada estrato deve ser proporcional ao tamanho do estrato ($N_i$) e √† variabilidade dentro do estrato ($\sigma_i$). Estratos maiores e mais vari√°veis devem ter amostras maiores.

### Aloca√ß√£o de Neyman

A Aloca√ß√£o de Neyman √© um m√©todo de aloca√ß√£o √≥tima que minimiza a vari√¢ncia do estimador sob um custo fixo. Se os custos de amostragem variarem entre os estratos, a Aloca√ß√£o de Neyman √© mais apropriada.

Seja $c_i$ o custo por unidade amostrada no estrato $i$. O objetivo √© minimizar $Var(\hat{\theta}_{strat})$ sujeito √† restri√ß√£o de custo total:

$$C = \sum_{i=1}^H n_i c_i$$

A fun√ß√£o Lagrangiana neste caso √©:

$$L(n_1, n_2, ..., n_H, \lambda) = \sum_{i=1}^H \frac{N_i^2 \sigma_i^2}{n_i} + \lambda \left( \sum_{i=1}^H n_i c_i - C \right)$$

Derivando em rela√ß√£o a $n_i$ e $\lambda$:

$$\frac{\partial L}{\partial n_i} = -\frac{N_i^2 \sigma_i^2}{n_i^2} + \lambda c_i = 0 \quad \text{para } i = 1, 2, ..., H$$
$$\frac{\partial L}{\partial \lambda} = \sum_{i=1}^H n_i c_i - C = 0$$

Da primeira equa√ß√£o:

$$n_i^2 = \frac{N_i^2 \sigma_i^2}{\lambda c_i} \Rightarrow n_i = \frac{N_i \sigma_i}{\sqrt{\lambda c_i}}$$

Substituindo na segunda equa√ß√£o:

$$\sum_{i=1}^H \frac{N_i \sigma_i}{\sqrt{\lambda c_i}} c_i = C \Rightarrow \sqrt{\lambda} = \frac{1}{C} \sum_{i=1}^H N_i \sigma_i \sqrt{c_i}$$

Portanto:

$$n_i = \frac{N_i \sigma_i \sqrt{c_i}}{\frac{1}{C} \sum_{j=1}^H N_j \sigma_j \sqrt{c_j}} = C \frac{N_i \sigma_i / \sqrt{c_i}}{\sum_{j=1}^H N_j \sigma_j \sqrt{c_j}}$$

Assim, o tamanho √≥timo da amostra para cada estrato usando a Aloca√ß√£o de Neyman √©:

$$n_i = C \cdot \frac{N_i \sigma_i / \sqrt{c_i}}{\sum_{j=1}^H N_j \sigma_j \sqrt{c_j}}$$

Esta f√≥rmula considera tanto o tamanho e a variabilidade do estrato quanto o custo de amostragem. Estratos com menor custo e maior variabilidade receber√£o amostras maiores.

### Exemplo

Suponha que temos uma popula√ß√£o dividida em tr√™s estratos com as seguintes caracter√≠sticas:

*   Estrato 1: $N_1 = 5000$, $\sigma_1 = 10$, $c_1 = 1$
*   Estrato 2: $N_2 = 3000$, $\sigma_2 = 15$, $c_2 = 2$
*   Estrato 3: $N_3 = 2000$, $\sigma_3 = 20$, $c_3 = 3$

E temos um custo total de $C = 1000$.

Calculando os tamanhos de amostra √≥timos para cada estrato:

$$n_1 = 1000 \cdot \frac{5000 \cdot 10 / \sqrt{1}}{5000 \cdot 10 \sqrt{1} + 3000 \cdot 15 / \sqrt{2} + 2000 \cdot 20 / \sqrt{3}}$$
$$n_2 = 1000 \cdot \frac{3000 \cdot 15 / \sqrt{2}}{5000 \cdot 10 \sqrt{1} + 3000 \cdot 15 / \sqrt{2} + 2000 \cdot 20 / \sqrt{3}}$$
$$n_3 = 1000 \cdot \frac{2000 \cdot 20 / \sqrt{3}}{5000 \cdot 10 \sqrt{1} + 3000 \cdot 15 / \sqrt{2} + 2000 \cdot 20 / \sqrt{3}}$$

Calculando os valores:

$$n_1 \approx 1000 \cdot \frac{50000}{50000 + 31819.8 + 23094} \approx 1000 \cdot \frac{50000}{104913.8} \approx 476.59$$
$$n_2 \approx 1000 \cdot \frac{31819.8}{104913.8} \approx 303.29$$
$$n_3 \approx 1000 \cdot \frac{23094}{104913.8} \approx 220.12$$

Arredondando para n√∫meros inteiros:

*   $n_1 \approx 477$
*   $n_2 \approx 303$
*   $n_3 \approx 220$

Portanto, para minimizar a vari√¢ncia com um custo total de 1000, devemos amostrar aproximadamente 477 unidades do estrato 1, 303 unidades do estrato 2 e 220 unidades do estrato 3.

### Vantagens e Desvantagens

**Vantagens:**

*   Reduz a variabilidade das estimativas comparado com a amostragem aleat√≥ria simples, especialmente quando os estratos s√£o homog√™neos internamente.
*   Permite estimativas espec√≠ficas para cada estrato.
*   Pode ser mais eficiente em termos de custo quando os custos de amostragem variam entre os estratos.

**Desvantagens:**

*   Requer conhecimento pr√©vio sobre a popula√ß√£o para formar os estratos.
*   A aloca√ß√£o √≥tima requer conhecimento da variabilidade dentro de cada estrato.
*   Pode ser mais complexo de implementar do que a amostragem aleat√≥ria simples.

### Conclus√£o

A amostragem estratificada √© uma t√©cnica poderosa para melhorar a precis√£o das estimativas em popula√ß√µes heterog√™neas. A escolha entre aloca√ß√£o proporcional e aloca√ß√£o de Neyman depende dos objetivos da pesquisa e das caracter√≠sticas da popula√ß√£o, incluindo custos de amostragem e variabilidade dentro dos estratos. A correta aplica√ß√£o dessas t√©cnicas pode levar a infer√™ncias mais precisas e eficientes.
### Otimiza√ß√£o em Problemas de Machine Learning

A otimiza√ß√£o desempenha um papel central em muitos algoritmos de machine learning. Seja para ajustar os pesos em uma rede neural, encontrar os melhores par√¢metros para um modelo de regress√£o ou otimizar a fun√ß√£o de custo em um algoritmo de clustering, a otimiza√ß√£o √© fundamental para o desempenho do modelo.

#### Gradiente Descendente

O gradiente descendente √© um dos algoritmos de otimiza√ß√£o mais utilizados em machine learning. A ideia b√°sica √© ajustar iterativamente os par√¢metros do modelo na dire√ß√£o oposta ao gradiente da fun√ß√£o de custo. Matematicamente, a atualiza√ß√£o dos par√¢metros $\theta$ √© dada por:

$$
\theta_{t+1} = \theta_t - \eta \nabla J(\theta_t)
$$

onde $\eta$ √© a taxa de aprendizado e $\nabla J(\theta_t)$ √© o gradiente da fun√ß√£o de custo $J$ em rela√ß√£o aos par√¢metros $\theta$ no passo $t$.

#### M√©todos de Segunda Ordem

M√©todos de segunda ordem, como o m√©todo de Newton e m√©todos quase-Newton (BFGS, L-BFGS), usam informa√ß√µes da segunda derivada (Hessiana) da fun√ß√£o de custo para otimizar os par√¢metros. Embora mais complexos computacionalmente, esses m√©todos podem convergir mais rapidamente do que o gradiente descendente em alguns casos.

#### Otimiza√ß√£o Estoc√°stica

Em grandes conjuntos de dados, calcular o gradiente completo da fun√ß√£o de custo pode ser computacionalmente proibitivo. A otimiza√ß√£o estoc√°stica (SGD) resolve esse problema atualizando os par√¢metros usando o gradiente calculado em um subconjunto aleat√≥rio dos dados (um mini-batch). Isso introduz uma vari√¢ncia que pode ajudar a escapar de m√≠nimos locais.

### Teoria dos Jogos

A teoria dos jogos √© um campo da matem√°tica que estuda intera√ß√µes estrat√©gicas entre agentes racionais. Ela oferece ferramentas para analisar situa√ß√µes onde o resultado de um agente depende n√£o s√≥ de suas pr√≥prias a√ß√µes, mas tamb√©m das a√ß√µes de outros agentes.

#### Equil√≠brio de Nash

Um conceito central na teoria dos jogos √© o Equil√≠brio de Nash. Um Equil√≠brio de Nash √© um conjunto de estrat√©gias, uma para cada jogador, onde nenhum jogador pode melhorar seu resultado mudando unilateralmente sua estrat√©gia, dadas as estrat√©gias dos outros jogadores.

#### Aplica√ß√µes

A teoria dos jogos tem aplica√ß√µes em diversas √°reas, incluindo economia, ci√™ncia pol√≠tica, biologia e ci√™ncia da computa√ß√£o. Em economia, √© usada para modelar mercados e leil√µes. Em ci√™ncia da computa√ß√£o, √© usada em design de algoritmos para leil√µes online e em an√°lise de intera√ß√µes em redes sociais.

### Cadeias de Markov

Uma Cadeia de Markov √© um processo estoc√°stico que satisfaz a propriedade de Markov, ou seja, o estado futuro depende apenas do estado presente e n√£o dos estados passados.

#### Defini√ß√£o Formal

Uma Cadeia de Markov √© definida por:
- Um conjunto de estados $S = \{s_1, s_2, ..., s_n\}$.
- Uma matriz de transi√ß√£o $P$, onde $P_{ij} = P(X_{t+1} = s_j | X_t = s_i)$ representa a probabilidade de transi√ß√£o do estado $s_i$ para o estado $s_j$.

#### Propriedades

- **Irredutibilidade:** Uma cadeia √© irredut√≠vel se √© poss√≠vel ir de qualquer estado para qualquer outro estado em um n√∫mero finito de passos.
- **Periodicidade:** O per√≠odo de um estado $i$ √© o maior inteiro $k$ tal que qualquer retorno ao estado $i$ ocorre em m√∫ltiplos de $k$ passos.
- **Recorr√™ncia:** Um estado $i$ √© recorrente se, come√ßando em $i$, o processo eventualmente retorna a $i$ com probabilidade 1.

#### Aplica√ß√µes

Cadeias de Markov s√£o usadas em diversas √°reas, como modelagem de filas, an√°lise de algoritmos, previs√£o do tempo e em modelos de linguagem natural.

<!-- END -->