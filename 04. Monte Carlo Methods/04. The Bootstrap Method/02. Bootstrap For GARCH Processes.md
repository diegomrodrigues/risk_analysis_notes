## O M√©todo Bootstrap Adaptado para Modelos GARCH

### Introdu√ß√£o
Em continuidade ao t√≥pico anterior, que introduziu o m√©todo *bootstrap* como uma alternativa n√£o param√©trica para simula√ß√£o em an√°lise de risco [^7], esta se√ß√£o aprofunda-se na adapta√ß√£o do *bootstrap* para modelos com par√¢metros variantes no tempo, especificamente modelos Generalized Autoregressive Conditional Heteroskedasticity (GARCH) [^8]. Esta adapta√ß√£o visa mitigar a limita√ß√£o da independ√™ncia dos retornos, inerente ao *bootstrap* tradicional, e capturar a din√¢mica de volatilidade comum em s√©ries temporais financeiras.

### Conceitos Fundamentais
Modelos GARCH s√£o amplamente utilizados para modelar a volatilidade condicional de s√©ries temporais financeiras [^8]. A ideia central √© que a volatilidade em um dado per√≠odo depende da volatilidade e dos retornos dos per√≠odos anteriores. Ao aplicar o *bootstrap* aos res√≠duos normalizados de um modelo GARCH, √© poss√≠vel simular cen√°rios futuros que incorporam a din√¢mica de volatilidade estimada pelo modelo [^8].

**Adapta√ß√£o do Bootstrap para Modelos GARCH:**

1.  **Ajuste do Modelo GARCH:** Estima-se um modelo GARCH para a s√©rie hist√≥rica de retornos, obtendo os par√¢metros do modelo e as volatilidades condicionais estimadas $\sigma_t$ para cada per√≠odo $t$ [^8].

2.  **C√°lculo dos Res√≠duos Normalizados:** Calcula-se os res√≠duos normalizados $\epsilon_t$ dividindo o retorno $r_t$ pela volatilidade condicional estimada $\sigma_t$:
    $$ \epsilon_t = \frac{r_t}{\sigma_t} $$
    Os res√≠duos normalizados representam os choques imprevis√≠veis nos retornos, ap√≥s remover a din√¢mica de volatilidade capturada pelo modelo GARCH [^8].

    > üí° **Exemplo Num√©rico:** Suponha que o retorno $r_t$ em um dia seja 0.01 (1%) e a volatilidade condicional estimada $\sigma_t$ pelo modelo GARCH seja 0.02 (2%). Ent√£o, o res√≠duo normalizado seria:
    > $$\epsilon_t = \frac{0.01}{0.02} = 0.5$$
    > Este valor de 0.5 representa o choque normalizado no retorno, indicando que o retorno foi metade do desvio padr√£o esperado com base na volatilidade condicional.

3.  **Reamostragem dos Res√≠duos Normalizados:** Aplica-se o m√©todo *bootstrap* aos res√≠duos normalizados $\epsilon_t$, reamostrando-os com reposi√ß√£o para criar uma nova s√©rie de res√≠duos normalizados $\epsilon_t^*$ [^8].

    > üí° **Exemplo Num√©rico:** Se temos os seguintes res√≠duos normalizados: [-0.5, 0.2, 1.0, -0.8, 0.3]. Ao reamostrar com reposi√ß√£o, podemos obter uma nova s√©rie como: [0.2, -0.5, 0.3, 1.0, -0.5]. Note que alguns valores podem se repetir, e outros podem n√£o aparecer na amostra reamostrada.

4.  **Reconstru√ß√£o dos Pseudoretornos:** Utiliza-se a s√©rie de res√≠duos normalizados reamostrados $\epsilon_t^*$ e as volatilidades condicionais estimadas $\sigma_t$ para reconstruir uma nova s√©rie de retornos simulados $r_t^*$:

    $$ r_t^* = \epsilon_t^* \cdot \sigma_t $$
    Esta etapa garante que os pseudoretornos simulados incorporem a din√¢mica de volatilidade modelada pelo GARCH [^8].

    > üí° **Exemplo Num√©rico:** Usando o res√≠duo normalizado reamostrado $\epsilon_t^* = 0.2$ e a volatilidade condicional estimada $\sigma_t = 0.02$, o pseudoretorno simulado seria:
    > $$r_t^* = 0.2 \cdot 0.02 = 0.004$$
    > Isso significa que o retorno simulado √© 0.4%, incorporando a volatilidade estimada pelo modelo GARCH.

5.  **Simula√ß√£o da Volatilidade Futura:** Para simular a volatilidade futura, utiliza-se o modelo GARCH com os par√¢metros estimados e os pseudoretornos simulados $r_t^*$ para projetar as volatilidades condicionais futuras $\sigma_{t+1}, \sigma_{t+2}, \ldots$. Isso requer uma inicializa√ß√£o adequada da volatilidade, geralmente utilizando a √∫ltima volatilidade condicional estimada na s√©rie hist√≥rica [^8].

    > üí° **Exemplo Num√©rico:** Suponha um modelo GARCH(1,1) da forma:
    > $$\sigma_{t+1}^2 = \alpha_0 + \alpha_1 r_t^{*2} + \beta_1 \sigma_t^2$$
    > Com par√¢metros estimados $\alpha_0 = 0.00001$, $\alpha_1 = 0.05$, $\beta_1 = 0.9$, o √∫ltimo retorno simulado $r_t^* = 0.004$, e a √∫ltima volatilidade condicional estimada $\sigma_t^2 = 0.0004$, a volatilidade condicional para o pr√≥ximo per√≠odo seria:
    > $$\sigma_{t+1}^2 = 0.00001 + 0.05 \cdot (0.004)^2 + 0.9 \cdot 0.0004 = 0.0003708$$
    > $$\sigma_{t+1} = \sqrt{0.0003708} \approx 0.01926$$
    > A volatilidade condicional projetada para o pr√≥ximo per√≠odo √© de aproximadamente 1.93%.

6.  **Repeti√ß√£o:** Repete-se os passos 3 a 5 um grande n√∫mero de vezes (K vezes) para gerar uma distribui√ß√£o de poss√≠veis trajet√≥rias futuras dos retornos e das volatilidades [^8].

    > üí° **Exemplo Num√©rico:** Se repetirmos os passos 3 a 5 K = 1000 vezes, teremos 1000 trajet√≥rias poss√≠veis de retornos e volatilidades. Podemos usar essas trajet√≥rias para calcular diversas estat√≠sticas de risco, como o VAR.

7.  **C√°lculo do VAR:** Utiliza-se as trajet√≥rias simuladas dos retornos para calcular o valor do portf√≥lio em cada cen√°rio. O VAR √© ent√£o estimado a partir dos quantis da distribui√ß√£o dos valores simulados do portf√≥lio [^8].

    > üí° **Exemplo Num√©rico:** Suponha que simulamos 1000 trajet√≥rias e calculamos o valor do portf√≥lio para cada uma delas. Para estimar o VAR a 95%, ordenamos os valores do portf√≥lio e pegamos o 50¬∫ menor valor. Este valor representa a perda que n√£o deve ser excedida em 95% dos cen√°rios simulados.

**Teorema 1** [Converg√™ncia Assint√≥tica do Bootstrap para Estat√≠sticas Suaves]: Seja $G(F)$ uma estat√≠stica suave da fun√ß√£o de distribui√ß√£o emp√≠rica $F$. Sob certas condi√ß√µes de regularidade, a distribui√ß√£o *bootstrap* de $G(F^*)$ converge fracamente para a distribui√ß√£o de $G(F)$ quando o tamanho da amostra tende ao infinito.

*Estrat√©gia da Demonstra√ß√£o:* A demonstra√ß√£o envolve o uso do Teorema da Fun√ß√£o Delta e argumentos de converg√™ncia fraca. √â necess√°rio mostrar que a estat√≠stica $G$ √© suficientemente suave e que a fun√ß√£o de distribui√ß√£o emp√≠rica converge para a verdadeira fun√ß√£o de distribui√ß√£o.

**Observa√ß√£o:** O Teorema 1 estabelece a base te√≥rica para a validade do m√©todo *bootstrap* em uma ampla classe de problemas estat√≠sticos. No contexto do *bootstrap*-GARCH, a estat√≠stica $G(F)$ pode representar o VAR ou outras medidas de risco calculadas a partir das trajet√≥rias simuladas dos retornos.

**Proposi√ß√£o 2.1** [Consist√™ncia do Estimador Bootstrap-GARCH]: Sob certas condi√ß√µes de regularidade do modelo GARCH e da s√©rie hist√≥rica, o estimador *bootstrap* do VAR baseado nos res√≠duos normalizados de um modelo GARCH converge em probabilidade para o verdadeiro VAR √† medida que o tamanho da amostra hist√≥rica aumenta e o n√∫mero de simula√ß√µes *bootstrap* tende ao infinito.

*Estrat√©gia da Demonstra√ß√£o:* A demonstra√ß√£o envolve combinar a teoria da converg√™ncia dos estimadores de modelos GARCH com a teoria da converg√™ncia do *bootstrap*. √â necess√°rio garantir que os res√≠duos normalizados converjam para uma distribui√ß√£o bem comportada e que o modelo GARCH capture adequadamente a din√¢mica de volatilidade.

*Prova da Proposi√ß√£o 2.1:*

I. Seja $VaR_{\alpha}$ o verdadeiro Valor em Risco ao n√≠vel $\alpha$. Seja $\widehat{VaR}_{\alpha, K}^{GARCH}$ o estimador Bootstrap-GARCH do VaR, baseado em $K$ simula√ß√µes Bootstrap dos res√≠duos normalizados de um modelo GARCH.

II. Queremos mostrar que para qualquer $\epsilon > 0$,
   $$P(|\widehat{VaR}_{\alpha, K}^{GARCH} - VaR_{\alpha}| > \epsilon) \rightarrow 0 \quad \text{quando } M \rightarrow \infty \text{ e } K \rightarrow \infty$$
   onde $M$ √© o tamanho da amostra hist√≥rica.

III. Sob condi√ß√µes de regularidade do modelo GARCH (por exemplo, exist√™ncia de momentos finitos, condi√ß√µes de estacionariedade) e da s√©rie hist√≥rica, os estimadores dos par√¢metros do modelo GARCH s√£o consistentes. Isso significa que os par√¢metros estimados $\widehat{\theta}$ convergem para os verdadeiros par√¢metros $\theta$ quando $M \rightarrow \infty$.

IV. Al√©m disso, sob condi√ß√µes de regularidade, os res√≠duos normalizados $\epsilon_t = r_t / \sigma_t$ convergem para uma distribui√ß√£o com m√©dia zero e vari√¢ncia unit√°ria.

V. Pela Proposi√ß√£o 1, a distribui√ß√£o emp√≠rica dos res√≠duos normalizados reamostrados converge para a verdadeira distribui√ß√£o dos res√≠duos normalizados quando $K \rightarrow \infty$.

VI. Combinando esses resultados, temos que as trajet√≥rias simuladas dos retornos $r_t^* = \epsilon_t^* \cdot \sigma_t$ convergem para a verdadeira distribui√ß√£o dos retornos, dado o modelo GARCH. Portanto, o estimador Bootstrap-GARCH do VAR converge em probabilidade para o verdadeiro VAR quando $M \rightarrow \infty$ e $K \rightarrow \infty$. ‚ñ†

**Lema 2.1** [Efeito da Estima√ß√£o dos Par√¢metros GARCH]: A precis√£o da estimativa dos par√¢metros do modelo GARCH tem um impacto direto na precis√£o do VAR estimado via Bootstrap-GARCH.

*Estrat√©gia da Demonstra√ß√£o:* A demonstra√ß√£o pode ser feita atrav√©s de simula√ß√µes de Monte Carlo, onde se varia a precis√£o da estimativa dos par√¢metros GARCH (e.g., usando diferentes tamanhos de amostra para a estima√ß√£o inicial) e observa-se o impacto na distribui√ß√£o do VAR estimado.

**Lema 2.2** [Impacto do Tamanho da Amostra no Bootstrap-GARCH]: Tamanhos de amostra hist√≥ricos pequenos podem levar a estimativas imprecisas dos par√¢metros do modelo GARCH e a uma representa√ß√£o pobre da distribui√ß√£o dos res√≠duos normalizados, afetando a precis√£o do estimador *bootstrap* do VAR.

*Estrat√©gia da Demonstra√ß√£o:* A demonstra√ß√£o envolve simula√ß√µes de Monte Carlo para avaliar o desempenho do estimador *bootstrap* do VAR com diferentes tamanhos de amostra hist√≥rica. M√©tricas como vi√©s, erro quadr√°tico m√©dio e cobertura dos intervalos de confian√ßa podem ser usadas para quantificar o impacto do tamanho da amostra.

*Prova do Lema 2.2:*

I. Seja $M$ o tamanho da amostra hist√≥rica. O desempenho do Bootstrap-GARCH depende da precis√£o das estimativas dos par√¢metros do modelo GARCH.

II. A precis√£o das estimativas dos par√¢metros do modelo GARCH aumenta com o tamanho da amostra. Para um modelo GARCH(1,1), a vari√¢ncia dos estimadores dos par√¢metros diminui com $M$.

III. Se $M$ √© pequeno, as estimativas dos par√¢metros do modelo GARCH podem ser imprecisas e inst√°veis. Isso leva a estimativas imprecisas das volatilidades condicionais $\sigma_t$ e, consequentemente, a res√≠duos normalizados $\epsilon_t$ que n√£o representam adequadamente os choques imprevis√≠veis nos retornos.

IV. A reamostragem desses res√≠duos imprecisos leva a simula√ß√µes de trajet√≥rias de retornos que n√£o refletem a verdadeira din√¢mica da s√©rie temporal. Isso afeta a precis√£o do estimador Bootstrap-GARCH do VAR.

V. Simula√ß√µes de Monte Carlo podem ser usadas para quantificar esse impacto. Ao simular dados de um modelo GARCH conhecido e aplicar o Bootstrap-GARCH com diferentes tamanhos de amostra, podemos avaliar o vi√©s e o erro quadr√°tico m√©dio do estimador do VAR. ‚ñ†

**Vantagens da Adapta√ß√£o GARCH:**

*   **Captura da Volatilidade Condicional:** Incorpora a din√¢mica de volatilidade, que √© uma caracter√≠stica fundamental de s√©ries temporais financeiras [^8].
*   **Melhoria na Precis√£o:** Pode levar a estimativas de risco mais precisas, especialmente em per√≠odos de alta volatilidade [^8].

**Limita√ß√µes da Adapta√ß√£o GARCH:**

*   **Complexidade:** A implementa√ß√£o √© mais complexa do que o *bootstrap* tradicional, exigindo o ajuste e a valida√ß√£o do modelo GARCH [^8].
*   **Sensibilidade ao Modelo:** A precis√£o das estimativas depende da qualidade do modelo GARCH ajustado. Um modelo mal especificado pode levar a resultados enganosos [^8].
*   **Assun√ß√£o de Estacionariedade:** Modelos GARCH geralmente assumem estacionariedade dos retornos, o que pode n√£o ser v√°lido em todos os cen√°rios [^8].

**Corol√°rio 2.1** [Intervalos de Confian√ßa para o VAR Bootstrap-GARCH]: Intervalos de confian√ßa para o VAR podem ser constru√≠dos a partir da distribui√ß√£o *bootstrap* das simula√ß√µes. A amplitude desses intervalos reflete a incerteza na estimativa do VAR.

*Estrat√©gia da Demonstra√ß√£o:* Os intervalos de confian√ßa podem ser constru√≠dos usando m√©todos percentis ou m√©todos baseados no erro padr√£o *bootstrap*. A escolha do m√©todo depende das propriedades da distribui√ß√£o *bootstrap*.

*Prova do Corol√°rio 2.1:*
I. Seja $\widehat{VaR}_{\alpha, K}^{GARCH, (i)}$ o $i$-√©simo estimador Bootstrap-GARCH do VaR, onde $i = 1, \dots, K$. Esses estimadores s√£o obtidos a partir de $K$ simula√ß√µes independentes do Bootstrap-GARCH.

II. Ordenamos os estimadores Bootstrap-GARCH do VaR: $\widehat{VaR}_{\alpha, K}^{GARCH, (1)} \leq \widehat{VaR}_{\alpha, K}^{GARCH, (2)} \leq \dots \leq \widehat{VaR}_{\alpha, K}^{GARCH, (K)}$.

III. Para um n√≠vel de confian√ßa $1 - \gamma$, onde $\gamma \in (0, 1)$, o intervalo de confian√ßa percentil Bootstrap-GARCH √© dado por:
$$IC = [\widehat{VaR}_{\alpha, K}^{GARCH, (K \cdot \gamma/2)}, \widehat{VaR}_{\alpha, K}^{GARCH, (K \cdot (1 - \gamma/2))}]$$
onde $K \cdot \gamma/2$ e $K \cdot (1 - \gamma/2)$ s√£o arredondados para o inteiro mais pr√≥ximo.

IV. A amplitude deste intervalo de confian√ßa reflete a incerteza na estimativa do VaR. Intervalos mais amplos indicam maior incerteza. A converg√™ncia deste intervalo para um intervalo centrado no verdadeiro $VaR_{\alpha}$ depende da consist√™ncia do estimador Bootstrap-GARCH (Proposi√ß√£o 2.1). ‚ñ†

    > üí° **Exemplo Num√©rico:** Se temos K=1000 simula√ß√µes Bootstrap-GARCH do VaR, e queremos construir um intervalo de confian√ßa de 95% (Œ≥ = 0.05), ent√£o:
    >  *  $K \cdot \gamma/2 = 1000 \cdot 0.05/2 = 25$
    >  *  $K \cdot (1 - \gamma/2) = 1000 \cdot (1 - 0.05/2) = 975$
    > O intervalo de confian√ßa de 95% seria dado pelos estimadores Bootstrap-GARCH do VaR nas posi√ß√µes 25 e 975 da lista ordenada. Se $\widehat{VaR}_{\alpha, K}^{GARCH, (25)} = -0.05$ e $\widehat{VaR}_{\alpha, K}^{GARCH, (975)} = -0.02$, ent√£o o intervalo de confian√ßa de 95% para o VaR seria [-0.05, -0.02].

### Conclus√£o
A adapta√ß√£o do m√©todo *bootstrap* para modelos GARCH representa uma abordagem sofisticada para a an√°lise de risco, permitindo a incorpora√ß√£o da din√¢mica de volatilidade em simula√ß√µes baseadas em dados hist√≥ricos [^8]. Embora apresente maior complexidade e depend√™ncia da qualidade do modelo GARCH, essa t√©cnica pode levar a estimativas de risco mais precisas e robustas, especialmente em mercados vol√°teis [^8]. A escolha entre o *bootstrap* tradicional e a adapta√ß√£o GARCH depende das caracter√≠sticas dos dados e dos objetivos da an√°lise de risco.

## 12.3 Speed Versus Accuracy

### Acur√°cia e Variabilidade
As simula√ß√µes inerentemente geram **variabilidade de amostragem**, ou varia√ß√µes nos valores dos estimadores, devido ao n√∫mero limitado de replica√ß√µes [^316]. Mais replica√ß√µes levam a estimativas mais precisas, mas demoram mais para serem estimadas [^316]. Defina $K$ como o n√∫mero de replica√ß√µes, ou tentativas pseudoaleat√≥rias. Para escolher $K$, √© √∫til avaliar o *trade-off* entre precis√£o e o n√∫mero de replica√ß√µes [^316].

A Figura 12-3 [^317] ilustra a **converg√™ncia da distribui√ß√£o emp√≠rica** na Figura 12-1 para a verdadeira. Com $K = 100$, o histograma que representa a distribui√ß√£o do pre√ßo final √© bastante irregular [^317]. O histograma torna-se mais suave com 1000 replica√ß√µes, ainda mais com 10.000 replica√ß√µes, e eventualmente deve convergir para a distribui√ß√£o cont√≠nua no painel direito [^317]. Uma vantagem do m√©todo de Monte Carlo √© que o usu√°rio pode avaliar o aumento na precis√£o diretamente √† medida que o n√∫mero de replica√ß√µes aumenta [^317].

Se o processo subjacente for normal, a distribui√ß√£o emp√≠rica deve convergir para uma distribui√ß√£o normal [^317]. Nesta situa√ß√£o, a an√°lise de Monte Carlo deve produzir exatamente o mesmo resultado que o m√©todo delta-normal: o VAR estimado do quantil da amostra deve convergir para o valor de $\alpha\sigma$ [^317]. Qualquer desvio deve-se √† varia√ß√£o da amostragem [^317]. Assumindo nenhuma outra fonte de erro, este efeito pode ser medido pelo erro padr√£o assint√≥tico para o quantil da amostra relatado no Cap√≠tulo 5, usando $K$ como o tamanho da amostra [^317]. Um m√©todo simples para avaliar a precis√£o √© repetir as simula√ß√µes m√∫ltiplas vezes, digamos, $M = 1000$, e calcular o erro padr√£o dos quantis estimados nos experimentos $M$ [^317]. Isso √© ilustrado na Tabela 12-2 [^318].

![Converg√™ncia da distribui√ß√£o emp√≠rica](./../images/figure3.jpg)

A Tabela 12-2 [^318] descreve os resultados de 1000 execu√ß√µes de simula√ß√£o em uma distribui√ß√£o normal padr√£o com um n√∫mero crescente de replica√ß√µes. A tabela mostra que, para um VAR de 99% com 100 replica√ß√µes, o erro padr√£o da estimativa em torno de -2,326 √© 0,409, bastante alto [^318]. Em nossa amostra de 1000 execu√ß√µes, a estimativa de VAR variou de -4,17 a -1,53 [^318]. Essa dispers√£o √© bastante perturbadora [^318]. Para aumentar a precis√£o do VAR por um fator de 10, precisamos aumentar o n√∫mero de replica√ß√µes por um fator de 100, para um total de 10.000 [^318]. De fato, a primeira linha mostra que isso diminui o erro padr√£o para 0,037, que √© aproximadamente 0,409 dividido por 10 [^318]. Note que, em contraste, o desvio padr√£o √© estimado de forma muito mais precisa porque usa dados de toda a distribui√ß√£o [^318].

Tamb√©m poder√≠amos relatar o erro padr√£o em termos relativos, definido como a raz√£o entre o erro padr√£o e o valor esperado da medida de risco [^318]. Por exemplo, os bancos normalmente relatam seu VAR de 99% usando cerca de 500 dias [^318]. Da Tabela 12-2 [^318], isso leva a um erro relativo no VAR de cerca de 0,170/2,326 = 7,3% [^318].

> üí° **Exemplo Num√©rico:** Vamos supor que um banco estima seu VAR de 99% usando 500 replica√ß√µes e obt√©m um VAR de \$ 1 milh√£o. Usando a Tabela 12-2, o erro padr√£o √© aproximadamente 0.170 * desvio padr√£o. Se o desvio padr√£o do portf√≥lio for \$ 10 milh√µes, o erro padr√£o do VAR seria 0.170 * 10 = \$ 1.7 milh√µes. O erro relativo seria \$ 1.7/\$ 1 = 170%. Isso demonstra como o erro relativo pode ser significativo com um n√∫mero limitado de simula√ß√µes.

O erro relativo depende do n√∫mero de replica√ß√µes, bem como da forma da distribui√ß√£o, como mostrado na Tabela 12-3 [^319]. A tabela mostra que o erro √© maior para distribui√ß√µes com assimetria √† esquerda e, inversamente, menor para distribui√ß√µes com assimetria √† direita [^319]. Isso ocorre porque quanto mais longa a cauda esquerda, menos precisa √© a estimativa de VAR [^319].

Alternativamente, poder√≠amos procurar o n√∫mero de replica√ß√µes necess√°rias para medir o VAR com um erro relativo de 1% [^319]. Para a distribui√ß√£o normal, precisamos de mais de 20.000 replica√ß√µes para garantir que o erro relativo na primeira linha esteja abaixo de 1% [^319].

### M√©todos de Acelera√ß√£o

Isso levou a uma busca por **m√©todos para acelerar os c√°lculos** [^319]. Um dos mais antigos e f√°ceis √© a **t√©cnica da vari√°vel antit√©tica**, que consiste em mudar o sinal de todas as amostras aleat√≥rias $\epsilon$ [^319]. Este m√©todo, que √© apropriado quando a distribui√ß√£o original √© sim√©trica, cria o dobro do n√∫mero de replica√ß√µes para os fatores de risco a um custo adicional pequeno [^319]. Ainda precisamos, no entanto, do dobro do n√∫mero original de avalia√ß√µes completas na data de destino [^319].

> üí° **Exemplo Num√©rico:** Imagine que estamos simulando retornos usando uma distribui√ß√£o normal padr√£o. Geramos um n√∫mero aleat√≥rio $\epsilon = 0.7$. Com a t√©cnica da vari√°vel antit√©tica, tamb√©m usar√≠amos $-\epsilon = -0.7$. Se o retorno simulado for calculado como $r = \mu + \sigma\epsilon$, onde $\mu = 0$ e $\sigma = 0.1$, ter√≠amos dois retornos simulados: $r_1 = 0 + 0.1 * 0.7 = 0.07$ e $r_2 = 0 + 0.1 * (-0.7) = -0.07$. Isso dobra o n√∫mero de simula√ß√µes efetivas sem gerar n√∫meros aleat√≥rios adicionais.

Essa abordagem pode ser aplicada ao m√©todo de simula√ß√£o hist√≥rica, onde podemos adicionar um vetor de mudan√ßas hist√≥ricas de pre√ßos com o sinal invertido [^319]. Isso tamb√©m √© √∫til para eliminar o efeito de tend√™ncias nos dados hist√≥ricos recentes [^319].

Outra ferramenta √∫til √© a **t√©cnica das vari√°veis de controle** [^319]. Estamos tentando estimar o VAR, uma fun√ß√£o da amostra de dados [^319]. Chame isso de $V(X)$ [^319]. Assuma agora que a fun√ß√£o pode ser aproximada por outra fun√ß√£o, como uma aproxima√ß√£o quadr√°tica $V^0(X)$, para a qual temos uma solu√ß√£o de forma fechada $v^0$ [^319].

Para qualquer amostra, o erro ent√£o √© conhecido como sendo $V^0(X) - v^0$ para a aproxima√ß√£o quadr√°tica [^320]. Se este erro for altamente correlacionado com o erro de amostragem em $V(X)$, o estimador de vari√°vel de controle pode ser tomado como

$$V_{CV} = V(X) - [V^0(X) - v^0] \qquad (12.5)$$

Este estimador tem uma vari√¢ncia muito menor do que o original quando a fun√ß√£o quadr√°tica fornece uma boa aproxima√ß√£o da verdadeira fun√ß√£o [^320].

*Prova da redu√ß√£o da vari√¢ncia do estimador de vari√°vel de controle:*

I. Sejam $V(X)$ o estimador original e $V_{CV}$ o estimador de vari√°vel de controle, dado por $V_{CV} = V(X) - [V^0(X) - v^0]$, onde $V^0(X)$ √© uma aproxima√ß√£o de $V(X)$ com valor esperado conhecido $v^0 = E[V^0(X)]$.

II. A vari√¢ncia do estimador de vari√°vel de controle √©:
$$Var(V_{CV}) = Var(V(X) - [V^0(X) - v^0]) = Var(V(X) - V^0(X))$$
pois $v^0$ √© uma constante e n√£o contribui para a vari√¢ncia.

III. Expandindo a vari√¢ncia, temos:
$$Var(V_{CV}) = Var(V(X)) + Var(V^0(X)) - 2Cov(V(X), V^0(X))$$

IV. Queremos mostrar que $Var(V_{CV}) < Var(V(X))$. Isso √© equivalente a mostrar que:
$$Var(V^0(X)) < 2Cov(V(X), V^0(X))$$

V. Usando a defini√ß√£o de correla√ß√£o, $\rho = \frac{Cov(V(X), V^0(X))}{\sqrt{Var(V(X))Var(V^0(X))}}$, podemos reescrever a covari√¢ncia como:
$$Cov(V(X), V^0(X)) = \rho \sqrt{Var(V(X))Var(V^0(X))}$$

VI. Substituindo na desigualdade, obtemos:
$$Var(V^0(X)) < 2\rho \sqrt{Var(V(X))Var(V^0(X))}$$
Dividindo ambos os lados por $\sqrt{Var(V^0(X))}$, temos:
$$\sqrt{Var(V^0(X))} < 2\rho \sqrt{Var(V(X))}$$
Elevando ao quadrado ambos os lados:
$$Var(V^0(X)) < 4\rho^2 Var(V(X))$$

VII. Para que $Var(V_{CV}) < Var(V(X))$, √© suficiente que a correla√ß√£o $\rho$ entre $V(X)$ e $V^0(X)$ seja alta o suficiente. Especificamente, se $\rho > \frac{1}{2} \sqrt{\frac{Var(V^0(X))}{Var(V(X))}}$, ent√£o a vari√¢ncia do estimador de vari√°vel de controle ser√° menor do que a vari√¢ncia do estimador original. Em casos pr√°ticos, uma correla√ß√£o alta entre $V(X)$ e $V^0(X)$ garante a redu√ß√£o da vari√¢ncia. ‚ñ†

> üí° **Exemplo Num√©rico:** Suponha que queremos estimar o VAR de uma carteira de op√ß√µes usando simula√ß√£o de Monte Carlo ($V(X)$). Podemos aproximar o VAR usando o m√©todo delta-normal ($V^0(X)$), que tem uma solu√ß√£o anal√≠tica ($v^0$). Se o VAR estimado por simula√ß√£o for $V(X) = \$ 1.2 milh√£o e o VAR estimado pelo m√©todo delta-normal for $V^0(X) = \$ 1 milh√£o (com $v^0 = \$ 1 milh√£o), ent√£o o estimador de vari√°vel de controle seria:
>
> $$V_{CV} = V(X) - [V^0(X) - v^0] = 1.2 - [1 - 1] = 1.2 \text{ (milh√µes)}$$
>
> Neste caso particular, a aproxima√ß√£o delta-normal n√£o adiciona informa√ß√£o, mas em geral, se a aproxima√ß√£o delta-normal fosse uma estimativa melhor, reduziria a vari√¢ncia do estimador.

O m√©todo de acelera√ß√£o mais eficaz √© a **t√©cnica de amostragem por import√¢ncia**, que tenta amostrar ao longo dos caminhos que s√£o mais importantes para o problema em quest√£o [^320]. A ideia √© que, se nosso objetivo √© medir com precis√£o um quantil de cauda, n√£o h√° sentido em fazer simula√ß√µes que gerem observa√ß√µes no centro da distribui√ß√£o [^320]. O m√©todo envolve mudan√ßas na distribui√ß√£o de vari√°veis aleat√≥rias [^320]. Glasserman et al. (2000) [^320] mostram que, em rela√ß√£o ao m√©todo de Monte Carlo usual, a vari√¢ncia dos estimadores de VAR pode ser reduzida por um fator de pelo menos 10 [^320].

Uma aplica√ß√£o relacionada √© a **t√©cnica de amostragem estratificada**, que pode ser explicada intuitivamente da seguinte forma: assuma que precisamos de VAR para uma posi√ß√£o longa em uma op√ß√£o de compra [^320]. Estamos tentando manter o n√∫mero de replica√ß√µes em $K = 1000$ [^320]. Para aumentar a precis√£o do estimador de VAR, poder√≠amos particionar a regi√£o de simula√ß√£o em duas zonas [^320]. Como antes, come√ßamos com uma distribui√ß√£o uniforme, que ent√£o √© transformada em uma distribui√ß√£o normal para o pre√ßo do ativo subjacente usando o *m√©todo de transforma√ß√£o inversa* [^320].

Defina essas duas zonas, ou estratos, para a distribui√ß√£o uniforme como [0,0, 0,1] e [0,1, 1,0] [^320]. Assim, *estratifica√ß√£o* √© o processo de agrupar os dados em regi√µes mutuamente exclusivas e coletivamente exaustivas [^320]. Normalmente, as probabilidades do n√∫mero aleat√≥rio cair em ambas as zonas s√£o selecionadas como $p_1 = 10\%$ e $p_2 = 90\%$, respectivamente [^320]. Agora mudamos essas probabilidades para 50% para ambas as regi√µes [^320]. O n√∫mero de observa√ß√µes agora √© $K_1 = 500$ para a primeira regi√£o e $K_2 = 500$ para a segunda [^320]. Isso aumenta o n√∫mero de amostras para o fator de risco na primeira regi√£o da cauda esquerda [^320].

Os estimadores para a m√©dia precisam ser ajustados para a estratifica√ß√£o [^320]. Ponderamos o estimador para cada regi√£o por sua probabilidade, isto √©,

$$E(F_T) = p_1 \frac{\sum_{i=1}^{K_1} F_i}{K_1} + p_2 \frac{\sum_{i=1}^{K_2} F_i}{K_2} \qquad (12.6)$$

> üí° **Exemplo Num√©rico:** Imagine que estamos simulando o pre√ßo de uma op√ß√£o de compra no vencimento ($F_T$). Dividimos a distribui√ß√£o uniforme em duas zonas: [0, 0.1] e [0.1, 1.0]. Inicialmente, a probabilidade de um n√∫mero aleat√≥rio cair na primeira zona (cauda esquerda) √© $p_1 = 0.1$ e na segunda zona √© $p_2 = 0.9$. Com amostragem estratificada, mudamos as probabilidades para $p_1 = 0.5$ e $p_2 = 0.5$, e realizamos $K_1 = 500$ simula√ß√µes na primeira zona e $K_2 = 500$ simula√ß√µes na segunda zona. Se a m√©dia dos pre√ßos simulados na primeira zona for $\frac{\sum_{i=1}^{500} F_i}{500} = \$ 10 e a m√©dia na segunda zona for $\frac{\sum_{i=1}^{500} F_i}{500} = \$ 50, ent√£o o pre√ßo esperado da op√ß√£o seria:
>
> $$E(F_T) = p_1 \cdot \frac{\sum_{i=1}^{K_1} F_i}{K_1} + p_2 \cdot \frac{\sum_{i=1}^{K_2} F_i}{K_2} = 0.1 \cdot 10 + 0.9 \cdot 50 = 46 \text{ (sem amostragem estratificada)}$$
> $$E(F_T) = p_1 \cdot \frac{\sum_{i=1}^{K_1} F_i}{K_1} + p_2 \cdot \frac{\sum_{i=1}^{K_2} F_i}{K_2} = 0.5 \cdot 10 + 0.5 \cdot 50 = 30 \text{ (com amostragem estratificada)}$$
>
> Ajustando as probabilidades e amostrando igualmente em ambas as zonas, damos mais peso √† cauda esquerda, o que melhora a precis√£o da estimativa do VAR.
<!-- END -->