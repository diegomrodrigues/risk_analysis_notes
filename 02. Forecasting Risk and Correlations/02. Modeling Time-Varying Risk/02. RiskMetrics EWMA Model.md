## Modeling Time-Varying Risk

### Introdu√ß√£o

Em continuidade √† discuss√£o sobre modelagem de risco vari√°vel no tempo, esta se√ß√£o aborda a abordagem RiskMetrics, que utiliza uma **M√©dia M√≥vel Ponderada Exponencialmente (EWMA)** para modelar as vari√¢ncias [^7]. Como vimos anteriormente, as m√©dias m√≥veis simples sofrem de diversas limita√ß√µes, como o tratamento igualit√°rio de dados antigos e recentes e a cria√ß√£o de "ghosting features". A abordagem EWMA busca mitigar essas limita√ß√µes ao atribuir pesos que decrescem exponencialmente √†s observa√ß√µes passadas, dando maior import√¢ncia aos dados mais recentes [^1].

### Conceitos Fundamentais

O modelo **RiskMetrics** √© uma abordagem pragm√°tica para modelar o risco [^7]. As vari√¢ncias s√£o modeladas usando uma previs√£o de m√©dia m√≥vel ponderada exponencialmente (EWMA) [^7]. Formalmente, a previs√£o para o tempo *t* √© uma m√©dia ponderada da previs√£o anterior, usando o peso $\lambda$, e da inova√ß√£o ao quadrado mais recente, usando o peso $(1-\lambda)$ [^7]:

$$
h_t = \lambda h_{t-1} + (1-\lambda)r_{t-1}^2 \qquad(9.9)
$$

Aqui, $\lambda$ √© o **fator de decaimento** (*decay factor*) e deve ser menor que a unidade [^7]. O modelo exponencial atribui pesos geometricamente decrescentes √†s observa√ß√µes passadas, atribuindo assim maior import√¢ncia √†s observa√ß√µes recentes [^7]. Recursivamente substituindo $h_{t-1}$ na Equa√ß√£o (9.9), podemos escrever [^7]:

$$
h_t = (1 - \lambda) (r_{t-1}^2 + \lambda r_{t-2}^2 + \lambda^2 r_{t-3}^2 + ...) \qquad(9.10)
$$

Este resultado √© equivalente ao **Teorema 1** da se√ß√£o anterior sobre m√©dias m√≥veis ponderadas exponencialmente.

> üí° **Exemplo Num√©rico:**
>
> Vamos usar a f√≥rmula EWMA com $\lambda = 0.94$. Suponha que $h_{t-1} = 0.0001$ (volatilidade di√°ria anterior) e $r_{t-1} = 0.015$ (retorno mais recente).
>
> $h_t = 0.94 * 0.0001 + (1 - 0.94) * (0.015)^2$
>
> $h_t = 0.000094 + 0.06 * 0.000225 = 0.000094 + 0.0000135 = 0.0001075$
>
> A volatilidade para o tempo *t* √© $\sqrt{0.0001075} \approx 0.01037$ ou 1.037%.
>
> Agora, suponha que no tempo *t*, o retorno $r_t$ √© 0.02. A nova volatilidade para o tempo *t+1* seria:
>
> $h_{t+1} = 0.94 * 0.0001075 + (1 - 0.94) * (0.02)^2$
>
> $h_{t+1} = 0.00010105 + 0.06 * 0.0004 = 0.00010105 + 0.000024 = 0.00012505$
>
> A volatilidade para o tempo *t+1* √© $\sqrt{0.00012505} \approx 0.01118$ ou 1.118%. Isso demonstra como o modelo EWMA se ajusta aos novos dados, dando maior peso aos retornos recentes.
>
> üí° **Exemplo Num√©rico:**
>
> Vamos analisar como diferentes valores de $\lambda$ afetam a volatilidade prevista.
>
> **Cen√°rio 1:** $\lambda = 0.9$
>
> $h_{t-1} = 0.0001$, $r_{t-1} = 0.015$
>
> $h_t = 0.9 * 0.0001 + (1 - 0.9) * (0.015)^2 = 0.00009 + 0.1 * 0.000225 = 0.0001125$
>
> Volatilidade: $\sqrt{0.0001125} \approx 0.01061$
>
> **Cen√°rio 2:** $\lambda = 0.98$
>
> $h_{t-1} = 0.0001$, $r_{t-1} = 0.015$
>
> $h_t = 0.98 * 0.0001 + (1 - 0.98) * (0.015)^2 = 0.000098 + 0.02 * 0.000225 = 0.0001025$
>
> Volatilidade: $\sqrt{0.0001025} \approx 0.01012$
>
> Com um $\lambda$ menor (0.9), a volatilidade estimada √© maior devido ao maior peso dado ao retorno recente ($r_{t-1}$). Com um $\lambda$ maior (0.98), a volatilidade estimada √© menor, pois d√° mais peso √† volatilidade anterior ($h_{t-1}$).

O gr√°fico da Figura 9-7 (n√£o inclu√≠da aqui, mas referenciada no texto original) mostra o padr√£o dos pesos para $\lambda = 0.94$ e $\lambda = 0.97$ [^7]. Para $\lambda = 0.94$, o peso mais recente √© $1 - 0.94 = 0.06$ [^7].

Os pesos decaem rapidamente, caindo abaixo de 0.00012 para dados com mais de 100 dias [^7]. Assim, o n√∫mero de *observa√ß√µes efetivas* √© relativamente pequeno [^7]. Este modelo √© um caso especial do processo GARCH onde $\alpha_0$ √© definido como 0 e $\alpha_1$ e $\beta$ somam um [^7]. O modelo, portanto, tem persist√™ncia de 1 e √© chamado **GARCH integrado (IGARCH)** [^7]. Como mostrado na Figura 9-8 (n√£o inclu√≠da aqui, mas referenciada no texto original), as previs√µes de 1 dia s√£o quase id√™nticas √†quelas obtidas com o modelo GARCH na Figura 9-4 [^7]. As previs√µes de per√≠odo mais longo, no entanto, s√£o marcadamente diferentes porque o processo EWMA n√£o retorna √† m√©dia [^7].

O modelo exponencial √© particularmente f√°cil de implementar porque depende de apenas um par√¢metro [^7]. Assim, √© mais robusto ao erro de estima√ß√£o do que outros modelos [^7]. Al√©m disso, como no caso do modelo GARCH, o estimador √© recursivo; a previs√£o √© baseada na previs√£o anterior e na inova√ß√£o mais recente [^7]. Toda a hist√≥ria √© resumida por um n√∫mero, $h_{t-1}$ [^7]. Isso contrasta com a m√©dia m√≥vel, por exemplo, onde os √∫ltimos *M* retornos devem ser usados para construir a previs√£o [^7].

O √∫nico par√¢metro neste modelo √© o fator de decaimento $\lambda$ [^7]. Em teoria, isso poderia ser encontrado maximizando a fun√ß√£o de verossimilhan√ßa [^7]. Operacionalmente, isso seria uma tarefa assustadora para realizar todos os dias para centenas de s√©ries temporais [^7]. Uma otimiza√ß√£o tem outras desvantagens [^7]. O fator de decaimento pode variar n√£o apenas entre s√©ries, mas tamb√©m ao longo do tempo, perdendo assim a consist√™ncia em diferentes per√≠odos [^7]. Al√©m disso, diferentes valores de $\lambda$ criam incompatibilidades entre os termos de covari√¢ncia e podem levar a valores n√£o razo√°veis para as correla√ß√µes, como veremos mais adiante [^7]. Na pr√°tica, o RiskMetrics usa apenas um fator de decaimento para todas as s√©ries, que √© definido como 0.94 para dados di√°rios [^7].

**Proposi√ß√£o 1**
O modelo EWMA pode ser expresso como uma soma ponderada infinita dos retornos ao quadrado passados, onde os pesos decaem exponencialmente. Especificamente:

$$
h_t = (1-\lambda) \sum_{i=1}^{\infty} \lambda^{i-1} r_{t-i}^2
$$

*Prova:* Esta representa√ß√£o decorre diretamente da substitui√ß√£o recursiva da Equa√ß√£o (9.9), conforme demonstrado na Equa√ß√£o (9.10). Cada termo na soma representa o impacto de um retorno ao quadrado passado, ponderado pelo fator de decaimento elevado √† pot√™ncia do n√∫mero de per√≠odos atr√°s.

I. Come√ßamos com a Equa√ß√£o (9.9):
$$
h_t = \lambda h_{t-1} + (1-\lambda)r_{t-1}^2
$$

II. Substitu√≠mos recursivamente $h_{t-1}$ usando a mesma Equa√ß√£o (9.9), com o √≠ndice de tempo deslocado:
$$
h_{t-1} = \lambda h_{t-2} + (1-\lambda)r_{t-2}^2
$$
Substituindo isso na express√£o original para $h_t$:
$$
h_t = \lambda [\lambda h_{t-2} + (1-\lambda)r_{t-2}^2] + (1-\lambda)r_{t-1}^2 = \lambda^2 h_{t-2} + \lambda(1-\lambda)r_{t-2}^2 + (1-\lambda)r_{t-1}^2
$$

III. Continuando a substitui√ß√£o recursiva para $h_{t-2}$:
$$
h_{t-2} = \lambda h_{t-3} + (1-\lambda)r_{t-3}^2
$$
Substituindo novamente:
$$
h_t = \lambda^2 [\lambda h_{t-3} + (1-\lambda)r_{t-3}^2] + \lambda(1-\lambda)r_{t-2}^2 + (1-\lambda)r_{t-1}^2 = \lambda^3 h_{t-3} + \lambda^2(1-\lambda)r_{t-3}^2 + \lambda(1-\lambda)r_{t-2}^2 + (1-\lambda)r_{t-1}^2
$$

IV. Observamos um padr√£o emergindo. Ap√≥s *n* substitui√ß√µes:
$$
h_t = \lambda^n h_{t-n} + (1-\lambda) \sum_{i=1}^{n} \lambda^{i-1} r_{t-i}^2
$$

V. Assumindo que o processo se iniciou h√° muito tempo, deixamos $n$ tender ao infinito.  Como $\lambda < 1$, $\lim_{n \to \infty} \lambda^n h_{t-n} = 0$, desde que $h_{t-n}$ seja limitado.

VI. Portanto, obtemos:
$$
h_t = (1-\lambda) \sum_{i=1}^{\infty} \lambda^{i-1} r_{t-i}^2
$$
que demonstra que o modelo EWMA pode ser expresso como uma soma ponderada infinita dos retornos ao quadrado passados, onde os pesos decaem exponencialmente. ‚ñ†

![Este gr√°fico compara os pesos dos dados no modelo EWMA com fatores de decaimento de 0,94 e 0,97.](./../images/ewma_decay_factors.png)

RiskMetrics tamb√©m fornece previs√µes de risco em horizontes mensais, definidos como 25 dias √∫teis [^7]. Em teoria, o modelo exponencial de 1 dia deve ser usado para extrapolar a volatilidade para o dia seguinte, depois para o seguinte, e assim por diante at√© o vig√©simo quinto dia, como foi feito para o modelo GARCH anteriormente [^7]. Aqui reside o problema [^7].

O par√¢metro de persist√™ncia para o modelo exponencial ($\alpha_1 + \beta$) √© um [^7]. Assim, o modelo n√£o permite revers√£o √† m√©dia e a volatilidade mensal deve ser a mesma que a volatilidade di√°ria [^7]. Na pr√°tica, no entanto, observamos a revers√£o √† m√©dia nas previs√µes de risco mensais [^7].

√â por isso que o RiskMetrics adota uma abordagem diferente [^7]. O estimador usa a mesma forma que a Equa√ß√£o (9.9), redefinindo $r_{t-1}$ como o estimador de vari√¢ncia m√≥vel de 25 dias, isto √© [^7]:

$$
h_t = \lambda h_{t-1} + (1-\lambda)s_{t-1}^2, \quad s_{t-1}^2 = \frac{1}{25}\sum_{k=1}^{25} r_{t-k}^2 \qquad(9.11)
$$

Na pr√°tica, isso cria estranhas caracter√≠sticas de "fantasma" no padr√£o da previs√£o de vari√¢ncia mensal [^7]. Ap√≥s experimentar com os dados, J.P. Morgan escolheu $\lambda = 0.97$ como o fator de decaimento ideal [^7]. Portanto, os modelos di√°rios e mensais s√£o inconsistentes entre si [^7]. No entanto, ambos s√£o f√°ceis de usar, aproximam-se bem do comportamento dos dados reais e s√£o robustos √† especifica√ß√£o incorreta [^7].

Para complementar a discuss√£o sobre a escolha do fator de decaimento $\lambda$, podemos analisar o impacto desse par√¢metro na velocidade de resposta do modelo a choques de volatilidade. Um valor menor de $\lambda$ implica uma resposta mais r√°pida a novos dados, enquanto um valor maior de $\lambda$ resulta em uma resposta mais lenta e suave.

**Teorema 1.1**
A meia-vida ($T_{1/2}$) do choque de volatilidade no modelo EWMA, definida como o n√∫mero de per√≠odos necess√°rios para que o impacto do choque seja reduzido pela metade, √© dada por:

$$
T_{1/2} = -\frac{\ln(2)}{\ln(\lambda)}
$$

*Prova:* Seja $I_0$ o impacto inicial do choque de volatilidade. Ap√≥s *n* per√≠odos, o impacto remanescente $I_n$ √© dado por $I_n = \lambda^n I_0$. Queremos encontrar *n* tal que $I_n = \frac{1}{2} I_0$. Portanto, $\lambda^n = \frac{1}{2}$. Tomando o logaritmo natural de ambos os lados, temos $n \ln(\lambda) = \ln(\frac{1}{2}) = -\ln(2)$. Resolvendo para *n*, obtemos $n = -\frac{\ln(2)}{\ln(\lambda)}$.  Portanto, $T_{1/2} = n = -\frac{\ln(2)}{\ln(\lambda)}$.

I. Definimos $I_0$ como o impacto inicial de um choque de volatilidade no tempo $t=0$.

II. Ap√≥s $n$ per√≠odos, o impacto remanescente, $I_n$, √© modelado como:
$$
I_n = \lambda^n I_0
$$
Isso decorre da aplica√ß√£o iterativa do fator de decaimento $\lambda$ a cada per√≠odo.

III. A meia-vida $T_{1/2}$ √© definida como o n√∫mero de per√≠odos ($n$) necess√°rios para que o impacto inicial seja reduzido pela metade. Portanto, queremos encontrar $n$ tal que:
$$
I_n = \frac{1}{2} I_0
$$

IV. Substitu√≠mos $I_n$ na equa√ß√£o do passo II:
$$
\frac{1}{2} I_0 = \lambda^n I_0
$$

V. Dividindo ambos os lados por $I_0$ (assumindo $I_0 \neq 0$):
$$
\frac{1}{2} = \lambda^n
$$

VI. Aplicamos o logaritmo natural (ln) a ambos os lados da equa√ß√£o:
$$
\ln\left(\frac{1}{2}\right) = \ln(\lambda^n)
$$

VII. Usamos a propriedade do logaritmo $\ln(a^b) = b \ln(a)$:
$$
\ln\left(\frac{1}{2}\right) = n \ln(\lambda)
$$

VIII. Como $\ln\left(\frac{1}{2}\right) = -\ln(2)$, reescrevemos a equa√ß√£o como:
$$
-\ln(2) = n \ln(\lambda)
$$

IX. Isolamos $n$ dividindo ambos os lados por $\ln(\lambda)$ (assumindo $\lambda \neq 1$):
$$
n = -\frac{\ln(2)}{\ln(\lambda)}
$$

X. Portanto, a meia-vida $T_{1/2}$ √© dada por:
$$
T_{1/2} = -\frac{\ln(2)}{\ln(\lambda)}
$$
‚ñ†
> üí° **Exemplo Num√©rico:**
>
> Calculando a meia-vida para diferentes valores de $\lambda$:
>
> *   Para $\lambda = 0.94$:
>    $T_{1/2} = -\frac{\ln(2)}{\ln(0.94)} \approx 10.99$ dias
>
> *   Para $\lambda = 0.97$:
>    $T_{1/2} = -\frac{\ln(2)}{\ln(0.97)} \approx 22.76$ dias
>
> *   Para $\lambda = 0.9$:
>    $T_{1/2} = -\frac{\ln(2)}{\ln(0.9)} \approx 6.58$ dias
>
> Um $\lambda$ maior resulta em uma meia-vida mais longa, o que significa que o impacto de um choque de volatilidade persiste por mais tempo. Um $\lambda$ menor resulta em uma meia-vida mais curta, indicando que o modelo reage mais rapidamente √†s mudan√ßas na volatilidade.
>
> üí° **Exemplo Num√©rico:**
>
> Usando Python para calcular a meia-vida:
>
> ```python
> import numpy as np
>
> lambda_values = [0.9, 0.94, 0.97]
>
> for lambda_val in lambda_values:
>     half_life = -np.log(2) / np.log(lambda_val)
>     print(f"Lambda: {lambda_val}, Half-life: {half_life:.2f} days")
> ```
>
> ```
> Lambda: 0.9, Half-life: 6.58 days
> Lambda: 0.94, Half-life: 10.99 days
> Lambda: 0.97, Half-life: 22.76 days
> ```

Este resultado fornece uma maneira direta de quantificar a persist√™ncia da volatilidade no modelo EWMA e auxilia na escolha de um valor apropriado para $\lambda$ com base nas caracter√≠sticas espec√≠ficas dos dados financeiros em an√°lise. Por exemplo, se $\lambda = 0.94$, ent√£o $T_{1/2} \approx 10.99$, o que significa que leva aproximadamente 11 dias para que o impacto de um choque de volatilidade seja reduzido pela metade.

### Conclus√£o

A abordagem RiskMetrics oferece uma maneira computacionalmente eficiente de modelar a volatilidade vari√°vel no tempo, particularmente atrav√©s do uso de m√©dias m√≥veis ponderadas exponencialmente [^7]. Embora essa abordagem simplifique o c√°lculo e forne√ßa resultados razo√°veis, ela possui limita√ß√µes importantes, incluindo a falta de revers√£o √† m√©dia e a inconsist√™ncia entre os modelos di√°rios e mensais [^7]. Apesar dessas limita√ß√µes, sua facilidade de implementa√ß√£o e robustez a tornam uma ferramenta √∫til na pr√°tica, embora seja fundamental reconhecer suas limita√ß√µes e considerar outras t√©cnicas mais sofisticadas para modelar e prever a volatilidade nos mercados financeiros [^7].

### Refer√™ncias
[^1]: Cap√≠tulo 4 descreve o risco de vari√°veis financeiras b√°sicas, como taxas de juros, taxas de c√¢mbio e pre√ßos de a√ß√µes.
[^7]: Se√ß√£o 9.2.4 descreve a abordagem RiskMetrics, incluindo sua f√≥rmula (Equa√ß√£o 9.9) e sua rela√ß√£o com o modelo IGARCH.
<!-- END -->