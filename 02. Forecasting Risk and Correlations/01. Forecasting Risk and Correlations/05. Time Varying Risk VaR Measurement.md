## Forecasting Risk and Correlations: Time-Varying Risk and Correlations

### Introdu√ß√£o
This chapter delves into techniques for forecasting variations in risk and correlations within financial markets [^1]. A core motivation is recognizing that financial markets exhibit time-varying volatility [^1]. Modeling this temporal variation is paramount for effective risk management, as escalating volatility directly impacts measures like Value at Risk (VaR) [^1]. As highlighted previously [^3], both the presence of stationary *fat tails* and time-varying distributions contribute to return distributions.

### Conceitos Fundamentais

#### 9.1 Time-Varying Risk or Outliers?
Empirical data often reveals that financial return distributions don't perfectly align with normal distributions, instead showcasing *fat tails* [^3]. Considering the \$/BP exchange rate as an example [^2]:

**Two Perspectives on Fat Tails:**

1.  **Stationary Distribution with Fat Tails:** This suggests a stable distribution exists with inherent *fat tails*. Approximating with a normal distribution is thus unsuitable [^3]. Distributions like t-Student and hyperbolic distributions become relevant.

2.  **Time-Varying Distribution:** The distribution changes over time [^3]. During turbulent times, stationary models might misinterpret large observations as *outliers*, when actually stemming from a distribution with temporarily greater dispersion [^3]. GARCH models are then useful.
![This figure compares the normal approximation with the actual empirical distribution of the $/BP exchange rate](./../images/normal_approximation_vs_bp_exchange.jpg)

To build on those perspectives, consider:

**Teorema 1 (Semi-Parametric Modeling of Fat Tails):** *A semi-parametric approach combines a parametric distribution to model the body of the distribution with a non-parametric method (such as kernel density estimation) to model the tails. This approach can capture both the characteristics of fat tails and the time variation of risk.*

The key is to use a standard parametric distribution (e.g., normal or t-Student) for most data, then apply a non-parametric estimator to extreme observations to adjust the distribution tails. This allows greater flexibility in tail modeling without imposing a rigid functional form.

**Lema 1 (Estimating Tail Index):** *The tail index, which measures the heaviness of the tail, can be estimated using the Hill estimator. Let $r_{(1)} \geq r_{(2)} \geq ... \geq r_{(n)}$ be the ordered returns, then the Hill estimator is given by:*

$$\hat{\gamma} = \frac{1}{k} \sum_{i=1}^{k} \ln(r_{(i)}) - \ln(r_{(k+1)})$$

*where $k$ is the number of top order statistics used in the estimation.*

This lemma provides a practical method for quantifying the fatness of the tails, a crucial parameter when choosing and implementing semi-parametric or purely non-parametric tail models.

> üí° **Exemplo Num√©rico:** Suppose we have the following ordered returns:
>
> $r_{(1)} = 0.05, r_{(2)} = 0.04, r_{(3)} = 0.03, r_{(4)} = 0.02, r_{(5)} = 0.01$
>
> If we choose $k = 3$, meaning we are considering the top 3 order statistics, then:
>
> $\hat{\gamma} = \frac{1}{3} [\ln(0.05) + \ln(0.04) + \ln(0.03)] - \ln(0.02)$
>
> $\hat{\gamma} = \frac{1}{3} [-2.9957 + -3.2189 + -3.5065] - (-3.9120)$
>
> $\hat{\gamma} = -3.2404 - (-3.9120) = 0.6716$
>
> The tail index estimate is approximately 0.6716. A higher tail index indicates heavier tails, meaning more extreme values are expected.

#### 9.2 Modeling Time-Varying Risk
Accurately predicting varying risk is vital in risk management, since volatility can influence VAR [^1].

9.2.1 Moving Averages
One approach to modeling time-varying risk is through **moving averages** [^4]. This calculates volatility as the average of squared returns over a fixed window [^4], as such:

$$
\sigma_t^2 = (1/M) \sum_{i=1}^{M} r_{t-i+1}^2
$$

where:
-   $r_t$ is the return at time *t*
-   *M* is the window size

> üí° **Exemplo Num√©rico:** With the following daily returns:
>
> Day 1: 0.01
>
> Day 2: -0.02
>
> Day 3: 0.015
>
> Day 4: 0.005
>
> Day 5: -0.01
>
> And a moving average window *M* = 3 days, calculate volatility for Day 5:
>
> $\sigma_5^2 = (1/3) * (0.015^2 + 0.005^2 + (-0.01)^2)$
>
> $\sigma_5^2 = 0.00011667$
>
> $\sigma_5 ‚âà 0.0108$
>
> The drawback being that past returns are weighted the same.

To ameliorate this issue, consider a weighted version:

**Teorema 2 (Weighted Moving Average):** *Volatility can be estimated with a weighted moving average, decreasing weights on older observations:*

$$\sigma_t^2 = \sum_{i=1}^{M} w_i r_{t-i+1}^2 $$

where $\sum_{i=1}^{M} w_i = 1$ and $w_i \geq 0$ for all $i$. With weights  $w_i = \lambda^{i-1} (1-\lambda) / (1 - \lambda^M)$, where $\lambda$ is a decay factor between 0 and 1, higher emphasis is on recent, lower emphasis on older events.

> üí° **Exemplo Num√©rico:** Using the same daily returns, calculate weighted volatility for Day 5 with *M* = 3 and $\lambda$ = 0.9. First, calculate $w_i$:
>
> To compute the weights, we use the formula $w_i = \lambda^{i-1} (1-\lambda) / (1 - \lambda^M)$. Since *M* = 3 and $\lambda$ = 0.9:
>
> For $i = 1$: $w_1 = (0.9)^{1-1} (1-0.9) / (1 - 0.9^3) = (1)(0.1) / (1 - 0.729) = 0.1 / 0.271 \approx 0.369$
>
> For $i = 2$: $w_2 = (0.9)^{2-1} (1-0.9) / (1 - 0.9^3) = (0.9)(0.1) / 0.271 = 0.09 / 0.271 \approx 0.332$
>
> For $i = 3$: $w_3 = (0.9)^{3-1} (1-0.9) / (1 - 0.9^3) = (0.81)(0.1) / 0.271 = 0.081 / 0.271 \approx 0.299$
>
> Now, the weighted volatility is:
>
> $\sigma_5^2 = 0.369 \cdot (0.015)^2 + 0.332 \cdot (0.005)^2 + 0.299 \cdot (-0.01)^2 \approx 0.000121225$
>
> Hence, weighted volatility is now $ ‚âà 0.01101$.
>
> In this example, the older return on Day 2 (-0.02) has less impact on the volatility calculation because of the weighting scheme.

**Corol√°rio 2.1 (EWMA Model):** *When M approaches infinity in the weighted moving average with the specified weights, we obtain the Exponentially Weighted Moving Average (EWMA) model, which is a special case of the IGARCH(1,1) model:*

$$\sigma_t^2 = \lambda \sigma_{t-1}^2 + (1 - \lambda)r_{t-1}^2$$

This follows directly from Teorema 2 by taking the limit as *M* goes to infinity. The EWMA model is widely used due to its simplicity and ability to capture time-varying volatility.

**Prova do Corol√°rio 2.1:**
Para mostrar que o modelo EWMA surge do Teorema 2 quando M se aproxima do infinito, com os pesos especificados, seguimos estes passos:

I. **Definir a soma ponderada da m√©dia m√≥vel:**
   $$\sigma_t^2 = \sum_{i=1}^{M} w_i r_{t-i+1}^2$$

II. **Substituir os pesos $w_i$:**
   $$\sigma_t^2 = \sum_{i=1}^{M} \frac{\lambda^{i-1} (1-\lambda)}{1 - \lambda^M} r_{t-i+1}^2$$

III. **Analisar o limite quando $M \to \infty$:**
   Quando $M$ tende para infinito, $\lambda^M$ tende para 0, uma vez que $0 < \lambda < 1$. Portanto, o termo $(1 - \lambda^M)$ no denominador aproxima-se de 1.

IV. **Reescrever a equa√ß√£o:**
   $$\sigma_t^2 = \lim_{M \to \infty} \sum_{i=1}^{M} (1-\lambda) \lambda^{i-1} r_{t-i+1}^2$$

V. **Expandir a soma e separar os termos:**
   Podemos escrever a express√£o acima como:
   $$\sigma_t^2 = (1-\lambda) r_{t}^2 + (1-\lambda) \lambda r_{t-1}^2 + (1-\lambda) \lambda^2 r_{t-2}^2 + \dots$$

VI. **Fatorar $\lambda$ e reconhecer a f√≥rmula recursiva:**
   Considere $\sigma_{t-1}^2$. Esta seria:
    $$\sigma_{t-1}^2 = \lim_{M \to \infty} \sum_{i=1}^{M} (1-\lambda) \lambda^{i-1} r_{t-1-i+1}^2 = (1-\lambda) r_{t-1}^2 + (1-\lambda) \lambda r_{t-2}^2 + (1-\lambda) \lambda^2 r_{t-3}^2 + \dots$$
   Multiplicando por $\lambda$:
   $$\lambda\sigma_{t-1}^2 = \lambda(1-\lambda) r_{t-1}^2 + \lambda(1-\lambda) \lambda r_{t-2}^2 + \lambda(1-\lambda) \lambda^2 r_{t-3}^2 + \dots$$
   
VII. **Substituir na equa√ß√£o original:**
   Note que todos os termos de $\lambda\sigma_{t-1}^2$ s√£o termos com um atraso na equa√ß√£o para $\sigma_t^2$, assim:
   $$\sigma_t^2 = (1-\lambda) r_{t-1}^2 + \lambda \sigma_{t-1}^2$$

VIII. **Reorganizar para obter a forma EWMA:**
    $$\sigma_t^2 = \lambda \sigma_{t-1}^2 + (1 - \lambda)r_{t-1}^2$$
Portanto, o modelo EWMA √© recuperado como o limite do modelo de m√©dia m√≥vel ponderada quando *M* se aproxima do infinito com os pesos especificados. $\blacksquare$

> üí° **Exemplo Num√©rico:** Suppose $\lambda = 0.94$, $\sigma_{t-1}^2 = 0.0001$, and $r_{t-1} = 0.015$. Then, the current volatility estimate using EWMA would be:
>
> $\sigma_t^2 = 0.94 \cdot 0.0001 + (1 - 0.94) \cdot (0.015)^2$
>
> $\sigma_t^2 = 0.000094 + 0.06 \cdot 0.000225 = 0.000094 + 0.0000135 = 0.0001075$
>
> $\sigma_t \approx 0.01037$

9.2.2 GARCH Estimation
To surpass moving averages, volatility models evolve to weight recent data [^5]. The **Generalized Autoregressive Conditional Heteroskedastic (GARCH)** model, developed by Engle (1982) and Bollerslev (1986) [^5] arises. "Heteroskedastic" means variances change [^5]. This model suggests return variance follows a predictable pattern [^5], reliant on the most recent innovation alongside prior conditional variance [^5].

**Teorema 3 (GARCH-in-Mean Model):** *The GARCH-M model extends the GARCH model by including the conditional variance (or its standard deviation) in the conditional mean equation:*

$$r_t = \mu + \theta \sigma_t^2 + \epsilon_t$$

$$\sigma_t^2 = \alpha_0 + \alpha_1 r_{t-1}^2 + \beta \sigma_{t-1}^2$$

where $\theta$ is the coefficient measuring the effect of conditional variance on the conditional mean.

> üí° **Exemplo Num√©rico:** With the parameters:
>
> $\alpha_0 = 0.00001$
>
> $\alpha_1 = 0.05$
>
> $\beta = 0.90$
>
> Yesterday‚Äôs return ($r_{t-1}$) was 0.02, and yesterday‚Äôs conditional variance ($\sigma_{t-1}^2$) was 0.00015, we can find the volatility of today ($\sigma_t^2$):
>
> $\sigma_t^2 = 0.00001 + 0.05 \cdot (0.02)^2 + 0.90 \cdot 0.00015$
>
> $\sigma_t^2 = 0.00001 + 0.00002 + 0.000135 = 0.000165$
>
> $\sigma_t ‚âà 0.0128$
>
> For a GARCH-M model, with $\theta = 0.1$, $\mu = 0.0001$. The mean return is now:
>
> $r_t = 0.0001 + 0.1 \cdot 0.000165 + \epsilon_t = 0.0001 + 0.0000165 + \epsilon_t = 0.0001165 + \epsilon_t$
>
> Here the expected return depends on a relation to volatility. If volatility increases, expected return also increases according to the model.

**Teorema 3.1 (Integrated GARCH Model - IGARCH):** *An IGARCH model is a restricted version of the GARCH model where the sum of the coefficients on the lagged squared return and lagged conditional variance is equal to one, implying that shocks to volatility are persistent:*

$$\sigma_t^2 = \alpha_0 + \alpha_1 r_{t-1}^2 + (1-\alpha_1) \sigma_{t-1}^2$$

This model is often used when dealing with highly persistent volatility, as is commonly found in financial time series.

**Prova do Teorema 3.1:**
Para provar que o modelo IGARCH √© um caso restrito do modelo GARCH onde a soma dos coeficientes √© igual a um, come√ßamos com a forma geral do modelo GARCH(1,1):
I. **Modelo GARCH(1,1) padr√£o:**
$$\sigma_t^2 = \alpha_0 + \alpha_1 r_{t-1}^2 + \beta \sigma_{t-1}^2$$
II. **Definir a restri√ß√£o IGARCH:**
No modelo IGARCH, a restri√ß√£o √© que a soma dos coeficientes $\alpha_1$ e $\beta$ seja igual a 1. Ou seja:
$$\alpha_1 + \beta = 1$$
III. **Expressar $\beta$ em termos de $\alpha_1$:**
A partir da restri√ß√£o IGARCH, podemos expressar $\beta$ em termos de $\alpha_1$:
$$\beta = 1 - \alpha_1$$
IV. **Substituir $\beta$ na equa√ß√£o GARCH(1,1):**
Substitu√≠mos $\beta$ na equa√ß√£o GARCH(1,1):
$$\sigma_t^2 = \alpha_0 + \alpha_1 r_{t-1}^2 + (1 - \alpha_1) \sigma_{t-1}^2$$
Esta √© precisamente a forma do modelo IGARCH.
V. **Interpretar o resultado:**
A equa√ß√£o IGARCH mostra que a vari√¢ncia condicional no tempo $t$ √© uma combina√ß√£o da inova√ß√£o quadrada mais recente ($r_{t-1}^2$) e da vari√¢ncia condicional anterior ($\sigma_{t-1}^2$), com os pesos $\alpha_1$ e $(1 - \alpha_1)$, respectivamente. A restri√ß√£o $\alpha_1 + \beta = 1$ garante que os choques na volatilidade sejam persistentes, pois eles s√£o totalmente integrados no processo da vari√¢ncia condicional. $\blacksquare$

> üí° **Exemplo Num√©rico:** Let's assume $\alpha_0 = 0.000005$, $\alpha_1 = 0.06$, $r_{t-1} = 0.015$, and $\sigma_{t-1}^2 = 0.00012$. Then, the conditional variance for time *t* in an IGARCH(1,1) model is:
>
> $\sigma_t^2 = 0.000005 + 0.06 \cdot (0.015)^2 + (1 - 0.06) \cdot 0.00012$
>
> $\sigma_t^2 = 0.000005 + 0.06 \cdot 0.000225 + 0.94 \cdot 0.00012 = 0.000005 + 0.0000135 + 0.0001128 = 0.0001313$
>
> The fact that $\alpha_1 + \beta = 1$ implies that any shock to volatility today will have a lasting impact on future volatility forecasts.

### 9.3 Modeling Correlations
Correlation is critical for portfolio risk. To show correlation estimation, examine the \$/BP and dollar/Deutschmark exchange rates.

#### 9.3.1 Moving Averages
With a fixed window *M*, moving average estimates can be used to measure correlation. The estimation process of moving correlation is:
**1. Calculate return pairs over the window**. The period length is given by $M$

$$
r_{A,i}, r_{B,i}; i=t-M+1, \cdots, t.
$$

**2. Calculate the volatility for each asset:**

$$
\sigma^2_{A,t} = \frac{1}{M} \sum_{i=t-M+1}^{t} r_{A,i}^2
$$

$$
\sigma^2_{B,t} = \frac{1}{M} \sum_{i=t-M+1}^{t} r_{B,i}^2
$$

**3. Calculate the Covariance:**

$$
\sigma_{AB,t} = \frac{1}{M-1} \sum_{i=t-M+1}^{t} (r_{A,i}-\bar{r_A})(r_{B,i}-\bar{r_B})
$$

**4. The moving average conditional correlation can be calculated by:**

$$
\rho_{AB,t} = \frac{\sigma_{AB,t}}{\sigma_{A,t} \sigma_{B,t}}
$$

> üí° **Exemplo Num√©rico:** For 5 daily returns of two assets (A and B):
>
> | Day | Return Asset A | Return Asset B |
> |-----|-----------------|-----------------|
> | 1   | 0.01            | 0.015           |
> | 2   | -0.02           | -0.025          |
> | 3   | 0.015           | 0.02            |
> | 4   | 0.005           | 0.008           |
> | 5   | -0.01           | -0.012          |
>
> With a window *M* = 3, and having calculated:
>
> *   Retornos m√©dios para A: $\bar{r_A} = \frac{0.015 + 0.005 - 0.01}{3} = 0.00333$
>
> *   Retornos m√©dios para B: $\bar{r_B} = \frac{0.02 + 0.008 - 0.012}{3} = 0.00533$
>
> The covariance is estimated at:
>
> $\sigma_{AB,t} = \frac{1}{3-1}[(0.015-0.00333)(0.02-0.00533)+(0.005-0.00333)(0.008-0.00533)+(-0.01-0.00333)(-0.012-0.00533)] =  0.00020335$.
>
> To proceed with correlation, calculate the volatilities:
>
> $\sigma_{A,t} = \sqrt{\frac{0.015^2 + 0.005^2 + (-0.01)^2}{3}} = 0.01077$
>
> $\sigma_{B,t} = \sqrt{\frac{0.02^2 + 0.008^2 + (-0.012)^2}{3}} = 0.01342$
>
> The moving average conditional correlation is then:
>
> $\rho_{AB,t} = \frac{0.00020335}{0.01077 \cdot 0.01342} = 1.406 $
>
> Notice that the correlation estimate is bigger than 1, which is not possible. This may be due to the short window and high volatility. It's important to carefully interpret the results based on the window size.
>

#### 9.3.2 GARCH
While GARCH estimation can extend to multivariate structure, the number of parameters grows very quickly with added series. A model to mitigate such complexity are the **Dynamic conditional correlation models**

**Teorema 4 (Dynamic Conditional Correlation Model):** *The DCC model is an approach to modeling dynamic correlations that reduces the number of parameters by modeling the correlations directly, rather than modeling the covariances.*

**Proposi√ß√£o 4.1 (CCC - Constant Conditional Correlation Model):** *Before the DCC model was introduced, the Constant Conditional Correlation (CCC) model was a simpler alternative to the full VECH model. The CCC model assumes that the conditional correlations are constant over time, but the conditional variances are time-varying and modeled using univariate GARCH models.*

The CCC model simplifies estimation by assuming constant correlations, making it computationally feasible for high-dimensional problems. However, it may not accurately capture the dynamic nature of correlations in many financial markets.

> üí° **Exemplo Num√©rico:** Suppose we have two assets, A and B. We model their variances using GARCH(1,1) models, and we assume a constant conditional correlation between them.
>
> $\sigma_{A,t}^2 = 0.00001 + 0.05 r_{A,t-1}^2 + 0.90 \sigma_{A,t-1}^2$
>
> $\sigma_{B,t}^2 = 0.000015 + 0.04 r_{B,t-1}^2 + 0.92 \sigma_{B,t-1}^2$
>
> Suppose the constant conditional correlation, estimated from historical data, is $\rho_{AB} = 0.6$. If at time t-1, $r_{A,t-1} = 0.01$, $r_{B,t-1} = 0.012$, $\sigma_{A,t-1}^2 = 0.0001$, and $\sigma_{B,t-1}^2 = 0.00015$, then we can calculate the conditional variances for time t:
>
> $\sigma_{A,t}^2 = 0.00001 + 0.05 (0.01)^2 + 0.90 (0.0001) = 0.0001055$
>
> $\sigma_{B,t}^2 = 0.000015 + 0.04 (0.012)^2 + 0.92 (0.00015) = 0.00015276$
>
> The conditional covariance between A and B at time t is:
>
> $\sigma_{AB,t} = \rho_{AB} \cdot \sigma_{A,t} \cdot \sigma_{B,t} = 0.6 \cdot \sqrt{0.0001055} \cdot \sqrt{0.00015276} = 0.6 \cdot 0.01027 \cdot 0.01236 = 0.0000762$
>
> The CCC model simplifies portfolio risk calculation by assuming the correlation is constant, but may not accurately reflect market dynamics.

#### 9.3.3 Exponential Averages
RiskMetrics uses the concept of exponential weights for covariances as:

$$h_{12,t} = \lambda h_{12,t-1} + (1 ‚àí \lambda) r_{1,t-1} r_{2,t-1} $$

where $\lambda$ is the decay factor (0.94 for daily, 0.97 for monthly). The conditional correlation is then:

To refine conditional correlation, use the following correction to avoid extreme values:

**Teorema 5 (Correction for Extreme Correlations):** *To prevent the estimated conditional correlation from reaching extreme values (close to +1 or -1), apply a transformation that compresses the correlation toward zero:*

$$\rho_{12,t}^* = \tanh(\omega \cdot \rho_{12,t})$$

where $\rho_{12,t}$ is the conditional correlation estimated via exponential averages, $\rho_{12,t}^*$ is the adjusted correlation, and $\omega$ controls the compression. The hyperbolic tangent ($\tanh$) maps real values to (-1, 1), retaining the valid bounds. Adjusting $\omega$ varies the compression strength.

**Prova do Teorema 5:**

Para provar a efic√°cia da corre√ß√£o para correla√ß√µes extremas usando a fun√ß√£o tangente hiperb√≥lica, considere as propriedades e o comportamento da fun√ß√£o.

I. **Fun√ß√£o Tangente Hiperb√≥lica (tanh):**

A fun√ß√£o tangente hiperb√≥lica √© definida como:

$$\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}$$

II. **Propriedades da tanh(x):**

*   A fun√ß√£o tanh(x) mapeia qualquer n√∫mero real para o intervalo (-1, 1).

*   tanh(0) = 0

*   Quando $x$ tende ao infinito, tanh(x) tende a 1.

*   Quando $x$ tende ao menos infinito, tanh(x) tende a -1.

*   A fun√ß√£o √© √≠mpar, ou seja, tanh(-x) = -tanh(x).

III. **Corre√ß√£o para Correla√ß√µes Extremas:**

A ideia por tr√°s da transforma√ß√£o √© "comprimir" os valores da correla√ß√£o estimados em dire√ß√£o a zero, evitando que atinjam valores extremos (+1 ou -1). A transforma√ß√£o √© dada por:

$$\rho_{12,t}^* = \tanh(\omega \cdot \rho_{12,t})$$

onde:

*   $\rho_{12,t}$ √© a correla√ß√£o condicional estimada.

*   $\rho_{12,t}^*$ √© a correla√ß√£o ajustada.

*   $\omega$ √© um par√¢metro que controla a for√ßa da compress√£o.

IV. **An√°lise da Compress√£o:**

*   Quando $\omega$ √© pequeno (pr√≥ximo de 0), a transforma√ß√£o comprime fortemente os valores da correla√ß√£o em dire√ß√£o a zero.

*   Quando $\omega$ √© grande, a transforma√ß√£o tem pouco efeito sobre os valores da correla√ß√£o, e $\rho_{12,t}^*$ se aproxima de $\rho_{12,t}$.

*   Independentemente do valor de $\omega$, $\rho_{12,t}^*$ sempre estar√° no intervalo (-1, 1), garantindo que a correla√ß√£o ajustada seja v√°lida.

V. **Justificativa:**

A justificativa para usar essa transforma√ß√£o √© que, em muitos casos, correla√ß√µes extremas (+1 ou -1) s√£o irrealistas e podem levar a decis√µes de portf√≥lio ruins. Ao comprimir as correla√ß√µes em dire√ß√£o a zero, o modelo se torna mais conservador e menos propenso a superestimar os benef√≠cios da diversifica√ß√£o.

VI. **Exemplo:**

Suponha que $\rho_{12,t} = 0.95$ e $\omega = 0.5$. Ent√£o:

$$\rho_{12,t}^* = \tanh(0.5 \cdot 0.95) = \tanh(0.475) \approx 0.442$$

Neste exemplo, a correla√ß√£o original de 0.95 √© comprimida para 0.442, mostrando o efeito da transforma√ß√£o.

VII. **Conclus√£o:**

Ao aplicar a fun√ß√£o tangente hiperb√≥lica com um par√¢metro de compress√£o $\omega$, as correla√ß√µes estimadas s√£o ajustadas para evitar valores extremos, mantendo-se dentro de limites v√°lidos e proporcionando uma estimativa mais conservadora e realista da correla√ß√£o condicional. $\blacksquare$

> üí° **Exemplo Num√©rico:**
>
> For a conditional covariance on day *t-1* of $h_{12,t-1} = 0.00015$, and returns $r_{1,t-1} = 0.01$ and $r_{2,t-1} = 0.012$, and a decay factor  $\lambda = 0.94$, we have:
>
> $h_{12,t} = 0.94 \cdot 0.00015 + (1 - 0.94) \cdot 0.01 \cdot 0.012 = 0.000141 + 0.0000072 = 0.0001482$
>
> Assuming the conditional variances are $h_{1,t} = 0.0002$ and $h_{2,t} = 0.00025$, the conditonal correlation is:
>
> $\rho_{12,t} = \frac{h_{12,t}}{\sqrt{h_{1,t} \cdot h_{2,t}}} = \frac{0.0001482}{\sqrt{0.0002 \cdot 0.00025}} = \frac{0.0001482}{0.0002236} ‚âà 0.6628$.
>
> With the correction with $\omega = 0.5$, the new $\rho_{12,t}^* = \tanh(0.5 \cdot 0.6628) = \tanh(0.3314) ‚âà 0.3213$.
>
> This correction ensures that the correlation estimate is less extreme and potentially more realistic for risk management purposes.

### Conclus√£o

Good risk management incorporates volatility and correlation models for accurate VAR calculations [^1], especially in periods of structural changes. These models can be time-varying or involve stationary models with fat tails.
### Refer√™ncias
[^1]: P√°gina 219: *‚ÄúThe purpose of this chapter is to present techniques to forecast vari-ation in risk and correlations. Section 9.1 motivates the problem by taking the example of a series that underwent structural changes leading to pre-dictable patterns in volatility.‚Äù*
[^2]: P√°gina 220: *‚ÄúAs an illustration, we will walk through this chapter focusing on the U.S. dollar/British pound ($/BP) exchange rate measured at daily intervals. Movements in the exchange rate are displayed in Figure 9-1. The 1990‚Äì1994 period was fairly typical, covering narrow trading ranges and wide swings. September 1992 was particularly tumultuous. After vain attempts by the Bank of England to support the pound against the German mark, the pound exited the European Monetary System. There were several days with very large moves. On September 17 alone, the pound fell by 6 percent against the mark and also against the dollar. Hence we can expect interesting patterns in volatility. In particular, the question is whether this structural change led to predictable time variation in risk.‚Äù*
[^3]: P√°gina 221: *‚ÄúOver this period, the average daily volatility was 0.694 percent, which translates into 11.02 percent per annum (using a 252-trading-day adjustment). This risk measure, however, surely was not constant over time. In addition, time variation in risk could explain the fact that the empirical distribution of returns does not quite exactly fit a normal distribution. Figure 9-2 compares the normal approximation with the actual empirical distribution of the $/BP exchange rate. Relative to the normal model, the actual distribution contains more observations in the center and in the tails. These fat tails can be explained by two alternative viewpoints. The first view is that the true distribution is stationary and indeed contains fat tails, in which case a normal approximation is clearly inappropriate. The other view is that the distribution does change through time. As a result, in times of turbulence, a stationary model could view large observations as outliers when they are really drawn from a distribution with temporarily greater dispersion. In practice, both explanations carry some truth. This is why fore-casting variation in risk is particularly fruitful for risk management. In‚Äù*
[^4]: P√°gina 222: *‚ÄúA very crude method, but one that is employed widely, is to use a moving window of fixed length for estimating volatility. For instance, a typical length is 20 trading days (about a calendar month) or 60 trading days (about a calendar quarter). Assuming that we observe$$r_t, r_{t-1}, \dots, r_{t-N+1}$$

for the *N* most recent observations, then the simple estimate of the volatility is given by

$$\hat{\sigma}_t = \sqrt{\frac{1}{N-1} \sum_{i=0}^{N-1} (r_{t-i} - \bar{r})^2}$$,

where $\bar{r}$ is the mean return over the *N* observations:

$$\bar{r} = \frac{1}{N} \sum_{i=0}^{N-1} r_{t-i}$$.

*Exponentially Weighted Moving Average (EWMA)*

EWMA models provide a more sophisticated approach to volatility estimation by assigning greater weight to more recent observations. This is based on the idea that recent data is more relevant for predicting future volatility. The EWMA model is defined as follows:

$$\hat{\sigma}_t^2 = \lambda \hat{\sigma}_{t-1}^2 + (1 - \lambda)r_{t-1}^2$$,

where $\lambda$ is a smoothing constant between 0 and 1. A smaller $\lambda$ gives more weight to recent returns.

*GARCH Models*

GARCH (Generalized Autoregressive Conditional Heteroskedasticity) models are a class of statistical models used to estimate volatility in time series data. They are more complex than simple moving average or EWMA models but can capture more complex dynamics in volatility. The GARCH(1,1) model is the most common form:

$$\hat{\sigma}_t^2 = \omega + \alpha r_{t-1}^2 + \beta \hat{\sigma}_{t-1}^2$$,

where $\omega$, $\alpha$, and $\beta$ are parameters to be estimated.

### Implied Volatility

Implied volatility is a forward-looking measure derived from the market prices of options. It represents the market's expectation of future volatility over the life of the option. The Black-Scholes model or other option pricing models are used to back out the implied volatility from observed option prices.

### Volatility as a Trading Signal

Volatility can be a valuable trading signal. Here's how:

1.  *Volatility Breakouts*:
    *   High volatility can signal the start of a new trend.
    *   Low volatility can suggest consolidation before a significant move.

2.  *Volatility as Risk Indicator*:
    *   High volatility implies higher risk and may require smaller position sizes.
    *   Low volatility implies lower risk, allowing for larger positions.

3.  *Volatility and Option Pricing*:
    *   Volatility is a key input in option pricing models.
    *   Trading strategies can be built around expected vs. implied volatility.

4.  *Volatility Targeting*:
    *   Adjusting position sizes to maintain a constant level of portfolio volatility.
    *   Reducing exposure during high volatility and increasing during low volatility.

### Practical Implementation

Consider a practical example in Python to estimate and visualize volatility using historical stock prices.

```python
import numpy as np
import pandas as pd
import yfinance as yf
import matplotlib.pyplot as plt

# Fetch historical data
ticker = 'AAPL'
data = yf.download(ticker, start='2020-01-01', end='2024-01-01')
data['Returns'] = np.log(data['Close'] / data['Close'].shift(1))
data = data.dropna()

# Calculate rolling volatility (20-day window)
data['Volatility'] = data['Returns'].rolling(window=20).std() * np.sqrt(252) # Annualized

# Plotting
plt.figure(figsize=(14, 7))
plt.plot(data['Volatility'], label='Volatility (20-day Rolling)')
plt.title(f'{ticker} Volatility')
plt.xlabel('Date')
plt.ylabel('Volatility')
plt.legend()
plt.show()

# EWMA Volatility
lambda_val = 0.94
data['EWMA_Volatility'] = data['Returns'].ewm(alpha=(1 - lambda_val)).std() * np.sqrt(252)

# Plotting EWMA Volatility
plt.figure(figsize=(14, 7))
plt.plot(data['EWMA_Volatility'], label='EWMA Volatility')
plt.title(f'{ticker} EWMA Volatility')
plt.xlabel('Date')
plt.ylabel('Volatility')
plt.legend()
plt.show()
```

This Python script downloads Apple stock prices, calculates daily returns, and then computes the rolling volatility using a 20-day window and the EWMA volatility. The script visualizes the computed volatilities, providing insights into how volatility changes over time.

### Advanced Volatility Strategies

1.  *Volatility Arbitrage*: Trading the difference between implied volatility and realized volatility.
2.  *Variance Swaps*: Contracts that pay the difference between realized variance and a fixed strike price.
3.  *Volatility Derivatives*: Options on volatility indices (e.g., VIX options).

### Conclusion

Volatility is a critical component of financial markets, offering insights into risk, trading opportunities, and portfolio management. Understanding and effectively utilizing volatility measures can significantly enhance trading and investment strategies. From simple historical measures to complex GARCH models and implied volatility, a comprehensive understanding of volatility provides a powerful tool for navigating market dynamics. <!-- END -->
