## Forecasting Risk and Correlations: Time-Varying Risk and Correlations

### Introdu√ß√£o
Este cap√≠tulo aborda t√©cnicas para prever a varia√ß√£o no risco e nas correla√ß√µes nos mercados financeiros [^1]. Uma motiva√ß√£o chave √© a observa√ß√£o de que os mercados financeiros exibem volatilidade que varia ao longo do tempo [^1]. Modelar essa varia√ß√£o temporal √© crucial para uma gest√£o de risco eficaz, pois o aumento da volatilidade impacta diretamente medidas como o Value at Risk (VaR) [^1].

### Conceitos Fundamentais

#### 9.1 Time-Varying Risk or Outliers?
A an√°lise de dados financeiros frequentemente revela que a distribui√ß√£o emp√≠rica dos retornos n√£o se ajusta perfeitamente a uma distribui√ß√£o normal [^3]. Especificamente, a distribui√ß√£o real tende a ter mais observa√ß√µes no centro e nas caudas, um fen√¥meno conhecido como *fat tails* [^3]. A taxa de c√¢mbio d√≥lar americano/libra esterlina (\$/BP) para ilustrar estes conceitos [^2].
![The graph plots the exchange rate between the U.S. dollar and the British pound from 1990 to 1994](./../images/dollar_pound_exchange_rate.jpg)

**Duas Perspectivas sobre Fat Tails:**

1.  **Distribui√ß√£o Estacion√°ria com Fat Tails:** Esta vis√£o postula que a distribui√ß√£o verdadeira √© estacion√°ria e, de fato, cont√©m *fat tails*. Neste caso, aproximar a distribui√ß√£o por uma normal seria inapropriado [^3]. A presen√ßa de *fat tails* √© uma caracter√≠stica intr√≠nseca dos dados, refletindo a ocorr√™ncia relativamente frequente de eventos extremos. Distribui√ß√µes como a t-Student e a distribui√ß√£o hiperb√≥lica s√£o frequentemente usadas para modelar dados com *fat tails*.

2.  **Distribui√ß√£o Time-Varying:** Alternativamente, a distribui√ß√£o pode mudar ao longo do tempo [^3]. Em per√≠odos de turbul√™ncia, um modelo estacion√°rio pode interpretar grandes observa√ß√µes como *outliers*, quando, na realidade, elas s√£o provenientes de uma distribui√ß√£o com maior dispers√£o tempor√°ria [^3]. Esta perspectiva enfatiza que a volatilidade n√£o √© constante, mas sim aglomerada em certos per√≠odos [^1]. Modelos GARCH (Generalized Autoregressive Conditional Heteroskedasticity) s√£o projetados para capturar essa varia√ß√£o temporal da volatilidade.

Para complementar a discuss√£o sobre as diferentes perspectivas sobre *fat tails*, podemos introduzir o conceito de distribui√ß√µes *semi-param√©tricas* que combinam elementos de ambas as abordagens.

**Teorema 1** (Modelagem Semi-Param√©trica de Fat Tails): Uma abordagem semi-param√©trica combina uma distribui√ß√£o param√©trica para modelar o corpo da distribui√ß√£o com um m√©todo n√£o-param√©trico (como a estima√ß√£o de densidade kernel) para modelar as caudas. Essa abordagem pode capturar tanto as caracter√≠sticas de *fat tails* quanto a varia√ß√£o temporal do risco.

*Proof strategy:* A ideia central √© usar uma distribui√ß√£o param√©trica padr√£o (e.g., normal ou t-Student) para modelar a maior parte dos dados, e ent√£o aplicar um estimador n√£o-param√©trico nas observa√ß√µes extremas para ajustar as caudas da distribui√ß√£o. Isso permite uma maior flexibilidade na modelagem das caudas, sem impor uma forma funcional r√≠gida.

#### 9.2 Modeling Time-Varying Risk
Modelar a varia√ß√£o temporal do risco √© crucial para uma gest√£o de risco eficaz, pois o aumento da volatilidade impacta diretamente medidas como o Value at Risk (VaR) [^1]. Esta se√ß√£o em particular foca em como a presen√ßa de *fat tails* nas distribui√ß√µes emp√≠ricas dos retornos financeiros pode ser explicada tanto por distribui√ß√µes estacion√°rias com *fat tails* inerentes, quanto por distribui√ß√µes que mudam ao longo do tempo, com per√≠odos de turbul√™ncia [^3].

9.2.1 Moving Averages
Uma abordagem para modelar a varia√ß√£o temporal do risco √© o uso de **moving averages** [^4]. Este m√©todo calcula a volatilidade como a m√©dia dos retornos ao quadrado ao longo de uma janela de tempo fixa [^4]. A formula√ß√£o √© dada por:

$$\sigma_t^2 = (1/M) \sum_{i=1}^{M} r_{t-i+1}^2 $$

Esta f√≥rmula calcula a volatilidade como a m√©dia dos quadrados dos retornos mais recentes *M* [^4]. Aqui, nos concentramos nos retornos brutos em vez dos retornos em torno da m√©dia, pois, para a maioria das s√©ries financeiras, ignorar os retornos esperados em intervalos de tempo muito curtos faz pouca diferen√ßa para as estimativas de volatilidade [^4].

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos os seguintes retornos di√°rios para um ativo:
>
> Dia 1: 0.01
>
> Dia 2: -0.02
>
> Dia 3: 0.015
>
> Dia 4: 0.005
>
> Dia 5: -0.01
>
> Usando uma m√©dia m√≥vel com janela de *M* = 3 dias, podemos calcular a volatilidade para o dia 5 da seguinte forma:
>
> $\sigma_5^2 = (1/3) \cdot (0.015^2 + 0.005^2 + (-0.01)^2)$
>
> $\sigma_5^2 = (1/3) \cdot (0.000225 + 0.000025 + 0.0001)$
>
> $\sigma_5^2 = (1/3) \cdot (0.00035)$
>
> $\sigma_5^2 = 0.00011667$
>
> Portanto, a volatilidade estimada para o dia 5 √© a raiz quadrada de 0.00011667, que √© aproximadamente 0.0108 ou 1.08%.
>
> Este exemplo demonstra como a volatilidade √© calculada usando os retornos dos √∫ltimos tr√™s dias. A principal limita√ß√£o aqui √© que todos os tr√™s dias t√™m o mesmo peso, independentemente de qu√£o recentes sejam.

Para atenuar as limita√ß√µes das m√©dias m√≥veis, podemos considerar uma vers√£o ponderada, onde pesos diferentes s√£o atribu√≠dos aos retornos ao quadrado.

**Teorema 2** (M√©dia M√≥vel Ponderada): A volatilidade pode ser estimada usando uma m√©dia m√≥vel ponderada, onde pesos decrescentes s√£o atribu√≠dos a observa√ß√µes mais antigas. Isso √© definido como:

$$\sigma_t^2 = \sum_{i=1}^{M} w_i r_{t-i+1}^2 $$

onde $\sum_{i=1}^{M} w_i = 1$ e $w_i \geq 0$ para todo $i$.

*Proof strategy:* A escolha dos pesos $w_i$ √© crucial. Uma escolha comum √© usar um decaimento exponencial, onde $w_i = \lambda^{i-1} (1-\lambda) / (1 - \lambda^M)$, com $\lambda$ sendo um fator de decaimento entre 0 e 1. Isso d√° mais peso √†s observa√ß√µes recentes e menos peso √†s observa√ß√µes mais antigas, atenuando o problema do "efeito fantasma" das m√©dias m√≥veis simples.

> üí° **Exemplo Num√©rico:**
>
> Usando os mesmos retornos do exemplo anterior, vamos calcular a volatilidade ponderada para o dia 5 com *M* = 3 e $\lambda$ = 0.9. Primeiro, calculamos os pesos $w_i$:
>
> $w_1 = \frac{(1 - 0.9)}{1 - 0.9^3} \cdot 0.9^{0} = \frac{0.1}{0.271} \approx 0.369$
>
> $w_2 = \frac{(1 - 0.9)}{1 - 0.9^3} \cdot 0.9^{1} = \frac{0.1}{0.271} \cdot 0.9 \approx 0.332$
>
> $w_3 = \frac{(1 - 0.9)}{1 - 0.9^3} \cdot 0.9^{2} = \frac{0.1}{0.271} \cdot 0.81 \approx 0.299$
>
> Note que $w_1 + w_2 + w_3 \approx 0.369 + 0.332 + 0.299 = 1$.
>
> Agora, calculamos a volatilidade ponderada:
>
> $\sigma_5^2 = 0.369 \cdot (0.015)^2 + 0.332 \cdot (0.005)^2 + 0.299 \cdot (-0.01)^2$
>
> $\sigma_5^2 = 0.369 \cdot 0.000225 + 0.332 \cdot 0.000025 + 0.299 \cdot 0.0001$
>
> $\sigma_5^2 = 0.000083025 + 0.0000083 + 0.0000299$
>
> $\sigma_5^2 \approx 0.000121225$
>
> Portanto, a volatilidade estimada para o dia 5 usando a m√©dia m√≥vel ponderada √© aproximadamente $\sqrt{0.000121225} \approx 0.01101$ ou 1.101%.
>
> Observe que a volatilidade ponderada √© ligeiramente diferente da volatilidade simples da m√©dia m√≥vel devido √† atribui√ß√£o de pesos diferentes aos retornos passados, dando mais import√¢ncia aos retornos mais recentes.

**Prova da Validade dos Pesos Exponenciais:**
Provaremos que os pesos $w_i = \lambda^{i-1} (1-\lambda) / (1 - \lambda^M)$ satisfazem $\sum_{i=1}^{M} w_i = 1$.

I.  Defina $S = \sum_{i=1}^{M} w_i = \sum_{i=1}^{M} \frac{\lambda^{i-1} (1-\lambda)}{1 - \lambda^M}$.

II. Podemos fatorar os termos constantes: $S =  \frac{1-\lambda}{1 - \lambda^M} \sum_{i=1}^{M} \lambda^{i-1}$.

III. A soma $\sum_{i=1}^{M} \lambda^{i-1}$ √© uma s√©rie geom√©trica com $M$ termos, primeiro termo $1$ e raz√£o $\lambda$.

IV. A soma de uma s√©rie geom√©trica √© dada por $\frac{1 - \lambda^M}{1 - \lambda}$.

V.  Substituindo na express√£o de $S$, obtemos $S = \frac{1-\lambda}{1 - \lambda^M} \cdot \frac{1 - \lambda^M}{1 - \lambda} = 1$.

VI. Portanto, $\sum_{i=1}^{M} w_i = 1$. $\blacksquare$

9.2.2 GARCH Estimation
Para superar as limita√ß√µes das m√©dias m√≥veis, a modelagem de volatilidade evoluiu para modelos que d√£o mais peso √†s informa√ß√µes recentes [^5]. O primeiro desses modelos foi o **Generalized Autoregressive Conditional Heteroskedastic (GARCH)**, proposto por Engle (1982) e Bollerslev (1986) [^5]. O termo *"heteroskedastic"* refere-se ao fato de que as vari√¢ncias est√£o mudando [^5]. O modelo GARCH assume que a vari√¢ncia dos retornos segue um processo previs√≠vel [^5]. A vari√¢ncia condicional depende da inova√ß√£o mais recente, mas tamb√©m da vari√¢ncia condicional anterior [^5].

Uma extens√£o natural do modelo GARCH(1,1) √© permitir que a m√©dia condicional dos retornos tamb√©m dependa da vari√¢ncia condicional. Isso leva ao modelo GARCH-in-Mean (GARCH-M).

**Teorema 3** (Modelo GARCH-in-Mean): O modelo GARCH-M estende o modelo GARCH ao incluir a vari√¢ncia condicional (ou seu desvio padr√£o) na equa√ß√£o da m√©dia condicional:

$$r_t = \mu + \theta \sigma_t^2 + \epsilon_t$$
$$\sigma_t^2 = \alpha_0 + \alpha_1 r_{t-1}^2 + \beta \sigma_{t-1}^2$$

onde $\theta$ √© o coeficiente que mede o efeito da vari√¢ncia condicional na m√©dia condicional.

*Proof strategy:* A estima√ß√£o do modelo GARCH-M √© semelhante √† do modelo GARCH padr√£o, geralmente via m√°xima verossimilhan√ßa. A interpreta√ß√£o de $\theta$ √© que ele captura a rela√ß√£o risco-retorno; um $\theta$ positivo indica que um aumento na volatilidade esperada leva a um aumento no retorno esperado.

> üí° **Exemplo Num√©rico:**
>
> Vamos considerar um modelo GARCH(1,1) com os seguintes par√¢metros estimados:
>
> $\alpha_0 = 0.00001$
>
> $\alpha_1 = 0.05$
>
> $\beta = 0.90$
>
> Suponha que o retorno de ontem ($r_{t-1}$) foi 0.02 (2%) e a vari√¢ncia condicional de ontem ($\sigma_{t-1}^2$) foi 0.00015. Podemos calcular a vari√¢ncia condicional de hoje ($\sigma_t^2$) da seguinte forma:
>
> $\sigma_t^2 = 0.00001 + 0.05 \cdot (0.02)^2 + 0.90 \cdot 0.00015$
>
> $\sigma_t^2 = 0.00001 + 0.05 \cdot 0.0004 + 0.90 \cdot 0.00015$
>
> $\sigma_t^2 = 0.00001 + 0.00002 + 0.000135$
>
> $\sigma_t^2 = 0.000165$
>
> A volatilidade condicional de hoje √© a raiz quadrada da vari√¢ncia condicional:
>
> $\sigma_t = \sqrt{0.000165} \approx 0.0128$ ou 1.28%.
>
> Agora, considere um modelo GARCH-M onde $\theta = 0.1$, $\mu = 0.0001$. Ent√£o o retorno esperado hoje √©:
> $r_t = 0.0001 + 0.1 * 0.000165 + \epsilon_t$
> $r_t = 0.0001 + 0.0000165 + \epsilon_t$
> $r_t = 0.0001165 + \epsilon_t$
>
> Este exemplo demonstra como o modelo GARCH calcula a volatilidade condicional com base nos retornos anteriores e na volatilidade anterior, e como o modelo GARCH-M incorpora a volatilidade na equa√ß√£o da m√©dia do retorno.
>
> ```python
> import numpy as np
>
> # Par√¢metros do modelo GARCH(1,1)
> alpha0 = 0.00001
> alpha1 = 0.05
> beta = 0.90
>
> # Retorno e vari√¢ncia condicional do dia anterior
> r_anterior = 0.02
> sigma2_anterior = 0.00015
>
> # Calcula a vari√¢ncia condicional atual
> sigma2_atual = alpha0 + alpha1 * (r_anterior**2) + beta * sigma2_anterior
>
> # Calcula a volatilidade condicional atual
> sigma_atual = np.sqrt(sigma2_atual)
>
> print(f"Vari√¢ncia condicional atual: {sigma2_atual}")
> print(f"Volatilidade condicional atual: {sigma_atual}")
> ```

### 9.3 Modeling Correlations
A correla√ß√£o √© de suma import√¢ncia para o risco de portf√≥lio, ainda mais do que as vari√¢ncias individuais. Para ilustrar a estima√ß√£o da correla√ß√£o, escolhemos duas s√©ries: a taxa de c√¢mbio d√≥lar/libra esterlina e a taxa d√≥lar/marco alem√£o.

#### 9.3.1 Moving Averages
O primeiro m√©todo √© baseado em m√©dias m√≥veis (MAs), usando uma janela fixa de comprimento M. As correla√ß√µes come√ßam baixas, em torno de 0,5, e depois aumentam para 0,9 quando a libra entra no SME. Durante a crise de setembro de 1992, as correla√ß√µes caem acentuadamente e depois voltam ao padr√£o pr√©-SME.

> üí° **Exemplo Num√©rico:**
>
> Suponha que tenhamos retornos di√°rios para dois ativos, A e B, durante 5 dias:
>
> | Dia | Retorno Ativo A | Retorno Ativo B |
> |-----|-----------------|-----------------|
> | 1   | 0.01            | 0.015           |
> | 2   | -0.02           | -0.025          |
> | 3   | 0.015           | 0.02            |
> | 4   | 0.005           | 0.008           |
> | 5   | -0.01           | -0.012          |
>
> Para calcular a correla√ß√£o usando uma m√©dia m√≥vel com *M* = 3 dias para o dia 5, precisamos dos retornos dos dias 3, 4 e 5.
>
> Primeiro, calculamos as covari√¢ncias para os dias 3, 4 e 5:
>
> $cov(A, B) = \frac{1}{M-1} \sum_{i=1}^{M} (A_i - \bar{A})(B_i - \bar{B})$
>
> Retornos m√©dios para A: $\bar{A} = \frac{0.015 + 0.005 - 0.01}{3} = 0.00333$
>
> Retornos m√©dios para B: $\bar{B} = \frac{0.02 + 0.008 - 0.012}{3} = 0.00533$
>
> Covari√¢ncia:
>
> $cov(A, B) = \frac{1}{2} [(0.015 - 0.00333)(0.02 - 0.00533) + (0.005 - 0.00333)(0.008 - 0.00533) + (-0.01 - 0.00333)(-0.012 - 0.00533)]$
>
> $cov(A, B) = \frac{1}{2} [(0.01167)(0.01467) + (0.00167)(0.00267) + (-0.01333)(-0.01733)]$
>
> $cov(A, B) = \frac{1}{2} [0.0001712 + 0.0000045 + 0.0002310] = \frac{1}{2} [0.0004067] = 0.00020335$
>
> Agora, calculamos os desvios padr√£o para A e B usando a mesma janela:
>
> $\sigma_A = \sqrt{\frac{1}{2} [(0.015 - 0.00333)^2 + (0.005 - 0.00333)^2 + (-0.01 - 0.00333)^2]} = \sqrt{\frac{1}{2} [0.0001362 + 0.0000028 + 0.0001777]} = \sqrt{0.00015835} \approx 0.01258$
>
> $\sigma_B = \sqrt{\frac{1}{2} [(0.02 - 0.00533)^2 + (0.008 - 0.00533)^2 + (-0.012 - 0.00533)^2]} = \sqrt{\frac{1}{2} [0.0002152 + 0.0000035 + 0.0003003]} = \sqrt{0.0002595} \approx 0.01611$
>
> Finalmente, a correla√ß√£o √©:
>
> $\rho_{A, B} = \frac{cov(A, B)}{\sigma_A \cdot \sigma_B} = \frac{0.00020335}{0.01258 \cdot 0.01611} = \frac{0.00020335}{0.00020266} \approx 1.003$
>
> Neste exemplo, a correla√ß√£o calculada √© ligeiramente superior a 1, o que pode ser devido a erros de arredondamento nos c√°lculos. Em cen√°rios pr√°ticos, √© essencial usar software estat√≠stico que possa realizar esses c√°lculos com maior precis√£o.

#### 9.3.2 GARCH
Em teoria, a estimativa GARCH poderia ser estendida a uma estrutura multivariada. O problema √© que o n√∫mero de par√¢metros a estimar aumenta exponencialmente com o n√∫mero de s√©ries.

Para mitigar o problema do aumento exponencial de par√¢metros nos modelos GARCH multivariados, pode-se impor restri√ß√µes na estrutura da matriz de covari√¢ncia condicional.

**Teorema 4** (Modelo DCC - Dynamic Conditional Correlation): O modelo DCC √© uma abordagem para modelar correla√ß√µes din√¢micas que reduz o n√∫mero de par√¢metros ao modelar as correla√ß√µes diretamente, em vez de modelar as covari√¢ncias.

*Proof strategy:* No modelo DCC, a matriz de covari√¢ncia condicional √© decomposta em desvios padr√µes condicionais e uma matriz de correla√ß√£o condicional. Os desvios padr√µes condicionais s√£o modelados usando modelos GARCH univariados, enquanto a matriz de correla√ß√£o condicional √© modelada usando um processo din√¢mico que depende de par√¢metros relativamente poucos. Isso torna o modelo DCC mais trat√°vel para portf√≥lios de ativos maiores.

#### 9.3.3 Exponential Averages
Aqui brilha a simplicidade da abordagem RiskMetrics. As covari√¢ncias s√£o estimadas, assim como as vari√¢ncias, usando um esquema de pondera√ß√£o exponencial, isto √©,

$$h_{12,t} = \lambda h_{12,t-1} + (1 ‚àí \lambda) r_{1,t-1} r_{2,t-1} $$

Como antes, o fator de decaimento √© arbitrariamente definido como 0,94 para dados di√°rios e 0,97 para dados mensais. A correla√ß√£o condicional ent√£o √©

Para refinar a estimativa da correla√ß√£o condicional usando m√©dias exponenciais, podemos introduzir um ajuste para evitar valores extremos.

**Teorema 5** (Corre√ß√£o para Correla√ß√µes Extremas): Para evitar que a correla√ß√£o condicional estimada atinja valores extremos (pr√≥ximos de +1 ou -1), podemos aplicar uma transforma√ß√£o que comprima a correla√ß√£o em dire√ß√£o a zero. Uma transforma√ß√£o comum √©:

$$\rho_{12,t}^* = \tanh(\omega \cdot \rho_{12,t})$$

onde $\rho_{12,t}$ √© a correla√ß√£o condicional estimada via m√©dias exponenciais, $\rho_{12,t}^*$ √© a correla√ß√£o ajustada, e $\omega$ √© um par√¢metro que controla a intensidade da compress√£o.

*Proof strategy:* A fun√ß√£o tangente hiperb√≥lica ($\tanh$) mapeia qualquer valor real para o intervalo (-1, 1), garantindo que a correla√ß√£o ajustada permane√ßa dentro dos limites v√°lidos. Ajustar o par√¢metro $\omega$ permite controlar o qu√£o fortemente a correla√ß√£o √© comprimida em dire√ß√£o a zero, mitigando o impacto de valores extremos que podem surgir de ru√≠do nos dados.

> üí° **Exemplo Num√©rico:**
>
> Suponha que a covari√¢ncia condicional estimada no dia *t-1* seja $h_{12,t-1} = 0.00015$, e os retornos no dia *t-1* para os ativos 1 e 2 sejam $r_{1,t-1} = 0.01$ e $r_{2,t-1} = 0.012$, respectivamente. Usando um fator de decaimento $\lambda = 0.94$, podemos calcular a covari√¢ncia condicional para o dia *t*:
>
> $h_{12,t} = 0.94 \cdot 0.00015 + (1 - 0.94) \cdot (0.01 \cdot 0.012)$
>
> $h_{12,t} = 0.94 \cdot 0.00015 + 0.06 \cdot 0.00012$
>
> $h_{12,t} = 0.000141 + 0.0000072 = 0.0001482$
>
> Agora, suponha que as vari√¢ncias condicionais estimadas para os ativos 1 e 2 sejam $h_{1,t} = 0.0002$ e $h_{2,t} = 0.00025$, respectivamente. A correla√ß√£o condicional estimada √©:
>
> $\rho_{12,t} = \frac{h_{12,t}}{\sqrt{h_{1,t} \cdot h_{2,t}}} = \frac{0.0001482}{\sqrt{0.0002 \cdot 0.00025}} = \frac{0.0001482}{\sqrt{0.00000005}} = \frac{0.0001482}{0.0002236} \approx 0.6628$
>
> Agora, aplicamos a corre√ß√£o para correla√ß√µes extremas com $\omega = 0.5$:
>
> $\rho_{12,t}^* = \tanh(0.5 \cdot 0.6628) = \tanh(0.3314) \approx 0.3213$
>
> Neste exemplo, a corre√ß√£o com a fun√ß√£o tangente hiperb√≥lica comprime a correla√ß√£o estimada de 0.6628 para 0.3213, evitando valores extremos e tornando a estimativa mais robusta.
>
> ```python
> import numpy as np
>
> # Covari√¢ncia condicional no dia t-1
> h12_anterior = 0.00015
>
> # Retornos no dia t-1 para os ativos 1 e 2
> r1_anterior = 0.01
> r2_anterior = 0.012
>
> # Fator de decaimento
> lambd = 0.94
>
> # Calcula a covari√¢ncia condicional atual
> h12_atual = lambd * h12_anterior + (1 - lambd) * (r1_anterior * r2_anterior)
>
> # Vari√¢ncias condicionais estimadas para os ativos 1 e 2
> h1_atual = 0.0002
> h2_atual = 0.00025
>
> # Calcula a correla√ß√£o condicional estimada
> rho12_atual = h12_atual / np.sqrt(h1_atual * h2_atual)
>
> # Par√¢metro para a corre√ß√£o de correla√ß√µes extremas
> omega = 0.5
>
> # Aplica a corre√ß√£o para correla√ß√µes extremas usando a fun√ß√£o tanh
> rho12_corrigido = np.tanh(omega * rho12_atual)
>
> print(f"Covari√¢ncia condicional atual: {h12_atual}")
> print(f"Correla√ß√£o condicional estimada: {rho12_atual}")
> print(f"Correla√ß√£o condicional corrigida: {rho12_corrigido}")
> ```

**Prova da Fun√ß√£o $\tanh$ estar no intervalo (-1, 1):**

Provaremos que a fun√ß√£o $\tanh(x)$ tem sua imagem contida no intervalo $(-1, 1)$ para todo $x \in \mathbb{R}$.

I.  A fun√ß√£o tangente hiperb√≥lica √© definida como $\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}$.

II. Podemos reescrever $\tanh(x)$ como $\tanh(x) = \frac{e^{2x} - 1}{e^{2x} + 1}$.

III. Analisando o limite quando $x$ tende ao infinito: $\lim_{x \to \infty} \tanh(x) = \lim_{x \to \infty} \frac{e^{2x} - 1}{e^{2x} + 1} = 1$.

IV. Analisando o limite quando $x$ tende a menos infinito: $\lim_{x \to -\infty} \tanh(x) = \lim_{x \to -\infty} \frac{e^{2x} - 1}{e^{2x} + 1} = -1$.

V.  Como $e^{2x} > 0$ para todo $x$, ent√£o $e^{2x} + 1 > e^{2x} - 1$, e portanto $|\frac{e^{2x} - 1}{e^{2x} + 1}| < 1$.

VI. Al√©m disso, $\tanh(x)$ √© uma fun√ß√£o cont√≠nua e mon√≥tona crescente.

VII. Portanto, $-1 < \tanh(x) < 1$ para todo $x \in \mathbb{R}$. $\blacksquare$

### Conclus√£o

Em resumo, uma gest√£o de risco precisa deve considerar modelagens de volatilidade e correla√ß√µes, pois √© o que de fato afeta o c√°lculo do VAR [^1]. Em per√≠odos de mudan√ßas estruturais, o modelo de volatilidade deve dar mais peso aos valores recentes.

### Refer√™ncias
[^1]: P√°gina 219: *‚ÄúThe purpose of this chapter is to present techniques to forecast vari-ation in risk and correlations. Section 9.1 motivates the problem by taking the example of a series that underwent structural changes leading to pre-dictable patterns in volatility.‚Äù*
[^2]: P√°gina 220: *‚ÄúAs an illustration, we will walk through this chapter focusing on the U.S. dollar/British pound ($/BP) exchange rate measured at daily intervals. Movements in the exchange rate are displayed in Figure 9-1. The 1990‚Äì1994 period was fairly typical, covering narrow trading ranges and wide swings. September 1992 was particularly tumultuous. After vain attempts by the Bank of England to support the pound against the German mark, the pound exited the European Monetary System. There were several days with very large moves. On September 17 alone, the pound fell by 6 percent against the mark and also against the dollar. Hence we can expect interesting patterns in volatility. In particular, the question is whether this structural change led to predictable time variation in risk.‚Äù*
[^3]: P√°gina 221: *‚ÄúOver this period, the average daily volatility was 0.694 percent, which translates into 11.02 percent per annum (using a 252-trading-day adjustment). This risk measure, however, surely was not constant over time. In addition, time variation in risk could explain the fact that the empirical distribution of returns does not quite exactly fit a normal distribution. Figure 9-2 compares the normal approximation with the actual empirical distribution of the $/BP exchange rate. Relative to the normal model, the actual distribution contains more observations in the center and in the tails. These fat tails can be explained by two alternative viewpoints. The first view is that the true distribution is stationary and indeed contains fat tails, in which case a normal approximation is clearly inappropriate. The other view is that the distribution does change through time. As a result, in times of turbulence, a stationary model could view large observations as outliers when they are really drawn from a distribution with temporarily greater dispersion. In practice, both explanations carry some truth. This is why fore-casting variation in risk is particularly fruitful for risk management. In‚Äù*
[^4]: P√°gina 222: *‚ÄúA very crude method, but one that is employed widely, is to use a moving window of fixed length for estimating volatility. For instance, a typical length is 20 trading days (about a calendar month) or 60 trading days (about a calendar quarter). Assuming that we observe returns r, over M days, this volatility estimate is constructed from a moving average (MA), that is, 2 =(1/M) M œÉŒµ Œ£ i-1 2 r ti (9.1) Here we focus on raw returns instead of returns around the mean. This is so because for most financial series, ignoring expected returns over very short time intervals makes little difference for volatility estimates. Each day, the forecast is updated by adding information from the preceding day and dropping information from (M + 1) days ago. All weights on past returns are equal and set to (1/M). Figure 9-3 displays 20- and 60-day moving averages for our $/BP rate. While simple to implement, this model has serious drawbacks. First, it ignores the dynamic ordering of observations. Recent information receives the same weight as older observations in the window that may no longer be relevant. Also, if there was a large return M days ago, dropping this return as the window moves 1 day forward will affect the volatility estimate sub-stantially. For instance, there was a 3 percent drop on September 17, 1992. This observation will increase the MA forecast immediately, which cor-rectly reflects the higher volatility. The MA(20), however, reverts to a lower value after 20 days; the MA(60) reverts to a lower value after 60 days. As a result, moving-average measures of volatility tend to look like plateaus of width M when plotted against time. The subsequent drop, however, is totally an artifact of the window length. This has been called the ghosting feature because the MA measure changes for no apparent reason.‚Äù*
[^5]: P√°gina 223: *‚ÄúThis is why volatility estimation has moved toward models that put more weight on recent information. The first such model was the generalized autoregressive conditional heteroskedastic (GARCH) model proposed by Engle (1982) and Bollerslev (1986) (see Box 9-1). Heteroskedastic refers to the fact that variances are changing. The GARCH model assumes that the variance of returns follows a pre-dictable process. The conditional variance depends on the latest innovation but also on the previous conditional variance. Define h, as the conditional variance, using information up to time t 1, and r1 as the previous day's return. The simplest such model is the GARCH(1,1) process, that is, h, = a + ar¬≤ + ·∫ûh,-1 1 (9.2)‚Äù*
[^6]: P√°gina 2249.  2.  Volatility Asymmetry

One stylized fact not captured by GARCH models is the asymmetry in the response of volatility to positive and negative return shocks. Empirical evidence suggests that negative return shocks (bad news) tend to increase volatility more than positive return shocks (good news) of the same magnitude. This phenomenon is known as the leverage effect or volatility asymmetry. Several extensions of the GARCH model have been proposed to capture this asymmetry, including the EGARCH, GJR-GARCH, and TGARCH models.

10. 3.  EGARCH Model

The Exponential GARCH (EGARCH) model, introduced by Nelson (1991), captures the asymmetry in volatility by modeling the logarithm of the conditional variance as a function of both the magnitude and sign of the lagged residuals. The EGARCH(1,1) model is specified as:
$$log(h_t) = \alpha_0 + \alpha_1 \frac{\epsilon_{t-1}}{\sqrt{h_{t-1}}} + \gamma \frac{\epsilon_{t-1}}{\sqrt{h_{t-1}}} + \beta log(h_{t-1})$$
where:
- $h_t$ is the conditional variance at time t,
- $\epsilon_{t-1}$ is the residual at time t-1,
- $\alpha_0$, $\alpha_1$, $\gamma$, and $\beta$ are parameters to be estimated.

The key feature of the EGARCH model is the inclusion of the term $\gamma \frac{\epsilon_{t-1}}{\sqrt{h_{t-1}}}$, which allows for asymmetric effects. If $\gamma < 0$, negative shocks ($\epsilon_{t-1} < 0$) will have a larger impact on volatility than positive shocks of the same magnitude.

11. 4.  GJR-GARCH Model

The GJR-GARCH model, named after Glosten, Jagannathan, and Runkle (1993), is another extension of the GARCH model that captures volatility asymmetry. The GJR-GARCH(1,1) model is given by:
$$h_t = \alpha_0 + \alpha_1 \epsilon_{t-1}^2 + \gamma \epsilon_{t-1}^2 I_{t-1} + \beta h_{t-1}$$
where:
- $h_t$ is the conditional variance at time t,
- $\epsilon_{t-1}$ is the residual at time t-1,
- $\alpha_0$, $\alpha_1$, $\gamma$, and $\beta$ are parameters to be estimated,
- $I_{t-1}$ is an indicator function that equals 1 if $\epsilon_{t-1} < 0$ and 0 otherwise.

In the GJR-GARCH model, the coefficient $\gamma$ captures the asymmetric effect. If $\gamma > 0$, negative shocks will have a larger impact on volatility than positive shocks.

12. 5.  TGARCH Model

The Threshold GARCH (TGARCH) model is similar to the GJR-GARCH model in that it uses an indicator function to capture asymmetric effects. The TGARCH(1,1) model is specified as:
$$\sqrt{h_t} = \alpha_0 + \alpha_1 |\epsilon_{t-1}| + \gamma \epsilon_{t-1} I_{t-1} + \beta \sqrt{h_{t-1}}$$
where:
- $h_t$ is the conditional variance at time t,
- $\epsilon_{t-1}$ is the residual at time t-1,
- $\alpha_0$, $\alpha_1$, $\gamma$, and $\beta$ are parameters to be estimated,
- $I_{t-1}$ is an indicator function that equals 1 if $\epsilon_{t-1} < 0$ and 0 otherwise.

In the TGARCH model, the coefficient $\gamma$ captures the asymmetric effect. If $\gamma \neq 0$, negative and positive shocks will have different impacts on volatility.

<!-- END -->