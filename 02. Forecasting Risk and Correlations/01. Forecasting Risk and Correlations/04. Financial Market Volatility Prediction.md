## Forecasting Risk and Correlations: Time-Varying Risk and Correlations

### IntroduÃ§Ã£o
Este capÃ­tulo aborda tÃ©cnicas para prever a variaÃ§Ã£o no risco e nas correlaÃ§Ãµes nos mercados financeiros [^1]. Uma motivaÃ§Ã£o chave Ã© a observaÃ§Ã£o de que os mercados financeiros exibem volatilidade que varia ao longo do tempo [^1]. Modelar essa variaÃ§Ã£o temporal Ã© crucial para uma gestÃ£o de risco eficaz, pois o aumento da volatilidade impacta diretamente medidas como o Value at Risk (VaR) [^1].

### Conceitos Fundamentais

#### 9.1 Time-Varying Risk or Outliers?
A anÃ¡lise de dados financeiros frequentemente revela que a distribuiÃ§Ã£o empÃ­rica dos retornos nÃ£o se ajusta perfeitamente a uma distribuiÃ§Ã£o normal [^3]. Especificamente, a distribuiÃ§Ã£o real tende a ter mais observaÃ§Ãµes no centro e nas caudas, um fenÃ´meno conhecido como *fat tails* [^3]. A taxa de cÃ¢mbio dÃ³lar americano/libra esterlina (\$/BP) para ilustrar estes conceitos [^2].
![The graph plots the exchange rate between the U.S. dollar and the British pound from 1990 to 1994](./../images/dollar_pound_exchange_rate.jpg)

**Duas Perspectivas sobre Fat Tails:**

1.  **DistribuiÃ§Ã£o EstacionÃ¡ria com Fat Tails:** Esta visÃ£o postula que a distribuiÃ§Ã£o verdadeira Ã© estacionÃ¡ria e, de fato, contÃ©m *fat tails*. Neste caso, aproximar a distribuiÃ§Ã£o por uma normal seria inapropriado [^3]. A presenÃ§a de *fat tails* Ã© uma caracterÃ­stica intrÃ­nseca dos dados, refletindo a ocorrÃªncia relativamente frequente de eventos extremos. DistribuiÃ§Ãµes como a t-Student e a distribuiÃ§Ã£o hiperbÃ³lica sÃ£o frequentemente usadas para modelar dados com *fat tails*.

2.  **DistribuiÃ§Ã£o Time-Varying:** Alternativamente, a distribuiÃ§Ã£o pode mudar ao longo do tempo [^3]. Em perÃ­odos de turbulÃªncia, um modelo estacionÃ¡rio pode interpretar grandes observaÃ§Ãµes como *outliers*, quando, na realidade, elas sÃ£o provenientes de uma distribuiÃ§Ã£o com maior dispersÃ£o temporÃ¡ria [^3]. Esta perspectiva enfatiza que a volatilidade nÃ£o Ã© constante, mas sim aglomerada em certos perÃ­odos [^1]. Modelos GARCH (Generalized Autoregressive Conditional Heteroskedasticity) sÃ£o projetados para capturar essa variaÃ§Ã£o temporal da volatilidade.

Para complementar a discussÃ£o sobre as diferentes perspectivas sobre *fat tails*, podemos introduzir o conceito de distribuiÃ§Ãµes *semi-paramÃ©tricas* que combinam elementos de ambas as abordagens.

**Teorema 1** (Modelagem Semi-ParamÃ©trica de Fat Tails): Uma abordagem semi-paramÃ©trica combina uma distribuiÃ§Ã£o paramÃ©trica para modelar o corpo da distribuiÃ§Ã£o com um mÃ©todo nÃ£o-paramÃ©trico (como a estimaÃ§Ã£o de densidade kernel) para modelar as caudas. Essa abordagem pode capturar tanto as caracterÃ­sticas de *fat tails* quanto a variaÃ§Ã£o temporal do risco.

*Proof strategy:* A ideia central Ã© usar uma distribuiÃ§Ã£o paramÃ©trica padrÃ£o (e.g., normal ou t-Student) para modelar a maior parte dos dados, e entÃ£o aplicar um estimador nÃ£o-paramÃ©trico nas observaÃ§Ãµes extremas para ajustar as caudas da distribuiÃ§Ã£o. Isso permite uma maior flexibilidade na modelagem das caudas, sem impor uma forma funcional rÃ­gida.

#### 9.2 Modeling Time-Varying Risk
Modelar a variaÃ§Ã£o temporal do risco Ã© crucial para uma gestÃ£o de risco eficaz, pois o aumento da volatilidade impacta diretamente medidas como o Value at Risk (VaR) [^1]. Esta seÃ§Ã£o em particular foca em como a presenÃ§a de *fat tails* nas distribuiÃ§Ãµes empÃ­ricas dos retornos financeiros pode ser explicada tanto por distribuiÃ§Ãµes estacionÃ¡rias com *fat tails* inerentes, quanto por distribuiÃ§Ãµes que mudam ao longo do tempo, com perÃ­odos de turbulÃªncia [^3].

9.2.1 Moving Averages
Uma abordagem para modelar a variaÃ§Ã£o temporal do risco Ã© o uso de **moving averages** [^4]. Este mÃ©todo calcula a volatilidade como a mÃ©dia dos retornos ao quadrado ao longo de uma janela de tempo fixa [^4]. A formulaÃ§Ã£o Ã© dada por:

$$\sigma_t^2 = (1/M) \sum_{i=1}^{M} r_{t-i+1}^2 $$

Esta fÃ³rmula calcula a volatilidade como a mÃ©dia dos quadrados dos retornos mais recentes *M* [^4]. Aqui, nos concentramos nos retornos brutos em vez dos retornos em torno da mÃ©dia, pois, para a maioria das sÃ©ries financeiras, ignorar os retornos esperados em intervalos de tempo muito curtos faz pouca diferenÃ§a para as estimativas de volatilidade [^4].

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Suponha que temos os seguintes retornos diÃ¡rios para um ativo:
>
> Dia 1: 0.01
>
> Dia 2: -0.02
>
> Dia 3: 0.015
>
> Dia 4: 0.005
>
> Dia 5: -0.01
>
> Usando uma mÃ©dia mÃ³vel com janela de *M* = 3 dias, podemos calcular a volatilidade para o dia 5 da seguinte forma:
>
> $\sigma_5^2 = (1/3) \cdot (0.015^2 + 0.005^2 + (-0.01)^2)$
>
> $\sigma_5^2 = (1/3) \cdot (0.000225 + 0.000025 + 0.0001)$
>
> $\sigma_5^2 = (1/3) \cdot (0.00035)$
>
> $\sigma_5^2 = 0.00011667$
>
> Portanto, a volatilidade estimada para o dia 5 Ã© a raiz quadrada de 0.00011667, que Ã© aproximadamente 0.0108 ou 1.08%.
>
> Este exemplo demonstra como a volatilidade Ã© calculada usando os retornos dos Ãºltimos trÃªs dias. A principal limitaÃ§Ã£o aqui Ã© que todos os trÃªs dias tÃªm o mesmo peso, independentemente de quÃ£o recentes sejam.

Para atenuar as limitaÃ§Ãµes das mÃ©dias mÃ³veis, podemos considerar uma versÃ£o ponderada, onde pesos diferentes sÃ£o atribuÃ­dos aos retornos ao quadrado.

**Teorema 2** (MÃ©dia MÃ³vel Ponderada): A volatilidade pode ser estimada usando uma mÃ©dia mÃ³vel ponderada, onde pesos decrescentes sÃ£o atribuÃ­dos a observaÃ§Ãµes mais antigas. Isso Ã© definido como:

$$\sigma_t^2 = \sum_{i=1}^{M} w_i r_{t-i+1}^2 $$

onde $\sum_{i=1}^{M} w_i = 1$ e $w_i \geq 0$ para todo $i$.

*Proof strategy:* A escolha dos pesos $w_i$ Ã© crucial. Uma escolha comum Ã© usar um decaimento exponencial, onde $w_i = \lambda^{i-1} (1-\lambda) / (1 - \lambda^M)$, com $\lambda$ sendo um fator de decaimento entre 0 e 1. Isso dÃ¡ mais peso Ã s observaÃ§Ãµes recentes e menos peso Ã s observaÃ§Ãµes mais antigas, atenuando o problema do "efeito fantasma" das mÃ©dias mÃ³veis simples.

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Usando os mesmos retornos do exemplo anterior, vamos calcular a volatilidade ponderada para o dia 5 com *M* = 3 e $\lambda$ = 0.9. Primeiro, calculamos os pesos $w_i$:
>
> $w_1 = \frac{(1 - 0.9)}{1 - 0.9^3} \cdot 0.9^{0} = \frac{0.1}{0.271} \approx 0.369$
>
> $w_2 = \frac{(1 - 0.9)}{1 - 0.9^3} \cdot 0.9^{1} = \frac{0.1}{0.271} \cdot 0.9 \approx 0.332$
>
> $w_3 = \frac{(1 - 0.9)}{1 - 0.9^3} \cdot 0.9^{2} = \frac{0.1}{0.271} \cdot 0.81 \approx 0.299$
>
> Note que $w_1 + w_2 + w_3 \approx 0.369 + 0.332 + 0.299 = 1$.
>
> Agora, calculamos a volatilidade ponderada:
>
> $\sigma_5^2 = 0.369 \cdot (0.015)^2 + 0.332 \cdot (0.005)^2 + 0.299 \cdot (-0.01)^2$
>
> $\sigma_5^2 = 0.369 \cdot 0.000225 + 0.332 \cdot 0.000025 + 0.299 \cdot 0.0001$
>
> $\sigma_5^2 = 0.000083025 + 0.0000083 + 0.0000299$
>
> $\sigma_5^2 \approx 0.000121225$
>
> Portanto, a volatilidade estimada para o dia 5 usando a mÃ©dia mÃ³vel ponderada Ã© aproximadamente $\sqrt{0.000121225} \approx 0.01101$ ou 1.101%.
>
> Observe que a volatilidade ponderada Ã© ligeiramente diferente da volatilidade simples da mÃ©dia mÃ³vel devido Ã  atribuiÃ§Ã£o de pesos diferentes aos retornos passados, dando mais importÃ¢ncia aos retornos mais recentes.

**Prova da Validade dos Pesos Exponenciais:**
Provaremos que os pesos $w_i = \lambda^{i-1} (1-\lambda) / (1 - \lambda^M)$ satisfazem $\sum_{i=1}^{M} w_i = 1$.

I.  Defina $S = \sum_{i=1}^{M} w_i = \sum_{i=1}^{M} \frac{\lambda^{i-1} (1-\lambda)}{1 - \lambda^M}$.

II. Podemos fatorar os termos constantes: $S =  \frac{1-\lambda}{1 - \lambda^M} \sum_{i=1}^{M} \lambda^{i-1}$.

III. A soma $\sum_{i=1}^{M} \lambda^{i-1}$ Ã© uma sÃ©rie geomÃ©trica com $M$ termos, primeiro termo $1$ e razÃ£o $\lambda$.

IV. A soma de uma sÃ©rie geomÃ©trica Ã© dada por $\frac{1 - \lambda^M}{1 - \lambda}$.

V.  Substituindo na expressÃ£o de $S$, obtemos $S = \frac{1-\lambda}{1 - \lambda^M} \cdot \frac{1 - \lambda^M}{1 - \lambda} = 1$.

VI. Portanto, $\sum_{i=1}^{M} w_i = 1$. $\blacksquare$

9.2.2 GARCH Estimation
Para superar as limitaÃ§Ãµes das mÃ©dias mÃ³veis, a modelagem de volatilidade evoluiu para modelos que dÃ£o mais peso Ã s informaÃ§Ãµes recentes [^5]. O primeiro desses modelos foi o **Generalized Autoregressive Conditional Heteroskedastic (GARCH)**, proposto por Engle (1982) e Bollerslev (1986) [^5]. O termo *"heteroskedastic"* refere-se ao fato de que as variÃ¢ncias estÃ£o mudando [^5]. O modelo GARCH assume que a variÃ¢ncia dos retornos segue um processo previsÃ­vel [^5]. A variÃ¢ncia condicional depende da inovaÃ§Ã£o mais recente, mas tambÃ©m da variÃ¢ncia condicional anterior [^5].

Uma extensÃ£o natural do modelo GARCH(1,1) Ã© permitir que a mÃ©dia condicional dos retornos tambÃ©m dependa da variÃ¢ncia condicional. Isso leva ao modelo GARCH-in-Mean (GARCH-M).

**Teorema 3** (Modelo GARCH-in-Mean): O modelo GARCH-M estende o modelo GARCH ao incluir a variÃ¢ncia condicional (ou seu desvio padrÃ£o) na equaÃ§Ã£o da mÃ©dia condicional:

$$r_t = \mu + \theta \sigma_t^2 + \epsilon_t$$
$$\sigma_t^2 = \alpha_0 + \alpha_1 r_{t-1}^2 + \beta \sigma_{t-1}^2$$

onde $\theta$ Ã© o coeficiente que mede o efeito da variÃ¢ncia condicional na mÃ©dia condicional.

*Proof strategy:* A estimaÃ§Ã£o do modelo GARCH-M Ã© semelhante Ã  do modelo GARCH padrÃ£o, geralmente via mÃ¡xima verossimilhanÃ§a. A interpretaÃ§Ã£o de $\theta$ Ã© que ele captura a relaÃ§Ã£o risco-retorno; um $\theta$ positivo indica que um aumento na volatilidade esperada leva a um aumento no retorno esperado.

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Vamos considerar um modelo GARCH(1,1) com os seguintes parÃ¢metros estimados:
>
> $\alpha_0 = 0.00001$
>
> $\alpha_1 = 0.05$
>
> $\beta = 0.90$
>
> Suponha que o retorno de ontem ($r_{t-1}$) foi 0.02 (2%) e a variÃ¢ncia condicional de ontem ($\sigma_{t-1}^2$) foi 0.00015. Podemos calcular a variÃ¢ncia condicional de hoje ($\sigma_t^2$) da seguinte forma:
>
> $\sigma_t^2 = 0.00001 + 0.05 \cdot (0.02)^2 + 0.90 \cdot 0.00015$
>
> $\sigma_t^2 = 0.00001 + 0.05 \cdot 0.0004 + 0.90 \cdot 0.00015$
>
> $\sigma_t^2 = 0.00001 + 0.00002 + 0.000135$
>
> $\sigma_t^2 = 0.000165$
>
> A volatilidade condicional de hoje Ã© a raiz quadrada da variÃ¢ncia condicional:
>
> $\sigma_t = \sqrt{0.000165} \approx 0.0128$ ou 1.28%.
>
> Agora, considere um modelo GARCH-M onde $\theta = 0.1$, $\mu = 0.0001$. EntÃ£o o retorno esperado hoje Ã©:
> $r_t = 0.0001 + 0.1 * 0.000165 + \epsilon_t$
> $r_t = 0.0001 + 0.0000165 + \epsilon_t$
> $r_t = 0.0001165 + \epsilon_t$
>
> Este exemplo demonstra como o modelo GARCH calcula a volatilidade condicional com base nos retornos anteriores e na volatilidade anterior, e como o modelo GARCH-M incorpora a volatilidade na equaÃ§Ã£o da mÃ©dia do retorno.
>
> ```python
> import numpy as np
>
> # ParÃ¢metros do modelo GARCH(1,1)
> alpha0 = 0.00001
> alpha1 = 0.05
> beta = 0.90
>
> # Retorno e variÃ¢ncia condicional do dia anterior
> r_anterior = 0.02
> sigma2_anterior = 0.00015
>
> # Calcula a variÃ¢ncia condicional atual
> sigma2_atual = alpha0 + alpha1 * (r_anterior**2) + beta * sigma2_anterior
>
> # Calcula a volatilidade condicional atual
> sigma_atual = np.sqrt(sigma2_atual)
>
> print(f"VariÃ¢ncia condicional atual: {sigma2_atual}")
> print(f"Volatilidade condicional atual: {sigma_atual}")
> ```

### 9.3 Modeling Correlations
A correlaÃ§Ã£o Ã© de suma importÃ¢ncia para o risco de portfÃ³lio, ainda mais do que as variÃ¢ncias individuais. Para ilustrar a estimaÃ§Ã£o da correlaÃ§Ã£o, escolhemos duas sÃ©ries: a taxa de cÃ¢mbio dÃ³lar/libra esterlina e a taxa dÃ³lar/marco alemÃ£o.

#### 9.3.1 Moving Averages
O primeiro mÃ©todo Ã© baseado em mÃ©dias mÃ³veis (MAs), usando uma janela fixa de comprimento M. As correlaÃ§Ãµes comeÃ§am baixas, em torno de 0,5, e depois aumentam para 0,9 quando a libra entra no SME. Durante a crise de setembro de 1992, as correlaÃ§Ãµes caem acentuadamente e depois voltam ao padrÃ£o prÃ©-SME.

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Suponha que tenhamos retornos diÃ¡rios para dois ativos, A e B, durante 5 dias:
>
> | Dia | Retorno Ativo A | Retorno Ativo B |
> |-----|-----------------|-----------------|
> | 1   | 0.01            | 0.015           |
> | 2   | -0.02           | -0.025          |
> | 3   | 0.015           | 0.02            |
> | 4   | 0.005           | 0.008           |
> | 5   | -0.01           | -0.012          |
>
> Para calcular a correlaÃ§Ã£o usando uma mÃ©dia mÃ³vel com *M* = 3 dias para o dia 5, precisamos dos retornos dos dias 3, 4 e 5.
>
> Primeiro, calculamos as covariÃ¢ncias para os dias 3, 4 e 5:
>
> $cov(A, B) = \frac{1}{M-1} \sum_{i=1}^{M} (A_i - \bar{A})(B_i - \bar{B})$
>
> Retornos mÃ©dios para A: $\bar{A} = \frac{0.015 + 0.005 - 0.01}{3} = 0.00333$
>
> Retornos mÃ©dios para B: $\bar{B} = \frac{0.02 + 0.008 - 0.012}{3} = 0.00533$
>
> CovariÃ¢ncia:
>
> $cov(A, B) = \frac{1}{2} [(0.015 - 0.00333)(0.02 - 0.00533) + (0.005 - 0.00333)(0.008 - 0.00533) + (-0.01 - 0.00333)(-0.012 - 0.00533)]$
>
> $cov(A, B) = \frac{1}{2} [(0.01167)(0.01467) + (0.00167)(0.00267) + (-0.01333)(-0.01733)]$
>
> $cov(A, B) = \frac{1}{2} [0.0001712 + 0.0000045 + 0.0002310] = \frac{1}{2} [0.0004067] = 0.00020335$
>
> Agora, calculamos os desvios padrÃ£o para A e B usando a mesma janela:
>
> $\sigma_A = \sqrt{\frac{1}{2} [(0.015 - 0.00333)^2 + (0.005 - 0.00333)^2 + (-0.01 - 0.00333)^2]} = \sqrt{\frac{1}{2} [0.0001362 + 0.0000028 + 0.0001777]} = \sqrt{0.00015835} \approx 0.01258$
>
> $\sigma_B = \sqrt{\frac{1}{2} [(0.02 - 0.00533)^2 + (0.008 - 0.00533)^2 + (-0.012 - 0.00533)^2]} = \sqrt{\frac{1}{2} [0.0002152 + 0.0000035 + 0.0003003]} = \sqrt{0.0002595} \approx 0.01611$
>
> Finalmente, a correlaÃ§Ã£o Ã©:
>
> $\rho_{A, B} = \frac{cov(A, B)}{\sigma_A \cdot \sigma_B} = \frac{0.00020335}{0.01258 \cdot 0.01611} = \frac{0.00020335}{0.00020266} \approx 1.003$
>
> Neste exemplo, a correlaÃ§Ã£o calculada Ã© ligeiramente superior a 1, o que pode ser devido a erros de arredondamento nos cÃ¡lculos. Em cenÃ¡rios prÃ¡ticos, Ã© essencial usar software estatÃ­stico que possa realizar esses cÃ¡lculos com maior precisÃ£o.

#### 9.3.2 GARCH
Em teoria, a estimativa GARCH poderia ser estendida a uma estrutura multivariada. O problema Ã© que o nÃºmero de parÃ¢metros a estimar aumenta exponencialmente com o nÃºmero de sÃ©ries.

Para mitigar o problema do aumento exponencial de parÃ¢metros nos modelos GARCH multivariados, pode-se impor restriÃ§Ãµes na estrutura da matriz de covariÃ¢ncia condicional.

**Teorema 4** (Modelo DCC - Dynamic Conditional Correlation): O modelo DCC Ã© uma abordagem para modelar correlaÃ§Ãµes dinÃ¢micas que reduz o nÃºmero de parÃ¢metros ao modelar as correlaÃ§Ãµes diretamente, em vez de modelar as covariÃ¢ncias.

*Proof strategy:* No modelo DCC, a matriz de covariÃ¢ncia condicional Ã© decomposta em desvios padrÃµes condicionais e uma matriz de correlaÃ§Ã£o condicional. Os desvios padrÃµes condicionais sÃ£o modelados usando modelos GARCH univariados, enquanto a matriz de correlaÃ§Ã£o condicional Ã© modelada usando um processo dinÃ¢mico que depende de parÃ¢metros relativamente poucos. Isso torna o modelo DCC mais tratÃ¡vel para portfÃ³lios de ativos maiores.

#### 9.3.3 Exponential Averages
Aqui brilha a simplicidade da abordagem RiskMetrics. As covariÃ¢ncias sÃ£o estimadas, assim como as variÃ¢ncias, usando um esquema de ponderaÃ§Ã£o exponencial, isto Ã©,

$$h_{12,t} = \lambda h_{12,t-1} + (1 âˆ’ \lambda) r_{1,t-1} r_{2,t-1} $$

Como antes, o fator de decaimento Ã© arbitrariamente definido como 0,94 para dados diÃ¡rios e 0,97 para dados mensais. A correlaÃ§Ã£o condicional entÃ£o Ã©

Para refinar a estimativa da correlaÃ§Ã£o condicional usando mÃ©dias exponenciais, podemos introduzir um ajuste para evitar valores extremos.

**Teorema 5** (CorreÃ§Ã£o para CorrelaÃ§Ãµes Extremas): Para evitar que a correlaÃ§Ã£o condicional estimada atinja valores extremos (prÃ³ximos de +1 ou -1), podemos aplicar uma transformaÃ§Ã£o que comprima a correlaÃ§Ã£o em direÃ§Ã£o a zero. Uma transformaÃ§Ã£o comum Ã©:

$$\rho_{12,t}^* = \tanh(\omega \cdot \rho_{12,t})$$

onde $\rho_{12,t}$ Ã© a correlaÃ§Ã£o condicional estimada via mÃ©dias exponenciais, $\rho_{12,t}^*$ Ã© a correlaÃ§Ã£o ajustada, e $\omega$ Ã© um parÃ¢metro que controla a intensidade da compressÃ£o.

*Proof strategy:* A funÃ§Ã£o tangente hiperbÃ³lica ($\tanh$) mapeia qualquer valor real para o intervalo (-1, 1), garantindo que a correlaÃ§Ã£o ajustada permaneÃ§a dentro dos limites vÃ¡lidos. Ajustar o parÃ¢metro $\omega$ permite controlar o quÃ£o fortemente a correlaÃ§Ã£o Ã© comprimida em direÃ§Ã£o a zero, mitigando o impacto de valores extremos que podem surgir de ruÃ­do nos dados.

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Suponha que a covariÃ¢ncia condicional estimada no dia *t-1* seja $h_{12,t-1} = 0.00015$, e os retornos no dia *t-1* para os ativos 1 e 2 sejam $r_{1,t-1} = 0.01$ e $r_{2,t-1} = 0.012$, respectivamente. Usando um fator de decaimento $\lambda = 0.94$, podemos calcular a covariÃ¢ncia condicional para o dia *t*:
>
> $h_{12,t} = 0.94 \cdot 0.00015 + (1 - 0.94) \cdot (0.01 \cdot 0.012)$
>
> $h_{12,t} = 0.94 \cdot 0.00015 + 0.06 \cdot 0.00012$
>
> $h_{12,t} = 0.000141 + 0.0000072 = 0.0001482$
>
> Agora, suponha que as variÃ¢ncias condicionais estimadas para os ativos 1 e 2 sejam $h_{1,t} = 0.0002$ e $h_{2,t} = 0.00025$, respectivamente. A correlaÃ§Ã£o condicional estimada Ã©:
>
> $\rho_{12,t} = \frac{h_{12,t}}{\sqrt{h_{1,t} \cdot h_{2,t}}} = \frac{0.0001482}{\sqrt{0.0002 \cdot 0.00025}} = \frac{0.0001482}{\sqrt{0.00000005}} = \frac{0.0001482}{0.0002236} \approx 0.6628$
>
> Agora, aplicamos a correÃ§Ã£o para correlaÃ§Ãµes extremas com $\omega = 0.5$:
>
> $\rho_{12,t}^* = \tanh(0.5 \cdot 0.6628) = \tanh(0.3314) \approx 0.3213$
>
> Neste exemplo, a correÃ§Ã£o com a funÃ§Ã£o tangente hiperbÃ³lica comprime a correlaÃ§Ã£o estimada de 0.6628 para 0.3213, evitando valores extremos e tornando a estimativa mais robusta.
>
> ```python
> import numpy as np
>
> # CovariÃ¢ncia condicional no dia t-1
> h12_anterior = 0.00015
>
> # Retornos no dia t-1 para os ativos 1 e 2
> r1_anterior = 0.01
> r2_anterior = 0.012
>
> # Fator de decaimento
> lambd = 0.94
>
> # Calcula a covariÃ¢ncia condicional atual
> h12_atual = lambd * h12_anterior + (1 - lambd) * (r1_anterior * r2_anterior)
>
> # VariÃ¢ncias condicionais estimadas para os ativos 1 e 2
> h1_atual = 0.0002
> h2_atual = 0.00025
>
> # Calcula a correlaÃ§Ã£o condicional estimada
> rho12_atual = h12_atual / np.sqrt(h1_atual * h2_atual)
>
> # ParÃ¢metro para a correÃ§Ã£o de correlaÃ§Ãµes extremas
> omega = 0.5
>
> # Aplica a correÃ§Ã£o para correlaÃ§Ãµes extremas usando a funÃ§Ã£o tanh
> rho12_corrigido = np.tanh(omega * rho12_atual)
>
> print(f"CovariÃ¢ncia condicional atual: {h12_atual}")
> print(f"CorrelaÃ§Ã£o condicional estimada: {rho12_atual}")
> print(f"CorrelaÃ§Ã£o condicional corrigida: {rho12_corrigido}")
> ```

**Prova da FunÃ§Ã£o $\tanh$ estar no intervalo (-1, 1):**

Provaremos que a funÃ§Ã£o $\tanh(x)$ tem sua imagem contida no intervalo $(-1, 1)$ para todo $x \in \mathbb{R}$.

I.  A funÃ§Ã£o tangente hiperbÃ³lica Ã© definida como $\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}$.

II. Podemos reescrever $\tanh(x)$ como $\tanh(x) = \frac{e^{2x} - 1}{e^{2x} + 1}$.

III. Analisando o limite quando $x$ tende ao infinito: $\lim_{x \to \infty} \tanh(x) = \lim_{x \to \infty} \frac{e^{2x} - 1}{e^{2x} + 1} = 1$.

IV. Analisando o limite quando $x$ tende a menos infinito: $\lim_{x \to -\infty} \tanh(x) = \lim_{x \to -\infty} \frac{e^{2x} - 1}{e^{2x} + 1} = -1$.

V.  Como $e^{2x} > 0$ para todo $x$, entÃ£o $e^{2x} + 1 > e^{2x} - 1$, e portanto $|\frac{e^{2x} - 1}{e^{2x} + 1}| < 1$.

VI. AlÃ©m disso, $\tanh(x)$ Ã© uma funÃ§Ã£o contÃ­nua e monÃ³tona crescente.

VII. Portanto, $-1 < \tanh(x) < 1$ para todo $x \in \mathbb{R}$. $\blacksquare$

### ConclusÃ£o

Em resumo, uma gestÃ£o de risco precisa deve considerar modelagens de volatilidade e correlaÃ§Ãµes, pois Ã© o que de fato afeta o cÃ¡lculo do VAR [^1]. Em perÃ­odos de mudanÃ§as estruturais, o modelo de volatilidade deve dar mais peso aos valores recentes.

### ReferÃªncias
[^1]: PÃ¡gina 219: *â€œThe purpose of this chapter is to present techniques to forecast vari-ation in risk and correlations. Section 9.1 motivates the problem by taking the example of a series that underwent structural changes leading to pre-dictable patterns in volatility.â€*
[^2]: PÃ¡gina 220: *â€œAs an illustration, we will walk through this chapter focusing on the U.S. dollar/British pound ($/BP) exchange rate measured at daily intervals. Movements in the exchange rate are displayed in Figure 9-1. The 1990â€“1994 period was fairly typical, covering narrow trading ranges and wide swings. September 1992 was particularly tumultuous. After vain attempts by the Bank of England to support the pound against the German mark, the pound exited the European Monetary System. There were several days with very large moves. On September 17 alone, the pound fell by 6 percent against the mark and also against the dollar. Hence we can expect interesting patterns in volatility. In particular, the question is whether this structural change led to predictable time variation in risk.â€*
[^3]: PÃ¡gina 221: *â€œOver this period, the average daily volatility was 0.694 percent, which translates into 11.02 percent per annum (using a 252-trading-day adjustment). This risk measure, however, surely was not constant over time. In addition, time variation in risk could explain the fact that the empirical distribution of returns does not quite exactly fit a normal distribution. Figure 9-2 compares the normal approximation with the actual empirical distribution of the $/BP exchange rate. Relative to the normal model, the actual distribution contains more observations in the center and in the tails. These fat tails can be explained by two alternative viewpoints. The first view is that the true distribution is stationary and indeed contains fat tails, in which case a normal approximation is clearly inappropriate. The other view is that the distribution does change through time. As a result, in times of turbulence, a stationary model could view large observations as outliers when they are really drawn from a distribution with temporarily greater dispersion. In practice, both explanations carry some truth. This is why fore-casting variation in risk is particularly fruitful for risk management. Inâ€*
[^4]: PÃ¡gina 222: *â€œA very crude method, but one that is employed widely, is to use a moving window of fixed length for estimating volatility. For instance, a typical length is 20 trading days (about a calendar month) or 60 trading days (about a calendar quarter). Assuming that we observe returns r, over M days, this volatility estimate is constructed from a moving average (MA), that is, 2 =(1/M) M ÏƒÎµ Î£ i-1 2 r ti (9.1) Here we focus on raw returns instead of returns around the mean. This is so because for most financial series, ignoring expected returns over very short time intervals makes little difference for volatility estimates. Each day, the forecast is updated by adding information from the preceding day and dropping information from (M + 1) days ago. All weights on past returns are equal and set to (1/M). Figure 9-3 displays 20- and 60-day moving averages for our $/BP rate. While simple to implement, this model has serious drawbacks. First, it ignores the dynamic ordering of observations. Recent information receives the same weight as older observations in the window that may no longer be relevant. Also, if there was a large return M days ago, dropping this return as the window moves 1 day forward will affect the volatility estimate sub-stantially. For instance, there was a 3 percent drop on September 17, 1992. This observation will increase the MA forecast immediately, which cor-rectly reflects the higher volatility. The MA(20), however, reverts to a lower value after 20 days; the MA(60) reverts to a lower value after 60 days. As a result, moving-average measures of volatility tend to look like plateaus of width M when plotted against time. The subsequent drop, however, is totally an artifact of the window length. This has been called the ghosting feature because the MA measure changes for no apparent reason.â€*
[^5]: PÃ¡gina 223: *â€œThis is why volatility estimation has moved toward models that put more weight on recent information. The first such model was the generalized autoregressive conditional heteroskedastic (GARCH) model proposed by Engle (1982) and Bollerslev (1986) (see Box 9-1). Heteroskedastic refers to the fact that variances are changing. The GARCH model assumes that the variance of returns follows a pre-dictable process. The conditional variance depends on the latest innovation but also on the previous conditional variance. Define h, as the conditional variance, using information up to time t 1, and r1 as the previous day's return. The simplest such model is the GARCH(1,1) process, that is, h, = a + arÂ² + áºžh,-1 1 (9.2)â€*
[^6]: PÃ¡gina 2249.  2.  Volatility Asymmetry

One stylized fact not captured by GARCH models is the asymmetry in the response of volatility to positive and negative return shocks. Empirical evidence suggests that negative return shocks (bad news) tend to increase volatility more than positive return shocks (good news) of the same magnitude. This phenomenon is known as the leverage effect or volatility asymmetry. Several extensions of the GARCH model have been proposed to capture this asymmetry, including the EGARCH, GJR-GARCH, and TGARCH models.

10. 3.  EGARCH Model

The Exponential GARCH (EGARCH) model, introduced by Nelson (1991), captures the asymmetry in volatility by modeling the logarithm of the conditional variance as a function of both the magnitude and sign of the lagged residuals. The EGARCH(1,1) model is specified as:
$$log(h_t) = \alpha_0 + \alpha_1 \frac{\epsilon_{t-1}}{\sqrt{h_{t-1}}} + \gamma \frac{\epsilon_{t-1}}{\sqrt{h_{t-1}}} + \beta log(h_{t-1})$$
where:
- $h_t$ is the conditional variance at time t,
- $\epsilon_{t-1}$ is the residual at time t-1,
- $\alpha_0$, $\alpha_1$, $\gamma$, and $\beta$ are parameters to be estimated.

The key feature of the EGARCH model is the inclusion of the term $\gamma \frac{\epsilon_{t-1}}{\sqrt{h_{t-1}}}$, which allows for asymmetric effects. If $\gamma < 0$, negative shocks ($\epsilon_{t-1} < 0$) will have a larger impact on volatility than positive shocks of the same magnitude.

11. 4.  GJR-GARCH Model

The GJR-GARCH model, named after Glosten, Jagannathan, and Runkle (1993), is another extension of the GARCH model that captures volatility asymmetry. The GJR-GARCH(1,1) model is given by:
$$h_t = \alpha_0 + \alpha_1 \epsilon_{t-1}^2 + \gamma \epsilon_{t-1}^2 I_{t-1} + \beta h_{t-1}$$
where:
- $h_t$ is the conditional variance at time t,
- $\epsilon_{t-1}$ is the residual at time t-1,
- $\alpha_0$, $\alpha_1$, $\gamma$, and $\beta$ are parameters to be estimated,
- $I_{t-1}$ is an indicator function that equals 1 if $\epsilon_{t-1} < 0$ and 0 otherwise.

In the GJR-GARCH model, the coefficient $\gamma$ captures the asymmetric effect. If $\gamma > 0$, negative shocks will have a larger impact on volatility than positive shocks.

12. 5.  TGARCH Model

The Threshold GARCH (TGARCH) model is similar to the GJR-GARCH model in that it uses an indicator function to capture asymmetric effects. The TGARCH(1,1) model is specified as:
$$\sqrt{h_t} = \alpha_0 + \alpha_1 |\epsilon_{t-1}| + \gamma \epsilon_{t-1} I_{t-1} + \beta \sqrt{h_{t-1}}$$
where:
- $h_t$ is the conditional variance at time t,
- $\epsilon_{t-1}$ is the residual at time t-1,
- $\alpha_0$, $\alpha_1$, $\gamma$, and $\beta$ are parameters to be estimated,
- $I_{t-1}$ is an indicator function that equals 1 if $\epsilon_{t-1} < 0$ and 0 otherwise.

In the TGARCH model, the coefficient $\gamma$ captures the asymmetric effect. If $\gamma \neq 0$, negative and positive shocks will have different impacts on volatility.

<!-- END -->